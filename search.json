[{"title":"转载：为什么大部分人做不了架构师？","url":"/2023/08/07/转载：为什么大部分人做不了架构师？/","content":"\n## 基本概念与设计方法\n\n在讲解架构思想之前，我们先统一介绍一下基本概念的含义，避免每个人对系统、框架、架构这些名词的理解不一致导致的误解。下面是《从0开始学架构》作者对每个名词的定义。其作用域仅限本文范畴，不用纠结其在其他上下文中的意义。\n\n> 系统：系统泛指由一群有关联的个体组成，根据某种规则运作，能完成个别元件不能单独完成的工作的群体。 子系统：子系统也是由一群有关联的个体所组成的系统，多半会是更大系统中的一部分。模块：从业务逻辑的角度来拆分系统后，得到的单元就是“模块”。划分模块的主要目的是职责分离。组件：从物理部署的角度来拆分系统后，得到的单元就是“组件”。划分组件的主要目的是单元复用。框架：是一整套开发规范，是提供基础功能的产品。架构：关注的是结构，是某一套开发规范下的具体落地方案，包括各个模块之间的组合关系以及它们协同起来完成功能的运作规则。\n\n\n\n由以上定义可见，所谓架构，是为了解决软件系统的某个复杂度带来的具体问题，将模块和组件以某种方式有机组合，基于某个具体的框架实现后的一种落地方案。\n\n而讨论架构时，往往只讨论到系统与子系统这个顶层的架构。\n\n可见，要进行架构选型，首先应该知道自己要解决的业务和系统复杂点在哪里，是作为秒杀系统有瞬间高并发，还是作为金融科技系统有极高的数据一致性和可用性要求等。\n\n**一般来说，系统的复杂度来源有以下几个方面：**\n\n- **高性能**\n\n如果业务的访问频率或实时性要求较高，则会对系统提出高性能的要求。\n\n如果是单机系统，需要利用多进程、多线程技术。\n\n如果是集群系统，则还涉及任务拆分、分配与调度，多机器状态管理，机器间通信，当单机性能达到瓶颈后，即使继续加机器也无法继续提升性能，还是要针对单个子任务进行性能提升。\n\n- **高可用**\n\n如果业务的可用性要求较高，也会带来高可用方面的复杂度。高可用又分为计算高可用和存储高可用。\n\n针对计算高可用，可以采用主备（冷备、温备、热备）、多主的方式来冗余计算能力，但会增加成本、可维护性方面的复杂度。\n\n针对存储高可用，同样是增加机器来冗余，但这也会带来多机器导致的数据不一致问题，如遇到延迟、中断、故障等情况。难点在于怎么减少数据不一致对业务的影响。\n\n既然主要解决思路是增加机器来做冗余，那么就涉及到了状态决策的问题。即如果判断当前主机的状态是正常还是异常，以及异常了要如何采取行动（比如切换哪台做主机）。\n\n对主机状态的判断，多采用机器信息采集或请求响应情况分析等手段，但又会产生采集信息这一条通信链路本身是否正常的问题，下文会具体展开讨论。事实上，状态决策本质上不可能做到完全正确。\n\n**而对于决策方式，有以下几种方式：**\n\n> 独裁式：存在一个独立的决策主体来收集信息并决定主机，这样的策略不会混乱，但这个主体本身存在单点问题。 协商式：两台备机通过事先指定的规则来协商决策出主机，规则虽然简单方便，但是如果两台备机之间的协商链路中断了，决策起来就会很困难，比如有网络延迟且机器未故障、网络中断且机器未故障、网络中断其机器已故障，多种情况需要处理。民主式：如果有多台备机，可以使用选举算法来投票出主机，比如 Paxos 就是一种选举算法，这种算法大多数都采取多数取胜的策略，算法本身较为复杂，且如果像协商式一样出现连接中断，就会脑裂，不同部分会各自决策出不同结果，需要规避。\n\n\n\n- **可扩展性**\n\n众所周知在互联网行业只有变化才是永远不变的，而开发一个系统基本都不是一蹴而就的，那应该如何为系统的未来可能性进行设计来保持可扩展性呢？\n\n这里首先要明确的一个观点就是，在做系统设计时，既不可能完全不考虑可扩展性，也不可能每个设计点都考虑可扩展性，前者很明显，后者则是为了避免舍本逐末，为了扩展而扩展，实际上可能会为不存在的预测花费过多的精力。\n\n那么怎么考虑系统的未来可能性从而做出相应的可扩展性设计呢？这里作者给出了一个方法：只预测两年内可能的变化，不要试图预测五年乃至十年的变化。因为对于变化快的行业来说，预测两年已经足够远了，再多就可能计划赶不上变化。而对变化慢的行业，则预测的意义更是不大。\n\n要应对变化，主要是将变与不变分隔开来。\n\n这里可以针对业务，提炼变化层和稳定层，通过变化层将变化隔离。比如通过一个 DAO 服务来对接各种变化的存储载体，但是上层稳定的逻辑不用知晓当前采用何种存储，只需按照固定的接口访问 DAO 即可获取数据。\n\n也可以将一些实现细节剥离开来，提炼出抽象层，仅在实现层去封装变化。比如面对运营上经常变化的业务规则，可以提炼出一个规则引擎来实现核心的抽象逻辑，而具体的规则实现则可以按需增加。\n\n如果是面对一个旧系统的维护，接到了新的重复性需求，而旧系统并不支持较好的可扩展性，这时是否需要花费时间精力去重构呢？作者也提出了《重构》一书中提到的原则：事不过三，三则重构。\n\n简而言之，不要一开始就考虑复杂的做法去满足可扩展性，而是等到第三次遇到类似的实现时再来重构，重构的时候采取上述说的隔离或者封装的方案。\n\n这一原则对新系统开发也是适用的。总而言之就是，不要为难以预测的未来去过度设计，为明确的未来保留适量的可扩展性即可。\n\n- **低成本**\n\n上面说的高性能、高可用都需要增加机器，带来的是成本的增加，而很多时候研发的预算是有限的。换句话说，低成本往往并不是架构设计的首要目标，而是设计架构时的约束限制。\n\n那如何在有限的成本下满足复杂性要求呢？往往只有“创新”才能达到低成本的目标。举几个例子：\n\n> NoSQL 的出现是为解决关系型数据库应对高并发的问题。 全文搜索引擎的出现是为解决数据库 like 搜索效率的问题。Hadoop 的出现是为解决文件系统无法应对海量数据存储与计算的问题。Facebook 的 HipHop PHP 和 HHVM 的出现是为解决 PHP 运行低效问题。新浪微博引入 SSD Cache 做 L2 缓存是为解决 Redis 高成本、容量小、穿透 DB 的问题。Linkedin 引入 Kafka 是为解决海量事件问题。\n\n\n\n上述案例都是为了在不显著增加成本的前提下，实现系统的目标。\n\n这里还要说明的是，创造新技术的复杂度本身就是很高的，因此一般中小公司基本都是靠引入现有的成熟新技术来达到低成本的目标；而大公司才更有可能自己去创造新的技术来达到低成本的目标，因为大公司才有足够的资源、技术和时间去创造新技术。\n\n- **安全**\n\n安全是一个研发人员很熟悉的目标，从整体来说，安全包含两方面：功能安全和架构安全。\n\n功能安全是为了“防小偷”，即避免系统因安全漏洞而被窃取数据，如 SQL 注入。常见的安全漏洞已经有很多框架支持，所以更建议利用现有框架的安全能力，来避免重复开发，也避免因自身考虑不够全面而遗漏。在此基础上，仍需持续攻防来完善自身的安全。\n\n架构安全是为了“防强盗”，即避免系统被暴力攻击导致系统故障，比如 DDOS 攻击。这里一方面只能通过防火墙集运营商或云服务商的大带宽和流量清洗的能力进行防范，另一方面也需要做好攻击发现与干预、恢复的能力。\n\n- **规模**\n\n架构师在宣讲时往往会先说自己任职和设计过的大型公司的架构，这是因为当系统的规模达到一定程度后，复杂度会发生质的变化，即所谓量变引起质变。\n\n这个量，体现在访问量、功能数量及数据量上。\n\n访问量映射到对高性能的要求。功能数量需要视具体业务会带来不同的复杂度。而数据量带来的收集、加工、存储、分析方面的挑战，现有的方案基本都是基于 Google 的三篇大数据论文的理论：\n\n> Google File System 是大数据文件存储的技术理论。Google Bigtable 是列式数据存储的技术理论。Google MapReduce 是大数据运算的技术理论。\n\n经过上面的分析可以看到，复杂度来源很多，想要一一应对，似乎会得到一个复杂无比的架构，但对于架构设计来说，其实刚开始设计时越简单越好，只要能解决问题，就可以从简单开始再慢慢去演化，对应的是下面三条原则：\n\n> 合适原则：不需要一开始就挑选业界领先的架构，它也许优秀，但可能不那么适合自己，比如有很多目前用不到的能力或者大大超出诉求从而增加很多成本。其实更需要考虑的是合理地将资源整合在一起发挥出最大功效，并能够快速落地。简单原则：有时候为了显示出自身的能力，往往会在一开始就将系统设计得非常复杂，复杂可能代表着先进，但更可能代表着“问题”，组件越多，就越可能出故障，越可能影响关联着的组件，定位问题也更加困难。其实只要能够解决诉求即可。演化原则：不要妄想一步到位，没有人可以准确预测未来所有发展，软件不像建筑，变化才是主题。架构的设计应该先满足业务需求，适当的预留扩展性，然后在未来的业务发展中再不断地迭代，保留有限的设计，修复缺陷，改正错误，去除无用部分。这也是重构、重写的价值所在。\n\n即使是 QQ、淘宝这种如今已经非常复杂的系统，刚开始时也只是一个简单的系统，甚至淘宝都是直接买来的系统，随着业务发展也只是先加服务器、引入一些组件解决性能问题，直到达到瓶颈才去重构重写，重新在新的复杂度要求下设计新的架构。\n\n明确了设计原则后，当面对一个具体的业务，我们可以按照如下步骤进行架构设计：\n\n> 识别复杂度：无论是新设计一个系统还是接手一个混乱的系统，第一步都是先将主要的复杂度问题列出来，然后根据业务、技术、团队等综合情况进行排序，优先解决当前面临的最主要的复杂度问题。复杂度的主要来源上文已经说过，可以按照经验或者排查法进行分析。方案对比：先看看业界是否有类似的业务，了解他们是怎么解决问题的，然后提出3~5个备选方案，不要只考虑做一个最优秀的方案，一个人的认知范围常常是有限的，逼自己多思考几个方案可以有效规避因为思维狭隘导致的局限性，当然也不要过多，不用给出非常详细的方案，太消耗精力。备选方案的差异要比较明显，才有扩宽思路和对比的价值。设计详细方案：当多个方案对比得出最终选择后，就可以对目标方案进行详细的设计，关键细节需要比较深入，如果方案本身很复杂，也可以采取分步骤、分阶段、分系统的实现方式来降低实现复杂度。当方案非常庞大的时候，可以汇集一个团队的智慧和经验来共同设计，防止因架构师的思维盲区导致问题。\n\n## 高性能架构模式\n\n### 存储高性能\n\n互联网业务大多是数据密集型的业务，其对性能的压力也常常来自于海量用户对数据的高频读写压力上。因此解决高性能问题，首先要解决数据读写的存储高性能问题。\n\n- **读写分离**\n\n在大多数业务中，用户查询和修改数据的频率是不同的，甚至是差别很大的，大部分情况下都是读多写少的，因此可以将对数据的读和写操作分开对待，对压力更大的读操作提供额外的机器分担压力，这就是读写分离。\n\n读写分离的基本实现是搭建数据库的主从集群，根据需要提供一主一从或一主多从。\n\n注意是主从不是主备，从和备的差别在于从机是要干活的。\n\n通常在读多写少的情况下，主机负责读写操作，从机只负责读操作，负责帮主机分担读操作的压力。而数据会通过复制机制（如全同步、半同步、异步）同步到从机，每台服务器都有所有业务数据。\n\n既然有数据的同步，就一定存在复制延迟导致的从机数据不一致问题，针对这个问题有几种常见的解法，如：\n\n> 写操作后同一用户一段时间内的读操作都发给主机，避免数据还没同步到从机，但这个逻辑容易遗漏。读从机失败后再读一次主机，该方法只能解决新数据未同步的问题，无法解决旧数据修改的问题（不会读取失败），且二次读取主机会给主机带来负担，容易被针对性攻击。关键读写操作全部走主机，从机仅负责非关键链路的读，该方法是基于保障关键业务的思路。\n\n除了数据同步的问题之外，只要涉及主从机同时支持业务访问的，就一定需要制定请求分配的机制。上面说的几个问题解法也涉及了一些分配机制的细节。具体到分配机制的实现来说，有两种思路：\n\n> 程序代码封装：实现简单，可对业务定制化，但每个语言都要自己实现一次，且很难做到同步修改，因此适合小团队。中间件封装：独立出一套系统管理读写的分配，对业务透明，兼容 SQL 协议，业务服务器就无需做额外修改适配。需要支持多语言、完整的 SQL 语法，涉及很多细节，容易出 BUG，且本身是个单点，需要特别保障性能和可用性，因此适合大公司。\n\n- **分库分表**\n\n除了高频访问的压力，当数据量大了以后，也会带来数据库存储方面的压力。此时就需要考虑分库分表的问题。分库分表既可以缓解访问的压力，也可以分散存储的压力。\n\n先说分库，所谓分库，就是指业务按照功能、模块、领域等不同，将数据分散存储到不同的数据库实例中。\n\n比如原本是一个 MySQL 数据库实例，在库中按照不同业务建了多张表，大体可以归类为 A、B 两个领域的数据。现在新建一个库，将原库中 A 领域的数据迁移到新的库中存储，还是按需建表，而 B 领域的数据继续留在原库中。\n\n分库一方面可以缓解访问和存储的压力，另一方面也可以增加抗风险能力，当一个库出问题后，另一个库中的数据并不会受到影响，而且还能分开管理权限。\n\n但分库也会带来一些问题：原本同一个库中的不同表可以方便地进行联表查询，分库后则会变得很复杂。由于数据在不同的库中，当要操作两个库中的数据时，无法使用事务操作，一致性也变得更难以保障。而且当增加备库来保障可用性的时候，成本是成倍增加的。\n\n基于以上问题，初创的业务并不建议在一开始就做这种拆分，会增加很多开发时的成本和复杂度，拖慢业务的节奏。\n\n再说分表。所谓分表，就是将原本存储在一张表里的数据，按照不同的维度，拆分成多张表来存储。\n\n按照诉求与业务的特性不同，可以采用垂直分表或水平分表的方式。\n\n垂直分表相当于垂直地给原表切了一刀，把不同的字段拆分到不同的子表中，这样拆分后，原本访问一张表可以获取的所有字段，现在则需要访问不同的表获取。\n\n垂直分表适合将表中某些不常用又占了大量空间的列（字段）拆分出去，可以提升访问常用字段的性能。\n\n但相应的，当真的需要的字段处于不同表中时，或者要新增记录存储所有字段数据时，要操作的表变多了。\n\n水平分表相当于横着给原表切了一刀，那么原表中的记录会被分散存储到不同的子表中，但是每张子表的字段都是全部字段。\n\n水平分表适合表的量级很大以至影响访问性能的场景，何时该拆分并没有绝对的指标，一般记录数超过千万时就需要警觉了。\n\n不同于垂直分表依然能访问到所有记录，水平分表后无法再在一张表中访问所有数据了，因此很多查询操作会受到影响，比如 join 操作就需要多次查询后合并结果，count 操作也需要计算多表的结果后相加，如果经常用到 count 的总数，可以额外维护一个总数表去更新，但也会带来数据一致性的问题。\n\n值得特别提出的是范围查询，原本的一张表可以通过范围查询到的数据，分表后也需要多次查询后合并数据，如果是业务经常用到的范围查询，那建议干脆就按照这种方式来分表，这也是分表的路由方式之一：范围路由。\n\n所谓路由方式是指：分表后当新插入记录时，如何判断该往哪张表插入。常用的插入方式有以下三种：\n\n> 范围路由：按照时间范围、ID 范围或者其他业务常用范围字段路由。这种方式在扩充新的表时比较方便，直接加表给新范围的数据插入即可，但是数量和冷热分布可能是不均匀的。 Hash 路由：根据 Hash 运算来路由新记录插入的表，这种方式需要提前就规划好分多少张表，才能决定 Hash 运算方式。但表数量其实很难预估，导致未来需要扩充新表时很麻烦，但数据在不同表中的分布是比较均匀的。配置路由：新增一个路由表来记录数据 id 和表 id 的映射，按照自定义的方式随时修改映射规则，设计简单，扩充新表也很方便。但每次操作表都需要额外操作一次路由表，其本身也成为了单点瓶颈。\n\n无论是垂直分表还是水平分表，单表切分为多表后，新的表即使在同一个数据库服务器中，也可能带来可观的性能提升，如果性能能够满足业务要求，可以不拆分到多台数据库服务器，毕竟分库也会引入很多复杂性的问题；如果单表拆分为多表后，单台服务器依然无法满足性能要求，那就不得不再次进行业务分库的设计了。\n\n- **NoSQL 数据库**\n\n上面发分库分表讨论的都是关系型数据库的优化方案，但关系型数据库也有其无法规避的缺点，比如无法直接存储某种结构化的数据、扩展表结构时会锁表影响线上性能、大数据场景下 I/O 较高、全文搜索的功能比较弱等。\n\n基于这些缺点，也有很多新的数据库框架被创造出来，解决其某方面的问题。\n\n比如以 Redis 为代表的的 KV 存储，可以解决无法存储结构化数据的问题；以 MongoDB 为代表的的文档数据库可以解决扩展表结构被强 Schema 约束的问题；以 HBase 为代表的的列式数据库可以解决大数据场景下的 I/O 问题；以 ES 为代表的的全文搜索引擎可以解决全文检索效率的问题等。\n\n这些数据库统称为 NoSQL 数据库，但 NoSQL 并不是全都不能写 SQL，而是 Not Only SQL 的意思。\n\nNoSQL 数据库除了聚焦于解决某方面的问题以外也会有其自身的缺点，比如 Redis 没有支持完整的 ACID 事务、列式存储在更新一条记录的多字段时性能较差等。因此并不是说使用了 NoSQL 就能一劳永逸，更多的是按需取用，解决业务面临的问题。\n\n关于 NoSQL 的更多了解，推荐大家可以看看《NoSQL 精粹》这本书。\n\n- **缓存**\n\n如果 NoSQL 也解决不了业务的高性能诉求，那么或许你需要加点**缓存**。\n\n缓存最直接的概念就是把常用的数据存在内存中，当业务请求来查询的时候直接从内存中拿出来，不用重新去数据库中按条件查询，也就省去了大量的磁盘 IO 时间。\n\n一般来说缓存都是通过 Key-Value 的方式存储在内存中，根据存储的位置，分为单机缓存和集中式缓存。单机缓存就是存在自身服务器所在的机器上，那么势必会有不同机器数据可能不一致，或者重复缓存的问题，要解决可以使用查询内容做路由来保障同一记录始终到同一台机器上查询缓存。集中式缓存则是所有服务器都去一个地方查缓存，会增加一些调用时间。\n\n缓存可以提升性能是很好理解的，但缓存同样有着它的问题需要应对或规避。数据时效性是最容易想到的问题，但也可以靠同时更新缓存的策略来保障数据的时效性，除此之外还有其他几个常见的问题。\n\n如果某条数据不存在，缓存中势必查不到对应的 KEY，从而就会请求数据库确认是否有新增加这条数据，如果始终没有这条数据，而客户端又反复频繁地查询这条数据，就会变相地对数据库造成很大的压力，换句话说，缓存失去了保护作用，请求穿透到了数据库，这称为**缓存穿透**。\n\n应对缓存穿透，最好的手段就是把“空值”这一情况也缓存下来，当客户端下次再查询时，发现缓存中说明了该数据是空值，则不会再问询数据库。但也要注意如果真的有对应数据写入了数据库，应当能及时清除”空值“缓存。\n\n为了保障缓存的数据及时更新，常常都会根据业务特性设置一个缓存过期时间，在缓存过期后，到再次生成期间，如果出现大量的查询，会导致请求都传递到数据库，而且会多次重复生成缓存，甚至可能拖垮整个系统，这就叫**缓存雪崩**，和缓存穿透的区别在于，穿透是面对空值的情况，而雪崩是由于缓存重新生成的间隔期大量请求产生的连锁效应。\n\n既然是缓存更新时重复生成所导致的问题，那么一种解法就是在缓存重新生成前给这个 KEY 加锁，加锁期间出现的请求都等待或返回默认值，而不去都尝试重新生成缓存。\n\n另一种方法是干脆不要由客户端请求来触发缓存更新，而是由后台脚本统一更新，同样可以规避重复请求导致的重复生成。但是这就失去了只缓存热点数据的能力，如果缓存因空间问题被清除了，也会因为后台没及时更新导致查不到缓存数据，这就会要求更复杂的后台更新策略，比如主动查询缓存有效性、缓存被删后通知后台主动更新等。\n\n虽说在有限的内存空间内最好缓存热点数据，但如果数据过热，比如微博的超级热搜，也会导致缓存服务器压力过大而崩溃，称之为**缓存热点**问题。\n\n可以复制多份缓存副本，来分散缓存服务器的单机压力，毕竟堆机器是最简单有效。此处也要注意，多个缓存副本不要设置相同的缓存过期时间，否则多处缓存同时过期，并同时更新，也容易引起缓存雪崩，应该设置一个时间范围内的随机值来更新缓存。\n\n### 计算高性能\n\n讲完存储高性能，再讲**计算高性能**，计算性能的优化可以先从单机性能优化开始，多进程、多线程、IO 多路复用、异步 IO 等都存在很多可以优化的地方，但基本系统或框架已经提供了基本的优化能力，只需使用即可。\n\n- **负载均衡**\n\n如果单机的性能优化已经到了瓶颈，无法应对业务的增长，就会开始增加服务器，构建集群。对于计算来说，每一台服务器接到同样的输入，都应该返回同样的输出，当服务器从单台变成多台之后，就会面临请求来了要由哪一台服务器处理的问题，我们当然希望由当前比较空闲的服务器去处理新的请求，这里对请求任务的处理分配问题，就叫**负载均衡**。\n\n负载均衡的策略，从分类上来说，可以分为三类：\n\n> DNS 负载均衡：通过 DNS 解析，来实现地理级别的均衡，其成本低，分配策略很简单，可以就近访问来提升访问速度，但 DNS 的缓存时间长，由于更新不及时所以无法快速调整，且控制权在各域名商下，且无法根据后端服务器的状态来决定分配策略。 硬件负载均衡：直接通过硬件设备来实现负载均衡，类似路由器路由，功能和性能都很强大，可以做到百万并发，也很稳定，支持安全防护能力，但是同样无法根据后端服务器状态进行策略调整，且价格昂贵。软件负载均衡：通过软件逻辑实现，比如 nginx，比较灵活，成本低，但是性能一般，功能也不如硬件强大。\n\n\n\n一般来说，DNS 负载均衡用于实现地理级别的负载均衡；硬件负载均衡用于实现集群级别的负载均衡；软件负载均衡用于实现机器级别的负载均衡。\n\n所以部署起来可以按照这三层去部署，第一层通过 DNS 将请求分发到北京、上海、深圳的机房；第二层通过硬件负载均衡将请求分发到当地三个集群中的一个；第三层通过软件策略将请求分发到具体的某台服务器去响应业务。\n\n就负载均衡算法来说，多是我们很熟悉的算法，如轮询、加权轮询、负载最低优先、性能最优优先、Hash 分配等，各有特点，按需采用即可。\n\n## 高可用架构模式\n\n### 理论方式\n\n- **CAP 与 BASE**\n\n在说高可用之前，先来说说 **CAP 理论**，即：\n\n在一个分布式系统（指互相连接并共享数据的节点的集合）中，当涉及读写操作时，只能保证一致性（Consistence）、可用性（Availability）、分区容错性（Partition Tolerance）三者中的两个，另外一个必须被牺牲。\n\n大家可能都知道 CAP 定理是什么，但大家可能不知道，CAP 定理的作者（Seth Gilbert & Nancy Lynch）其实并没有详细解释 CAP 三个单词的具体含义，目前大家熟悉的解释其实是另一个人（Robert Greiner）给出的。而且他还给出了两版有所差异的解释。\n\n书中第二版解释算是对第一版解释的加强，他要加强的点主要是：\n\n> CAP 描述的分布式系统，是互相连结并共享数据的节点的集合。因为其实并不是所有的分布式系统都会互连和共享数据。CAP 理论是在涉及读写操作的场景下的理论，而不是分布式系统的所有功能。一致性只需要保障客户端读操作能读到最新的写操作结果，并不要求时时刻刻分布式系统的数据都是一致的，这是不现实的，只要保障客户读到的一致即可。可用性要求非故障的节点在合理的时间内能返回合理的响应，所谓合理是指非错误、非超时，即使数据不是最新的数据，也是合理的“旧数据”，是符合可用性的。分区容错性要求网络分区后系统能继续履行职责，不仅仅要求系统不宕机，还要求能发挥作用，能处理业务逻辑。比如接口直接返回错误其实也代表系统在运行，但却没有履行职责。\n\n\n\n在分布式系统下，P（分区容忍）是必须选择的，否则当分区后系统无法履行职责时，为了保障 C（一致性），就要拒绝写入数据，也就是不可用了。\n\n在此基础上，其实我们能选择的只有 C+P 或者 A+P，根据业务特性来选择要优先保障一致性还是可用性。\n\n在选择保障策略时，有几个需要注意的点：\n\n> CAP 关注的其实是数据的粒度，而不是整个系统的粒度，因此对于系统内的不同数据（对应不同子业务），其实是可以按照业务特性采取不同的 CAP 策略的。CAP 实际忽略了网络延迟，也就是允许数据复制过程中的短时间不一致，如果某些业务比如金融业务无法容忍这一点，那就只能对单个对象做单点写入，其他节点备份，无法做多点写入。但对于不同的对象，其实可以分库来实现分布式。当没有发生分区现象时，也就是不用考虑 P 时，上述限制就不存在，此时应该考虑如何保障 CA。当发生分区后，牺牲 CAP 的其中一个并不代表什么都不用做，而是应该为分区后的恢复 CA 做准备，比如记录分区期间的日志以供恢复时使用。\n\n伴随 CAP 的一个退而求其次，也更现实的追求，是 BASE 理论，即基本可用，保障核心业务的可用性；软状态，允许系统存在数据不一致的中间状态；最终一致性，一段时间后系统应该达到一致。\n\n- **FMEA 分析法**\n\n要保障高可用，我们该怎么下手呢？俗话说知己知彼才能有的放矢，因此做高可用的前提是了解系统存在怎样的风险，并且还要识别出风险的优先级，先治理更可能发生的、影响更大的风险。说得简单，到底怎么做？业界其实已经提供了排查系统风险的基本方法论，即 FMEA（Failure mode and effects analysis）——故障模式与影响分析。\n\nFMEA 的基本思路是，面对初始的架构设计图，考虑假设其中某个部件发生故障，对系统会造成什么影响，进而判断架构是否需要优化。\n\n具体来说，需要画一张表，按照如下步骤逐个列出：\n\n> 功能点：列出业务流程中的每个功能点。故障模式：量化描述该功能可能发生怎样的故障，比如 MySQL 响应时间超过3秒。故障影响：量化描述该每个故障可能导致的影响，但不用非常精确，比如20%用户无法登录。严重程度：设定标准，给每个影响的严重程度打分。故障原因：对于每个故障，考虑有哪些原因导致该故障。故障概率：对于每个原因，考虑其发生的概率，不用精确，分档打分即可。风险程度：=严重程度 * 故障概率，据此就可以算出风险的处理优先级了，肯定是程度分数越高的越应该优先解决。已有措施、解决措施、后续规划：用于梳理现状，思考未来的改进方案等。\n\n基于上面这套方法论，我们可以有效地对系统的风险进行梳理，找出需要优先解决的风险点，从而提高系统的可用性。\n\n除了 FMEA，其实还有一种应用更广泛的风险分析和治理的理论，即 BCP——业务连续性计划，它是一套基于业务规律的规章流程，保障业务或组织在面对突发状况时其关键业务功能可以持续不中断。\n\n相比 FMEA，BCP 除了评估风险及重要程度，还要求详细地描述应对方案、残余风险、灾备恢复方案，并要求进行相应故障的培训和演习安排，尽最大努力保障业务连续性。\n\n知道风险在哪、优先治理何种风险之后，就可以着手优化架构。和高性能架构模式一样，高可用架构也可以从存储和计算两个方面来分析。\n\n### 存储高可用\n\n**存储高可用**的本质都是通过将数据复制到多个存储设备，通过数据冗余的方式来提高可用性。\n\n- **双机架构**\n\n让我们先从简单的增加一台机器开始，即**双机架构**。\n\n当机器变成两台后，根据两台机器担任的角色不同，就会分成不同的策略，比如主备、主从、主主。\n\n**主备复制**的架构是指一台机器作为客户端访问的主机，另一台机器纯粹作为冗余备份用，当主机没有故障时，备机不会被客户端访问到，仅仅需要从主机同步数据。这种策略很简单，可以应对主机故障情况下的业务可用性问题，但在平常无法分担主机的读写压力，有点浪费。\n\n**主从复制**的架构和主备复制的差别在于，从机除了复制备份数据，还需要干活，即还需要承担一部分的客户端请求（一般是分担读操作）。当主机故障时，从机的读操作不会受到影响，但需要增加读操作的请求分发策略，且和主备不同，由于从机直接提供数据读，如果主从复制延迟大，数据不一致会对业务造成更明显的影响。\n\n对于主备和主从两种策略，如果主机故障，都需要让另一台机器变成主机，才能继续完整地提供服务，如果全靠人工干预来切换，会比较滞后和易错，最好是能够自动完成切换，这就涉及**双机切换**的策略。\n\n在考虑双机切换时，要考虑什么？首先是需要感知机器的状态，是两台机器直连传递互相的状态，还是都传递给第三方来仲裁？所谓状态要包含哪些内容才能定义一台主机是故障呢？是发现一次问题就切换还是多观察一会再切换？切换后如果主机恢复了是切换回来还是自动变备机呢？需不需要人工二次确认一下？\n\n这些问题可能都得根据业务的特性来得出答案，此处仅给出三种常见的双机切换模式：\n\n> 互连式：两台机器直接连接传递信息，并根据传递的状态信息判断是否要切换主机，如果通道本身发生故障则无法判断是否要切换了，可以再增加一个通道构成双通道保障，不过也只是降低同时故障的概率。中介式：通过第三方中介来收集机器状态并执行策略，如果通道发生断连，中介可以直接切换其他机器作为主机，但这要求中介本身是高可用的，已经有比较成熟的开源解决方案如 zookeeper、keepalived。模拟式：备机模拟成客户端，向主机发送业务类似的读写请求，根据响应情况来判断主机的状态决定是否要切换主机，这样可以最真实地感受到客户端角度下的主机故障，但和互连式不同，能获取到的其他机器信息很少，容易出现判断偏差。\n\n\n\n最后一种双机架构是**主主复制**，和前面两种只有一主的策略不同，这次两台都是主机，客户端的请求可以达到任何一台主机，不存在切换主机的问题。但这对数据的设计就有了严格的要求，如果存在唯一 ID、严格的库存数量等数据，就无法适用，这种策略适合那些偏临时性、可丢失、可覆盖的数据场景。\n\n- **数据集群**\n\n采用双机架构的前提是一台主机能够存储所有的业务数据并处理所有的业务请求，但机器的存储和处理能力是有上限的，在大数据场景下就需要多台服务器来构成**数据集群**。\n\n如果是因为处理能力达到瓶颈，此时可以增加从机帮主机分担压力，即一主多从，称为**数据集中集群**。这种集群方式需要任务分配算法将请求分散到不同机器上去，主要的问题在于数据需要复制到多台从机，数据的一致性保障会比一主一从更为复杂。且当主机故障时，多台从机协商新主机的策略也会变得复杂。这里有开源的 zookeeper ZAB 算法可以直接参考。\n\n如果是因为存储量级达到瓶颈，此时可以将数据分散存储到不同服务器，每台服务器负责存储一部分数据，同时也备份一部分数据，称为**数据分散集群**。数据分散集群同样需要做负载均衡，在数据分区的分配上，hadoop 采用独立服务器负责数据分区的分配，ES 集群通过选举一台服务器来做数据分区的分配。除了负载均衡，还需要支持扩缩容，此外由于数据是分散存储的，当部分服务器故障时，要能够将故障服务器的数据在其他服务器上恢复，并把原本分配到故障服务器的数据分配到其他正常的服务器上，即分区容错性。\n\n- **数据分区**\n\n数据集群可以在单台乃至多台服务器故障时依然保持业务可用，但如果因为地理级灾难导致整个集群都故障了（断网、火灾等），那整个服务就不可用了。面对这种情况，就需要基于不同地理位置做**数据分区**。\n\n做不同地理位置的数据分区，首先要根据业务特性制定分区规则，大多还是按照地理位置提供的服务去做数据分区，比如中国区主要存储中国用户的数据。\n\n既然分区是为了防灾，那么一个分区肯定不止存储自身的数据，还需要做数据备份。从数据备份的策略来说，主要有三种模式：\n\n> 集中式：存在一个总备份中心，所有的分区数据都往这个总中心备份，设计起来简单，各个分区间没有联系，不会互相影响，也很容易扩展新的分区。但总中心的成本较高，而且总中心如果出故障，就要全部重新备份。互备式：每个分区备份另一个分区的数据，可以形成一个备份环，或者按地理位置远近来搭对备份，这样可以直接利用已有的设备做数据备份。但设计较复杂，各个分区间需要联系，当扩展新分区时，需要修改原有的备份线路。独立式：每个分区配备自己的备份中心，一般设立在分区地理位置附近的城市，设计也简单，各个分区间不会影响，扩展新分区也容易。但是成本会很高，而且只能防范城市级的灾难。\n\n### 计算高可用\n\n从存储高可用的思路可以看出，高可用主要是通过增加机器冗余来实现备份，对**计算高可用**来说也是如此。通过增加机器，分担服务器的压力，并在单机发生故障的时候将请求分配到其他机器来保障业务可用性。\n\n因此计算高可用的复杂性也主要是在多机器下任务分配的问题，比如当任务来临（比如客户端请求到来）时，如何选择执行任务的服务器？如果任务执行失败，如何重新分配呢？这里又可以回到前文说过的负载均衡相关的解法上。\n\n计算服务器和存储服务器在多机器情况下的架构是类似的，也分为主备、主从和集群。\n\n**主备架构**下，备机仅仅用作冗余，平常不会接收到客户端请求，当主机故障时，备机才会升级为主机提供服务。备机分为冷备和温备。冷备是指备机只准备好程序包和配置文件，但实际平常并不会启动系统。温备是指备机的系统是持续启动的，只是不对外提供服务，从而可以随时切换主机。\n\n**主从架构**下，从机也要执行任务，由任务分配器按照预先定义的规则将任务分配给主机和从机。相比起主备，主从可以发挥一定的从机性能，避免成本空费，但任务的分配就变得复杂一些。\n\n**集群架构**又分为对称集群和非对称集群。\n\n**对称集群**也叫负载均衡集群，其中所有的服务器都是同等对待的，任务会均衡地分配到每台服务器。此时可以采用随机、轮询、Hash 等简单的分配机制，如果某台服务器故障，不再给它分配任务即可。\n\n**非对称集群**下不同的服务器有不同的角色，比如分为 master 和 slave。此时任务分配器需要有一定的规则将任务分配给不同角色的服务器，还需要有选举策略来在 master 故障时选择新的 master。这个选举策略的复杂度就丰俭由人了。\n\n- **异地多活**\n\n讲存储高可用已经说过数据分区，计算高可用也有类似的高可用保障思路，归纳来说，它们都可以根据需要做**异地多活**，来提高整体的处理能力，并防范地区级的灾难。异地多活中的”异地“，就是指集群部署到不同的地理位置，“活”则强调集群是随时能提供服务的，不同于“备”还需要一个切换过程。\n\n按照规模，异地多活可以分为同城异区、跨城异地和跨国异地。显而易见，不同模式下能够应对的地区级故障是越来越高的，但同样的，距离越远，通信成本与延迟就越高，对通信通道可用性的挑战也越高。因此跨城异地已经不适合对数据一致性要求非常高的业务，而跨国异地往往是用来给不同国家的用户提供不同服务的。\n\n由于异地多活需要花费很高的成本，极大地增加系统复杂度，因此在设计异地多活架构时，可以不用强求为所有业务都做异地多活，可以优先为核心业务实现异地多活。尽量保障绝大部分用户的异地多活，对于没能保障的用户，通过挂公告、事后补偿、完善失败提示等措施进行安抚、提升体验。毕竟要做到100%可用性是不可能的，只能在能接受的成本下尽量逼近，所以当可用性达到一定瓶颈后，补偿手段的成本或许更低。\n\n在异地部署的情况下，数据一定会冗余存储，物理上就无法实现绝对的实时同步，且距离越远对数据一致性的挑战越大，虽然可以靠减少距离、搭建高速专用网络等方式来提高一致性，但也只是提高而已，因此大部分情况下， 只需考虑保障业务能接受范围下的最终一致性即可。\n\n在同步数据的时候，可以采用多种方式，比如通过消息队列同步、利用数据库自带的同步机制同步、通过换机房重试来解决同步延迟问题、通过 session id 让同一数据的请求都到同一机房从而不用同步等。\n\n可见，整个异地多活的设计步骤首先是对业务分级，挑选出核心业务做异地多活，然后对需要做异地多活的数据进行特征分析，考虑数据量、唯一性、实时性要求、可丢失性、可恢复性等，根据数据特性设计数据同步的方案。最后考虑各种异常情况下的处理手段，比如多通道同步、日志记录恢复、用户补偿等，此时可以借用前文所说的 FMEA 等方法进行分析。\n\n- **接口级故障**\n\n前面讨论的都是较为宏观的服务器、分区级的故障发生时该怎么办，实际上在平常的开发中，还应该防微杜渐，从接口粒度的角度，来防范和应对接口级的故障。应对的核心思路依然是优先保障核心业务和绝大部分用户可用。\n\n对于**接口级故障**，有几个常用的方法：限流、排队、降级、熔断。其中限流和排队属于事前防范的措施，而降级和熔断属于接口真的故障后的处理手段。\n\n**限流**的目的在于控制接口的访问量，避免被高频访问冲垮。\n\n从限流维度来说，可以基于请求限流，即限制某个指标下、某个时间段内的请求数量，阈值的定义需要基于压测和线上情况来逐步调优。还可以基于资源限流，比如根据连接数、文件句柄、线程数等，这种维度更适合特殊的业务。\n\n实现限流常用的有时间窗算法和桶算法。\n\n**时间窗算法**分为固定时间窗和滑动时间窗。\n\n**固定时间窗**通过统计固定时间周期内的量级来决定限流，但存在一个临界点的问题，如果在两个时间窗的中间发生超大流量，而在两个时间窗内都各自没有超出限制，就会出现无法被限流拦截的接口故障。因此**滑动时间窗**采用了部分重叠的时间统计周期来解决临界点问题。\n\n桶算法分为漏桶和令牌桶。\n\n**漏桶算法**是将请求放入桶中，处理单元从桶里拿请求去进行处理，如果桶堆满了就丢弃掉新的请求，可以理解为桶下面有个漏斗将请求往处理单元流动，整个桶的容量是有限的。这种模式下流入的速率取决于请求的频率，当桶内有堆积的待处理请求时，流出速率是匀速的。漏桶算法适用于瞬时高并发的场景（如秒杀），处理可能慢一点，但可以缓存部分请求不丢弃。\n\n**令牌桶算法**是在桶内放令牌，令牌数是有限的，新的请求需要先到桶里拿到令牌才能被处理，拿不到就会被丢弃。和漏桶匀速流出处理不同，令牌桶还能通过控制放令牌的速率来控制接收新请求的频率，对于突发流量，可靠累计的令牌来处理，但是相对的处理速度也会突增。令牌桶算法适用于控制第三方服务访问速度的场景，防止压垮下游。\n\n除了限流，还有一种控制处理速度的方法就是**排队**。当新请求到来后先加入队列，出队端通过固定速度出队处理请求，避免处理单元压力过大。队列也有长度限制，其机制和漏桶算法差不多。\n\n如果真的事前防范真的被突破了，接口很可能或已经发生了故障，还能做什么呢？\n\n一种手段是**熔断**，即当处理量达到阈值，就主动停掉外部接口的访问能力，这其实也是一种防范措施，对外的表现虽然是接口访问故障，但系统内部得以被保护，不会引起更大的问题，待存量处理被消化完，或者外部请求减弱，或完成扩容后，再开放接口。熔断的设计主要是阈值，需要按照业务特点和统计数据制定。\n\n当接口故障后（无论是被动还是主动断开），最好能提供**降级**策略。降级是丢车保帅，放弃一下非核心业务，保障核心业务可用，或者最低程度能提供故障公告，让用户不要反复尝试请求来加重问题了。比起手动降级，更好的做法也是自动降级，需要具备检测和发现降级时机的机制。\n\n## 可扩展架构模式\n\n再回顾一遍互联网行业的金科玉律：只有变化才是不变的。在设计架构时，一开始就要抱着业务随时可能变动导致架构也要跟着变动的思想准备去设计，差别只在于变化的快慢而已。因此在设计架构时一定是要考虑可扩展性的。\n\n在思考怎样才是可扩展的时候，先想一想平常开发中什么情况下会觉得扩展性不好？大都是因为系统庞大、耦合严重、牵一发而动全身。因此对可扩展架构设计来说，基本的思想就是**拆分**。\n\n拆分也有多种指导思想，如果面向业务流程来谈拆分，就是分层架构；如果面向系统服务来谈拆分，就是 SOA、微服务架构；如果面向系统功能来拆分，就是微内核架构。\n\n- **分层架构**\n\n**分层架构**是我们最熟悉的，因为互联网业务下，已经很少有纯单机的服务，因此至少都是 C/S 架构、B/S 架构，也就是至少也分为了客户端/浏览器和后台服务器这两层。如果进一步拆分，就会将后台服务基于职责进行自顶向下的划分，比如分为接入层、应用层、逻辑层、领域层等。\n\n分层的目的当然是为了让各个层次间的服务减少耦合，方便进行各自范畴下的优化，因此需要保证各层级间的差异是足够清晰、边界足够明显的，否则当要增加新功能的时候就会不知道该放到哪一层。各个层只处理本层逻辑，隔离关注点。\n\n额外需注意的是一旦确定了分层，请求就必须层层传递，不能跳层，这是为了避免架构混乱，增加维护和扩展的复杂度，比如为了方便直接跨层从接入层调用领域层查询数据，当需要进行统一的逻辑处理时，就无法切面处理所有请求了。\n\n- **SOA 架构**\n\n**SOA 架构**更多出现在传统企业中，其主要解决的问题是企业中 IT 建设重复且效率低下，各部门自行接入独立的 IT 系统，彼此之间架构、协议都不同，为了让各个系统的服务能够协调工作，SOA 架构应运而生。\n\n其有三个关键概念：服务、ESB 和松耦合。\n\n服务是指各个业务功能，比如原本各部门原本的系统提供的服务，可大可小。由于各服务之间无法直接通信，因此需要 ESB，即企业服务总线进行对接，它将不同服务连接在一起，屏蔽各个服务的不同接口标准，类似计算机中的总线。松耦合是指各个服务的依赖需要尽量少，否则某个服务升级后整个系统无法使用就麻烦了。\n\n这里也可以看出，ESB 作为总线，为了对接各个服务，要处理各种不同的协议，其协议转换耗费了大量的性能，会成为整个系统的瓶颈。\n\n- **微服务**\n\n**微服务**是近几年最耳熟能详的架构，其实它和 SOA 有一些相同之处，比如都是将各个服务拆分开来提供能力。但是和 SOA 也有一些本质的区别，微服务是没有 ESB 的，其通信协议是一致的，因此通信管道仅仅做消息的传递，不理解内容和格式，也就没有 ESB 的问题。而且为了快速交付、迭代，其服务的粒度会划分地更细，对自动化部署能力也就要求更高，否则部署成本太大，达不到轻量快速的目的。\n\n当然微服务虽然很火，但也不是解决所有问题的银弹，它也会有一些问题存在。如果服务划分的太细，那么互相之间的依赖关系就会变得特别复杂，服务数量、接口量、部署量过多，团队的效率可能大降，如果没有自动化支撑，交付效率会很低。由于调用链太长（多个服务），因此性能也会下降，问题定位会更困难，如果没有服务治理的能力，管理起来会很混乱，不知道每个服务的情况如何。\n\n因此如何拆分服务就成了每个使用微服务架构的团队的重要考量点。这里也提供一些拆分的思路：\n\n> 三个火枪手原则：考虑每三个人负责一个服务，互相可以形成稳定的人员备份，讨论起来也更容易得出结论，在此基础上考虑能负责多大的一个服务。基于业务逻辑拆分：最直观的就是按逻辑拆分，如果职责不清，就参考三个火枪手原则确定服务大小。基于稳定性拆分：按照服务的稳定性分为稳定服务和变动服务，稳定服务粒度可以粗一些，变动服务粒度可以细一些，目的是减少变动服务之间的影响，但总体数量依然要控制。基于可靠性拆分：按照可靠性排序，要求高的可以拆细一些，由前文可知，服务越简单，高可用方案就会越简单，成本也会越低。优先保障核心服务的高可用。基于性能拆分：类似可靠性，性能要求越高的，拆出来单独做高性能优化，可有效降低成本。\n\n微服务架构如果没有完善的基础设施保障服务治理，那么也会带来很多问题，降低效率，因此根据团队和业务的规模，可以按以下优先级进行基础设施的支持：\n\n> 优先支持服务发现、服务路由、服务容错（重试、流控、隔离），这些是微服务的基础。接着支持接口框架（统一的协议格式与规范）、API 网关（接入鉴权、权限控制、传输加密、请求路由等），可以提高开发效率。然后支持自动化部署、自动化测试能力，并搭建配置中心，可以提升测试和运维的效率。最后支持服务监控、服务跟踪、服务安全（接入安全、数据安全、传输安全、配置化安全策略等）的能力，可以进一步提高运维效率。\n\n\n\n- **微内核架构**\n\n最后说说**微内核架构**，也叫插件化架构，顾名思义，是面向功能拆分的，通常包含核心系统和插件模块。在微内核架构中，核心系统需要支持插件的管理和链接，即如何加载插件，何时加载插件，插件如何新增和操作，插件如何和核心引擎通信等。\n\n举一个最常见的微内核架构的例子——规则引擎，在这个架构中，引擎是内核，负责解析规则，并将输入通过规则处理后得到输出。而各种规则则是插件，通常根据各种业务场景进行配置，存储到数据库中。\n\n## 总结\n\n人们通常把某项互联网业务的发展分为四个时期：初创期、发展期、竞争期和成熟期。\n\n在初创期通常求快，系统能买就买，能用开源就用开源，能用的就是好的，先要活下来；到了发展期开始堆功能和优化，要求能快速实现需求，并有余力对一些系统的问题进行优化，当优化到顶的时候就需要从架构层面来拆分优化了；进入竞争期后，经过发展期的快速迭代，可能会存在很多重复造轮子和混乱的交互，此时就需要通过平台化、服务化来解决一些公共的问题；最后到达成熟期后，主要在于补齐短板，优化弱项，保障系统的稳定。\n\n在整个发展的过程中，同一个功能的前后要求也是不同的，随着用户规模的增加，性能会越来越难保障，可用性问题的影响也会越来越大，因此复杂度就来了。\n\n对于架构师来说，首要的任务是从当前系统的一大堆纷繁复杂的问题中识别出真正要通过架构重构来解决的问题，集中力量快速突破，但整体来说，要徐徐图之，不要想着用重构来一次性解决所有问题。\n\n对项目中的问题做好分类，划分优先级，先易后难，才更容易通过较少的资源占用，较快地得到成果，提高士气。然后再循序渐进，每个阶段控制在 1~3 个月，稳步推进。\n\n当然，在这个过程中，免不了和上下游团队沟通协作，需要注意的是自己的目标和其他团队的目标可能是不同的，需要对重构的价值进行换位思考，让双方都可以合作共赢，才能借力前进。\n\n还是回到开头的那句话，架构设计的主要目的是为了解决软件系统复杂度带来的问题。首先找到主要矛盾在哪，做到有的放矢，然后再结合知识、经验进行设计，去解决面前的问题。\n\n[为什么大部分人做不了架构师？ - 掘金 (juejin.cn)](https://juejin.cn/post/7251779626682023994)\n","tags":["其他"],"categories":["其他"]},{"title":"lambda表达式","url":"/2023/08/05/lambda表达式/","content":"\n## 简介\n\nLambda 表达式，也可称为闭包，它是推动 Java 8 发布的最重要新特性。\n\nLambda 允许把函数作为一个方法的参数（函数作为参数传递进方法中）。\n\n使用 Lambda 表达式可以使代码变的更加简洁紧凑。\n\n### 语法\n\nlambda 表达式的语法格式如下：\n\n```java\n(parameters) -> expression //或 \n(parameters) ->{ statements; }\n```\n\n## 函数式接口\n\n要了解Lambda表达式,首先需要了解什么是函数式接口，函数式接口定义：一个接口有且只有一个抽象方法\n\n注意：\n\n1. 如果一个接口只有一个抽象方法，那么该接口就是一个函数式接口\n2. 如果我们在某个接口上声明了 @FunctionalInterface 注解，那么编译器就会按照函数式接口的定义来要求该接口，这样如果有两个抽象方法，程序编译就会报错的。所以，从某种意义上来说，只要你保证你的接口中只有一个抽象方法，你可以不加这个注解。加上就会自动进行检测的。\n   定义方式：\n\n```java\n@FunctionalInterface\ninterface NoParameterNoReturn {\n\t//注意：只能有一个方法\n\tvoid test();\n}\n```\n\n但是这种方式也是可以的：我们知道在 jdk1.8之后接口中的方法式可以有具体实现的\n\n```java\n@FunctionalInterface\ninterface NoParameterNoReturn {\n\tvoid test();\n\tdefault void test2() {\n\t\tSystem.out.println(\"JDK1.8新特性，default默认方法可以有具体的实现\");\n\t}\n}\n```\n\n## Lambda表达式的基本使用\n\n### 无返回值函数式接口\n\n```java\n//无返回值无参数\n@FunctionalInterface\ninterface NoParameterNoReturn {\n    void test();\n}\n//无返回值一个参数\n@FunctionalInterface\ninterface OneParameterNoReturn {\n    void test(int a);\n}\n//无返回值两个参数\n@FunctionalInterface\ninterface MoreParameterNoReturn {\n    void test(int a,int b);\n}\npublic class TestDemo {\n    public static void main(String[] args) {\n        NoParameterNoReturn n = ()->{\n            System.out.println(\"无参数无返回值\");\n        };\n        n.test();\n\n        OneParameterNoReturn o = (a)-> {\n            System.out.println(\"无返回值一个参数\"+a);\n        };\n        o.test(666);\n        MoreParameterNoReturn m = (int a,int b)->{\n            System.out.println(\"无返回值两个参数\"+a+\" \"+b);\n        };\n        m.test(666,999);\n    }\n}\n```\n\n### 有返回值函数接口\n\n```java\n//有返回值无参数\n@FunctionalInterface\ninterface NoParameterReturn {\n    int test();\n}\n//有返回值一个参数\n@FunctionalInterface\ninterface OneParameterReturn {\n    int test(int a);\n}\n//有返回值多个参数\n@FunctionalInterface\ninterface MoreParameterReturn {\n    int test(int a,int b);\n}\npublic class TestDemo {\n    public static void main(String[] args) {\n        NoParameterReturn n = ()->{\n            return 666;\n        };\n        int ret1 = n.test();\n        System.out.println(ret1);\n        System.out.println(\"================\");\n        OneParameterReturn o = (int a)->{\n            return a;\n        };\n        int ret2 = o.test(999);\n        System.out.println(ret2);\n        System.out.println(\"================\");\n        MoreParameterReturn m = (int a,int b)-> {\n            return a+b;\n        };\n        int ret3 = m.test(10,90);\n        System.out.println(ret3);\n    }\n}\n```\n\n## 语法精简\n\nLambda表达式的语法还可以精简，显得非常有逼格，但是可读性就非常差。\n\n1. 参数类型可以省略，如果需要省略，每个参数的类型都要省略。\n2. 参数的小括号里面只有一个参数，那么小括号可以省略\n3. 如果方法体当中只有一句代码，那么大括号可以省略\n4. 如果方法体中只有一条语句，其是return语句，那么大括号可以省略，且去掉return关键字\n   把上面的代码精简示例：\n\n```java\n\tpublic static void main(String[] args) {\n        MoreParameterNoReturn moreParameterNoReturn = (a, b)->{\n            System.out.println(\"无返回值多个参数，省略参数类型：\"+a+\" \"+b);\n        };\n        moreParameterNoReturn.test(20,30);\n        OneParameterNoReturn oneParameterNoReturn = a ->{\n            System.out.println(\"无参数一个返回值,小括号可以省略：\"+ a);\n        };\n        oneParameterNoReturn.test(10);\n        NoParameterNoReturn noParameterNoReturn = ()->System.out.println(\"无参数无返回值，方法体中只有 一行代码\");\n        noParameterNoReturn.test();\n        //方法体中只有一条语句，且是return语句\n        NoParameterReturn noParameterReturn = ()-> 40;\n        int ret = noParameterReturn.test();\n        System.out.println(ret);\n    }\n```\n\n## 变量捕获\n\nLambda 表达式中存在变量捕获 ，了解了变量捕获之后，我们才能更好的理解Lambda 表达式的作用域 。Java当中的匿名类中，会存在变量捕获。\n\n```java\n//变量如果出现在内部会报错\npublic class VariableCapture {\n    public static void main(String[] args) {\n        int a = 100;\n        Test t = new Test(){\n            int a = 100  //error\n            @Override\n            public void func(){\n                System.out.println(\"捕获的变量是：\"+a);\n            }\n        };\n        t.func();\n    }\n}\nclass Test{\n    public void func(){\n        System.out.println(\"func\");\n    }\n}\n```\n\n## Lambda在集合当中的使用\n\n为了能够让Lambda和Java的集合类集更好的一起使用，集合当中，也新增了部分接口，以便与Lambda表达式对接。要用Lambda遍历集合就一定要看懂源码。\n\n![d27c0eee706b43fbbbfb14456cba081a](https://presenter.oss-cn-shanghai.aliyuncs.com/wordpress/d27c0eee706b43fbbbfb14456cba081a.png)\n\n## jdk8提供的接口\n\njdk8中提供了四中最基本的函数式接口供我们使用，减少我们编写额外的接口。\n\n- Predicate：泛型单入参返回布尔值出参\n- Function：泛型单入参返回泛型出参\n- Supplier：无入参返回泛型出参\n- Consumer：泛型单入参无出参\n\n**Predicate**:\n\n```java\n@FunctionalInterface\npublic interface Predicate<T> {\n    /**\n     * Evaluates this predicate on the given argument.\n     *\n     * @param t the input argument\n     * @return {@code true} if the input argument matches the predicate,\n     * @return {@code true}如果输入参数与谓词匹配，\n     * otherwise {@code false\n     */\n    boolean test(T t);\n}\n @Test\n    public void customPredicate(){\n        predicate(\"hello\",x-> x.contains(\"x\"));\n    }\n    /**\n     * 入参 --> true/false\n     * @param str\n     * @param t\n     */\n    public void predicate(String str, Predicate<String> t){\n        if(t.test(str)){\n            System.out.println(\"haha\");\n        }else {\n            System.out.println(\"what's up\");\n        }\n    }\n```\n\n **Function**:\n\n```java\n@FunctionalInterface\npublic interface Function<T, R> {\n    /**\n     * Applies this function to the given argument.\n     * @param t the function argument\n     * @return the function result\n     */\n    R apply(T t);\n}\n    @Test\n    public void customFunction(){\n        System.out.println(function(10, x -> x * x));\n    }\n    /**\n     * 入参 --> 出参\n     */\n    public int  function(int i, Function<Integer,Integer> f){\n        return f.apply(i);\n    }\n```\n\n**Supplier**:\n\n```java\n@FunctionalInterface\npublic interface Supplier<T> {\n    /**\n\n   * Gets a result.\n      @return a result\n          */\n         T get();\n     }\n@Test\npublic void customSupplier(){\n    System.out.println(supplier(10, () -> new Random().nextInt(20)));\n}\n/**\n * 空参 --> 出参\n * @return\n */\npublic int  supplier(int i, Supplier<Integer> s){\n    return s.get();\n}\n```\n\nConsumer:\n\n```java\n@FunctionalInterface\npublic interface Consumer<T> {\n \n    /**\n     * Performs this operation on the given argument.\n     * @param t the input argument\n     */\n    void accept(T t);\n}\n \n    @Test\n    public void customConsumer(){\n        consumer(10, (x) -> System.out.println(++x));\n    }\n    /**\n     * 入参 --> 空参\n     */\n    public void  consumer(int i, Consumer<Integer> c){\n         c.accept(i);\n    }\n```\n","tags":["java"],"categories":["java"]},{"title":"ipv6","url":"/2023/08/02/ipv6/","content":"\n## 简介\n\nIPv6是英文“Internet Protocol Version 6”（互联网协议第6版）的缩写，是互联网工程任务组（[IETF](https://baike.baidu.com/item/IETF/2800318?fromModule=lemma_inlink)）设计的用于替代[IPv4](https://baike.baidu.com/item/IPv4/422599?fromModule=lemma_inlink)的下一代IP协议，其地址数量号称可以为全世界的每一粒沙子编上一个地址 。\n\n由于IPv4最大的问题在于网络地址资源不足，严重制约了互联网的应用和发展。IPv6的使用，不仅能解决网络地址资源数量的问题，而且也解决了多种接入设备连入互联网的障碍 。\n\n互联网数字分配机构（[IANA](https://baike.baidu.com/item/IANA/2800158?fromModule=lemma_inlink)）在2016年已向国际互联网工程任务组（IETF）提出建议，要求新制定的国际互联网标准只支持IPv6，不再兼容IPv4。\n\n## 表示方法\n\n![574e9258d109b3de99d9701cccbf6c81800a4c5b](https://presenter.oss-cn-shanghai.aliyuncs.com/wordpress/574e9258d109b3de99d9701cccbf6c81800a4c5b.gif)\n\nIPv6的长分布式结构图\n\nIPv6的地址长度为128位，是IPv4地址长度的4倍。于是IPv4点分十进制格式不再适用，采用十六进制表示。IPv6有3种表示方法。\n\n一、冒分十六进制表示法\n\n格式为X:X:X:X:X:X:X:X，其中每个X表示地址中的16b，以十六进制表示，例如：\n\nABCD:EF01:2345:6789:ABCD:EF01:2345:6789\n\n这种表示法中，每个X的前导0是可以省略的，例如：\n\n2001:0DB8:0000:0023:0008:0800:200C:417A→ 2001:DB8:0:23:8:800:200C:417A\n\n二、0位压缩表示法\n\n在某些情况下，一个IPv6地址中间可能包含很长的一段0，可以把连续的一段0压缩为“::”。但为保证地址解析的唯一性，地址中”::”只能出现一次，例如：\n\nFF01:0:0:0:0:0:0:1101 → FF01::1101\n\n0:0:0:0:0:0:0:1 → ::1\n\n0:0:0:0:0:0:0:0 → ::\n\n三、内嵌IPv4地址表示法\n\n为了实现IPv4-IPv6互通，IPv4地址会嵌入IPv6地址中，此时地址常表示为：X:X:X:X:X:X:d.d.d.d，前96b采用冒分十六进制表示，而最后32b地址则使用IPv4的点分十进制表示，例如::192.168.0.1与::FFFF:192.168.0.1就是两个典型的例子，注意在前96b中，压缩0位的方法依旧适用\n\n## 报文内容\n\nIPv6[报文](https://baike.baidu.com/item/报文?fromModule=lemma_inlink)的整体结构分为IPv6报头（另译：基本首部 、扩展报头和上层协议数据3部分。IPv6报头是必选报文头部，长度固定为40B，包含该报文的基本信息；扩展报头是可选报头，可能存在0个、1个或多个，IPv6协议通过扩展报头实现各种丰富的功能；上层协议数据是该IPv6报文携带的上层数据，可能是[ICMPv6](https://baike.baidu.com/item/ICMPv6?fromModule=lemma_inlink)报文、[TCP](https://baike.baidu.com/item/TCP/33012?fromModule=lemma_inlink)报文、UDP报文或其他可能报文。\n\nIPv6的**报文头部**结构如图：\n\n![eaf81a4c510fd9f94e7dcd152d2dd42a2834a460](https://presenter.oss-cn-shanghai.aliyuncs.com/wordpress/eaf81a4c510fd9f94e7dcd152d2dd42a2834a460.jpg)\n\nIPv6的报文头部结构  \n\n| 版本号   | 表示协议版本．值为6                                          |\n| -------- | ------------------------------------------------------------ |\n| 流量等级 | 主要用于QoS                                                  |\n| 流标签   | 用来标识同一个流里面的报文                                   |\n| 载荷长度 | 包含扩展报头和数据部分的长度，最多可表示65535字节数，超过则置为0 [25] |\n| 下一报头 | 该字段用来指明报头后接的报文头部的类型，若存在扩展头，表示第一个扩展头的类型，否则表示其上层协议的类型，它是IPv6各种功能的核心实现方法 |\n| 跳数限制 | 该字段类似于IPv4中的[TTL](https://baike.baidu.com/item/TTL/130248?fromModule=lemma_inlink)，每次转发跳数减一，该字段达到0时包将会被丢弃 |\n| 源地址   | 标识该报文的来源地址                                         |\n| 目的地址 | 标识该报文的目的地址                                         |\n\n**扩展报头**：IPv6报文中不再有“选项”字段，而是通过“下一报头”字段配合IPv6扩展报头来实现选项的功能。使用扩展头时，将在IPv6报文下一报头字段表明首个扩展报头的类型，再根据该类型对扩展报头进行读取与处理。每个扩展报头同样包含下一报头字段，若接下来有其他扩展报头，即在该字段中继续标明接下来的扩展报头的类型，从而达到添加连续多个扩展报头的目的。在最后一个扩展报头的下一报头字段中，则标明该报文上层协议的类型，用以读取上层协议数据 。\n\n![b17eca8065380cd733642891a944ad3459828150](https://presenter.oss-cn-shanghai.aliyuncs.com/wordpress/b17eca8065380cd733642891a944ad3459828150.png)\n\n扩展报头 \n","tags":["计算机网络"],"categories":["计算机网络"]},{"title":"jenkins","url":"/2023/08/02/jenkins/","content":"\n## docker安装jenkins\n\n安装命令：\n\n```bash\ndocker run -d -u root --name jenkins -p 8088:8080 -v /opt/nan/jenkins_home:/var/jenkins_home jenkins/jenkins:latest\n```\n\n安装好之后在浏览器输入ip和端口看到以下界面\n\n![img](https://presenter.oss-cn-shanghai.aliyuncs.com/wordpress/1808388-20230112140446180-1457455354.png)\n\n在映射出来的路径找到对应文件，将密码输入就可以了。安装就算完成了\n\n## jenkins的插件\n\n很多插件可以在Jenkins中直接下载，不能下载的在jenkins官网中的插件页面可以搜索所有的插件。我这里已经下载好了中文插件。\n\n##  拉取git远程仓库\n\n在项目中打开配置找到源码管理，选择git\n\n![image-20230805184038958](https://presenter.oss-cn-shanghai.aliyuncs.com/wordpress/image-20230805184038958.png)\n\n输入地址，然后点击添加，添加一个凭证，在里面输入你的github或者其他平台的账号，然后在credentials里选择刚才添加的凭证。点击保存就会将远程仓库的代码拉取到本地。\n\n## 绑定coding触发\n\n还是在配置中，找到构建触发器。这里需要下载generic webhook trigger插件才能看到下面这个选项。\n\n![image-20230805184812350](https://presenter.oss-cn-shanghai.aliyuncs.com/wordpress/image-20230805184812350.png)\n\n只需要配置上token，然后生成的链接粘贴到coding的项目中的开发者选项中的webhook功能中。\n\n如果有多个分支可以下载git parameter插件，然后按照如下配置\n\n![image-20230805185508886](https://presenter.oss-cn-shanghai.aliyuncs.com/wordpress/image-20230805185508886.png)\n\n![image-20230805185654003](https://presenter.oss-cn-shanghai.aliyuncs.com/wordpress/image-20230805185654003.png)\n","tags":["jenkins"],"categories":["工具"]},{"title":"java中的注解","url":"/2023/08/02/java中的注解/","content":"\n# java中的注解\n\n## 常见（java.lang.annotation包下的元注解）\n\n### **@Target:注解的作用目标**\n\n> @Target(ElementType.TYPE)——接口、类、枚举、注解\n> @Target(ElementType.FIELD)——字段、枚举的常量\n> @Target(ElementType.METHOD)——方法\n> @Target(ElementType.PARAMETER)——方法参数\n> @Target(ElementType.CONSTRUCTOR) ——构造函数\n> @Target(ElementType.LOCAL_VARIABLE)——局部变量\n> @Target(ElementType.ANNOTATION_TYPE)——注解\n> @Target(ElementType.PACKAGE)——包，用于记录java文件的package信息\n\n### **@Retention:是用来修饰注解的，注解的注解，也称为元注解**\n\n@Retention修饰注解，用来表示注解的生命周期，生命周期的长短取决于@Retention的属性RetentionPolicy指定的值，例如@Retention(RetentionPolicy.RUNTIME)\n\n| 取值                    | 描述                                                         | 作用范围          | 使用场景                                                     |\n| ----------------------- | ------------------------------------------------------------ | ----------------- | ------------------------------------------------------------ |\n| RetentionPolicy.SOURCE  | 表示注解只保留在源文件，当java文件编译成class文件，就会消失  | 源文件            | 只是做一些检查性的操作，，比如 @Override 和 @SuppressWarnings |\n| RetentionPolicy.CLASS   | 注解被保留到class文件，但jvm加载class文件时候被遗弃，这是默认的生命周期 | class文件（默认） | 要在编译时进行一些预处理操作，比如生成一些辅助代码（如 ButterKnife） |\n| RetentionPolicy.RUNTIME | 注解不仅被保存到class文件中，jvm加载class文件之后，仍然存在  | 运行时也存在      | 需要在运行时去动态获取注解信息                               |\n\n### **@Documented**\n\n**@**Documented 注解表明这个注解应该被 javadoc工具记录. 默认情况下,javadoc是不包括注解的. 但如果声明注解时指定了 @Documented,则它会被 javadoc 之类的工具处理, 所以注解类型信息也会被包括在生成的文档中，是一个标记注解，没有成员。\n\n### **@Inherited**\n\n@Inherited是一个标识，**用来修饰注解**\n作用：如果一个类用上了@Inherited修饰的注解，那么其子类也会继承这个注解\n\n注意：\n\n1. 接口用上个@Inherited修饰的注解，其实现类不会继承这个注解\n2. 父类的方法用了@Inherited修饰的注解，子类也不会继承这个注解\n\n当用了@Inherited修饰的注解的@Retention是RetentionPolicy.RUNTIME，则增强了继承性，在反射中可以获取得到\n\n### **@Native** \n\n注解用于标识一个字段或方法是与本地平台相关的，并且不受 Java 语言规范的限制。这意味着该字段或方法的实现是依赖于底层本地平台的，而不是纯粹的 Java 代码。\n\n在 Java 代码中使用 @Native 注解，通常表示这个成员是使用本地代码（C、C++ 或其他本地语言）编写的，可以直接访问底层系统资源。这样的成员通常在 Java 的某个类库或框架中充当了一个与本地平台交互的接口。\n\n### **@Repeatable**\n\n注解是用于声明其它类型注解的元注解，来表示这个声明的注解是可重复的。@Repeatable的值是另一个注解，其可以通过这个另一个注解的值来包含这个可重复的注解。\n\n**示例**\n\nValue注解：\n\n```java\n@Target(ElementType.METHOD)\n@Retention(RetentionPolicy.RUNTIME)\n@Repeatable(Values.class)\npublic @interface Value {\n    String value() default \"value\";\n}\n```\n\nValues注解：\n\n```java\n@Target(ElementType.METHOD)\n@Retention(RetentionPolicy.RUNTIME)\npublic @interface Values {\n    Value[] value();\n}\n```\n\n其中，`@Value`注解上的元注解`@Repeatable`中的值，使用了`@Values`注解，`@Values`注解中包含的值类型是一个`@Value`注解的数组！\n这就解释了官方文档中`@Repeatable`中值的使用。\n\n**测试**\n\n注解使用方法\n\n```java\npublic class AnnotationClass {\n\n    @Value(\"hello\")\n    @Value(\"world\")\n    public void test(String var1, String var2) {\n        System.out.println(var1 + \" \" + var2);\n    }\n}\n```\n\n测试用例\n\n```java\n// 获取使用`@Value`注解的`test`方法，并打印这个方法上的注解长度和信息\n    @Test\n    public void testValue() {\n        Method[] methods = AnnotationClass.class.getMethods();\n        for (Method method : methods){\n            if (method.getName().equals(\"test\")) {\n                Annotation[] annotations = method.getDeclaredAnnotations();\n                System.out.println(annotations.length);\n                System.out.println(method.getName() + \" = \" + Arrays.toString(annotations));\n            }\n        }\n    }\n```\n\n因为`test`方法上使用了两个`@Value`注解，所以猜测打印注解长度为2，然后打印详情，可是结果并不同。\n\n```bash\n1\ntest = [@com.example.annotations.Values(value=[@com.example.annotations.Value(value=hello), @com.example.annotations.Value(value=world)])]\n```\n\n结果显示，`test`方法上的注解长度为 1 , 且打印信息为`@Values`注解，它的值包含了使用的两个注解。\n因此可知在jdk8中，相同注解只是以集合的方式进行了保存，原理并没有变化。\n\n## java扩展包中的参数校验注解（javax.validation，javax也就是jakarta）\n\n### @Constraint注解介绍\n\n`@Constraint`注解是Java Bean Validation框架中的一个注解，用于自定义约束注解，即自定义校验规则。\n\n通过在自定义注解上添加`@Constraint`注解，可以将该注解标记为一个自定义约束注解。同时，需要指定一个实现了`ConstraintValidator`接口的验证器类，用于验证该注解所标记的字段或参数是否符合自定义的校验规则。\n\n`@Constraint`注解有以下属性：\n\n1. `validatedBy`：用于指定实现了`ConstraintValidator`接口的验证器类。该属性的值是一个Class[对象数组](https://so.csdn.net/so/search?q=对象数组&spm=1001.2101.3001.7020)，可以指定多个验证器类。\n2. `message`：用于指定当校验失败时，所返回的错误信息。可以使用占位符{}，在校验器中使用具体的参数替换。\n3. `groups`：用于指定分组，即根据不同的分组应用不同的校验规则。\n4. `payload`：用于指定元数据，即可以通过该属性传递一些额外的验证信息。\n\n使用`@Constraint`注解，可以通过自定义注解的方式，为字段或参数添加自定义的校验规则，并实现校验逻辑。这样，在进行参数校验时，可以方便地通过注解的方式来调用自定义的校验规则。\n\n这里用若依系统的例子\n\n```java\n/**\n * 自定义xss校验注解\n * \n * @author ruoyi\n */\n@Retention(RetentionPolicy.RUNTIME)\n@Target(value = { ElementType.METHOD, ElementType.FIELD, ElementType.CONSTRUCTOR, ElementType.PARAMETER })\n@Constraint(validatedBy = { XssValidator.class })\npublic @interface Xss\n{\n    String message()\n\n    default \"不允许任何脚本运行\";\n\n    Class<?>[] groups() default {};\n\n    Class<? extends Payload>[] payload() default {};\n}\n\n```\n\n```java\n/**\n * 自定义xss校验注解实现\n * \n * @author ruoyi\n */\npublic class XssValidator implements ConstraintValidator<Xss, String>\n{\n    private static final String HTML_PATTERN = \"<(\\\\S*?)[^>]*>.*?|<.*? />\";\n\n    @Override\n    public boolean isValid(String value, ConstraintValidatorContext constraintValidatorContext)\n    {\n        if (StringUtils.isBlank(value))\n        {\n            return true;\n        }\n        return !containsHtml(value);\n    }\n\n    public static boolean containsHtml(String value)\n    {\n        Pattern pattern = Pattern.compile(HTML_PATTERN);\n        Matcher matcher = pattern.matcher(value);\n        return matcher.matches();\n    }\n}\n```\n\n","tags":["java"],"categories":["java"]},{"title":"动态规划","url":"/2023/08/01/动态规划/","content":"\n## 动态规划算法\n\n动态规划（Dynamic programming）是一种在数学、计算机科学和经济学中使用的，通过把原问题分解为相对简单的子问题的方式求解复杂问题的方法。 动态规划常常适用于有重叠子问题和最优子结构性质的问题，动态规划方法所耗时间往往远少于朴素解法。 动态规划背后的基本思想非常简单。大致上，若要解一个给定问题，我们需要解其不同部分（即子问题），再合并子问题的解以得出原问题的解。 通常许多子问题非常相似，为此动态规划法试图仅仅解决每个子问题一次，从而减少计算量： 一旦某个给定子问题的解已经算出，则将其记忆化存储，以便下次需要同一个子问题解之时直接查表。 这种做法在重复子问题的数目关于输入的规模呈指数增长时特别有用。 关于动态规划最经典的问题当属背包问题。\n\n## 性质\n\n1. 最优子结构性质。如果问题的最优解所包含的子问题的解也是最优的，我们就称该问题具有最优子结构性质（即满足最优化原理）。最优子结构性质为动态规划算法解决问题提供了重要线索。\n2. 子问题重叠性质。子问题重叠性质是指在用递归算法自顶向下对问题进行求解时，每次产生的子问题并不总是新问题，有些子问题会被重复计算多次。动态规划算法正是利用了这种子问题的重叠性质，对每一个子问题只计算一次，然后将其计算结果保存在一个表格中，当再次需要计算已经计算过的子问题时，只是在表格中简单地查看一下结果，从而获得较高的效率。\n3. 无后效性：即某阶段状态一旦确定，就不受这个状态以后决策的影响。也就是说，某状态以后的过程不会影响以前的状态，只与当前状态有关。\n\n## 步骤\n\n1. 划分：按照问题的特征，把问题分为若干阶段。注意：划分后的阶段一定是有序的或者可排序的\n2. 确定状态和状态变量：将问题发展到各个阶段时所处的各种不同的客观情况表现出来。状态的选择要满足无后续性\n3. 确定决策并写出状态转移方程：状态转移就是根据上一阶段的决策和状态来导出本阶段的状态。根据相邻两个阶段状态之间的联系来确定决策方法和状态转移方程\n4. 边界条件：状态转移方程是一个递推式，因此需要找到递推终止的条件\n\n**即：**\n\n【初始状态】→【决策1】→【决策2】→…→【决策n】→【结束状态】\n\n*注意：*\n\n1. 问题阶段\n2. 每个阶段的状态\n3. 相邻两个阶段之间的递归关系\n\n## **背包问题**\n\n*问题描述：假设我们有n种类型的物品，分别编号为1, 2...n。其中编号为i的物品价值为vi，它的重量为wi。为了简化问题，假定价值和重量都是整数值。现在，假设我们有一个背包，它能够承载的重量是Cap。现在，我们希望往包里装这些物品，使得包里装的物品价值最大化，那么我们该如何来选择装的东西呢？注意：每种物品只有一件，可以选择放或者不放。初始化数据为：n=5，w={2,2,6,5,4}，v={6,3,5,4,6}，Cap=10*\n\n解法如下：\n\n1. 描述最优解的结构\n\n设子问题：f[i][v]表示允许前i件物品放入容量为v的背包时可以获得的最大价值。注：这里的i从0到5，v从0到10\n\n为了能够得到已经计算过的，更小规模的子问题，我们可以根据当前限重来只考虑第i件物品放或者不放，那么就可以转化为涉及前i-1件物品的问题，\n\n```python\n#n：物品件数；c:最大承重为c的背包；w:各个物品的重量；v:各个物品的价值\n#第一步建立最大价值矩阵(横坐标表示[0,c]整数背包承重):(n+1)*(c+1)\n#技巧:python 生成二维数组(数组)通常先生成列再生成行\ndef bag(n,c,w,p)：\n    res=[[-1 for j in range(c+1)]for i in range(n+1)]\n    for j in range(c+1):\n        #第0行全部赋值为0，物品编号从1开始.为了下面赋值方便\n        res[0][j]=0\n    for i in range(1:n+1):\n        for j in range(1:c+1):\n            res[i][j]=res[i-1][j]\n            #生成了n*c有效矩阵，以下公式w[i-1],p[i-1]代表从第一个元素w[0],p[0]开始取。\n            if(j>=w[i-1]) and res[i-1][j-w[i-1]]+p[i-1]>res[i][j]：\n                res[i][j]=res[i-1][j-w[i-1]]+p[i-1]\n    return res\n#以下代码功能：标记出有放入背包的物品\n#反过来标记，在相同价值情况下，后一件物品比前一件物品的最大价值大，则表示物品i#有被加入到背包，x数组设置为True。设初始为j=c。\ndef show(n,c,w,res):  \n    print('最大价值为:',res[n][c])  \n    x=[False for i in range(n)]  \n    j=c  \n    for i in range(1,n+1):  \n        if res[i][j]>res[i-1][j]:  \n            x[i-1]=True  \n            j-=w[i-1]  \n    print '选择的物品为:'  \n    for i in range(n):  \n        if x[i]:  \n            print '第',i,'个,' \n    print'' \nif __name__=='__main__':  \n    n=5  \n    c=10  \n    w=[2,2,6,5,4]  \n    p=[6,3,5,4,6]  \n    res=bag(n,c,w,p)  \n    show(n,c,w,res)\n```\n","tags":["算法"],"categories":["算法"]},{"title":"Go六个常用的接口的使用","url":"/2023/07/30/Go六个常用的接口的使用/","content":"\n## fmt.Stringer\n\n在开发过程，我们经常会调用`fmt`包下的打印函数(如`println`或`printf`)将调试信息输出到控制台：\n\n```go\nfmt.Println(\"test\")\nfmt.Printf(\"%d\\n\",10)\n```\n\n这些打印函数会自动决定如何在控制台输出这些信息，对于自定义类型，如果我们想自定义其在控制台的输出，要怎么做呢？\n\n`fmt`包的`Stringer`用于定义类型的格式化输出，该接口的定义如下：\n\n```go\ntype Stringer interface {\n    String() string\n}\n```\n\n对于实现了`Stringer`接口的类型，打印函数会自动调用该类型的`String()`方法，将该方法的返回值输出到控制台，比如我们自定义一个`Reason`类型，用于表示季节：\n\n```go\npackage main \n\ntype Reason uint\n\nconst (\n\tSPRING Reason = iota + 1\n\tSUMMER\n\tAUTUMN\n\tWINTER\n)\n\nfunc main() {\n\tfmt.Println(SPRING) //输出：1\n    fmt.Println(SUMMER) //输出：2\n  \tfmt.Println(AUTUMN) //输出：3\n  \tfmt.Println(WINTER) //输出：4\n}\n```\n\n实现Stringer接口后，就可以将`Reason`类以中文的格式打印出来了：\n\n```go\nfunc (r Reason) String() string {\n\treturn ReasonText[r] //自定义输出：将数值转化为文本\n}\n\nvar ReasonText = map[Reason]string{\n\tSPRING: \"春天\",\n\tSUMMER: \"夏天\",\n\tAUTUMN: \"秋天\",\n\tWINTER: \"冬天\",\n}\n\nfunc main() {\n\tfmt.Println(SPRING) //输出：春天\n  fmt.Println(SUMMER) //输出：夏天\n  fmt.Println(AUTUMN) //输出：秋天\n  fmt.Println(WINTER) //输出：冬天\n}\n```\n\n## sort.Interface\n\n除了格式化输出信息外，排序功能也是开发中经常用到的，`Go`标准库的`sort`包的`Sort()`就是常用的排序函数，该函数定义如下：\n\n```go\nfunc Sort(data Interface) {\n\tn := data.Len()\n\tquickSort(data, 0, n, maxDepth(n))\n}\n```\n\n可以看到，`Sort`函数接收一个`Inferface`类型的参数，`Interface`类型是一个接口，其定义如下：\n\n```go\ntype Interface interface {\n    Len() int\n    Less(i, j int) bool\n    Swap(i, j int)\n}\n```\n\n`Interface`类型的`Len`方法用于返回长度，`Less`方法用于元素比较大小，`Swap`方法实现元素位置交换，任何拥有这个方法的类型，都可以传递给`sort.Sort`进行排序。\n\n下面是一个实现`sort.Interface`接口，并调用`sort.Sort`函数的示例：\n\n```go\npackage main\n\nimport (\n\t\"fmt\"\n\t\"sort\"\n)\n\ntype Student struct {\n\tID    int\n\tName  string\n\tScore int\n}\n\ntype Students []Student\n\nfunc (s Students) Len() int {\n\treturn len(s)\n}\nfunc (s Students) Less(i, j int) bool {\n\treturn s[i].Score > s[j].Score\n}\nfunc (s Students) Swap(i, j int) {\n\ts[i], s[j] = s[j], s[i]\n}\n\nfunc main() {\n\tstudents := []Student{\n    {ID: 1, Name: \"A\", Score: 95},\n\t\t{ID: 2, Name: \"B\", Score: 100},\n\t\t{ID: 3, Name: \"C\", Score: 90},\n    {ID: 4, Name: \"D\", Score: 80},             \n\t}\n\tsort.Sort(Students(students))\n\tfmt.Println(students)\n}\n```\n\n## io.Reader和io.Writer\n\n网络数据的读取与发送、文件的读取与写入，本质都是写入或取出一段字节数据(即字节数组)，Go标准库对字节的读取与写入抽象为`io`包的`Reader`和`Writer`接口：\n\n```go\ntype Reader interface {\n\tRead(p []byte) (n int, err error)\n}\n\ntype Writer interface {\n\tWrite(p []byte) (n int, err error)\n}\n```\n\n在Go标准库内有很多实现了`io.Reader`和`io.Writer`接口，比如`os.File`或者`Response.Boy`:\n\n```go\npackage main\n\nimport (\n\t\"io\"\n\t\"net/http\"\n\t\"os\"\n)\n\nfunc main() {\n\turl := \"\"\n\tresponse, err := http.Get(url)\n\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\t//os.Stdout是os.File类型\n\tio.Copy(os.Stdout, response.Body)\n}\n```\n\n上面我们调用`io.Copy`方法将请求到的数据输出到控制台，`io.Copy`函数定义如下：\n\n```go\nfunc Copy(dst Writer, src Reader) (written int64, err error) {\n\treturn copyBuffer(dst, src, nil)\n}\n```\n\n可以看到这个方法接收的参数就是`Writer`和`Reader`接口，我们也可以自定义类型来实现`Writer`或者`Reader`接口：\n\n```go\npackage main\n\nimport (\n\t\"fmt\"\n\t\"io\"\n\t\"net/http\"\n)\n\ntype Data string\n\nfunc (d *Data) Write(p []byte) (n int, err error) {\n\tn = len(p)\n\t*d = Data(string(p))\n\treturn n, nil\n}\n\nfunc main() {\n\turl := \"\"\n\tresponse, err := http.Get(url)\n\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\tvar d Data\n\tio.Copy(&d, response.Body)\n\tfmt.Println(d)\n}\n```\n\n## error\n\n`Go`语言的函数支持多个返回值，一般推荐把`error`类型作为函数最后一个返回值，用于告诉调用者函数调用是否发生错误，`error`类型实际上就是一个接口：\n\n```go\ntype error interface {\n    Error() string\n}\n```\n\n可以看到`error`只定义了一个方法，该方法返回一个字符串的错误信息，我们可以使用`errors`包的方法创建并返回一个`error`类型：\n\n```go\nvar err error = errors.New(\"Not Found\")\n```\n\n也可以在实现`error`接口的基础，包含更多的错误信息，方便调用者判断错误类型：\n\n```go\npackage main\n\nimport (\n\t\"fmt\"\n\t\"os\"\n)\n\ntype FileNotFound struct {\n\tMessage  string\n\tFileName string\n\terr      error\n}\n\nfunc (f FileNotFound) Error() string {\n\treturn f.Message\n}\n\nfunc GetLogFile(fileName string) (*os.File, error) {\n\tf, err := os.Open(fileName)\n\tif err != nil {\n\t\treturn nil, &FileNotFound{FileName: fileName, err: err, Message: \"Not found\"}\n\t}\n\treturn f, nil\n}\n\nfunc main() {\n\tvar err error\n\tf, err = GetLogFile(\"1.txt\")\n\n\tif e, ok := err.(FileNotFound); ok {\n\t\tfmt.Println(e.Message)\n\t}\n}\n```\n\n## http.Handler\n\n`http`包的`Handler`接口定义如下，该接口定义了处理`HTTP`请求应该实现的方法。\n\n```go\ntype Handler interface {\n    ServeHTTP(w ResponseWriter, r *Request)\n}\n```\n\n在`Go`语言中，只需要简单的几行代码便可以启动一个`Web`服务器：\n\n```go\npackage main\n\nimport \"net/http\"\n\nfunc main() {\n\thttp.HandleFunc(\"/user\", func(w http.ResponseWriter, r *http.Request) {\n\t\tw.Write([]byte(\"User Info\"))\n\t})\n\thttp.ListenAndServe(\":8080\", nil)\n}\n```\n\n`http.HandleFunc()`会将我们自己的匿名函数封装为`HandlerFunc`函数，`HandlerFunc`函数的定义如下，可以看到这个函数实现了`Handler`接口：\n\n```go\ntype HandlerFunc func(ResponseWriter, *Request)\n\nfunc (f HandlerFunc) ServeHTTP(w ResponseWriter, r *Request) {\n\tf(w, r)\n}\n```\n","tags":["go"],"categories":["go"]},{"title":"golang的函数定义和使用","url":"/2023/07/29/golang的函数定义和使用/","content":"\n## 函数的申明\n\nGo语言里的函数可分为两种：\n\n1. 带名字的叫普通函数\n2. 没带名字的叫匿名函数\n\n使用`func`关键字，后面一次接`函数名`，`参数列表`，`返回值列表`，`用{}包裹的代码块`\n\n```go\nfunc 函数名(形式参数列表)(返回值列表){\n    函数体\n}\n```\n\n## 函数的可变参数\n\n### 多个类型一致的参数\n\n```go\n// 使用 ...类型，表示一个元素为int类型的切片\nfunc TestParams(args ...string) {\n  fmt.Printf(\"args: %v\\n\", args)\n}\n\n\nfunc main() {\n  type_func.TestParams(\"A\", \"B\", \"C\")\n  type_func.TestParams(\"A\", \"B\", \"C\", \"D\")\n  // args: [A B C]\n  // args: [A B C D]\n}\n```\n\n`...` 是 Go 语言为了方便程序员写代码而实现的语法糖，如果该函数下有多个类型的参数，这个语法糖必须得是最后一个参数。\n\n这个语法糖，只能在定义函数时使用。\n\n### 多个类型不一致的参数\n\n上面的例子中，我们的参数类型都为string，如果你希望多个参数切这些参数的类型都不一样，可以指定类型`...interface{}`，然后再遍历。\n\n下面代码使用之前说过的`switch`和`arg.(type)`来演示不一致参数的情况。\n\n```go\nfunc main() {\n  var v1 int = 1\n  var v2 int64 = 234\n  var v3 string = \"hello\"\n  var v4 float32 = 1.234\n  PrintType(v1, v2, v3, v4)\n}\n\nfunc PrintType(args ...interface{}) {\n  for _, arg := range args {\n    switch arg.(type) {\n    case int:\n      fmt.Println(arg, \"is an int value.\")\n    case string:\n      fmt.Println(arg, \"is a string value.\")\n    case int64:\n      fmt.Println(arg, \"is an int64 value.\")\n    default:\n      fmt.Println(arg, \"is an unknown type.\")\n    }\n  }\n}\n```\n\n## 函数传递可变参数\n\n上面提到了可以使用 `...` 来接收多个参数，除此之外，它还有一个用法，就是用来解序列，将函数的可变参数（一个切片）一个一个取出来，传递给另一个可变参数的函数，而不是传递可变参数变量本身。\n\n这个方法，只能再给函数传递参数的时候使用，这两个是成对出现的。\n\n```go\nfunc main() {\n\n  args := []int{1, 2, 3, 4}\n  test(args...)\n}\n\nfunc test(args ...int) {\n  fmt.Printf(\"args: %v\\n\", args)\n}\n```\n\n## 函数的返回值\n\n函数的返回值是在定义函数的时候就已经确定好了。\n\n一般有两种情况，一种是没有返回值，一种是有。同事Go语言支持返回多个值。\n\n> 当函数没有指定返回值时。函数体可以使用`return`来结束函数的运行，但`return`后不能跟任何东西。\n\nGo返回多个值的函数：\n\n```go\nfunc main() {\n\n  args := []int{1, 2, 3, 4}\n  test(args...)\n\n  number1, number2, string1 := returnTwo()\n\n  fmt.Printf(\"number1: %v\\n\", number1)\n  fmt.Printf(\"number2: %v\\n\", number2)\n  fmt.Printf(\"string1: %v\\n\", string1)\n}\n\nfunc returnTwo() (int, int, string) {\n  return 1, 2, \"111\"\n}\n\n// 结果\nnumber1: 1\nnumber2: 2\nstring1: 111\n```\n\n## 匿名函数\n\n匿名函数，就是没有名字的函数，它只有函数逻辑体。\n\n下面就是一个立即执行的函数。\n\n### 立即执行函数\n\n```go\nfunc(data int) {\n    fmt.Println(\"hello\", data)\n}(100)\n```\n\n### 作为回调函数使用\n\n```go\nfunc main() {\n  excute(func(str string) {\n    print(\"call back\" + str)\n  })\n}\n\nfunc excute(call func(string)) {\n  call(\"123\")\n}\n\n// 结果\ncall back123\n```\n\n这些东西其实在其他语言里也有同样的概念，想`JS`里面的匿名函数\n\n### 函数作为变量\n\n在Go里面函数，也有和JS一样的用法和概念，比如将函数赋值给变量，临时性死区等。\n\n下面是将函数赋值给变量的方式。\n\n```go\nfunc main() {\n  // func1()  // 不删除会形成临时死区\n  var func1 = func() {\n    print(\"success!!!!\")\n  }\n  func1()\n}\n  // 结果\n  success!!!!\n```\n\n然后换种方式\n\n```go\nfunc main() {\n  func1()  // 不删除会形成临时死区\n  var func1 = func() {\n    print(\"success!!!!\")\n  }\n}\n```\n\n执行时会报错`.\\main.go:20:2: undefined: func1`。原因是将匿名函数赋值给变量之后，在定义`func1`前的代码是找不到这个变量的.\n\n## 函数和方法\n\n在看其他代码的时候有时候会出现像这样定义函数：\n\n```go\nfunc main() {\n  person1 := Person{\"my name\"}\n  person1.printName()\n}\n\n// 定义一个名为Person的结构体\ntype Person struct {\n  name string\n}\n\n// 定义一个与Person绑定的方法\nfunc (p Person) printName() {\n  fmt.Print(p.name)\n}\n\n// go run main.go后的结果\nmy name\n```\n\n像这种定义函数的其实是Go里面的方法，给结构体定义方法。通过函数名称前的` (p Person)`，与结构体进行绑定。\n\n方法，是一种特殊的函数。当你一个函数和对象/结构体进行绑定的时候，我们就称这个函数是一个方法。\n","tags":["go"],"categories":["go"]},{"title":"gin框架学习","url":"/2023/07/29/gin框架学习/","content":"\n## 创建Engine\n在gin框架中，Engine被定义成为一个结构体，Engine代表gin框架的一个结构体定义，其中包含了路由组、中间件、页面渲染接口、框架配置设置等相关内容。\n\n默认的Engine可以通过**gin.Default**进行创建，或者使用gin.New()同样可以创建。两种方式如下所示：\n\n```go\nengine1 = gin.Default()\nengine2 = gin.New()\n//gin.Default()和gin.New()的区别在于：\n//gin.Default也使用gin.New()创建engine实例，但是会默认使用Logger和Recovery中间件。\n//Logger是负责进行打印并输出日志的中间件，方便开发者进行程序调试。Recovery中间件的作用是如果程序执行过程中遇到panic中断了服务，则Recovery会恢复程序执行，并返回服务器500内部错误。\n```\n\n通常情况下，我们使用默认的gin.Default创建Engine实例。\n\n运行Engine\n\n```go\n engine1.Run([主机地址:端口号])\n// 例如:\n// 不带参数，默认主机地址为localhost，默认端口为8080\nengine1.Run()\n// 带参数，主机地址为apphost，端口为8090\nengine1.Run(\"apphost:8090\")\n```\n\n## 处理HTTP请求\n在上面我们创建的engine实例中，包含很多方法可以直接处理不同类型的HTTP请求。\n\n### HTTP请求类型\n\nhttp协议中一共定义了八种方法或者称之为类型来表明对请求网络资源（Request-URI）的不同的操作方式，分别是：`OPTIONS、HEAD、GET、POST、PUT、DELETE、TRACE、CONNECT`。\n\n虽然一共有八种请求操作类型，但是实际开发中常用的就：`GET、POST、DELETE`等几种。\n\n### Context-上下文\n\nContext是gin框架中封装的一个结构体，这是gin框架中最重要，最基础的一个结构体对象。\n\n该结构体可以提供我们操作请求，处理请求，获取数据等相关的操作，通常称之为上下文对象，简单说为我们提供操作环境。\n\n可以通过`context.Query和context.DefaultQuery`获取GET请求携带的参数。\n\n可以通过`context.Writer.Write`向请求发起端返回数据。\n\n\n### 通用处理\n\nengine中可以直接进行HTTP请求的处理，在engine中使用Handle方法进行http请求的处理。Handle方法包含三个参数，具体如下所示：\n\n```go\nfunc (group *RouterGroup) Handle(httpMethod, relativePath string, handlers ...HandlerFunc) IRoutes\n```\n\n- `httpMethod`：第一个参数表示要处理的HTTP的请求类型，是GET、POST、DELETE等8种请求类型中的一种- \n- `relativePath`：第二个参数表示要解析的接口，由开发者进行定义。\n- `handlers`：第三个参数是处理对应的请求的代码的定义。\n\n**Handle处理GET请求**\n\n```go\n...\n// 通过Handle方法第一个参数指定处理GET类型的请求，解析的接口是/hello\n// url:http://localhost:8080/hello?name=syb\n// GET请求附带的参数在url中的?后面\nengine.Handle(\"GET\", \"/hello\", func(context *gin.Context) {\n    // 获取请求接口\n    fmt.Println(context.FullPath())\n    // 获取字符串参数\n    name := context.DefaultQuery(\"name\", \"\")\n    fmt.Println(name)\n\n    // 返回给前端输出\n    context.Writer.Write([]byte(\"Hello ,\" + name))\n})\n...\n\n```\n\n`context.FullPath()`：**返回请求接口地址。**上述代码返回的是\"/hello\"。\n\n`context.DefaultQuery(key(string), defaultValue(string))`：**读取GET请求附带的参数。**第一个参数指定要读取的参数的键值key，第二个参数是若读取不到要返回的默认字符串。\n\n`context.Writer.Write(([]byte))`：**给前端返回数据。**数据类型是byte字符数组。\n\n**Handle处理POST请求**\n\n```go\n\n...\n// 通过Handle方法第一个参数指定处理POST类型的请求，解析的接口是/login\n// url:http://localhost:8080/login\nengine.Handle(\"POST\", \"/login\", func(context *gin.Context) {\n\n    fmt.Println(context.FullPath())\n    // 读取用户名\n    username := context.PostForm(\"username\")\n    fmt.Println(username)\n\n    // 读取用户密码\n    password := context.PostForm(\"pwd\")\n    fmt.Println(password)\n\n    context.Writer.Write([]byte(\"User login\"))\n})\n...\n\n```\n\n`context.PostForm(key(string))`：**读取POST请求附带的参数。**参数指定要读取的参数的键值key。\n","tags":["go","gin"],"categories":["go"]},{"title":"常用正则表达式","url":"/2023/07/28/常用正则表达式/","content":"\n# 常用正则表达式\n\n## 一、校验数字的表达式\n\n\n\n1. 数字：^[0-9]*$\n2. n位的数字：^\\d{n}$\n3. 至少n位的数字：^\\d{n,}$\n4. m-n位的数字：^\\d{m,n}$\n5. 零和非零开头的数字：^(0|[1-9][0-9]*)$\n6. 非零开头的最多带两位小数的数字：^([1-9][0-9]*)+(.[0-9]{1,2})?$\n7. 带1-2位小数的正数或负数：^(\\-)?\\d+(\\.\\d{1,2})?$\n8. 正数、负数、和小数：^(\\-|\\+)?\\d+(\\.\\d+)?$\n9. 有两位小数的正实数：^[0-9]+(.[0-9]{2})?$\n10. 有1~3位小数的正实数：^[0-9]+(.[0-9]{1,3})?$\n11. 非零的正整数：^[1-9]\\d*$ 或 ^([1-9][0-9]*){1,3}$ 或 ^\\+?[1-9][0-9]*$\n12. 非零的负整数：^\\-[1-9][]0-9\"*$ 或 ^-[1-9]\\d*$\n13. 非负整数：^\\d+$ 或 ^[1-9]\\d*|0$\n14. 非正整数：^-[1-9]\\d*|0$ 或 ^((-\\d+)|(0+))$\n15. 非负浮点数：^\\d+(\\.\\d+)?$ 或 ^[1-9]\\d*\\.\\d*|0\\.\\d*[1-9]\\d*|0?\\.0+|0$\n16. 非正浮点数：^((-\\d+(\\.\\d+)?)|(0+(\\.0+)?))$ 或 ^(-([1-9]\\d*\\.\\d*|0\\.\\d*[1-9]\\d*))|0?\\.0+|0$\n17. 正浮点数：^[1-9]\\d*\\.\\d*|0\\.\\d*[1-9]\\d*$ 或 ^(([0-9]+\\.[0-9]*[1-9][0-9]*)|([0-9]*[1-9][0-9]*\\.[0-9]+)|([0-9]*[1-9][0-9]*))$\n18. 负浮点数：^-([1-9]\\d*\\.\\d*|0\\.\\d*[1-9]\\d*)$ 或 ^(-(([0-9]+\\.[0-9]*[1-9][0-9]*)|([0-9]*[1-9][0-9]*\\.[0-9]+)|([0-9]*[1-9][0-9]*)))$\n19. 浮点数：^(-?\\d+)(\\.\\d+)?$ 或 ^-?([1-9]\\d*\\.\\d*|0\\.\\d*[1-9]\\d*|0?\\.0+|0)$\n\n \n\n \n\n## 二、校验字符的表达式\n\n \n\n1. 汉字：^[\\u4e00-\\u9fa5]{0,}$\n2. 英文和数字：^[A-Za-z0-9]+$ 或 ^[A-Za-z0-9]{4,40}$\n3. 长度为3-20的所有字符：^.{3,20}$\n4. 由26个英文字母组成的字符串：^[A-Za-z]+$\n5. 由26个大写英文字母组成的字符串：^[A-Z]+$\n6. 由26个小写英文字母组成的字符串：^[a-z]+$\n7. 由数字和26个英文字母组成的字符串：^[A-Za-z0-9]+$\n8. 由数字、26个英文字母或者下划线组成的字符串：^\\w+$ 或 ^\\w{3,20}$\n9. 中文、英文、数字包括下划线：^[\\u4E00-\\u9FA5A-Za-z0-9_]+$\n10. 中文、英文、数字但不包括下划线等符号：^[\\u4E00-\\u9FA5A-Za-z0-9]+$ 或 ^[\\u4E00-\\u9FA5A-Za-z0-9]{2,20}$\n11. 可以输入含有^%&',;=?$\\\"等字符：[^%&',;=?$\\x22]+ 12 禁止输入含有~的字符：[^~\\x22]+\n\n \n\n**其它：**\n\n.*匹配除 \\n 以外的任何字符。\n\n/[\\u4E00-\\u9FA5]/ 汉字\n\n/[\\uFF00-\\uFFFF]/ 全角符号\n\n/[\\u0000-\\u00FF]/ 半角符号\n\n \n\n## 三、特殊需求表达式\n\n \n\n1. Email地址：^\\w+([-+.]\\w+)*@\\w+([-.]\\w+)*\\.\\w+([-.]\\w+)*$\n2. 域名：[a-zA-Z0-9][-a-zA-Z0-9]{0,62}(/.[a-zA-Z0-9][-a-zA-Z0-9]{0,62})+/.?\n3. InternetURL：[a-zA-z]+://[^\\s]* 或 ^http://([\\w-]+\\.)+[\\w-]+(/[\\w-./?%&=]*)?$\n4. 手机号码：^(13[0-9]|14[5|7]|15[0|1|2|3|5|6|7|8|9]|18[0|1|2|3|5|6|7|8|9])\\d{8}$\n5. 电话号码(\"XXX-XXXXXXX\"、\"XXXX-XXXXXXXX\"、\"XXX-XXXXXXX\"、\"XXX-XXXXXXXX\"、\"XXXXXXX\"和\"XXXXXXXX)：^(\\(\\d{3,4}-)|\\d{3.4}-)?\\d{7,8}$\n6. 国内电话号码(0511-4405222、021-87888822)：\\d{3}-\\d{8}|\\d{4}-\\d{7}\n7. 身份证号(15位、18位数字)：^\\d{15}|\\d{18}$\n8. 短身份证号码(数字、字母x结尾)：^([0-9]){7,18}(x|X)?$ 或 ^\\d{8,18}|[0-9x]{8,18}|[0-9X]{8,18}?$\n9. 帐号是否合法(字母开头，允许5-16字节，允许字母数字下划线)：^[a-zA-Z][a-zA-Z0-9_]{4,15}$\n10. 密码(以字母开头，长度在6~18之间，只能包含字母、数字和下划线)：^[a-zA-Z]\\w{5,17}$\n11. 强密码(必须包含大小写字母和数字的组合，不能使用特殊字符，长度在8-10之间)：^(?=.*\\d)(?=.*[a-z])(?=.*[A-Z]).{8,10}$\n12. 日期格式：^\\d{4}-\\d{1,2}-\\d{1,2}\n13. 一年的12个月(01～09和1～12)：^(0?[1-9]|1[0-2])$\n14. 一个月的31天(01～09和1～31)：^((0?[1-9])|((1|2)[0-9])|30|31)$\n15. 钱的输入格式：\n16. 1.有四种钱的表示形式我们可以接受:\"10000.00\" 和 \"10,000.00\", 和没有 \"分\" 的 \"10000\" 和 \"10,000\"：^[1-9][0-9]*$\n17. 2.这表示任意一个不以0开头的数字,但是,这也意味着一个字符\"0\"不通过,所以我们采用下面的形式：^(0|[1-9][0-9]*)$\n18. 3.一个0或者一个不以0开头的数字.我们还可以允许开头有一个负号：^(0|-?[1-9][0-9]*)$\n19. 4.这表示一个0或者一个可能为负的开头不为0的数字.让用户以0开头好了.把负号的也去掉,因为钱总不能是负的吧.下面我们要加的是说明可能的小数部分：^[0-9]+(.[0-9]+)?$\n20. 5.必须说明的是,小数点后面至少应该有1位数,所以\"10.\"是不通过的,但是 \"10\" 和 \"10.2\" 是通过的：^[0-9]+(.[0-9]{2})?$\n21. 6.这样我们规定小数点后面必须有两位,如果你认为太苛刻了,可以这样：^[0-9]+(.[0-9]{1,2})?$\n22. 7.这样就允许用户只写一位小数.下面我们该考虑数字中的逗号了,我们可以这样：^[0-9]{1,3}(,[0-9]{3})*(.[0-9]{1,2})?$\n\n23 8.1到3个数字,后面跟着任意个 逗号+3个数字,逗号成为可选,而不是必须：^([0-9]+|[0-9]{1,3}(,[0-9]{3})*)(.[0-9]{1,2})?$\n\n24. 备注：这就是最终结果了,别忘了\"+\"可以用\"*\"替代如果你觉得空字符串也可以接受的话(奇怪,为什么?)最后,别忘了在用函数时去掉去掉那个反斜杠,一般的错误都在这里\n25. xml文件：^([a-zA-Z]+-?)+[a-zA-Z0-9]+\\\\.[x|X][m|M][l|L]$\n26. 中文字符的[正则表达式](https://so.csdn.net/so/search?q=正则表达式&spm=1001.2101.3001.7020)：[\\u4e00-\\u9fa5]\n27. 双字节字符：[^\\x00-\\xff] (包括汉字在内，可以用来计算字符串的长度(一个双字节字符长度计2，ASCII字符计1))\n28. 空白行的正则表达式：\\n\\s*\\r (可以用来删除空白行)\n29. HTML标记的正则表达式：<(\\S*?)[^>]*>.*?</\\1>|<.*? /> (网上流传的版本太糟糕，上面这个也仅仅能部分，对于复杂的嵌套标记依旧无能为力)\n30. 首尾空白字符的正则表达式：^\\s*|\\s*$或(^\\s*)|(\\s*$) (可以用来删除行首行尾的空白字符(包括空格、制表符、换页符等等)，非常有用的表达式)\n31. 腾讯QQ号：[1-9][0-9]{4,} (腾讯QQ号从10000开始)\n32. 中国邮政编码：[1-9]\\d{5}(?!\\d) (中国邮政编码为6位数字)\n33. IP地址：\\d+\\.\\d+\\.\\d+\\.\\d+ (提取IP地址时有用)\n34. IP地址：((?:(?:25[0-5]|2[0-4]\\\\d|[01]?\\\\d?\\\\d)\\\\.){3}(?:25[0-5]|2[0-4]\\\\d|[01]?\\\\d?\\\\d))\n35. IP-v4地址：\\\\b(?:(?:25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)\\\\.){3}(?:25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)\\\\b (提取IP地址时有用)\n36. 校验IP-v6地址:(([0-9a-fA-F]{1,4}:){7,7}[0-9a-fA-F]{1,4}|([0-9a-fA-F]{1,4}:){1,7}:|([0-9a-fA-F]{1,4}:){1,6}:[0-9a-fA-F]{1,4}|([0-9a-fA-F]{1,4}:){1,5}(:[0-9a-fA-F]{1,4}){1,2}|([0-9a-fA-F]{1,4}:){1,4}(:[0-9a-fA-F]{1,4}){1,3}|([0-9a-fA-F]{1,4}:){1,3}(:[0-9a-fA-F]{1,4}){1,4}|([0-9a-fA-F]{1,4}:){1,2}(:[0-9a-fA-F]{1,4}){1,5}|[0-9a-fA-F]{1,4}:((:[0-9a-fA-F]{1,4}){1,6})|:((:[0-9a-fA-F]{1,4}){1,7}|:)|fe80:(:[0-9a-fA-F]{0,4}){0,4}%[0-9a-zA-Z]{1,}|::(ffff(:0{1,4}){0,1}:){0,1}((25[0-5]|(2[0-4]|1{0,1}[0-9]){0,1}[0-9])\\\\.){3,3}(25[0-5]|(2[0-4]|1{0,1}[0-9]){0,1}[0-9])|([0-9a-fA-F]{1,4}:){1,4}:((25[0-5]|(2[0-4]|1{0,1}[0-9]){0,1}[0-9])\\\\.){3,3}(25[0-5]|(2[0-4]|1{0,1}[0-9]){0,1}[0-9]))\n37. 子网掩码：((?:(?:25[0-5]|2[0-4]\\\\d|[01]?\\\\d?\\\\d)\\\\.){3}(?:25[0-5]|2[0-4]\\\\d|[01]?\\\\d?\\\\d))\n38. 校验日期:^(?:(?!0000)[0-9]{4}-(?:(?:0[1-9]|1[0-2])-(?:0[1-9]|1[0-9]|2[0-8])|(?:0[13-9]|1[0-2])-(?:29|30)|(?:0[13578]|1[02])-31)|(?:[0-9]{2}(?:0[48]|[2468][048]|[13579][26])|(?:0[48]|[2468][048]|[13579][26])00)-02-29)$(“yyyy-mm-dd“ 格式的日期校验，已考虑平闰年。)\n39. 抽取注释：<!--(.*?)-->\n40. 查找CSS属性:^\\\\s*[a-zA-Z\\\\-]+\\\\s*[:]{1}\\\\s[a-zA-Z0-9\\\\s.#]+[;]{1}\n41. 提取页面超链接:(<a\\\\s*(?!.*\\\\brel=)[^>]*)(href=\"https?:\\\\/\\\\/)((?!(?:(?:www\\\\.)?'.implode('|(?:www\\\\.)?', $follow_list).'))[^\" rel=\"external nofollow\" ]+)\"((?!.*\\\\brel=)[^>]*)(?:[^>]*)>\n42. 提取网页图片:\\\\< *[img][^\\\\\\\\>]*[src] *= *[\\\\\"\\\\']{0,1}([^\\\\\"\\\\'\\\\ >]*)\n43. 提取网页颜色代码:^#([A-Fa-f0-9]{6}|[A-Fa-f0-9]{3})$\n44. 文件扩展名效验:^([a-zA-Z]\\\\:|\\\\\\\\)\\\\\\\\([^\\\\\\\\]+\\\\\\\\)*[^\\\\/:*?\"<>|]+\\\\.txt(l)?$\n45. 判断IE版本：^.*MSIE [5-8](?:\\\\.[0-9]+)?(?!.*Trident\\\\/[5-9]\\\\.0).*$\n\n \n\n| 元字符       | 描述                                                         |\n| ------------ | ------------------------------------------------------------ |\n| \\            | 将下一个字符标记符、或一个向后引用、或一个八进制转义符。例如，“\\\\n”匹配\\n。“\\n”匹配换行符。序列“\\\\”匹配“\\”而“\\(”则匹配“(”。即相当于多种编程语言中都有的“转义字符”的概念。 |\n| ^            | 匹配输入字行首。如果设置了RegExp对象的Multiline属性，^也匹配“\\n”或“\\r”之后的位置。 |\n| $            | 匹配输入行尾。如果设置了RegExp对象的Multiline属性，$也匹配“\\n”或“\\r”之前的位置。 |\n| *            | 匹配前面的子表达式任意次。例如，zo*能匹配“z”，也能匹配“zo”以及“zoo”。*等价于{0,}。 |\n| +            | 匹配前面的子表达式一次或多次(大于等于1次）。例如，“zo+”能匹配“zo”以及“zoo”，但不能匹配“z”。+等价于{1,}。 |\n| ?            | 匹配前面的子表达式零次或一次。例如，“do(es)?”可以匹配“do”或“does”。?等价于{0,1}。 |\n| {*n*}        | *n*是一个非负整数。匹配确定的*n*次。例如，“o{2}”不能匹配“Bob”中的“o”，但是能匹配“food”中的两个o。 |\n| {*n*,}       | *n*是一个非负整数。至少匹配*n*次。例如，“o{2,}”不能匹配“Bob”中的“o”，但能匹配“foooood”中的所有o。“o{1,}”等价于“o+”。“o{0,}”则等价于“o*”。 |\n| {*n*,*m*}    | *m*和*n*均为非负整数，其中*n*<=*m*。最少匹配*n*次且最多匹配*m*次。例如，“o{1,3}”将匹配“fooooood”中的前三个o为一组，后三个o为一组。“o{0,1}”等价于“o?”。请注意在逗号和两个数之间不能有空格。 |\n| ?            | 当该字符紧跟在任何一个其他限制符（*,+,?，{*n*}，{*n*,}，{*n*,*m*}）后面时，匹配模式是非贪婪的。非贪婪模式尽可能少地匹配所搜索的字符串，而默认的贪婪模式则尽可能多地匹配所搜索的字符串。例如，对于字符串“oooo”，“o+”将尽可能多地匹配“o”，得到结果[“oooo”]，而“o+?”将尽可能少地匹配“o”，得到结果 ['o', 'o', 'o', 'o'] |\n| .点          | 匹配除“\\n”和\"\\r\"之外的任何单个字符。要匹配包括“\\n”和\"\\r\"在内的任何字符，请使用像“[\\s\\S]”的模式。 |\n| (pattern)    | 匹配pattern并获取这一匹配。所获取的匹配可以从产生的Matches集合得到，在VBScript中使用SubMatches集合，在JScript中则使用$0…$9属性。要匹配圆括号字符，请使用“”或“”或“”。 |\n| (?:pattern)  | 非获取匹配，匹配pattern但不获取匹配结果，不进行存储供以后使用。这在使用或字符“(\\|)”来组合一个模式的各个部分时很有用。例如“industr(?:y\\|ies)”就是一个比“industry\\|industries”更简略的表达式。 |\n| (?=pattern)  | 非获取匹配，正向肯定预查，在任何匹配pattern的字符串开始处匹配查找字符串，该匹配不需要获取供以后使用。例如，“Windows(?=95\\|98\\|NT\\|2000)”能匹配“Windows2000”中的“Windows”，但不能匹配“Windows3.1”中的“Windows”。预查不消耗字符，也就是说，在一个匹配发生后，在最后一次匹配之后立即开始下一次匹配的搜索，而不是从包含预查的字符之后开始。 |\n| (?!pattern)  | 非获取匹配，正向否定预查，在任何不匹配pattern的字符串开始处匹配查找字符串，该匹配不需要获取供以后使用。例如“Windows(?!95\\|98\\|NT\\|2000)”能匹配“Windows3.1”中的“Windows”，但不能匹配“Windows2000”中的“Windows”。 |\n| (?<=pattern) | 非获取匹配，反向肯定预查，与正向肯定预查类似，只是方向相反。例如，“(?<=95\\|98\\|NT\\|2000)Windows”能匹配“2000Windows”中的“Windows”，但不能匹配“3.1Windows”中的“Windows”。*python的正则表达式没有完全按照正则表达式规范实现，所以一些高级特性建议使用其他语言如java、scala等 |\n| (?<!patte_n) | 非获取匹配，反向否定预查，与正向否定预查类似，只是方向相反。例如“(?<!95\\|98\\|NT\\|2000)Windows”能匹配“3.1Windows”中的“Windows”，但不能匹配“2000Windows”中的“Windows”。*python的正则表达式没有完全按照正则表达式规范实现，所以一些高级特性建议使用其他语言如java、scala等 |\n| x\\|y         | 匹配x或y。例如，“z\\|food”能匹配“z”或“food”(此处请谨慎)。“[z\\|f]ood”则匹配“zood”或“food”。 |\n| [xyz]        | 字符集合。匹配所包含的任意一个字符。例如，“[abc]”可以匹配“plain”中的“a”。 |\n| [^xyz]       | 负值字符集合。匹配未包含的任意字符。例如，“[^abc]”可以匹配“plain”中的“plin”任一字符。 |\n| [a-z]        | 字符范围。匹配指定范围内的任意字符。例如，“[a-z]”可以匹配“a”到“z”范围内的任意小写字母字符。注意:只有连字符在字符组内部时,并且出现在两个字符之间时,才能表示字符的范围; 如果出字符组的开头,则只能表示连字符本身. |\n| [^a-z]       | 负值字符范围。匹配任何不在指定范围内的任意字符。例如，“[^a-z]”可以匹配任何不在“a”到“z”范围内的任意字符。 |\n| \\b           | 匹配一个单词的边界，也就是指单词和空格间的位置（即正则表达式的“匹配”有两种概念，一种是匹配字符，一种是匹配位置，这里的\\b就是匹配位置的）。例如，“er\\b”可以匹配“never”中的“er”，但不能匹配“verb”中的“er”；“\\b1_”可以匹配“1_23”中的“1_”，但不能匹配“21_3”中的“1_”。 |\n| \\B           | 匹配非单词边界。“er\\B”能匹配“verb”中的“er”，但不能匹配“never”中的“er”。 |\n| \\cx          | 匹配由x指明的控制字符。例如，\\cM匹配一个Control-M或回车符。x的值必须为A-Z或a-z之一。否则，将c视为一个原义的“c”字符。 |\n| \\d           | 匹配一个数字字符。等价于[0-9]。grep 要加上-P，perl正则支持   |\n| \\D           | 匹配一个非数字字符。等价于[^0-9]。grep要加上-P，perl正则支持 |\n| \\f           | 匹配一个换页符。等价于\\x0c和\\cL。                            |\n| \\n           | 匹配一个换行符。等价于\\x0a和\\cJ。                            |\n| \\r           | 匹配一个回车符。等价于\\x0d和\\cM。                            |\n| \\s           | 匹配任何不可见字符，包括空格、制表符、换页符等等。等价于[ \\f\\n\\r\\t\\v]。 |\n| \\S           | 匹配任何可见字符。等价于[^ \\f\\n\\r\\t\\v]。                     |\n| \\t           | 匹配一个制表符。等价于\\x09和\\cI。                            |\n| \\v           | 匹配一个垂直制表符。等价于\\x0b和\\cK。                        |\n| \\w           | 匹配包括下划线的任何单词字符。类似但不等价于“[A-Za-z0-9_]”，这里的\"单词\"字符使用Unicode字符集。 |\n| \\W           | 匹配任何非单词字符。等价于“[^A-Za-z0-9_]”。                  |\n| \\x*n*        | 匹配*n*，其中*n*为十六进制转义值。十六进制转义值必须为确定的两个数字长。例如，“\\x41”匹配“A”。“\\x041”则等价于“\\x04&1”。正则表达式中可以使用ASCII编码。 |\n| \\*num*       | 匹配*num*，其中*num*是一个正整数。对所获取的匹配的引用。例如，“(.)\\1”匹配两个连续的相同字符。 |\n| \\*n*         | 标识一个八进制转义值或一个向后引用。如果\\*n*之前至少*n*个获取的子表达式，则*n*为向后引用。否则，如果*n*为八进制数字（0-7），则*n*为一个八进制转义值。 |\n| \\*nm*        | 标识一个八进制转义值或一个向后引用。如果\\*nm*之前至少有*nm*个获得子表达式，则*nm*为向后引用。如果\\*nm*之前至少有*n*个获取，则*n*为一个后跟文字*m*的向后引用。如果前面的条件都不满足，若*n*和*m*均为八进制数字（0-7），则\\*nm*将匹配八进制转义值*nm*。 |\n| \\*nml*       | 如果*n*为八进制数字（0-7），且*m*和*l*均为八进制数字（0-7），则匹配八进制转义值*nml*。 |\n| \\u*n*        | 匹配*n*，其中*n*是一个用四个十六进制数字表示的Unicode字符。例如，\\u00A9匹配版权符号（©）。 |\n| \\p{P}        | 小写 p 是 property 的意思，表示 Unicode 属性，用于 Unicode 正表达式的前缀。中括号内的“P”表示Unicode 字符集七个字符属性之一：标点字符。其他六个属性：L：字母；M：标记符号（一般不会单独出现）；Z：分隔符（比如空格、换行等）；S：符号（比如数学符号、货币符号等）；N：数字（比如阿拉伯数字、罗马数字等）；C：其他字符。**注：此语法部分语言不支持，例：javascript。* |\n| \\<\\>         | 匹配词（word）的开始（\\<）和结束（\\>）。例如正则表达式\\<the\\>能够匹配字符串\"for the wise\"中的\"the\"，但是不能匹配字符串\"otherwise\"中的\"the\"。注意：这个元字符不是所有的软件都支持的。 |\n| ( )          | 将( 和 ) 之间的表达式定义为“组”（group），并且将匹配这个表达式的字符保存到一个临时区域（一个正则表达式中最多可以保存9个），它们可以用 \\1 到\\9 的符号来引用。 |\n| \\|           | 将两个匹配条件进行逻辑“或”（or）运算。例如正则表达式(him\\|her) 匹配\"it belongs to him\"和\"it belongs to her\"，但是不能匹配\"it belongs to them.\"。注意：这个元字符不是所有的软件都支持的。 |\n","tags":["工具"],"categories":["工具"]},{"title":"Angular基础","url":"/2023/07/27/Angular基础/","content":"\n# Angular基础\n\n## 简介\n\nAngular 是一个开发平台，基于 [TypeScript](https://www.typescriptlang.org/)。作为一个平台，Angular 包含了：\n\n- 基于组件的框架，可用于构建可扩展的 Web 应用程序\n- 集成良好的库（library），涵盖各种功能，包括路由、表单管理、客户端——服务器通信等\n- 开发人员工具，可帮助您开发、构建、测试和更新代码\n\n当你用 Angular 搭建一个应用，你正在利用一个可以从单开发人员项目扩展到企业级应用程序的平台。Angular  被设计用来使版本迭代尽可能简单。因此，你可以毫不费力地利用最新成果（developments）。最为重要的是，Angular 的生态系统由多达  170 万的开发人员、库（library）作者和内容创作者构成的多元化群体组成。\n\n## Angular开发环境搭建\n\n#### 脚手架安装\n\nnode安装成功之后，可以使用npm命令安装脚手架\n\n```bash\nnpm install -g @angular/cli  # 装的是最新的版本\nnpm install -g @angular/cli@xx.xx.x # 也可以安装指定版本\n```\n\n#### 创建一个新项目并执行\n\n```bash\nng new project_name  #project_name用户可以自定义项目名\ncd project_name\nng serve\n#浏览器输入http://localhost:4200 便可看到相关页面\n```\n\n### 目录介绍\n\n每个工作区中的所有项目共享同一个 [CLI 配置环境](https://angular.cn/guide/workspace-config)。该工作区的顶层包含着全工作区级的配置文件、根应用的配置文件以及一些包含根应用的源文件和测试文件的子文件夹。\n\n| 工作区配置文件      | 用途                                                         |\n| ------------------- | ------------------------------------------------------------ |\n| `.editorconfig`     | 代码编辑器的配置。参阅 [EditorConfig](https://editorconfig.org)。 |\n| `.gitignore`        | 指定 [Git](https://git-scm.com/) 应忽略的不必追踪的文件。    |\n| `README.md`         | 根应用的简介文档。                                           |\n| `angular.json`      | 为工作区中的所有项目指定 CLI 的默认配置，包括 CLI 要用到的构建、启动开发服务器和测试工具的配置项，比如 [Karma](https://karma-runner.github.io) 和 [Protractor](http://www.protractortest.org)。欲知详情，参阅 [Angular 工作区配置](https://angular.cn/guide/workspace-config) 部分。 |\n| `package.json`      | 配置工作区中所有项目可用的 [npm 包依赖](https://angular.cn/guide/npm-packages)。关于此文件的具体格式和内容，参阅 [npm 的文档](https://docs.npmjs.com/files/package.json)。 |\n| `package-lock.json` | 提供 npm 客户端安装到 `node_modules` 的所有软件包的版本信息。欲知详情，参阅 [npm 的文档](https://docs.npmjs.com/files/package-lock.json)。如果你使用的是 yarn 客户端，那么该文件[就是 yarn.lock](https://yarnpkg.com/lang/en/docs/yarn-lock)。 |\n| `src/`              | 根项目的源文件。                                             |\n| `node_modules/`     | 为整个工作区提供 [npm 包](https://angular.cn/guide/npm-packages)。这些工作区级的 `node_modules` 依赖对其中的所有项目可见。 |\n| `tsconfig.json`     | 工作区中所有项目的基本 [TypeScript](https://www.typescriptlang.org) 配置。所有其它配置文件都继承自这个基本配置。欲知详情，参阅 TypeScript 文档中的 [通过 extends 进行配置继承](https://www.typescriptlang.org/docs/handbook/tsconfig-json.html#configuration-inheritance-with-extends) 部分 |\n\n![image-20230727161341227](https://presenter.oss-cn-shanghai.aliyuncs.com/wordpress/image-20230727161341227.png)\n\n## 组件介绍\n\n介绍组件之前，我们先来介绍一下`组件`和`模块`之前的关系，框架都是推崇组件化开发的，页面上所有的元素都可以看做一个组件，具体页面中组件划分的粒度是多大，还是按照自己的个人开发习惯来进行。在Angular中我们知道了`app模块`是我们的根模块,他管理整个单页面应用中涉及到的`其他模块`和`组件`。我们来熟悉一下app.module.ts这个根模块文件。\n\n![image-20230727204415551](https://presenter.oss-cn-shanghai.aliyuncs.com/wordpress/image-20230727204415551.png)\n\n> @NgModule是 Angular中的装饰器，是需要从'@angular/core'导入进来 作用： 帮助开发者组织业务代码，开发者可以利用 NgModule 把关系比较紧密的组件组织到一起，他不仅可以控制组件，还可以控制指令，管道等\n\n**declarations**：用来放`组件、指令、管道`的声明， 组件、指令、管道都必须属于一个模块，而且只能属于`一个`模块。\n\n**imports**：用来导入`外部模块`而非组件。\n\n**exports**: 我们这个模块需要导出的一些`组件,指令,模块`等; 如果别的模块导入了我们这个模块,那么别的模块就可以直接使用我们在这里导出的组件,指令,模块等.\n\n**providers**：需要使用的`Service`都放在这里。指定应用程序的根级别需要使用的service\n\n**bootstrap**：定义启动组件。你可能注意到了这个配置项是一个数组，也就是说可以指定这个组件作为启动点。一般这里不需要做改动。\n\n## Hello World以及组件讲解\n\n首先我们先将app.component.html中的内容全部清空，为我们接下来的组件学习做准备。\n\n**1. 在app文件夹下，新建一个组件文件，文件名为hello-world.component.ts**\n\n![image-20230727205557462](https://presenter.oss-cn-shanghai.aliyuncs.com/wordpress/image-20230727205557462.png)\n从上图片中，我们可以得知组件的组成有以下三部分组成：\n\n- **类** （类名的命名是根据组件的文件名来决定的，首字母大写的驼峰命名方式）\n- **装饰器@component**, 需要从'@angular/core'中导入，其作用是把某个类标记为Angular组件，并为他配置一些元数据，目前这里只涉及到3个元数据，其中`selector`也称作是选择器，我们可以把他理解成我们自定义组件的名字，一般他的命名也是`app-组件文件`的名字，更多的元数据应用可以参照官网。\n- **HTML模板**，就是template。\n\n**2. 上边已经提到，组件必须在模块中声明才可以正常使用，所以我在根模块声明一下**\n\n![image-20230727205626396](https://presenter.oss-cn-shanghai.aliyuncs.com/wordpress/image-20230727205626396.png)\n**3. 我们将定义好的组件在app的html中引用一下**\n\n![image-20230727205659084](https://presenter.oss-cn-shanghai.aliyuncs.com/wordpress/image-20230727205659084.png)\n\n> 这个时候页面上已经可以完美的展现出 hello world了，这样一个简单的组件也就封装好了。\n","tags":["Angular"],"categories":["前端"]},{"title":"了解一点rtsp协议","url":"/2023/07/25/了解一点rtsp协议/","content":"\n## 简介\n\n以下取自百度百科\n\n> 实时流[传输协议](https://baike.baidu.com/item/传输协议/8048821?fromModule=lemma_inlink)（Real Time [Streaming](https://baike.baidu.com/item/Streaming/3790847?fromModule=lemma_inlink) Protocol，RTSP），RFC2326（中文版），是[TCP/IP协议](https://baike.baidu.com/item/TCP/IP协议/212915?fromModule=lemma_inlink)体系中的一个应用层协议，由哥伦比亚大学、[网景](https://baike.baidu.com/item/网景/70176?fromModule=lemma_inlink)和[RealNetworks](https://baike.baidu.com/item/RealNetworks/1987003?fromModule=lemma_inlink)公司提交的IETF RFC标准。该协议定义了[一对多](https://baike.baidu.com/item/一对多/1327103?fromModule=lemma_inlink)[应用程序](https://baike.baidu.com/item/应用程序/5985445?fromModule=lemma_inlink)如何有效地通过IP网络传送多媒体数据。RTSP在[体系结构](https://baike.baidu.com/item/体系结构/8174145?fromModule=lemma_inlink)上位于[RTP](https://baike.baidu.com/item/RTP/8974125?fromModule=lemma_inlink)和R[TCP](https://baike.baidu.com/item/TCP/33012?fromModule=lemma_inlink)之上，它使用TCP或[UDP](https://baike.baidu.com/item/UDP/571511?fromModule=lemma_inlink)完成[数据传输](https://baike.baidu.com/item/数据传输/2987565?fromModule=lemma_inlink)。[HTTP](https://baike.baidu.com/item/HTTP/243074?fromModule=lemma_inlink)与RTSP相比，[HTTP请求](https://baike.baidu.com/item/HTTP请求/10882159?fromModule=lemma_inlink)由[客户机](https://baike.baidu.com/item/客户机/5168153?fromModule=lemma_inlink)发出，服务器作出响应；使用RTSP时，客户机和服务器都可以发出请求，即RTSP可以是双向的。RTSP是用来控制声音或影像的多媒体串流协议，并允许同时多个串流需求控制，传输时所用的网络通讯协定并不在其定义的范围内，[服务器端](https://baike.baidu.com/item/服务器端/3369401?fromModule=lemma_inlink)可以自行选择使用TCP或UDP来传送串流内容，它的语法和运作跟HTTP 1.1类似，但并不特别强调[时间同步](https://baike.baidu.com/item/时间同步/1810349?fromModule=lemma_inlink)，所以比较能容忍[网络延迟](https://baike.baidu.com/item/网络延迟/10680325?fromModule=lemma_inlink)。而前面提到的允许同时多个串流需求控制（Multicast），除了可以降低服务器端的网络用量，更进而支持多方视讯会议（Video Conference）。因为与[HTTP1.1](https://baike.baidu.com/item/HTTP1.1/9636659?fromModule=lemma_inlink)的运作方式相似，所以[代理服务器](https://baike.baidu.com/item/代理服务器/97996?fromModule=lemma_inlink)〈[Proxy](https://baike.baidu.com/item/Proxy/612388?fromModule=lemma_inlink)〉的快取功能〈Cache〉也同样适用于RTSP，并因RTSP具有重新导向功能，可视实际负载情况来转换提供服务的服务器，以避免过大的负载集中于同一服务器而造成延迟。\n\n可以用生活中的例子来讲，你在观看节目的时候，可以随意的后退暂停，也可以自己想看什么就看什么，不用加入别人的组，整个资源都被你一个人享用。就和你平时看爱奇艺，B站什么的没区别。\n\n## RTSP方法\n\nRTSP常用的方法包括：OPTIONS、DESCRIBE、ANNOUNCE、SETUP、TEARDOWN、PLAY、PAUSE、GET_PARAMETER和SET_PARAMETER等。详细使用介绍如下：\nRTSP方法\n\n| 方法          | 方向     | 对象 | 要求 | 含义                                                         |\n| ------------- | -------- | ---- | ---- | ------------------------------------------------------------ |\n| DESCRIBE      | C->S     | P，S | 推荐 | 检查演示或媒体对象的描述，也允许使用接收头指定用户理解的描述格式。DESCRIBE的答复-响应组成媒体RTSP初始阶段 |\n| ANNOUNCE      | C->SS->C | P，S | 可选 | 当从用户发往服务器时，ANNOUNCE将请求URL识别的演示或媒体对象描述发送给服务器；反之，ANNOUNCE实时更新连接描述。如新媒体流加入演示，整个演示描述再次发送，而不仅仅是附加组件，使组件能被删除 |\n| GET_PARAMETER | C->SS->C | P，S | 可选 | GET_PARAMETER请求检查URL指定的演示与媒体的参数值。没有实体体时，GET_PARAMETER也许能用来测试用户与服务器的连通情况 |\n| OPTIONS       | C->SS->C | P，S | 要求 | 可在任意时刻发出OPTIONS请求，如用户打算尝试非标准请求，并不影响服务器状态 |\n| PAUSE         | C->S     | P，S | 推荐 | PAUSE请求引起流发送临时中断。如请求URL命名一个流，仅回放和记录被停止；如请求URL命名一个演示或流组，演示或组中所有当前活动的流发送都停止。恢复回放或记录后，必须维持同步。在SETUP消息中连接头超时参数所指定时段期间被暂停后，尽管服务器可能关闭连接并释放资源，但服务器资源会被预订 |\n| PLAY          | C->S     | P，S | 要求 | PLAY告诉服务器以SETUP指定的机制开始发送数据；直到一些SETUP请求被成功响应，客户端才可发布PLAY请求。PLAY请求将正常播放时间设置在所指定范围的起始处，发送流数据直到范围的结束处。PLAY请求可排成队列，服务器将PLAY请求排成队列，顺序执行 |\n| RECORD        | C->S     | P，S | 可选 | 该方法根据演示描述初始化媒体数据记录范围，时标反映开始和结束时间；如没有给出时间范围，使用演示描述提供的开始和结束时间。如连接已经启动，立即开始记录，服务器数据请求URL或其他URL决定是否存储记录的数据；如服务器没有使用URL请求，响应应为201（创建），并包含描述请求状态和参考新资源的实体与位置头。支持现场演示记录的媒体服务器必须支持时钟范围格式，smpte格式没有意义 |\n| REDIRECT      | S->C     | P，S | 可选 | 重定向请求通知客户端连接到另一服务器地址。它包含强制头地址，指示客户端发布URL请求；也可能包括参数范围，以指明重定向何时生效。若客户端要继续发送或接收URL媒体，客户端必须对当前连接发送TEARDOWN请求，而对指定主执新连接发送SETUP请求 |\n| SETUP         | C->S     | S    | 要求 | 对URL的SETUP请求指定用于流媒体的传输机制。客户端对正播放的流发布一个SETUP请求，以改变服务器允许的传输参数。如不允许这样做，响应错误为\"455 Method Not Valid In This State”。为了透过防火墙，客户端必须指明传输参数，即使对这些参数没有影响 |\n| SET_PARAMETER | C->SS->C | P，S | 可选 | 这个方法请求设置演示或URL指定流的参数值。请求仅应包含单个参数，允许客户端决定某个特殊请求为何失败。如请求包含多个参数，所有参数可成功设置，服务器必须只对该请求起作用。服务器必须允许参数可重复设置成同一值，但不让改变参数值。注意：媒体流传输参数必须用SETUP命令设置。将设置传输参数限制为SETUP有利于防火墙。将参数划分成规则排列形式，结果有更多有意义的错误指示 |\n| TEARDOWN      | C->S     | P，S | 要求 | TEARDOWN请求停止给定URL流发送，释放相关资源。如URL是此演示URL，任何RTSP连接标识不再有效。除非全部传输参数是连接描述定义的，SETUP请求必须在连接可再次播放前发布 |\n\n## RTSP报文解析\n\nRTSP有两类报文：**请求报文**和**响应报文**。请求报文是指从客户向服务器发送请求报文，响应报文是指从服务器到客户的应答。RTSP报文由三部分组成，即开始行、首部行和实体主体。\n\n### 1、请求报文\n\n在请求报文中，开始行就是请求行，RTSP请求报文的结构如下图所示：\n\n![image-20230725174141886](https://presenter.oss-cn-shanghai.aliyuncs.com/wordpress/20190929143502463.jpg)\n\n### 2、响应报文\n\n响应报文的开始行是状态行，RTSP响应报文的结构如下图所示：\n\n![20190929143610233](https://presenter.oss-cn-shanghai.aliyuncs.com/wordpress/20190929143610233.jpg)\n","tags":["rtsp"],"categories":["计算机网络"]},{"title":"elasticsearch基础","url":"/2023/07/23/elasticsearch基础/","content":"\n## 概述\n\nElaticsearch，简称为es， es是一个开源的高扩展的分布式全文检索引擎，它可以近乎实时的存储、检索数据；本身扩展性很好，可以扩展到上百台服务器，处理PB级别的数据。es也使用Java开发并使用 `Lucene` 作为其核心来实现所有索引和搜索的功能，但是它的目的是通过简单的 **RESTful API** 来隐藏 Lucene 的复杂性，从而让全文搜索变得简单。\n\n据国际权威的数据库产品评测机构 DB Engines 的统计，在2016年1月，ElasticSearch已超过Solr等，成为排名第一的搜索引擎类应用。\n","tags":["elasticsearch"],"categories":["工具"]},{"title":"贪心算法","url":"/2023/07/23/贪心算法/","content":"\n## 关于\n\n**贪心算法**（又称贪婪算法）是一种能够得到某种度量意义下的最优解的分级处理方法，它总是做出在当前看来是最优的选择，也就是说贪心策略并不是从整体上加以考虑，它所做出的选择只是在某种意义上的局部最优解算法。\n\n**贪心算法可解决的问题通常大部分都有如下的特性：**\n\n1. 随着算法的进行，将积累起其它两个集合：一个包含已经被考虑过并被选出的候选对象，另一个包含已经被考虑过但被丢弃的候选对象。\n2. 有一个函数来检查一个候选对象的集合是否提供了问题的解答。该函数不考虑此时的解决方法是否最优。\n3. 还有一个函数检查是否一个候选对象的集合是可行的，也即是否可能往该集合上添加更多的候选对象以获得一个解。和上一个函数一样，此时不考虑解决方法的最优性。\n4. 选择函数可以指出哪一个剩余的候选对象最有希望构成问题的解。\n5. 最后，目标函数给出解的值。\n6. 为了解决问题，需要寻找一个构成解的候选对象集合，它可以优化目标函数，贪婪算法一步一步的进行。起初，算法选出的候选对象的集合为空。接下来的每一步中，根据选择函数，算法从剩余候选对象中选出最有希望构成解的对象。如果集合中加上该对象后不可行，那么该对象就被丢弃并不再考虑；否则就加到集合里。每一次都扩充集合，并检查该集合是否构成解。如果贪婪算法正确工作，那么找到的第一个解通常是最优的。\n\n**算法思路：**\n\n贪心算法是一种改进了的分级处理方法。用贪心法设计算法的特点是一步一步的进行，根据某个优化测度(可能是目标函数，也可能不是目标函数)，每一步上都要保证能获得局部最优解。每一步只考虑一个[数据](https://wiki.mbalib.com/wiki/数据)，它的选取应满足局部优化条件。若下一个数据与部分最优解连在一起不再是可行解时，就不把该数据添加到部分解中，直到把所有数据枚举完，或者不能再添加为止。这种能够得到某种度量意义下的最优解的分级处理方法成为贪心法。\n\n**求解过程需要：**\n\n1. 候选集合S，为了构造问题的解决方案，有一个候选集合C作为问题的可能解，问题的最终解均取自于候选集合C。\n2. 解集合S，随着贪心选择的进行，解集合不断扩展，直到构成一个满足问题的完整解。\n3. 解决函数solution，检查解集合是否构成问题的完整解。\n4. 选择函数select，即贪心策略，这是贪心算法的关键，它指出哪个候选对象有希望构成成问题的解。\n5. 可行函数feasible，检查解集合中加入一个候选对象是否可行，即解集合扩展后是否满足约束条件。\n\n## 例题\n\n### 零钱找回问题\n\n这个问题在我们的日常生活中就更加普遍了。假设1元、2元、5元、10元、20元、50元、100元的纸币分别有c0, c1, c2, c3, c4, c5, c6张。现在要用这些钱来支付K元，至少要用多少张纸币？用贪心算法的思想，很显然，每一步尽可能用面值大的纸币即可。在日常生活中我们自然而然也是这么做的。在程序中已经事先将Value按照从小到大的顺序排好。\n\n```c++\n#include<iostream>\n#include<algorithm>\nusing namespace std;\nconst int N=7; \nint Count[N]={3,0,2,1,0,3,5};\nint Value[N]={1,2,5,10,20,50,100};\n\nint solve(int money) \n{\n\tint num=0;\n\tfor(int i=N-1;i>=0;i--) \n\t{\n\t\tint c=min(money/Value[i],Count[i]);\n\t\tmoney=money-c*Value[i];\n\t\tnum+=c;\n\t}\n\tif(money>0) num=-1;\n\treturn num;\n}\n\nint main() \n{\n\tint money;\n\tcin>>money;\n\tint res=solve(money);\n\tif(res!=-1) cout<<res<<endl;\n\telse cout<<\"NO\"<<endl;\n}\n```\n\n### 背包问题\n\n在选择物品i装入背包时，可以选择物品的一部分，而不一定要全部装入背包。这时便可以使用贪心算法求解了。计算每种物品的单位重量价值作为贪心选择的依据指标，选择单位重量价值最高的物品，将尽可能多的该物品装入背包，依此策略一直地进行下去，直到背包装满为止。在零一背包问题中贪心选择之所以不能得到最优解原因是贪心选择无法保证最终能将背包装满，部分闲置的背包空间使每公斤背包空间的价值降低了。在程序中已经事先将单位重量价值按照从大到小的顺序排好。\n```c++\n#include<iostream>   \nusing namespace std;   \nconst int N=4;  \nvoid knapsack(float M,float v[],float w[],float x[]);  \n  \nint main()  \n{  \n    float M=50;\n\t//背包所能容纳的重量   \n    float w[]={0,10,30,20,5};\n\t//每种物品的重量  \n    float v[]={0,200,400,100,10};  \n  \t//每种物品的价值 \n    float x[N+1]={0};  \n    //记录结果的数组 \n    knapsack(M,v,w,x);  \n    cout<<\"选择装下的物品比例：\"<<endl;  \n    for(int i=1;i<=N;i++) cout<<\"[\"<<i<<\"]:\"<<x[i]<<endl;  \n}  \n  \nvoid knapsack(float M,float v[],float w[],float x[])  \n{  \n    int i;  \n    //物品整件被装下  \n    for(i=1;i<=N;i++)\n    {  \n        if(w[i]>M) break;   \n        x[i]=1;  \n        M-=w[i];  \n    }   \n    //物品部分被装下  \n    if(i<=N) x[i]=M/w[i];   \n} \n```\n\n## 引用\n\n[贪心算法](https://wiki.mbalib.com/wiki/%E8%B4%AA%E5%BF%83%E7%AE%97%E6%B3%95)\n\n[csdn-贪心算法](https://blog.csdn.net/weixin_49370884/article/details/126247776)\n","tags":["算法"],"categories":["算法"]},{"title":"回溯算法思想","url":"/2023/07/22/回溯算法思想/","content":"\n## 关于\n\n回溯法作为一种常见的算法思想，其概念为：按选优条件向前搜索，以达到目标。当探索到某一步时，发现原先选择并不优或达不到目标，就退回一步重新选择，这种走不通就退回再走的技术为回溯法，而满足回溯条件的某个状态的点称为“回溯点”。回溯法和穷举法的思想相近，不同在于穷举法是将所有的情况都列举出来以后再进行筛选，而回溯法在列举过程如果发现当前情况不满足要求，就返回上一步进行新的尝试。\n\n> 回溯法的策略是：在包含问题的所有解的解空间树中，按照**深度优先搜索**的策略，从根结点出发深度探索解空间树。当探索到某一结点时，要先判断该结点是否包含问题的解，如果包含，就从该结点出发继续探索下去，如果该结点不包含问题的解，则逐层向其祖先结点回溯，直到探索到叶节点则结束本次遍历。\n\n步骤：\n\n1. 定义问题的解空间。\n2. 确定易于搜索的解空间结构。\n3. 以深度优先搜索的策略搜索解空间，并在搜索过程中用剪枝函数避免无效搜索。\n\n## 案例\n\n### 1、八皇后问题\n\n该问题的描述是：在8×8格的国际象棋上摆放8个皇后，使其不能互相攻击，即任意两个皇后都不能处于同一行、同一列或同一斜线上，问有多少种摆法。该问题有多种解法，递归法是最简单的一种，本文使用递归法，来借这个问题来介绍回溯法。\n  如果是初次接触该问题，一看到这个题目可能会觉得手足无措。可以尝试着将题目转换为：在一个8x8的二维数组上，每次在每一行放置一个元素，使得这8行的元素互相不在同一行、同一列或同一斜线上。假如8x8棋盘原始的元素都是0，在某行某列放置皇后后，该位置的元素改为1。所以可以通过该列的8行是否存在元素1，来判断该列是否存在皇后。将八皇后问题转换成这样的描述后，该题目就转换成了解决两个问题：\n\n1. **判断要放置的元素和之前放置过的元素互相不在同一行、同一列或同一斜线上？**\n2. **如何撤销该行中放置的皇后？**\n\n基于上面的知识铺垫，我们就可以推导出用递归方法解决八皇后问题的步骤：\n\n1. 搜索。从下标为0的行开始，尝试在该行的某个列放置皇后，然后继续进行下一行的搜索，也就是进行递归的过程。\n2. 输出，当搜索的行下标为8时，代表该次搜索已经完成，可以输出结果，总的可能性+1。\n3. 判断。这是八皇后算法的核心，判断某行某列的位置上是否可以放置皇后。\n\n示例代码如下：\n\n```java\n\n/*\n * 在8×8格的国际象棋上摆放8个皇后，使其不能互相攻击，即任意两个皇后都不能处于同一行、同一列或同一斜线上，问有多少种摆法。\n */\npublic class EightQueen {\n\t\n\t/*总的可能数，初始化为0，每输出一次结果，自增1*/\n\tprivate static int count=0;\n\t/*创建一个8x8的棋盘，默认初始化元素为0，代表未放置皇后*/\n\tprivate static int[][] chess=new int[8][8];\n\t\n\tpublic static void main(String[] args) {\n\t\t/*传参0，代表从第一行开始遍历，寻找放置皇后的位置*/\n\t\teightQueen(0);\n\t\tSystem.out.println(\"八皇后问题总共有\"+count+\"种结果\");\n\t}\n\t\n\tprivate static void eightQueen(int row){\n\t\t/*如果遍历完八行都找到放置皇后的位置则打印*/\n\t\tif(row>7){                       \n\t\t\tprintQueen();                       \n\t\t\tcount++;\n\t\t\treturn;\n\t\t}\n\t\t/*在每一行放置皇后，即遍历某行中的每一列*/\n\t\tfor(int col=0;col<8;col++){\n\t\t\t/*判断是否可以放置皇后*/\n\t\t\tif(isExistQueen(row,col)){\n\t\t\t\t/*该位置放置皇后*/\n\t\t\t\tchess[row][col]=1;\n\t\t\t\t/*然后继续在下一行进行判断*/\n\t\t\t\teightQueen(row+1);\n\t\t\t\t/*清零，这也是回溯法要注意的地方，一种方法尝试后，需要将之前做的尝试回退，以免影响到下一次尝试*/\n\t\t\t\tchess[row][col]=0;           \n\t\t\t}\n\t\t}\n\t}\n\t\n\tprivate static void printQueen(){\n\t\tSystem.out.println(\"第 \"+(count+1)+\"种结果:\");\n\t\tfor(int row=0;row<8;row++){\n\t\t\tfor(int col=0;col<8;col++){\n\t\t\t\t/*放置皇后*/\n\t\t\t\tif(chess[row][col]==1){\n\t\t\t\t\tSystem.out.print(\"q \");\n\t\t\t\t/*放置士兵*/\n\t\t\t\t}else{\n\t\t\t\t\tSystem.out.print(\"s \");\n\t\t\t\t}\n\t\t\t}\n\t\t\tSystem.out.println();\n\t\t}\n\t\tSystem.out.println();\n\t}\n\t\n\tprivate static boolean isExistQueen(int row,int col){\n\t\tint i,k;\n\t\t/*判断同一列中是否存在1，即皇后*/\n\t\tfor(i=0;i<8;i++){\n\t\t\tif(chess[i][col]==1)\n\t\t\t\treturn false;\n\t\t}\n\t\t/*判断从(0,0)到(i,k)区域内，即左上角的对角线位置上是否存在1，即皇后\n\t\t*此时不检查左下角，是因为左下角对应的行还没开始放置皇后，不用检查*/ \n\t\tfor(i=row,k=col;i>=0&&k>=0;i--,k--){\n\t\t\tif(chess[i][k]==1)\n\t\t\t\treturn false;\n\t\t}\n\t\t/*判断从(0,7)到(i,k)区域内，即右上角的对角线位置上是否存在1，即皇后\n\t\t*此时不检查右下角，是因为右下角对应的行还没开始放置皇后，不用检查*/ \n\t\tfor(i=row,k=col;i>=0&&k<8;i--,k++){\n\t\t\tif(chess[i][k]==1)\n\t\t\t\treturn false;\n\t\t}\n\t\treturn true;\n\t}\n}\n```\n\n部分测试结果如下：\n\n    第 92种结果:\n    s s s s s s s q\n    s s s q s s s s\n    q s s s s s s s\n    s s q s s s s s\n    s s s s s q s s\n    s q s s s s s s\n    s s s s s s q s\n    s s s s q s s s\n    八皇后问题总共有92种结果\n","tags":["算法"],"categories":["算法"]},{"title":"枚举算法","url":"/2023/07/22/枚举算法/","content":"\n## 关于\n\n**什么是枚举算法**\n\n一种将问题的所有可能结果一一列举，并用条件检验是否成立的解题思维。\n\n较为详细地说，如果一个问题的答案已经知道在什么样的范围，而且所有的可能性是可以有限列举的，那么我们可以采用一一列举的方式，检验是否成立。一一列举在实际编程中体现为采用循环，检验就是采用条件语句进行检验。例如，已知一个整数为23\\**，\\*表示这些数已经模糊了，但已知这个数是7的倍数或16的倍数，列举23**的所有可能结果，此时显然这个数最小的可能是2300，最大的可能是2399，于是采用循环以及条件检验，遍历检验这个范围的每个数。\n\n**如何设计枚举算法**\n\n结果可能有多个时可以考虑使用枚举；答案范围是可以确定的，或者说所有可能是可列举的；可检验，可以通过条件语句检验列举的可能是否成立。\n\n\n\n## 例子\n\n这里用leetcode上的柠檬水找零题目举例。\n\n*在柠檬水摊上，每一杯柠檬水的售价为 5 美元。顾客排队购买你的产品，（按账单 bills 支付的顺序）一次购买一杯。*\n\n*每位顾客只买一杯柠檬水，然后向你付 5 美元、10 美元或 20 美元。你必须给每个顾客正确找零，也就是说净交易是每位顾客向你支付 5 美元。*\n\n*注意，一开始你手头没有任何零钱。*\n\n*给你一个整数数组 bills ，其中 bills[i] 是第 i 位顾客付的账。如果你能给每位顾客正确找零，返回 true ，否则返回 false 。*\n\n****\n\n示例 1：\n\n```\n输入：bills = [5,5,5,10,20]\n输出：true\n解释：\n前 3 位顾客那里，我们按顺序收取 3 张 5 美元的钞票。\n第 4 位顾客那里，我们收取一张 10 美元的钞票，并返还 5 美元。\n第 5 位顾客那里，我们找还一张 10 美元的钞票和一张 5 美元的钞票。\n由于所有客户都得到了正确的找零，所以我们输出 true。\n```\n\n示例 2：\n\n```\n输入：bills = [5,5,10,10,20]\n输出：false\n解释：\n前 2 位顾客那里，我们按顺序收取 2 张 5 美元的钞票。\n对于接下来的 2 位顾客，我们收取一张 10 美元的钞票，然后返还 5 美元。\n对于最后一位顾客，我们无法退回 15 美元，因为我们现在只有两张 10 美元的钞票。\n由于不是每位顾客都得到了正确的找零，所以答案是 false。\n```\n\n**[题解：这里引用获赞最多的题解](https://leetcode.cn/problems/lemonade-change/solutions/2353707/fen-lei-tao-lun-jian-ji-xie-fa-pythonjav-37oe/)**\n\n由于 10 美元钞票只能用于 20 美元的找零，而5 美元钞票既可以用于 20 美元的找零，又可以用于 10 美元的找零，更加通用（使用场景更多），所以如果可以用 10 美元，应当优先用 10 美元，其次用 5 美元。如果优先用 5 美元，可能会面临 `bills[i]=10` 无法找零的情况。\n\n设当前有 *five* 张 5 美元钞票，*ten* 张 10 美元钞票。20 美元的无需统计，因为它无法用来找零。\n\n设 `b=bills[i]`，分类讨论：\n\n如果 `b=5`，无需找零，*five* 加一。\n如果 `b=10`，返还 5 美元，*five*减一，*ten* 加一。\n如果 `b=20` 且 `ten>0`，返还 10+5 美元，*five* 和 *ten* 都减一。\n如果 `b=20` 且 `ten=0`，返还 5+5+5 美元，*five* 减三。\n如果发现 `five<0`，说明无法正确找零，返回 false。\n如果中途没有返回 false，那么循环结束后返回 true。\n\n```java\nclass Solution {\n    public boolean lemonadeChange(int[] bills) {\n        int five = 0, ten = 0;\n        for (int b : bills) {\n            if (b == 5) { // 无需找零\n                five++;\n            } else if (b == 10) { // 返还 5\n                five--;\n                ten++;\n            } else if (ten > 0) { // 此时 b=20，返还 10+5\n                five--;\n                ten--;\n            } else { // 此时 b=20，返还 5+5+5\n                five -= 3;\n            }\n            if (five < 0) { // 无法正确找零\n                return false;\n            }\n        }\n        return true;\n    }\n}\n\n```\n\n\n\n引用：\n\n[860. 柠檬水找零 - 力扣（LeetCode）](https://leetcode.cn/problems/lemonade-change/solutions/2353707/fen-lei-tao-lun-jian-ji-xie-fa-pythonjav-37oe/)\n\n[枚举算法](https://zhuanlan.zhihu.com/p/555394745)\n","tags":["算法"],"categories":["算法"]},{"title":"p2p连接","url":"/2023/07/21/p2p连接/","content":"\n## 关于\n\nNAT技术（Network Address  Translation，网络地址转换）是一种把内部网络（简称为内网）私有IP地址转换为外部网络（简称为外网）公共IP地址的技术，它使得一定范围内的多台主机只利用一个公共IP地址连接到外网，可以在很大程度上缓解了公网IP地址紧缺的问题，同时也能防止外网攻击保障内网安全。如下图：\n\n![img](https://presenter.oss-cn-shanghai.aliyuncs.com/wordpress/v2-c3322f6baa1a2e29cfe937df02a64871_720w.png)\n\nNAT主要的通过对数据包头的地址替换来完成内网计算机访问外网服务器的。当内部机器要访问外部网络时，NAT设备把内网机器的IP与端口号(网络层地址与传输层地址，如：192.168.1.100:666)，转换成 NAT 的外部  IP与端口号(如：100.10.10.10:1666)，发送给外网服务器；数据返回时，再把目的IP和端口端口号(100.10.10.10:1666)的数据包替换为内网机器的IP地址和端口号(192.168.1.100:666)，发给内网机器。若通讯协议的内容中有IP地址的传递，如FTP协议，NAT在转换时还要把数据包内涉及协议地址交互的地方替换，否则协议就会出现地址混乱。在  NAT设备中维护了这个要替换地址的映射表，并根据内部计算机的通讯需求维护该表。外部网络来数据包能否进入内网，主要是看是否已经有可转换的映射表项，若没有就会丢弃。\n\n## NAT类型\n\nNAT分为两大类，基本NAT(Basic Network Address Translator)和NAPT(Network Address/Port Translator)。\n\n基本NAT，它仅将内网主机的私有IP地址转换成公网IP地址，但并不将TCP/UDP端口信息进行转换，有动态与静态之区分。静态NAT：私有地址与公有地址进行一对一的映射，这种一对一映射无法缓解可用公有地址短缺的问题。动态NAT：私有地址与公有地址进行一对多的映射，先建立公有地址池，当私有地址向外通信时，会从公有地址池中选择非在用的公有地址进行映射，当通信结束时，释放映射关系，公有地址重新恢复到地址池中待用。\n\nNAPT(Network Address/Port  Translator)，从名称上我们也可以看得出，NAPT不但会转换经过的数据包的IP地址，还会转换数据包的TCP/UDP端口。由于现在大部分都属于NAPT，故这里不详细讨论基础NAT，下文的NAT指NAPT。\n\nNAT有4种类型：完全锥形NAT(Full Clone NAT)、限制性锥形NAT(Restricted Clone NAT)、端口限制性锥形NAT( Port Restricted  Clone NAT)、对称式NAT(Symmetric NAT)，前面3种是锥形NAT(Clone NAT)。\n\n### 2.1.完全锥形NAT(Full Clone NAT)\n\n完全锥形NAT(Full Clone NAT)：所有从同一个内网主机的IP和端口发送出来的请求都会被映射到同一个NAT的外网IP和端口，且任何一个外网主机均可通过此映射表项发送数据包到对应的内网主机。外网主机可以主动连接内网主机，有点类似于静态NAT。\n\n### 2.2.限制性锥形NAT(Restricted Clone NAT)\n\n限制性锥形NAT(Restricted Clone  NAT)：所有从同一个内网主机的IP(标为Src_IP)和端口(标记Src_IP)发送出来的外网请求都会被映射到同一个NAT的外网IP和端口，但增加了一个限制：只有被内网主机(Src_IP:Src_IP)请求过的外网主机IP才能被使用(此外网主机可使用任意端口)，否则外网发送的数据包会被丢弃。限制性锥形NAT也被称为IP限制性锥形NAT或地址限制性锥形NAT。\n\n### 2.3.端口限制性锥形NAT( Port Restricted Clone NAT)\n\n端口限制性锥形NAT( Port Restricted Clone  NAT)：所有从同一个内网主机的IP(标为Src_IP)和端口(标记Src_IP)发送出来的外网请求都会被映射到同一个NAT的外网IP和端口，但限制：只有被内网主机(Src_IP:Src_IP)请求过的外网主机IP和端口才能被使用，否则外网发送的数据包会被丢弃。即在IP受限锥形NAT基础上增加了端口的限制。\n\n### 2.4.对称式NAT(Symmetric NAT)\n\n对称式NAT(Symmetric  NAT)：所有从同一个内网主机的IP(标为Src_IP)和端口(标记Src_IP)发送到同一个外网主机(IP地址标为目的Des_IP，端口标记为Des_Port)的请求都会被映射到同一个NAT的外网IP和端口。即此映射表项只能被外网主机(Des_IP:Des_Port)所用。\n\n看一个例子，假设有如下网络，Client使用666端口访问了Server1的1999端口、1988端口和Server2的1888端口。\n\n![image-20230721085410781](https://presenter.oss-cn-shanghai.aliyuncs.com/wordpress/image-20230721085410781.png)\n\n根据NAT类型，可能产生如下映射表，↔符号左表示内网主机IP和端口，↔符号右表示NAT的外网IP和端口，@符号右表示限制条件：外网主机地址IP和端口。\n\n![image-20230721085428394](https://presenter.oss-cn-shanghai.aliyuncs.com/wordpress/image-20230721085428394.png)\n\n实际上大部运营商提供的光猫上网服务都是锥形NAT的，而3G、4G网络、公共WiFi等因为安全因素都是对称式NAT。\n\n## NAT穿透\n\nNAT技术虽然在一定程度上在解决IPv4地址、构建防火墙、保证网络安全方面都发挥了一定的作用，因不允许外网主机访问内网主机，却破坏了端到端的网络通信。为了让跨越NAT的主机之间有效的P2P通信，需要用到NAT穿透，或者叫做NAT打洞。\n\nSTUN（Session Traversal Utilities for NAT，NAT会话穿越应用程序，IETF RFC  3489）是一种网络协议，它允许位于NAT（或多重NAT）后的客户端找出自己的公网地址，查出自己位于哪种类型的NAT之后以及NAT为某一个本地端口所绑定的Internet端端口。\n\n### 检测NAT类型\n\n第一步 对称式NAT、锥形NAT检测：\n\n1. Client首先使用相同的端口分别连接Server1和Server2，Server1获取到NAT映射的IP1:Port1，Server2获取到NAT映射的IP2:Port2；\n2. Server2把IP2:Port2发给Server1，Server1对比IP1:Port1和IP2:Port2，若不相等，NAT是对称式；否则就是锥形NAT。\n\n![image-20230721085521225](https://presenter.oss-cn-shanghai.aliyuncs.com/wordpress/image-20230721085521225.png)\n\n第二步 限制锥形NAT、完全锥形NAT检测：\n\n1. Client首先向Server2发送消息Mesg，Server2获取到NAT映射的IP2:Port2和Mesg；\n2. Server2把IP2:Port2和Mesg发给Server1；\n3. Server1向IP2:Port2发送消息Mesg，Client如果收到Mesg，NAT完全锥形，否则就是限制性锥形。\n\n![image-20230721085538769](https://presenter.oss-cn-shanghai.aliyuncs.com/wordpress/image-20230721085538769.png)\n\n第三步 IP限制锥形NAT、端口限制锥形NAT检测：\n\n1. Client首先向Server1发送消息Mesg，Server1使用Port_S1接收Mesg，并获取到NAT映射的IP1:Port1；\n2. Server1另取一闲置端口Port_Sx(Port_Sx≠Port_S1)，Server1使用Port_Sx回复Mesg到IP1:Port1，若Client收到Mesg，NAT是IP限制锥形，否则是端口限制锥形。\n\n![image-20230721085555219](https://presenter.oss-cn-shanghai.aliyuncs.com/wordpress/image-20230721085555219.png)\n\n### NAT穿透原理与能力\n\nNAT穿透原理如下图可以简要分为6步：\n\n1. Client1和Client2分别与Server连接，Server由此获取两者在NAT1和NAT2上的外网映射IP1:Port1和IP2:Port2；\n2. Server把IP1:Port1发给Client2并告之连接Client；\n3. Client2发送请求IP1:Port1，NAT1接收到数据包由于没有对应的映射表项，NAT1把数据包丢弃，但在NAT2上留下IP1:Port1映射表项；\n4. Client2向Server发送消息：请求Server转告Client1连接Client2，Server发送IP2:Port2给Client1并告知连接IP2:Port2；\n5. Client1连接IP2:Port2；\n6. Client2接收到Client1连接，穿透成功；接收不到则穿透失败。\n\n![image-20230721085613481](https://presenter.oss-cn-shanghai.aliyuncs.com/wordpress/image-20230721085613481.png)\n\n## 使用开源项目搭建p2p\n\n目前github有两款比较火的内网穿透工具，分别是[frp](https://github.com/fatedier/frp)和[nps](https://github.com/ehang-io/nps)\n\n包括[测试本地nat工具](https://github.com/HMBSbige/NatTypeTester/releases/download/3.4/NatTypeTester.exe)\n","tags":["计算机网络"],"categories":["计算机网络"]},{"title":"java中使用websocket","url":"/2023/07/16/java中的websocket/","content":"\n## websocket介绍\n\n WebSocket是基于TCP的应用层协议，用于在C/S架构的应用中实现双向通信，它实现了浏览器与服务器全双工(full-duplex)通信，也就是允许服务器主动发送信息给客户端。\n\nWebSocket 协议主要为了解决基于 HTTP/1.x 的 Web 应用无法实现服务端向客户端主动推送的问题, 为了兼容现有的设施, WebSocket 协议使用与 HTTP 协议相同的端口, 并使用 HTTP Upgrade 机制来进行 WebSocket 握手, 当握手完成之后, 通信双方便可以按照 WebSocket 协议的方式进行交互。\n\n需要特别注意的是：虽然WebSocket协议在建立连接时会使用HTTP协议，但这并不意味着WebSocket协议是基于HTTP协议实现的。\n\n## WebSocket与Http的区别\n\n实际上，WebSocket协议与Http协议有着本质的区别：\n\n### 1.通信方式不同\n\nWebSocket是双向通信模式，客户端与服务器之间只有在握手阶段是使用HTTP协议的“请求-响应”模式交互，而一旦连接建立之后的通信则使用双向模式交互，不论是客户端还是服务端都可以随时将数据发送给对方；而HTTP协议则至始至终都采用“请求-响应”模式进行通信。也正因为如此，HTTP协议的通信效率没有WebSocket高。\n![image-20230716190955787](https://presenter.oss-cn-shanghai.aliyuncs.com/wordpress/image-20230716190955787.png)\n\n### 2.协议格式不同\n\nWebSocket与HTTP的协议格式是完全不同的，具体来讲：\n（1）HTTP协议（参见：rfc2616）比较臃肿，而WebSocket协议比较轻量。\n（2）对于HTTP协议来讲，一个数据包就是一条完整的消息；而WebSocket客户端与服务端通信的最小单位是帧（frame），由1个或多个帧组成一条完整的消息（message）。即：发送端将消息切割成多个帧，并发送给服务端；服务端接收消息帧，并将关联的帧重新组装成完整的消息。\nWebSocket协议格式：\n\n```bash\nbash复制代码 0                   1                   2                   3\n 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1\n+-+-+-+-+-------+-+-------------+-------------------------------+\n|F|R|R|R| opcode|M| Payload len |    Extended payload length    |\n|I|S|S|S|  (4)  |A|     (7)     |             (16/64)           |\n|N|V|V|V|       |S|             |   (if payload len==126/127)   |\n| |1|2|3|       |K|             |                               |\n+-+-+-+-+-------+-+-------------+ - - - - - - - - - - - - - - - +\n|     Extended payload length continued, if payload len == 127  |\n+ - - - - - - - - - - - - - - - +-------------------------------+\n|                               |Masking-key, if MASK set to 1  |\n+-------------------------------+-------------------------------+\n| Masking-key (continued)       |          Payload Data         |\n+-------------------------------- - - - - - - - - - - - - - - - +\n:                     Payload Data continued ...                :\n+ - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - +\n|                     Payload Data continued ...                |\n+---------------------------------------------------------------+\n```\n\nHTTP请求消息格式：\n\n```bash\nbash复制代码Request-LineCRLF\ngeneral-headerCRLF\nrequest-headerCRLF\nentity-headerCRLF\nCRLF\n[ message-body ]\n```\n\nHTTP响应消息格式：\n\n```bash\nbash复制代码Status-LineCRLF\ngeneral-headerCRLF\nresponse-headerCRLF\nentity-headerCRLF\nCRLF\n[ message-body ]\n```\n\n虽然WebSocket和HTTP是不同应用协议，但rfc6455规定：“WebSocket设计为通过80和443端口工作，以及支持HTTP代理和中介”，从而使其与HTTP协议兼容。为了实现兼容性，WebSocket握手时使用HTTP Upgrade头从HTTP协议更改为WebSocket协议。\n\n## 为什么要使用WebSocket\n\n随着Web应用的发展，特别是动态网页的普及，越来越多的场景需要实现数据动态刷新。\n在早期的时候，实现数据刷新的方式通常有如下3种：\n1.客户端定时查询\n客户端定时查询（如：每隔10秒钟查询一次）是最原始也是最简单的实现数据刷新的方法，服务端不用做任何改动，只需要在客户端添加一个定时器即可。但是这种方式的缺点也很明显：大量的定时请求都是无效的，因为服务端的数据并没有更新，相应地也导致了大量的带宽浪费。\n\n2.长轮训机制\n长轮训机制是对客户端定时查询的一种改进，即：客户端依旧保持定时发送请求给服务端，但是服务端并不立即响应，而是等到真正有数据更新的时候才发送给客户端。实际上，并不是当没有数据更新时服务端就永远都不响应客户端，而是需要在等待一个超时时间之后结束该次长轮训请求。相对于客户端定时查询方式而言，当数据更新频率不确定时长轮训机制能够很明显地减少请求数。但是，在数据更新比较频繁的场景下，长轮训方式的优势就没那么明显了。\n在Web开发中使用得最为普遍的长轮训实现方案为Comet（Comet (web技术)），Tomcat和Jetty都有对应的实现支持，详见：WhatIsComet，Why Asynchronous Servlets。\n\n3.HTTP Streaming\n不论是长轮训机制还是传统的客户端定时查询方式，都需要客户端不断地发送请求以获取数据更新，而HTTP Streaming则试图改变这种方式，其实现机制为：客户端发送获取数据更新请求到服务端时，服务端将保持该请求的响应数据流一直打开，只要有数据更新就实时地发送给客户端。\n虽然这个设想是非常美好的，但这带来了新的问题：\n(1)HTTP Streaming的实现机制违背了HTTP协议本身的语义，使得客户端与服务端不再是“请求-响应”的交互方式，而是直接在二者建立起了一个单向的“通信管道”。\n(2)在HTTP Streaming模式下，服务端只要得到数据更新就发送给客户端，那么就需要客户端与服务端协商如何区分每一个更新数据包的开始和结尾，否则就可能出现解析数据错误的情况。\n(3)另外，处于客户端与服务端的网络中介（如：代理）可能会缓存响应数据流，这可能会导致客户端无法真正获取到服务端的更新数据，这实际上与HTTP Streaming的本意是相违背的。\n鉴于上述原因，在实际应用中HTTP Streaming并没有真正流行起来，反之使用得最多的是长轮训机制。\n\n显然，上述几种实现数据动态刷新的方式都是基于HTTP协议实现的，或多或少地存在这样那样的问题和缺陷；而WebSocket是一个全新的应用层协议，专门用于Web应用中需要实现动态刷新的场景。\n相比起HTTP协议，WebSocket具备如下特点：\n\n支持双向通信，实时性更强。\n更好的二进制支持。\n较少的控制开销：连接创建后，WebSockete客户端、服务端进行数据交换时，协议控制的数据包头部较小。\n支持扩展。\n\n\n\n## Java中实现简单的websocket\n\n引入依赖\n\n```xml\n<dependency>\n     <groupId>org.java-websocket</groupId>\n     <artifactId>Java-WebSocket</artifactId>\n     <version>1.5.3</version>\n</dependency>\n```\n\n服务端：\n\n```java\npublic class ChatServer extends WebSocketServer {\n\n    public ChatServer(int port) throws UnknownHostException {\n        super(new InetSocketAddress(port));\n    }\n\n    public ChatServer(InetSocketAddress address) {\n        super(address);\n    }\n\n    public ChatServer(int port, Draft_6455 draft) {\n        super(new InetSocketAddress(port), Collections.<Draft>singletonList(draft));\n    }\n\n    @Override\n    public void onOpen(WebSocket conn, ClientHandshake handshake) {\n        conn.send(\"Welcome to the server!\"); //This method sends a message to the new client\n        broadcast(\"new connection: \" + handshake\n                .getResourceDescriptor()); //This method sends a message to all clients connected\n        System.out.println(\n                conn.getRemoteSocketAddress().getAddress().getHostAddress() + \" entered the room!\");\n    }\n\n    @Override\n    public void onClose(WebSocket conn, int code, String reason, boolean remote) {\n        broadcast(conn + \" has left the room!\");\n        System.out.println(conn + \" has left the room!\");\n    }\n\n    @Override\n    public void onMessage(WebSocket conn, String message) {\n        broadcast(message);\n        System.out.println(conn + \": \" + message);\n    }\n\n    @Override\n    public void onMessage(WebSocket conn, ByteBuffer message) {\n        broadcast(message.array());\n        System.out.println(conn + \": \" + message);\n    }\n\n\n    public static void main(String[] args) throws InterruptedException, IOException {\n        int port = 8887; // 843 flash policy port\n        try {\n            port = Integer.parseInt(args[0]);\n        } catch (Exception ex) {\n        }\n        ChatServer s = new ChatServer(port);\n        s.start();\n        System.out.println(\"ChatServer started on port: \" + s.getPort());\n\n        BufferedReader sysin = new BufferedReader(new InputStreamReader(System.in));\n        while (true) {\n            String in = sysin.readLine();\n            s.broadcast(in);\n            if (in.equals(\"exit\")) {\n                s.stop(1000);\n                break;\n            }\n        }\n    }\n\n    @Override\n    public void onError(WebSocket conn, Exception ex) {\n        ex.printStackTrace();\n        if (conn != null) {\n            // some errors like port binding failed may not be assignable to a specific websocket\n        }\n    }\n\n    @Override\n    public void onStart() {\n        System.out.println(\"Server started!\");\n        setConnectionLostTimeout(0);\n        setConnectionLostTimeout(100);\n    }\n\n}\n```\n\n客户端：\n\n```java\npublic class ExampleClient extends WebSocketClient {\n\n    public ExampleClient(URI serverUri, Draft draft) {\n        super(serverUri, draft);\n    }\n\n    public ExampleClient(URI serverURI) {\n        super(serverURI);\n    }\n\n    public ExampleClient(URI serverUri, Map<String, String> httpHeaders) {\n        super(serverUri, httpHeaders);\n    }\n\n    @Override\n    public void onOpen(ServerHandshake handshakedata) {\n        send(\"Hello, it is me. Mario :)\");\n        System.out.println(\"opened connection\");\n        // if you plan to refuse connection based on ip or httpfields overload: onWebsocketHandshakeReceivedAsClient\n    }\n\n    @Override\n    public void onMessage(String message) {\n        System.out.println(\"received: \" + message);\n    }\n\n    @Override\n    public void onClose(int code, String reason, boolean remote) {\n        // The close codes are documented in class org.java_websocket.framing.CloseFrame\n        System.out.println(\n                \"Connection closed by \" + (remote ? \"remote peer\" : \"us\") + \" Code: \" + code + \" Reason: \"\n                        + reason);\n    }\n\n    @Override\n    public void onError(Exception ex) {\n        ex.printStackTrace();\n        // if the error is fatal then onClose will be called additionally\n    }\n\n    public static void main(String[] args) throws URISyntaxException {\n        ExampleClient c = new ExampleClient(new URI(\n                \"ws://localhost:8887\")); // more about drafts here: http://github.com/TooTallNate/Java-WebSocket/wiki/Drafts\n        c.connect();\n    }\n\n}\n```\n\n运行实例(服务端)：\n\n```bash\nChatServer started on port: 8887\nServer started!\n127.0.0.1 entered the room!\norg.java_websocket.WebSocketImpl@684c7918: Hello, it is me. Mario :)\nnihao1\n127.0.0.1 entered the room!\norg.java_websocket.WebSocketImpl@a842999 has left the room!\n127.0.0.1 entered the room!\norg.java_websocket.WebSocketImpl@4fd85867 has left the room!\n\n```\n\n运行实例(客户端):\n\n```java\nopened connection\nreceived: Welcome to the server!\nreceived: new connection: /\nreceived: Hello, it is me. Mario :)\nreceived: nihao1\nreceived: new connection: /\nreceived: org.java_websocket.WebSocketImpl@a842999 has left the room!\nreceived: new connection: /\nreceived: org.java_websocket.WebSocketImpl@4fd85867 has left the room!\n```\n\n","tags":["websocket"],"categories":["websocket"]},{"title":"kubernetes集群部署","url":"/2023/07/12/kubernetes集群部署/","content":"\n## 1. 安装kube集群（4节点）\n\n### 1.1 准备工作（所有的节点都执行）\n\n编辑4台服务器的 `/etc/hosts` 文件 ,添加下面内容（每个节点都执行一遍）：\n\n```text\n192.168.2.1 node1\n192.168.2.2 node2\n192.168.2.3 node3\n192.168.2.4 node4\n```\n\n设置hostname（以node1为例）：\n\n```bash\nhostnamectl set-hostname  node1  # node1 是自定义名字\n```\n\n或者修改 `/etc/hostname` 文件，写入`node1`（其他的子节点都一样）：\n\n```bash\nvim /etc/hostname\n```\n\n修改之后`/etc/hostname`的内容为：\n\n```bash\nnode1\n```\n\n所有节点执行时间同步：\n\n```bash\n# 启动chronyd服务\nsystemctl start chronyd\nsystemctl enable chronyd\ndate\n```\n\n所有节点禁用SELinux和Firewalld服务：\n\n```bash\nsystemctl stop firewalld\nsystemctl disable firewalld\n\nsed -i 's/enforcing/disabled/' /etc/selinux/config # 重启后生效\n```\n\n所有节点禁用swap分区：\n\n```bash\n# 临时禁用swap分区\nswapoff -a\n\n# 永久禁用swap分区\nvi /etc/fstab \n# 注释掉下面的设置\n# /dev/mapper/centos-swap swap\n# 之后需要重启服务器生效\n```\n\n所有节点添加网桥过滤和地址转发功能：\n\n```bash\ncat > /etc/sysctl.d/kubernetes.conf << EOF\nnet.bridge.bridge-nf-call-ip6tables = 1\nnet.bridge.bridge-nf-call-iptables = 1\nnet.ipv4.ip_forward = 1\nEOF\n\n# 然后执行,生效\nsysctl --system\n```\n\n然后所有节点安装docker-ce（略）\n\n需要注意的是要配置docker的cgroupdriver：\n\n```json\n{\n  // 添加这行\n  \"exec-opts\": [\"native.cgroupdriver=systemd\"],\n}\n```\n\n所有节点的kubernetes镜像切换成国内源：\n\n```bash\ncat > /etc/yum.repos.d/kubernetes.repo << EOF\n[kubernetes]\nname=Kubernetes\nbaseurl=https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64\nenabled=1\ngpgcheck=0\nrepo_gpgcheck=0\ngpgkey=https://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg https://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpg\nEOF\n```\n\n所有节点安装指定版本 kubeadm，kubelet 和 kubectl（我这里选择`1.23.0`版本的）：\n\n```bash\nyum install -y kubelet-1.23.0 kubeadm-1.23.0 kubectl-1.23.0\n\n# 设置kubelet开机启动（看你自己）\nsystemctl enable kubelet\n```\n\n### 1.2 更改kubelet的容器路径（不需要可以跳过）\n\n```bash\nvim /usr/lib/systemd/system/kubelet.service.d/10-kubeadm.conf\n```\n\n修改完之后配置文件如下：\n\n```bash\n[Service]\nEnvironment=\"KUBELET_KUBECONFIG_ARGS=--bootstrap-kubeconfig=/etc/kubernetes/bootstrap-kubelet.conf --root-dir=/mnt/sdb_new/kubelet/ --kubeconfig=/etc/kubernetes/kubelet.conf\"\n```\n\n使配置生效：\n\n```bash\nsystemctl daemon-reload\nsystemctl restart docker\nsystemctl restart kubelet\n```\n\n### 1.3 部署Kubernetes集群\n\n#### 1.3.1 覆盖kubernetes的镜像地址（只需要在master节点上操作初始化命令）\n\n1. 首先要覆盖kubeadm的镜像地址，因为这个是外网的无法访问，需要替换成国内的镜像地址，使用此命令列出集群在配置过程中需要哪些镜像：\n\n```bash\n[root@node1 home]# kubeadm config images list\nI0418 18:26:04.047449   19242 version.go:255] remote version is much newer: v1.27.1; falling back to: stable-1.23\nk8s.gcr.io/kube-apiserver:v1.23.17\nk8s.gcr.io/kube-controller-manager:v1.23.17\nk8s.gcr.io/kube-scheduler:v1.23.17\nk8s.gcr.io/kube-proxy:v1.23.17\nk8s.gcr.io/pause:3.6\nk8s.gcr.io/etcd:3.5.1-0\nk8s.gcr.io/coredns/coredns:v1.8.6\n```\n\n2. 更改为阿里云的镜像地址：\n\n```bash\n[root@node1 home]# kubeadm config images list  --image-repository registry.aliyuncs.com/google_containers\nI0418 18:28:18.740057   20021 version.go:255] remote version is much newer: v1.27.1; falling back to: stable-1.23\nregistry.aliyuncs.com/google_containers/kube-apiserver:v1.23.17\nregistry.aliyuncs.com/google_containers/kube-controller-manager:v1.23.17\nregistry.aliyuncs.com/google_containers/kube-scheduler:v1.23.17\nregistry.aliyuncs.com/google_containers/kube-proxy:v1.23.17\nregistry.aliyuncs.com/google_containers/pause:3.6\nregistry.aliyuncs.com/google_containers/etcd:3.5.1-0\nregistry.aliyuncs.com/google_containers/coredns:v1.8.6\n```\n\n3. 然后将镜像手动拉取下来，这样在初始化的时候回更快一些（还有一个办法就是直接在docker上把镜像pull下来，docker只要配置一下国内源即可快速的将镜像pull下来）：\n\n```bash\n[root@node1 home]# kubeadm config images pull  --image-repository registry.aliyuncs.com/google_containers\nI0418 18:28:31.795554   20088 version.go:255] remote version is much newer: v1.27.1; falling back to: stable-1.23\n[config/images] Pulled registry.aliyuncs.com/google_containers/kube-apiserver:v1.23.17\n[config/images] Pulled registry.aliyuncs.com/google_containers/kube-controller-manager:v1.23.17\n[config/images] Pulled registry.aliyuncs.com/google_containers/kube-scheduler:v1.23.17\n[config/images] Pulled registry.aliyuncs.com/google_containers/kube-proxy:v1.23.17\n[config/images] Pulled registry.aliyuncs.com/google_containers/pause:3.6\n[config/images] Pulled registry.aliyuncs.com/google_containers/etcd:3.5.1-0\n[config/images] Pulled registry.aliyuncs.com/google_containers/coredns:v1.8.6\n```\n\n#### 1.3.2 初始化kubernetes（只需要在master节点上操作初始化命令）\n\n初始化 Kubernetes，指定网络地址段 和 镜像地址（后续的子节点可以使用join命令进行动态的追加）：\n\n```bash\n[root@node1 home]# kubeadm init \\\n  --apiserver-advertise-address=192.168.2.1 \\\n  --image-repository registry.aliyuncs.com/google_containers \\\n  --kubernetes-version v1.23.0 \\\n  --service-cidr=10.96.0.0/12 \\\n  --pod-network-cidr=10.244.0.0/16 \\\n  --ignore-preflight-errors=all\n\n# –apiserver-advertise-address # 集群通告地址(master 机器IP，这里用的万兆网)\n# –image-repository # 由于默认拉取镜像地址k8s.gcr.io国内无法访问，这里指定阿里云镜像仓库地址\n# –kubernetes-version #K8s版本，与上面安装的一致\n# –service-cidr #集群内部虚拟网络，Pod统一访问入口，可以不用更改，直接用上面的参数\n# –pod-network-cidr #Pod网络，与下面部署的CNI网络组件yaml中保持一致，可以不用更改，直接用上面的参数\n```\n\n执行完之后要手动执行一些参数（尤其是 **加入集群的join命令** 需要复制记录下载）：\n\n```bash\n[addons] Applied essential addon: kube-proxy\n\nYour Kubernetes control-plane has initialized successfully!\n\nTo start using your cluster, you need to run the following as a regular user:\n\n  mkdir -p $HOME/.kube\n  sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config\n  sudo chown $(id -u):$(id -g) $HOME/.kube/config\n\nAlternatively, if you are the root user, you can run:\n\n  export KUBECONFIG=/etc/kubernetes/admin.conf\n\nYou should now deploy a pod network to the cluster.\nRun \"kubectl apply -f [podnetwork].yaml\" with one of the options listed at:\n  https://kubernetes.io/docs/concepts/cluster-administration/addons/\n\nThen you can join any number of worker nodes by running the following on each as root:\n\nkubeadm join 192.168.2.1:6443 --token ochspx.15in9qkiu5z8tx2y \\\n        --discovery-token-ca-cert-hash sha256:1f31202107af96a07df9fd78c3aa9bb44fd40076ac123e8ff28d6ab691a02a31\n```\n\n执行参数：\n\n```bash\n[root@node1 home]# mkdir -p $HOME/.kube\n[root@node1 home]# sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config\n[root@node1 home]# sudo chown $(id -u):$(id -g) $HOME/.kube/config\n[root@node1 home]# \n[root@node1 home]# vim /root/.bash_profile\n```\n\n加入以下这段：\n\n```bash\n# 超级用户变量\nexport KUBECONFIG=/etc/kubernetes/admin.conf\n# 设置别名\nalias k=kubectl\n# 设置kubectl命令补齐功能\nsource <(kubectl completion bash)\n```\n\n激活 `.bash_profile`：\n\n```bash\n[root@node1 home]# source /root/.bash_profile\n```\n\n这段要**复制记录**下来（来自k8s初始化成功之后出现的`join`命令，需要先配置完Flannel才能加入子节点），后续子节点加入master节点需要执行这段命令：\n\n```bash\nkubeadm join 192.168.2.1:6443 --token ochspx.15in9qkiu5z8tx2y \\\n        --discovery-token-ca-cert-hash sha256:1f31202107af96a07df9fd78c3aa9bb44fd40076ac123e8ff28d6ab691a02a31\n```\n\n#### 1.3.3 设定kubeletl网络（主节点部署）\n\n部署容器网络，CNI网络插件(在Master上执行，著名的有flannel、calico、canal和kube-router等，简单易用的实现是为CoreOS提供的flannel项目)，这里使用Flannel实现。\n\n下载`kube-flannel.yml`：\n\n```bash\n[root@node1 home]# wget https://raw.githubusercontent.com/flannel-io/flannel/master/Documenta\n```\n\n注意：国内无法下载，这里贴一个模版直接复制粘贴\n\n```yml\n---\napiVersion: policy/v1beta1\nkind: PodSecurityPolicy\nmetadata:\n  name: psp.flannel.unprivileged\n  annotations:\n    seccomp.security.alpha.kubernetes.io/allowedProfileNames: docker/default\n    seccomp.security.alpha.kubernetes.io/defaultProfileName: docker/default\n    apparmor.security.beta.kubernetes.io/allowedProfileNames: runtime/default\n    apparmor.security.beta.kubernetes.io/defaultProfileName: runtime/default\nspec:\n  privileged: false\n  volumes:\n    - configMap\n    - secret\n    - emptyDir\n    - hostPath\n  allowedHostPaths:\n    - pathPrefix: \"/etc/cni/net.d\"\n    - pathPrefix: \"/etc/kube-flannel\"\n    - pathPrefix: \"/run/flannel\"\n  readOnlyRootFilesystem: false\n  # Users and groups\n  runAsUser:\n    rule: RunAsAny\n  supplementalGroups:\n    rule: RunAsAny\n  fsGroup:\n    rule: RunAsAny\n  # Privilege Escalation\n  allowPrivilegeEscalation: false\n  defaultAllowPrivilegeEscalation: false\n  # Capabilities\n  allowedCapabilities: [ 'NET_ADMIN', 'NET_RAW' ]\n  defaultAddCapabilities: [ ]\n  requiredDropCapabilities: [ ]\n  # Host namespaces\n  hostPID: false\n  hostIPC: false\n  hostNetwork: true\n  hostPorts:\n    - min: 0\n      max: 65535\n  # SELinux\n  seLinux:\n    # SELinux is unused in CaaSP\n    rule: 'RunAsAny'\n---\nkind: ClusterRole\napiVersion: rbac.authorization.k8s.io/v1\nmetadata:\n  name: flannel\nrules:\n  - apiGroups: [ 'extensions' ]\n    resources: [ 'podsecuritypolicies' ]\n    verbs: [ 'use' ]\n    resourceNames: [ 'psp.flannel.unprivileged' ]\n  - apiGroups:\n      - \"\"\n    resources:\n      - pods\n    verbs:\n      - get\n  - apiGroups:\n      - \"\"\n    resources:\n      - nodes\n    verbs:\n      - list\n      - watch\n  - apiGroups:\n      - \"\"\n    resources:\n      - nodes/status\n    verbs:\n      - patch\n---\nkind: ClusterRoleBinding\napiVersion: rbac.authorization.k8s.io/v1\nmetadata:\n  name: flannel\nroleRef:\n  apiGroup: rbac.authorization.k8s.io\n  kind: ClusterRole\n  name: flannel\nsubjects:\n  - kind: ServiceAccount\n    name: flannel\n    namespace: kube-system\n---\napiVersion: v1\nkind: ServiceAccount\nmetadata:\n  name: flannel\n  namespace: kube-system\n---\nkind: ConfigMap\napiVersion: v1\nmetadata:\n  name: kube-flannel-cfg\n  namespace: kube-system\n  labels:\n    tier: node\n    app: flannel\ndata:\n  cni-conf.json: |\n    {\n      \"name\": \"cbr0\",\n      \"cniVersion\": \"0.3.1\",\n      \"plugins\": [\n        {\n          \"type\": \"flannel\",\n          \"delegate\": {\n            \"hairpinMode\": true,\n            \"isDefaultGateway\": true\n          }\n        },\n        {\n          \"type\": \"portmap\",\n          \"capabilities\": {\n            \"portMappings\": true\n          }\n        }\n      ]\n    }\n  net-conf.json: |\n    {\n      \"Network\": \"10.244.0.0/16\",\n      \"Backend\": {\n        \"Type\": \"vxlan\"\n      }\n    }\n---\napiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: kube-flannel-ds\n  namespace: kube-system\n  labels:\n    tier: node\n    app: flannel\nspec:\n  selector:\n    matchLabels:\n      app: flannel\n  template:\n    metadata:\n      labels:\n        tier: node\n        app: flannel\n    spec:\n      affinity:\n        nodeAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n            nodeSelectorTerms:\n              - matchExpressions:\n                  - key: kubernetes.io/os\n                    operator: In\n                    values:\n                      - linux\n      hostNetwork: true\n      priorityClassName: system-node-critical\n      tolerations:\n        - operator: Exists\n          effect: NoSchedule\n      serviceAccountName: flannel\n      initContainers:\n        - name: install-cni-plugin\n          image: rancher/mirrored-flannelcni-flannel-cni-plugin:v1.0.0\n          command:\n            - cp\n          args:\n            - -f\n            - /flannel\n            - /opt/cni/bin/flannel\n          volumeMounts:\n            - name: cni-plugin\n              mountPath: /opt/cni/bin\n        - name: install-cni\n          image: lizhenliang/flannel:v0.11.0-amd64\n          command:\n            - cp\n          args:\n            - -f\n            - /etc/kube-flannel/cni-conf.json\n            - /etc/cni/net.d/10-flannel.conflist\n          volumeMounts:\n            - name: cni\n              mountPath: /etc/cni/net.d\n            - name: flannel-cfg\n              mountPath: /etc/kube-flannel/\n      containers:\n        - name: kube-flannel\n          image: lizhenliang/flannel:v0.11.0-amd64\n          command:\n            - /opt/bin/flanneld\n          args:\n            - --ip-masq\n            - --kube-subnet-mgr\n          resources:\n            requests:\n              cpu: \"100m\"\n              memory: \"50Mi\"\n            limits:\n              cpu: \"100m\"\n              memory: \"50Mi\"\n          securityContext:\n            privileged: false\n            capabilities:\n              add: [ \"NET_ADMIN\", \"NET_RAW\" ]\n          env:\n            - name: POD_NAME\n              valueFrom:\n                fieldRef:\n                  fieldPath: metadata.name\n            - name: POD_NAMESPACE\n              valueFrom:\n                fieldRef:\n                  fieldPath: metadata.namespace\n          volumeMounts:\n            - name: run\n              mountPath: /run/flannel\n            - name: flannel-cfg\n              mountPath: /etc/kube-flannel/\n      volumes:\n        - name: run\n          hostPath:\n            path: /run/flannel\n        - name: cni-plugin\n          hostPath:\n            path: /opt/cni/bin\n        - name: cni\n          hostPath:\n            path: /etc/cni/net.d\n        - name: flannel-cfg\n          configMap:\n            name: kube-flannel-cfg\n```\n\n修改配置之后安装组件：\n\n```bash\n[root@node1 home]# kubectl apply -f kube-flannel.yml\n```\n\n查看`flannel pod`状态（必须要为`Running`状态，如果`kube-flannel`起不来，那么就用`kubectl describe pod kube-flannel-ds-f5jn6 -n kube-flannel`命令查看`pod`起不来的原因，然后去搜度娘获取解决方案）：\n\n```bash\n[root@node1 home]# # 必须所有的容器都是Running\n[root@node1 home]# kubectl get pod --all-namespaces\nNAMESPACE      NAME                                 READY   STATUS    RESTARTS   AGE\nkube-flannel   kube-flannel-ds-f5jn6                1/1     Running   0          8m21s\nkube-system    coredns-6d8c4cb4d-ctqw5              1/1     Running   0          42m\nkube-system    coredns-6d8c4cb4d-n52fq              1/1     Running   0          42m\nkube-system    etcd-k8s-master                      1/1     Running   0          42m\nkube-system    kube-apiserver-k8s-master            1/1     Running   0          42m\nkube-system    kube-controller-manager-k8s-master   1/1     Running   0          42m\nkube-system    kube-proxy-swpkz                     1/1     Running   0          42m\nkube-system    kube-scheduler-k8s-master            1/1     Running   0          42m\n```\n\n查看通信状态：\n\n```bash\n[root@node1 home]# kubectl get pod -n kube-system\nNAME                                 READY   STATUS    RESTARTS   AGE\ncoredns-6d8c4cb4d-ctqw5              1/1     Running   0          52m\ncoredns-6d8c4cb4d-n52fq              1/1     Running   0          52m\netcd-k8s-master                      1/1     Running   0          53m\nkube-apiserver-k8s-master            1/1     Running   0          53m\nkube-controller-manager-k8s-master   1/1     Running   0          53m\nkube-proxy-swpkz                     1/1     Running   0          52m\nkube-scheduler-k8s-master            1/1     Running   0          53m\n[root@node1 home]# \n[root@node1 home]# 获取主节点的状态\n[root@node1 home]# kubectl get cs\nWarning: v1 ComponentStatus is deprecated in v1.19+\nNAME                 STATUS    MESSAGE                         ERROR\ncontroller-manager   Healthy   ok\nscheduler            Healthy   ok\netcd-0               Healthy   {\"health\":\"true\",\"reason\":\"\"}\n[root@node1 home]# kubectl get node\nNAME         STATUS   ROLES                  AGE   VERSION\nnode1        Ready    control-plane,master   52m   v1.23.0\n```\n\n查看节点状态（此时还只有主节点，还没添加子节点）：\n\n```bash\n[root@node1 home]# kubectl get node\nNAME         STATUS   ROLES                  AGE   VERSION\nnode1        Ready    control-plane,master   53m   v1.23.0\n```\n\n**至此 K8s master主服务器 已经部署完成！**\n\n#### 1.3.4 子节点加入集群（在子节点上操作）\n\n初始化会生成`join`命令，需要在**子节点**执行即可，以下`token`作为举例，以实际为主，例如：\n\n```bash\n[root@node2 home]# kubeadm join 192.168.2.1:6443 --token ochspx.15in9qkiu5z8tx2y         --discovery-token-ca-cert-hash sha256:1f31202107af96a07df9fd78c3aa9bb44fd40076ac123e8ff28d6ab691a02a31\n[preflight] Running pre-flight checks\n[preflight] Reading configuration from the cluster...\n[preflight] FYI: You can look at this config file with 'kubectl -n kube-system get cm kubeadm-config -o yaml'\n[kubelet-start] Writing kubelet configuration to file \"/var/lib/kubelet/config.yaml\"\n[kubelet-start] Writing kubelet environment file with flags to file \"/var/lib/kubelet/kubeadm-flags.env\"\n[kubelet-start] Starting the kubelet\n[kubelet-start] Waiting for the kubelet to perform the TLS Bootstrap...\n\nThis node has joined the cluster:\n* Certificate signing request was sent to apiserver and a response was received.\n* The Kubelet was informed of the new secure connection details.\n\nRun 'kubectl get nodes' on the control-plane to see this node join the cluster.\n```\n\n默认的 `join token` 有效期限为24小时，当过期后该 `token` 就不能用了，这时需要重新创建 `token`，创建新的`join token`需要在主节点上创建，创建命令如下：\n\n```bash\n[root@node1 home]# kubeadm token create --print-join-command\n```\n\n加入之后再在主节点查看集群中节点的状态（**必须要都为`Ready`状态**）：\n\n```bash\n[root@node1 home]# kubectl get nodes\nNAME         STATUS     ROLES                  AGE     VERSION\nnode1        Ready      control-plane,master   63m     v1.23.0\nnode2        Ready      <none>                 3m57s   v1.23.0\nnode3        Ready      <none>                 29s     v1.23.0\n```\n\n**如果所有的节点`STATUS`都为`Ready`的话，那么到此，所有的子节点加入完成！**\n\n#### 1.3.5 删除子节点（在master主节点上操作）\n\n```bash\n# kubectl drain <node name> --delete-local-data --force --ignore-daemonsets\n# 其中 <node name> 是在k8s集群中使用 <kubectl get nodes> 查询到的节点名称\n# 假设这里删除 node3 子节点\n[root@node1 home]# kubectl drain node3 --delete-local-data --force --ignore-daemonsets\n[root@node1 home]# kubectl delete node node3\n```\n\n然后在删除的子节点上操作重置k8s（重置k8s会删除一些配置文件），这里在`node3`子节点上操作：\n\n```bash\n[root@node3 home]# # 子节点重置k8s\n[root@node3 home]# kubeadm reset\n[reset] WARNING: Changes made to this host by 'kubeadm init' or 'kubeadm join' will be reverted.\n[reset] Are you sure you want to proceed? [y/N]: y\n[preflight] Running pre-flight checks\nW0425 01:59:40.412616   15604 removeetcdmember.go:80] [reset] No kubeadm config, using etcd pod spec to get data directory\n[reset] No etcd config found. Assuming external etcd\n[reset] Please, manually reset etcd to prevent further issues\n[reset] Stopping the kubelet service\n[reset] Unmounting mounted directories in \"/var/lib/kubelet\"\n[reset] Deleting contents of config directories: [/etc/kubernetes/manifests /etc/kubernetes/pki]\n[reset] Deleting files: [/etc/kubernetes/admin.conf /etc/kubernetes/kubelet.conf /etc/kubernetes/bootstrap-kubelet.conf /etc/kubernetes/controller-manager.conf /etc/kubernetes/scheduler.conf]\n[reset] Deleting contents of stateful directories: [/var/lib/kubelet /var/lib/dockershim /var/run/kubernetes /var/lib/cni]\n\nThe reset process does not clean CNI configuration. To do so, you must remove /etc/cni/net.d\n\nThe reset process does not reset or clean up iptables rules or IPVS tables.\nIf you wish to reset iptables, you must do so manually by using the \"iptables\" command.\n\nIf your cluster was setup to utilize IPVS, run ipvsadm --clear (or similar)\nto reset your system's IPVS tables.\n\nThe reset process does not clean your kubeconfig files and you must remove them manually.\nPlease, check the contents of the $HOME/.kube/config file.\n```\n\n然后在被删除的子节点上手动删除k8s配置文件、flannel网络配置文件 和 flannel网口：\n\n```bash\n[root@node3 home]# rm -rf /etc/cni/net.d/\n[root@node3 home]# rm -rf /root/.kube/config\n[root@node3 home]# # 删除cni网络\n[root@node3 home]# ifconfig cni0 down\n[root@node3 home]# ip link delete cni0\n[root@node3 home]# ifconfig flannel.1 down\n[root@node3 home]# ip link delete flannel.1\n```\n\n## k8s常用命令集合\n\nk8s常用命令集合：\n\n```bash\n# 查看当前集群的所有的节点\nkubectl get node\n# 显示 Node 的详细信息（一般用不着）\nkubectl describe node node1\n\n# 查看所有的pod\nkubectl get pod --all-namespaces\n# 查看pod的详细信息\nkubectl get pods -o wide --all-namespaces\n\n# 查看所有创建的服务\nkubectl get service\n\n# 查看所有的deploy\nkubectl get deploy\n\n# 重启 pod（这个方式会删除原来的pod，然后再重新生成一个pod达到重启的目的）\n# 有yaml文件的重启\nkubectl replace --force -f xxx.yaml\n# 无yaml文件的重启\nkubectl get pod <POD_NAME> -n <NAMESPACE> -o yaml | kubectl replace --force -f -\n\n# 查看pod的详细信息\nkubectl describe pod nfs-client-provisioner-65c77c7bf9-54rdp -n default\n\n# 根据 yaml 文件创建Pod资源\nkubectl apply -f pod.yaml\n# 删除基于 pod.yaml 文件定义的Pod \nkubectl delete -f pod.yaml\n\n# 查看容器的日志\nkubectl logs <pod-name>\n# 实时查看日志\nkubectl logs -f <pod-name>\n# 若 pod 只有一个容器，可以不加 -c\nkubectl log  <pod-name> -c <container_name>\n# 返回所有标记为 app=frontend 的 pod 的合并日志\nkubectl logs -l app=frontend\n\n# 通过bash获得 pod 中某个容器的TTY，相当于登录容器\n# kubectl exec -it <pod-name> -c <container-name> -- bash\neg:\nkubectl exec -it redis-master-cln81 -- bash\n\n# 查看 endpoint 列表\nkubectl get endpoints\n\n# 查看已有的token\nkubeadm token list\n```\n\n## 完整的卸载k8s\n\n```bash\n# 首先清理运行到k8s群集中的pod，使用\nkubectl delete node --all\n\n# 使用脚本停止所有k8s服务\nfor service in kube-apiserver kube-controller-manager kubectl kubelet etcd kube-proxy kube-scheduler; \ndo\n    systemctl stop $service\ndone\n\n# 使用命令卸载k8s\nkubeadm reset -f\n\n# 卸载k8s相关程序\nyum -y remove kube*\n\n# 删除相关的配置文件\nmodprobe -r ipip\nlsmod\n\n# 然后手动删除配置文件和flannel网络配置和flannel网口：\nrm -rf /etc/cni\nrm -rf /root/.kube\n# 删除cni网络\nifconfig cni0 down\nip link delete cni0\nifconfig flannel.1 down\nip link delete flannel.1\n\n# 删除残留的配置文件\nrm -rf ~/.kube/\nrm -rf /etc/kubernetes/\nrm -rf /etc/systemd/system/kubelet.service.d\nrm -rf /etc/systemd/system/kubelet.service\nrm -rf /etc/systemd/system/multi-user.target.wants/kubelet.service\nrm -rf /var/lib/kubelet\nrm -rf /usr/libexec/kubernetes/kubelet-plugins\nrm -rf /usr/bin/kube*\nrm -rf /opt/cni\nrm -rf /var/lib/etcd\nrm -rf /var/etcd\n\n# 更新镜像\nyum clean all\nyum makecache\n```\n","tags":["k8s"],"categories":["k8s"]},{"title":"spring Batch批量处理","url":"/2023/07/10/Batch批量处理/","content":"\n## 引言\n\n在Java后端开发中，批量处理是一个非常常见的需求。例如，我们需要从数据库中读取大量数据，对这些数据进行处理，然后将处理后的结果写回到数据库中。这时候，使用Spring Batch框架可以帮助我们快速地实现批量处理的功能。\n\n## 什么是Spring Batch？\n\nSpring Batch是一个轻量级的批量处理框架，它基于Spring框架，提供了一套完整的批量处理解决方案。Spring Batch可以帮助我们处理大量的数据，支持事务管理、并发处理、错误处理等功能。\n\n## Spring Batch的核心概念\n\n在使用Spring Batch进行批量处理之前，我们需要了解一些Spring Batch的核心概念。(在springboot3之后，同时springBatch也有改动)\n\nspring官网教程：[Getting Started | Creating a Batch Service --- 开始使用|创建批处理服务 (spring.io)](https://spring.io/guides/gs/batch-processing/)\n\n### Job\n\nJob是Spring Batch中的最高级别的概念，它代表了一个完整的批量处理任务。一个Job由多个Step组成，每个Step代表了一个具体的处理步骤。\n\n### Step\n\nStep是Spring Batch中的一个处理步骤，它包含了一个ItemReader、一个ItemProcessor和一个ItemWriter。ItemReader用于读取数据，ItemProcessor用于处理数据，ItemWriter用于写入数据。\n\n### ItemReader\n\nItemReader用于读取数据，它可以从文件、数据库、消息队列等数据源中读取数据，并将读取到的数据传递给ItemProcessor进行处理。\n\n### ItemProcessor\n\nItemProcessor用于处理数据，它可以对读取到的数据进行处理，并将处理后的数据传递给ItemWriter进行写入。\n\n### ItemWriter\n\nItemWriter用于写入数据，它可以将处理后的数据写入到文件、数据库、消息队列等数据源中。\n\n## 使用Spring Batch进行批量处理\n\n下面我们来看一个使用Spring Batch进行批量处理的例子。假设我们有一个用户表，其中包含了大量的用户数据。我们需要从用户表中读取数据，对数据进行处理，然后将处理后的结果写回到用户表中。\n\n### BatchConfig\n\n```java\n@Configuration\npublic class BatchConfig {\n    \n    //创建itemReader\n    @Bean\n    public FlatFileItemReader<Person> reader(){\n        return new FlatFileItemReaderBuilder<Person>()\n                .name(\"personItemReader\")\n                .resource(new ClassPathResource(\"sample-data.csv\"))\n                .delimited()\n                .names(new String[]{\"firstName\",\"lastName\"})\n                .fieldSetMapper(new BeanWrapperFieldSetMapper<Person>(){{\n                    setTargetType(Person.class);\n                }})\n                .build();\n    }\n\t//ItemProcessor\n    @Bean\n    public PersonItemProcessor processor() {\n        return new PersonItemProcessor();\n    }\n    //ItemWriter\n    @Bean\n    public JdbcBatchItemWriter<Person> writer(DataSource dataSource) {\n        return new JdbcBatchItemWriterBuilder<Person>()\n                .itemSqlParameterSourceProvider(new BeanPropertyItemSqlParameterSourceProvider<>())\n                .sql(\"INSERT INTO people (first_name, last_name) VALUES (:firstName, :lastName)\")\n                .dataSource(dataSource)\n                .build();\n    }\n    //Job\n    @Bean\n    public Job importUserJob(JobRepository jobRepository,Step step1){\n        return new JobBuilder(\"importUserJob\",jobRepository)\n                .incrementer(new RunIdIncrementer())\n                .flow(step1)\n                .end()\n                .build();\n    }\n    //Step\n    @Bean\n    public Step step1(JobRepository jobRepository,\n                      PlatformTransactionManager transactionManager,\n                      JdbcBatchItemWriter<Person> writer){\n        return new StepBuilder(\"step1\", jobRepository)\n                .<Person, Person> chunk(10, transactionManager)\n                .reader(reader())\n                .processor(processor())\n                .writer(writer)\n                .build();\n    }\n}\n```\n\n### ItemProcessor\n\n```java\npublic class PersonItemProcessor implements ItemProcessor<Person, Person> {\n\n    private static final Logger log = LoggerFactory.getLogger(PersonItemProcessor.class);\n\n    @Override\n    public Person process(final Person person) throws Exception {\n        final String firstName = person.getFirstName().toUpperCase();\n        final String lastName = person.getLastName().toUpperCase();\n\n        final Person transformedPerson = new Person(firstName, lastName);\n\n        log.info(\"Converting (\" + person + \") into (\" + transformedPerson + \")\");\n\n        return transformedPerson;\n    }\n}\n```\n\n### Person\n\n```java\n */\npublic class Person {\n    private String lastName;\n    private String firstName;\n\n    public Person() {\n    }\n\n    public Person(String firstName, String lastName) {\n        this.firstName = firstName;\n        this.lastName = lastName;\n    }\n\n    public void setFirstName(String firstName) {\n        this.firstName = firstName;\n    }\n\n    public String getFirstName() {\n        return firstName;\n    }\n\n    public String getLastName() {\n        return lastName;\n    }\n\n    public void setLastName(String lastName) {\n        this.lastName = lastName;\n    }\n\n    @Override\n    public String toString() {\n        return \"firstName: \" + firstName + \", lastName: \" + lastName;\n    }\n\n}\n```\n\n### 配置文件\n\n```properties\nspring.datasource.driver-class-name=com.mysql.cj.jdbc.Driver\nspring.datasource.username=root\nspring.datasource.password=123456\nspring.datasource.url=jdbc:mysql://192.168.5.57:3306/Person_demo?characterEncoding=utf8&useSSL=false&serverTimezone=UTC&rewriteBatchedStatements=true&allowMultiQueries=true&allowPublicKeyRetrieval=true\nspring.batch.jdbc.initialize-schema=always\n```\n\n### sample-data.csv\n\n```\nJill,Doe\nJoe,Doe\nJustin,Doe\nJane,Doe\nJohn,Doe\n```\n\n","tags":["spring"],"categories":["spring"]},{"title":"java的NIO","url":"/2023/07/08/java的NIO/","content":"\n## 简介\n\nJava NIO有两种解释：一种叫非阻塞IO（Non-blocking I/O），另一种也叫新的IO（New I/O），其实是同一个概念。它是一种**同步非阻塞**的I/O模型，也是I/O多路复用的基础，已经被越来越多地应用到大型应用服务器，成为解决高并发与大量连接、I/O处理问题的有效方式。\n\nNIO是一种基于**通道和缓冲区**的I/O方式，它可以使用Native函数库**直接分配堆外内存**（区别于JVM的运行时数据区），然后通过一个存储在Java堆里面的DirectByteBuffer对象作为这块内存的直接引用进行操作。这样能在一些场景显著提高性能，因为避免了在Java堆和Native堆中来回复制数据。 \n\n## NIO与BIO的区别\n\n1）BIO以流的方式处理数据，而NIO以**块的方式**处理数据，块I/O的效率比流I/O高很多；\n\n2）BIO是阻塞的，NIO是**非阻塞**的；\n\n3）BIO基于字节流和字符流进行操作，而NIO基于**Channel（通道）和Buffer（缓冲区）进行操作**，数据总是从通道读取到缓冲区中，或者从缓冲区写入到通道中。**Selector（选择器）用于监听多个通道**的时间（比如：连接请求，数据到达等），因此使用**单个线程就可以监听多个客户端通道**；\n\n4）BIO是单向的，如：InputStream, OutputStream；而**NIO是双向的**，既可以用来进行读操作，又可以用来进行写操作。\n\n## NIO主要组件介绍\n\n### Buffer\n\nBuffer（缓冲区）是一个用于存储特定基本类型数据的容器。除了boolean外，其余每种基本类型都有一个对应的buffer类。\n\nBuffer类的子类有：\n\n- ByteBuffer\n- CharBuffer\n- DoubleBuffer\n- FloatBuffer\n- IntBuffer\n- LongBuffer\n- ShortBuffer\n\n### Channel\n\nChannel（通道）表示到实体，如硬件设备、文件、网络套接字或可以执行一个或多个不同 I/O 操作（如读取或写入）的程序组件的开放的连接。\n\nChannel接口的常用实现类有：\n\n- FileChannel（对应文件IO）\n- DatagramChannel（对应UDP）\n- SocketChannel和ServerSocketChannel（对应TCP的客户端和服务器端）\n\nChannel和IO中的Stream（流）是差不多一个等级的。\n\n### Selector\n\nSelector（选择器）用于监听多个通道的事件（比如：连接打开，数据到达）。因此，单个的线程可以监听多个数据通道。即用选择器，借助单一线程，就可对数量庞大的活动I/O通道实施监控和维护。\n\n他们之间的关系就像下面这张图\n\n![Buffer、Channel和Selector三者之间的关系](https://presenter.oss-cn-shanghai.aliyuncs.com/wordpress/channel-buffer-selector.png)\n\n## Buffer（缓冲区）\n\n在传统的 BIO 中，数据的读写是面向流的， 分为字节流和字符流。\n\n在Java 1.4 的 NIO库中，所有数据都是用缓冲区处理的，这是新库和之前的 BIO 的一个重要区别，有点类似于 BIO 中的缓冲流。NIO 在读取数据时，它是直接读到缓冲区中的。在写入数据时，写入到缓冲区中。 使用 NIO在读写数据时，都是通过缓冲区进行操作。\n\n你可以将 Buffer 理解为一个数组，`IntBuffer`、`FloatBuffer`、`CharBuffer` 等分别对应 `int[]`、`float[]`、`char[]` 等。\n\n为了更清晰地认识缓冲区，我们来简单看看`Buffer` 类中定义的四个成员变量：\n\n```java\npublic abstract class Buffer {\n    // Invariants: mark <= position <= limit <= capacity\n    private int mark = -1;\n    private int position = 0;\n    private int limit;\n    private int capacity;\n}\n```\n\n这四个成员变量的具体含义如下：\n\n1. 容量（`capacity`）：`Buffer`可以存储的最大数据量，`Buffer`创建时设置且不可改变；\n2. 界限（`limit`）：`Buffer` 中可以读/写数据的边界。写模式下，`limit` 代表最多能写入的数据，一般等于 `capacity`（可以通过`limit(int newLimit) `方法设置）；读模式下，`limit` 等于 Buffer 中实际写入的数据大小。\n3. 位置（`position`）：下一个可以被读写的数据的位置（索引）。从写操作模式到读操作模式切换的时候（flip），`position` 都会归零，这样就可以从头开始读写了。\n4. 标记（`mark`）：`Buffer`允许将位置直接定位到该标记处，这是一个可选属性；\n\n并且，上述变量满足如下的关系：**0 <= mark <= position <= limit <= capacity** 。\n\n另外，Buffer 有读模式和写模式这两种模式，分别用于从 Buffer 中读取数据或者向 Buffer 中写入数据。Buffer 被创建之后默认是写模式，调用 `flip()` 可以切换到读模式。如果要再次切换回写模式，可以调用 `clear()` 或者 `compact()` 方法。\n\n![position 、limit 和 capacity 之前的关系](https://oss.javaguide.cn/github/javaguide/java/nio/JavaNIOBuffer.png)\n\n​\t\t\t\t\t\t\t\t\t\t\t\t\t*position 、limit 和 capacity 之前的关系*\n\n![position 、limit 和 capacity 之前的关系](https://oss.javaguide.cn/github/javaguide/java/nio/NIOBufferClassAttributes.png)\n\n​\t\t\t\t\t\t\t\t\t\t\t\t\t\t*position 、limit 和 capacity 之前的关系*\n\n`Buffer` 对象不能通过 `new` 调用构造方法创建对象 ，只能通过静态方法实例化 `Buffer`。\n\n这里以 `ByteBuffer `为例进行介绍：\n\n\n\n```java\n// 分配堆内存\npublic static ByteBuffer allocate(int capacity); \n// 分配直接内存\npublic static ByteBuffer allocateDirect(int capacity); \n```\n\nBuffer 最核心的两个方法：\n\n1. `get` : 读取缓冲区的数据\n2. `put` ：向缓冲区写入数据\n\n除上述两个方法之外，其他的重要方法：\n\n- `flip` ：将缓冲区从写模式切换到读模式，它会将 `limit` 的值设置为当前 `position` 的值，将 `position` 的值设置为 0。\n- `clear`: 清空缓冲区，将缓冲区从读模式切换到写模式，并将 `position` 的值设置为 0，将 `limit` 的值设置为 `capacity` 的值。\n- ......\n\nBuffer 中数据变化的过程：\n\n\n\n```java\nimport java.nio.*;\n\npublic class CharBufferDemo {\n\n    public static void main(String[] args) {\n\n        CharBuffer charBuffer = CharBuffer.allocate(8);\n        System.out.println(\"初始状态：\");\n        printState(charBuffer);\n\n        charBuffer.put('i').put(' ').put('l').put('o').put('v').put('e');\n        System.out.println(\"写入了i love之后\");\n        printState(charBuffer);\n\n        //调用flip方法，读取charBuffer的值\n        charBuffer.flip();\n        System.out.println(\"调用flip方法之后\");\n        printState(charBuffer);\n        \n        // 读取字符\n        while (charBuffer.hasRemaining()){\n            System.out.println(charBuffer.get()+\" \");\n        }\n\n        // 调用clear()方法，清空缓冲区，将 position 的值置为 0，将 limit 的值置为 capacity 的值\n        charBuffer.clear();\n        System.out.println(\"调用clear()方法后的状态：\");\n        printState(charBuffer);\n\n    }\n\n    // 打印buffer的capacity、limit、position、mark的位置\n    private static void printState(CharBuffer buffer) {\n        System.out.print(\"capacity: \" + buffer.capacity());\n        System.out.print(\", limit: \" + buffer.limit());\n        System.out.print(\", position: \" + buffer.position());\n        System.out.print(\", mark 开始读取的字符: \" + buffer.mark());\n        System.out.println(\"\\n\");\n    }\n}\n```\n\n输出:\n\n```bash\n初始状态：\ncapacity: 8, limit: 8, position: 0, mark 开始读取的字符:         \n\n写入了i love之后\ncapacity: 8, limit: 8, position: 6, mark 开始读取的字符:   \n\n调用flip方法之后\ncapacity: 8, limit: 6, position: 0, mark 开始读取的字符: i love\n\ni \n  \nl \no \nv \ne \n调用clear()方法后的状态：\ncapacity: 8, limit: 8, position: 0, mark 开始读取的字符: i love  \n```\n\n## Channel（通道）\n\nChannel 是一个通道，它建立了与数据源（如文件、网络套接字等）之间的连接。我们可以利用它来读取和写入数据，就像打开了一条自来水管，让数据在 Channel 中自由流动。\n\nBIO 中的流是单向的，分为各种 `InputStream`（输入流）和 `OutputStream`（输出流），数据只是在一个方向上传输。通道与流的不同之处在于通道是双向的，它可以用于读、写或者同时用于读写。\n\nChannel 与前面介绍的 Buffer 打交道，读操作的时候将 Channel 中的数据填充到 Buffer中，而写操作时将 Buffer中的数据写入到 Channel 中。Channel 和 Buffer之间的关系如图所示\n\n![Channel 和 Buffer之间的关系](https://presenter.oss-cn-shanghai.aliyuncs.com/wordpress/channel-buffer.png)\n\n另外，因为 Channel 是全双工的，所以它可以比流更好地映射底层操作系统的 API。特别是在 UNIX 网络编程模型中，底层操作系统的通道都是全双工的，同时支持读写操作。\n\n`Channel` 的子类如下图所示。\n\n![Channel 的子类](https://presenter.oss-cn-shanghai.aliyuncs.com/wordpress/channel-subclasses.png)\n\n其中，最常用的是以下几种类型的通道：\n\n- `FileChannel`：文件访问通道；\n- `SocketChannel`、`ServerSocketChannel`：TCP通信通道；\n- `DatagramChannel`：UDP 通信通道；\n\n![Channel继承关系图](https://presenter.oss-cn-shanghai.aliyuncs.com/wordpress/channel-inheritance-relationship.png)\n\nChannel 最核心的两个方法：\n\n1. `read` ：用于从 Buffer 中读取数据；\n2. `write` ：向 Buffer 中写入数据。\n\n这里我们以 `FileChannel` 为例演示一下是读取文件数据的。\n\n\n\n```java\n   public static void main(String[] args) throws IOException {\n        RandomAccessFile reader = new RandomAccessFile(\"E:\\\\IDEA project\\\\demo1\\\\src\\\\main\\\\java\\\\com\\\\example\\\\demo\\\\NIODemo\\\\text.ini\",\"r\");\n        FileChannel channel = reader.getChannel();\n        ByteBuffer buffer = ByteBuffer.allocate(1024);\n        channel.read(buffer);\n\n    }\n```\n\n## Selector（选择器）\n\nSelector（选择器） 是 NIO中的一个关键组件，它允许一个线程处理多个 Channel。Selector 是基于事件驱动的 I/O 多路复用模型，主要运作原理是：通过 Selector 注册通道的事件，Selector 会不断地轮询注册在其上的 Channel。当事件发生时，比如：某个 Channel上面有新的 TCP 连接接入、读和写事件，这个 Channel就处于就绪状态，会被 Selector 轮询出来。Selector 会将相关的 Channel加入到就绪集合中。通过 SelectionKey可以获取就绪 Channel的集合，然后对这些就绪的 Channel进行响应的 I/O 操作。\n\n![Selector 选择器工作示意图](https://oss.javaguide.cn/github/javaguide/java/nio/selector-channel-selectionkey.png)\n\n一个多路复用器 Selector 可以同时轮询多个 Channel，由于 JDK使用了 `epoll()` 代替传统的 `select` 实现，所以它并没有最大连接句柄 `1024/2048` 的限制。这也就意味着只需要一个线程负责 Selector 的轮询，就可以接入成千上万的客户端。\n\nSelector 可以监听以下四种事件类型：\n\n1. `SelectionKey.OP_ACCEPT`：表示通道接受连接的事件，这通常用于 `ServerSocketChannel`。\n2. `SelectionKey.OP_CONNECT`：表示通道完成连接的事件，这通常用于 `SocketChannel`。\n3. `SelectionKey.OP_READ`：表示通道准备好进行读取的事件，即有数据可读。\n4. `SelectionKey.OP_WRITE`：表示通道准备好进行写入的事件，即可以写入数据。\n\n`Selector `是抽象类，可以通过调用此类的 `open()` 静态方法来创建 Selector 实例。Selector 可以同时监控多个 `SelectableChannel` 的 `IO` 状况，是非阻塞 `IO` 的核心。\n\n一个Selector 实例有三个 `SelectionKey` 集合：\n\n1. 所有的 `SelectionKey` 集合：代表了注册在该 Selector 上的 `Channel`，这个集合可以通过 `keys()` 方法返回。\n2. 被选择的 `SelectionKey` 集合：代表了所有可通过 `select()` 方法获取的、需要进行 `IO` 处理的 Channel，这个集合可以通过 `selectedKeys()` 返回。\n3. 被取消的 `SelectionKey` 集合：代表了所有被取消注册关系的 `Channel`，在下一次执行 `select()` 方法时，这些 `Channel` 对应的 `SelectionKey` 会被彻底删除，程序通常无须直接访问该集合，也没有暴露访问的方法。\n\n简单演示一下如何遍历被选择的 `SelectionKey` 集合并进行处理：\n\n\n\n```java\nSet<SelectionKey> selectedKeys = selector.selectedKeys();\nIterator<SelectionKey> keyIterator = selectedKeys.iterator();\nwhile (keyIterator.hasNext()) {\n    SelectionKey key = keyIterator.next();\n    if (key != null) {\n        if (key.isAcceptable()) {\n            // ServerSocketChannel 接收了一个新连接\n        } else if (key.isConnectable()) {\n            // 表示一个新连接建立\n        } else if (key.isReadable()) {\n            // Channel 有准备好的数据，可以读取\n        } else if (key.isWritable()) {\n            // Channel 有空闲的 Buffer，可以写入数据\n        }\n    }\n    keyIterator.remove();\n}\n```\n\nSelector 还提供了一系列和 `select()` 相关的方法：\n\n- `int select()`：监控所有注册的 `Channel`，当它们中间有需要处理的 `IO` 操作时，该方法返回，并将对应的 `SelectionKey` 加入被选择的 `SelectionKey` 集合中，该方法返回这些 `Channel` 的数量。\n- `int select(long timeout)`：可以设置超时时长的 `select()` 操作。\n- `int selectNow()`：执行一个立即返回的 `select()` 操作，相对于无参数的 `select()` 方法而言，该方法不会阻塞线程。\n- `Selector wakeup()`：使一个还未返回的 `select()` 方法立刻返回。\n- ......\n\n使用 Selector 实现网络读写的简单示例：\n\n\n\n```java\nimport java.io.IOException;\nimport java.net.InetSocketAddress;\nimport java.nio.ByteBuffer;\nimport java.nio.channels.SelectionKey;\nimport java.nio.channels.Selector;\nimport java.nio.channels.ServerSocketChannel;\nimport java.nio.channels.SocketChannel;\nimport java.util.Iterator;\nimport java.util.Set;\n\npublic class NioSelectorExample {\n\n  public static void main(String[] args) {\n    try {\n      ServerSocketChannel serverSocketChannel = ServerSocketChannel.open();\n      serverSocketChannel.configureBlocking(false);\n      serverSocketChannel.socket().bind(new InetSocketAddress(8080));\n\n      Selector selector = Selector.open();\n      // 将 ServerSocketChannel 注册到 Selector 并监听 OP_ACCEPT 事件\n      serverSocketChannel.register(selector, SelectionKey.OP_ACCEPT);\n\n      while (true) {\n        int readyChannels = selector.select();\n\n        if (readyChannels == 0) {\n          continue;\n        }\n\n        Set<SelectionKey> selectedKeys = selector.selectedKeys();\n        Iterator<SelectionKey> keyIterator = selectedKeys.iterator();\n\n        while (keyIterator.hasNext()) {\n          SelectionKey key = keyIterator.next();\n\n          if (key.isAcceptable()) {\n            // 处理连接事件\n            ServerSocketChannel server = (ServerSocketChannel) key.channel();\n            SocketChannel client = server.accept();\n            client.configureBlocking(false);\n\n            // 将客户端通道注册到 Selector 并监听 OP_READ 事件\n            client.register(selector, SelectionKey.OP_READ);\n          } else if (key.isReadable()) {\n            // 处理读事件\n            SocketChannel client = (SocketChannel) key.channel();\n            ByteBuffer buffer = ByteBuffer.allocate(1024);\n            int bytesRead = client.read(buffer);\n\n            if (bytesRead > 0) {\n              buffer.flip();\n              System.out.println(\"收到数据：\" +new String(buffer.array(), 0, bytesRead));\n              // 将客户端通道注册到 Selector 并监听 OP_WRITE 事件\n              client.register(selector, SelectionKey.OP_WRITE);\n            } else if (bytesRead < 0) {\n              // 客户端断开连接\n              client.close();\n            }\n          } else if (key.isWritable()) {\n            // 处理写事件\n            SocketChannel client = (SocketChannel) key.channel();\n            ByteBuffer buffer = ByteBuffer.wrap(\"Hello, Client!\".getBytes());\n            client.write(buffer);\n\n            // 将客户端通道注册到 Selector 并监听 OP_READ 事件\n            client.register(selector, SelectionKey.OP_READ);\n          }\n\n          keyIterator.remove();\n        }\n      }\n    } catch (IOException e) {\n      e.printStackTrace();\n    }\n  }\n}\n```\n\n在示例中，我们创建了一个简单的服务器，监听8080端口，使用 Selector 处理连接、读取和写入事件。当接收到客户端的数据时，服务器将读取数据并将其打印到控制台，然后向客户端回复 \"Hello, Client!\"。\n\n## [#](#nio-零拷贝) NIO 零拷贝\n\n零拷贝是提升 IO 操作性能的一个常用手段，像 ActiveMQ、Kafka 、RocketMQ、QMQ、Netty 等顶级开源项目都用到了零拷贝。\n\n零拷贝是指计算机执行 IO 操作时，CPU 不需要将数据从一个存储区域复制到另一个存储区域，从而可以减少上下文切换以及 CPU 的拷贝时间。也就是说，零拷贝主主要解决操作系统在处理 I/O 操作时频繁复制数据的问题。零拷贝的常见实现技术有： `mmap+write`、`sendfile`和 `sendfile + DMA gather copy` 。\n\n下图展示了各种零拷贝技术的对比图：\n\n|                            | CPU 拷贝 | DMA 拷贝 | 系统调用   | 上下文切换 |\n| -------------------------- | -------- | -------- | ---------- | ---------- |\n| 传统方法                   | 2        | 2        | read+write | 4          |\n| mmap+write                 | 1        | 2        | mmap+write | 4          |\n| sendfile                   | 1        | 2        | sendfile   | 2          |\n| sendfile + DMA gather copy | 0        | 2        | sendfile   | 2          |\n\n可以看出，无论是传统的 I/O 方式，还是引入了零拷贝之后，2 次 DMA(Direct Memory Access) 拷贝是都少不了的。因为两次 DMA 都是依赖硬件完成的。零拷贝主要是减少了 CPU 拷贝及上下文的切换。\n\nJava 对零拷贝的支持：\n\n- `MappedByteBuffer` 是 NIO 基于内存映射（`mmap`）这种零拷⻉⽅式的提供的⼀种实现，底层实际是调用了 Linux 内核的 `mmap` 系统调用。它可以将一个文件或者文件的一部分映射到内存中，形成一个虚拟内存文件，这样就可以直接操作内存中的数据，而不需要通过系统调用来读写文件。\n- `FileChannel` 的`transferTo()/transferFrom()`是 NIO 基于发送文件（`sendfile`）这种零拷贝方式的提供的一种实现，底层实际是调用了 Linux 内核的 `sendfile`系统调用。它可以直接将文件数据从磁盘发送到网络，而不需要经过用户空间的缓冲区。关于`FileChannel`的用法可以看看这篇文章：[Java NIO 文件通道 FileChannel 用法open in new window](https://www.cnblogs.com/robothy/p/14235598.html)。\n\n代码示例：\n\n```java\nprivate void loadFileIntoMemory(File xmlFile) throws IOException {\n  FileInputStream fis = new FileInputStream(xmlFile);\n  // 创建 FileChannel 对象\n  FileChannel fc = fis.getChannel();\n  // FileChannle.map() 将文件映射到直接内存并返回 MappedByteBuffer 对象\n  MappedByteBuffer mmb = fc.map(FileChannel.MapMode.READ_ONLY, 0, fc.size());\n  xmlFileBuffer = new byte[(int)fc.size()];\n  mmb.get(xmlFileBuffer);\n  fis.close();\n}\n```\n\n转载：[Java NIO 核心知识总结 ](https://javaguide.cn/java/io/nio-basis.html#nio-零拷贝)\n","tags":["java"],"categories":["java"]},{"title":"分治算法思想","url":"/2023/07/08/分治算法思想/","content":"\n## 基本概念\n\n　　在计算机科学中，分治法是一种很重要的算法。字面上的解释是“分而治之”，就是把一个复杂的问题分成两个或更多的相同或相似的子问题，再把子问题分成更小的子问题……直到最后子问题可以简单的直接求解，原问题的解即子问题的解的合并。这个技巧是很多高效算法的基础，如排序算法([快速排序](http://www.cnblogs.com/xsyfl/p/6901315.html)，[归并排序](http://www.cnblogs.com/xsyfl/p/6905974.html))，傅立叶变换(快速傅立叶变换)……\n\n　　任何一个可以用计算机求解的问题所需的计算时间都与其规模有关。问题的规模越小，越容易直接求解，解题所需的计算时间也越少。例如，对于n个元素的排序问题，当n=1时，不需任何计算。n=2时，只要作一次比较即可排好序。n=3时只要作3次比较即可，…。而当n较大时，问题就不那么容易处理了。要想直接解决一个规模较大的问题，有时是相当困难的。\n\n## 基本思想及策略\n\n　　分治法的设计思想是：将一个难以直接解决的大问题，分割成一些规模较小的相同问题，以便各个击破，分而治之。\n\n　　分治策略是：对于一个规模为n的问题，若该问题可以容易地解决（比如说规模n较小）则直接解决，否则将其分解为k个规模较小的子问题，这些子问题互相独立且与原问题形式相同，递归地解这些子问题，然后将各子问题的解合并得到原问题的解。这种算法设计策略叫做分治法。\n\n　　如果原问题可分割成k个子问题，1<k≤n，且这些子问题都可解并可利用这些子问题的解求出原问题的解，那么这种分治法就是可行的。由分治法产生的子问题往往是原问题的较小模式，这就为使用递归技术提供了方便。在这种情况下，反复应用分治手段，可以使子问题与原问题类型一致而其规模却不断缩小，最终使子问题缩小到很容易直接求出其解。这自然导致递归过程的产生。分治与递归像一对孪生兄弟，经常同时应用在算法设计之中，并由此产生许多高效算法。\n\n## 分治法使用场景\n\n　　分治法所能解决的问题一般具有以下几个特征：\n\n　　1) 该问题的规模缩小到一定的程度就可以容易地解决\n\n　　2) 该问题可以分解为若干个规模较小的相同问题，即该问题具有最优子结构性质。\n\n　　3) 利用该问题分解出的子问题的解可以合并为该问题的解；\n\n　　4) 该问题所分解出的各个子问题是相互独立的，即子问题之间不包含公共的子子问题。\n\n　　第一条特征是绝大多数问题都可以满足的，因为问题的计算复杂性一般是随着问题规模的增加而增加；\n\n　　**第二条特征是应用分治法的前提**它也是大多数问题可以满足的，此特征反映了递归思想的应用；、\n\n　　**第三条特征是关键，能否利用分治法完全取决于问题是否具有第三条特征**，如果具备了第一条和第二条特征，而不具备第三条特征，则可以考虑用贪心法或动态规划法。\n\n　　**第四条特征涉及到分治法的效率**，如果各子问题是不独立的则分治法要做许多不必要的工作，重复地解公共的子问题，此时虽然可用分治法，但**一般用动态规划法较好**。\n\n## 分治法得基本步骤\n\n　　分治法在每一层递归上都有三个步骤：\n\n　　step1 分解：将原问题分解为若干个规模较小，相互独立，与原问题形式相同的子问题；\n\n　　step2 解决：若子问题规模较小而容易被解决则直接解，否则递归地解各个子问题\n\n　　step3 合并：将各个子问题的解合并为原问题的解。\n\n　　它的一般的算法设计模式如下：\n\n　　Divide-and-Conquer(P)\n\n　　1. if |P|≤n0\n\n　　2. then return(ADHOC(P))\n\n　　3. 将P分解为较小的子问题 P1 ,P2 ,…,Pk\n\n　　4. for i←1 to k\n\n　　5. do yi ← Divide-and-Conquer(Pi) △ 递归解决Pi\n\n　　6. T ← MERGE(y1,y2,…,yk) △ 合并子问题\n\n　　7. return(T)\n\n　　其中|P|表示问题P的规模；n0为一阈值，表示当问题P的规模不超过n0时，问题已容易直接解出，不必再继续分解。ADHOC(P)是该分治法中的基本子算法，用于直接解小规模的问题P。因此，当P的规模不超过n0时直接用算法ADHOC(P)求解。算法MERGE(y1,y2,…,yk)是该分治法中的合并子算法，用于将P的子问题P1 ,P2 ,…,Pk的相应的解y1,y2,…,yk合并为P的解。\n\n## 分治法的复杂性分析\n\n　　一个分治法将规模为n的问题分成k个规模为n／m的子问题去解。设分解阀值n0=1，且adhoc解规模为1的问题耗费1个单位时间。再设将原问题分解为k个子问题以及用merge将k个子问题的解合并为原问题的解需用f(n)个单位时间。用T(n)表示该分治法解规模为|P|=n的问题所需的计算时间，则有：\n\n　　T（n）= k T(n/m)+f(n)\n\n　　通过迭代法求得方程的解：\n\n　　递归方程及其解只给出n等于m的方幂时T(n)的值，但是如果认为T(n)足够平滑，那么由n等于m的方幂时T(n)的值可以估计T(n)的增长速度。通常假定T(n)是单调上升的，从而当mi≤n<mi+1时，T(mi)≤T(n)<T(mi+1)。\n\n## 可使用分治法求解的一些经典问题\n\n　　（1）二分搜索\n\n　　（2）大整数乘法\n\n　　（3）Strassen矩阵乘法\n\n　　（4）棋盘覆盖\n\n　　（5）合并排序\n\n　　（6）快速排序\n\n　　（7）线性时间选择\n\n　　（8）最接近点对问题\n\n　　（9）循环赛日程表\n\n　　（10）汉诺塔\n\n## 一些经典问题求解代码实现\n\n### 1）二分搜索\n\n二分搜索又叫做二分查找、折半查找，它是一种效率较高得查找方法。\n\n二分搜索得要求：\n\n线性表为有序表，并且要用向量作为表得存储结构。\n\n二分搜索得基本思想：先确定待查找记录所在的范围，然后逐步缩小范围直至找到或找不到该记录位置。\n\n二分查找步骤：\n\n1、先确定中间位置：\n\nmiddle = (left+right)/2;\n\n2、将待查找得key值与data[middle].key值相比较。若相等，则查找成功并返回该位置，否则须确定新得查找区间，继续二分查找，具体方法如下：\n\n如果data[middle].key大于key，由于data为有序线性表，可知data[middle...right].key均大于key，因此若表中存在关键字等于key得节点，则一定在位置middle左边的子表中。反之，　data[middle].key小于key，　因此若表中存在关键字等于key得节点，则一定在位置middle右边的子表中。下一次查找针对新得区域进行查找。\n\n```java\n 1 public static void main(String[] args) {\n 2         int[] a = {1,2,3,4,5,6,7,8,9};\n 3         int pos =bSearch(a, 0, a.length-1, 1);\n 4         System.out.println(pos);\n 5     }\n 6     \n 7     \n 8     public static int bSearch(int[] data,int left,int right,int key){\n 9         //获取中间位置\n10         int middle = (left+right)/2;\n11         //比较key值如相等，返回当前位置，否则确认新的查找空间\n12         if(data[middle] == key){\n13             return middle;\n14         }else if(data[middle] >key){\n15             return bSearch(data, left, middle-1, key);\n16         }else{\n17             return bSearch(data, middle+1, right, key);\n18         }\n19     }\n```\n\n### 2）汉诺塔\n\n在汉诺塔游戏中，有三个分别命名为A、B、C得塔座，几个大小各不相同，从小到大一次编号得圆盘，每个原盘中间有一个小孔。最初，所有得圆盘都在A塔座上，其中最大得圆盘在最下面，然后是第二大，以此类推.\n\n![img](https://presenter.oss-cn-shanghai.aliyuncs.com/wordpress/1030037-20170531112031243-1835538124.png)\n\n游戏的目的是将所有的圆盘从塔座A移动到塔座B;塔座C用来防止临时圆盘,游戏的规则如下:\n\n1、一次只能移动一个圆盘\n\n2、任何时候都不能将一个较大的圆盘压在较小的圆盘上面.\n\n3、除了第二条限制,任何塔座的最上面的圆盘都可以移动到其他塔座上.\n\n汉诺塔问题解决思想:\n\n　　在解决汉诺塔问题时,事实上,我们应该最先关注的是第四个圆盘，要把第四个圆盘移到B柱上，就需要将123移动到C上。接下来的问题就变成了如何把3移动到C，那么就需要将12移动到B上，然后考虑怎么将2移动到B上，可以推出第一步将1移动到C上。（在整个过程中的思想都是一样的，为了移动哪一个，就需要移动那些）\n\n代码实现：（这个案例中用到了分治思想，同时也用到了递归）\n\n```java\npublic class Moved {\n 2     private static int count = 1;\n 3     public static void main(String[] args) {\n 4         moved(4, \"第一根柱子\", \"第二根柱子\", \"第三根柱子\");\n 5     }\n 6     \n 7     /**\n 8      * \n 9      * @param i  圆盘数量\n10      * @param a  圆盘初始所在塔座\n11      * @param b  圆盘将要移动到的塔座\n12      * @param c     辅助圆盘移动的塔座\n13      */\n14     public static void moved(int i,String a,String b,String c){\n15         if(i == 1){\n16             disPaly(1, a, b);\n17         }else{\n18             //将i-1根圆盘由A移动到C\n19             moved(i-1, a, c, b);\n20             //将圆盘i 由A移动到B\n21             disPaly(i, a, b);\n22             //将i-1根圆盘由C移动到A\n23             moved(i-1,c,b,a);\n24         }\n25     }\n26     \n27     public static void disPaly(int i,String a,String b){\n28         System.out.println(\"第\"+count+\"步：移动第\"+i+\"个塔从\"+a+\"到\"+b);\n29         count++;\n30     }\n31 }\n```\n","tags":["算法"],"categories":["算法"]},{"title":"关于宽表的优缺点和解决方法","url":"/2023/07/08/关于宽表的优缺点和解决方法/","content":"\n## 前言\n\n大家使用宽表主要原因有两个。\n\n一是为了**提高查询性能**。现代BI（*商业智能，又称商业智慧或商务智能，指用现代数据仓库技术、线上分析处理技术、数据挖掘和数据展示技术进行数据分析以实现商业价值*）通常使用关系数据库作为后台，而SQL通常使用的HASH JOIN算法，在关联表数量和关联层级变多的时候，计算性能会急剧下降，有七八个表三四层级关联时就能观察到这个现象，而BI业务中的关联复杂度远远超过这个规模，直接使用SQL的JOIN就无法达到前端立等可取的查询需要了。为了避免关联带来的性能问题，就要先将关联消除，即将多表事先关联好采用单表存储（也就是宽表），再查询的时候就可以不用再关联，从而达到提升查询性能的目的。\n\n二是为了**降低业务难度**。因为多表关联尤其是复杂关联在BI前端很难表达和使用。如果采用自动关联（根据字段类型等信息匹配）当遇到同维字段（如一个表有2个以上地区字段）时会“晕掉”不知道该关联哪个，表间循环关联或自关联的情况也无法处理；如果将众多表开放给用户来自行选择关联，由于业务用户无法理解表间关系而几乎没有可用性；分步关联可以描述复杂的关联需求，但一旦前一步出错就要推倒重来。所以，无论采用何种方式，工程实现和用户使用都很麻烦。但是基于单表来做就会简单很多，业务用户使用时没有什么障碍，因此将多表组织成宽表就成了“自然而然”的事情。\n\n### 缺点\n\n**数据冗余容量大**\n\n宽表不符合范式要求，将多个表合并成一个表会存在大量冗余数据，冗余程度跟原表数据量和表间关系有关，通常如果存在多层外键表，其冗余程度会呈指数级上升。大量数据冗余不仅会带来存储上的压力（多个表组合出来的宽表数量可能非常多）造成数据库容量问题，在查询计算时由于大量冗余数据参与运算还会影响计算性能，导致虽然用了宽表但仍然查询很慢。\n\n**数据错误**\n\n由于宽表不符合三范式要求，数据存储时可能出现一致性错误（脏写）。比如同一个销售员在不同记录中可能存储了不同的性别，同一个供应商在不同记录中的所在地可能出现矛盾。基于这样的数据做分析结果显然不对，而这种错误非常隐蔽很难被发现。\n\n另外，如果构建的宽表不合理还会出现汇总错误。比如基于一对多的A表和B表构建宽表，如果A中有计算指标（如金额），在宽表中就会重复，基于重复的指标再汇总就会出现错误。\n\n**灵活性差**\n\n宽表本质上是一种按需建模的手段，根据业务需求来构建宽表（虽然理论上可以把所有表的组合都形成宽表，但这只存在于理论上，如果要实际操作会发现需要的存储空间大到完全无法接受的程度），这就出现了一个矛盾：BI系统建设的初衷主要是为了满足业务灵活查询的需要，即事先并不知道业务需求，有些查询是在业务开展过程中逐渐催生出来的，有些是业务用户临时起意的查询，这种灵活多变的需求采用宽表这种要事先加工的解决办法极为矛盾，想要获得宽表的好就得牺牲灵活性，可谓鱼与熊掌不可兼得。\n\n**可用性问题**\n\n除了以上问题，宽表由于字段过多还会引起可用性低的问题。一个事实表会对应多个维表，维表又有维表，而且表之间还可能存在自关联/循环关联的情况，这种结构在数据库系统中很常见，基于这些结构的表构建宽表，尤其要表达多个层级的时候，宽表字段数量会急剧增加，经常可能达到成百上千个（有的数据库表有字段数量限制，这时又要横向分表），试想一下，在用户接入界面如果出现上千个字段要怎么用？这就是宽表带来的可用性差的问题。\n\n## SPL+DQL消灭宽表\n\n借助开源集算器SPL可以完成这个目标。\n\nSPL（Structured Process Language）是一个开源结构化数据计算引擎，本身提供了不依赖数据库的强大计算能力，SPL内置了很多高性能算法，尤其是对关联运算做了优化，对不同的关联场景采用不同的手段，可以大幅提升关联性能，从而不用宽表也能实时关联以满足多维分析时效性的需要。同时，SPL还提供了高性能存储，配合高效算法可以进一步发挥性能优势。\n\n只有高性能还不够，SPL原生的计算语法不适合多维分析应用接入（生成SPL语句对BI系统改造较大）。目前大部分多维分析前端都是基于SQL开发的，但SQL体系（不用宽表时）在描述复杂关联计算上又很困难，基于这样的原因，SPL设计了专门的类SQL查询语法DQL（Dimensional Query Language）用于构建语义层。前端生成DQL语句，DQL Server将其转换成SPL语句，再基于SPL计算引擎和存储引擎完成查询返回给前端，实现全链路BI查询。需要注意的是，SPL只作为计算引擎存在，前端界面仍要由用户自行实现（或选用相应产品）。\n\n### SPL：关联实现技术\n\nSPL如何不用宽表也能实现实时关联以满足性能要求的目标？\n\n在BI业务中绝大部分的JOIN都是等值JOIN，也就是关联条件为等式的 JOIN。SPL把等值关联分为外键关联和主键关联。**外键关联**是指用一个表的非主键字段，去关联另一个表的主键，前者称为事实表，后者称为维表，两个表是多对一的关系，比如订单表和客户表。**主键关联**是指用一个表的主键关联另一个表的主键或部分主键，比如客户表和 VIP 客户表（一对一）、订单表和订单明细表（一对多）。\n\n这两类 JOIN 都涉及到主键，如果充分利用这个特征采用不同的算法，就可以实现高性能的实时关联了。\n\n不过很遗憾，SQL 对 JOIN 的定义并不涉及主键，只是两个表做笛卡尔积后再按某种条件过滤。这个定义很简单也很宽泛，几乎可以描述一切。但是，如果严格按这个定义去实现 JOIN，理论上没办法在计算时利用主键的特征来提高性能，只能是工程上做些有限的优化，在情况较复杂时（表多且层次多）经常无效。\n\nSPL 改变了 JOIN 的定义，针对这两类 JOIN 分别处理，就可以利用主键的特征来减少运算量，从而提高计算性能。\n\n#### 外键关联\n\n和SQL不同，SPL中明确地区分了维表和事实表。BI系统中的维表都通常不大，可以事先读入内存建立索引，这样在关联时可以少计算一半的HASH值。\n\n对于多层维表（维表还有维表的情况）还可以用**外键地址化**的技术做好**预关联**。即将维表（本表）的外键字段值转换成对应维表（外键表）记录的地址。这样被关联的维表数据可以直接用地址取出而不必再进行HASH值计算和比对，多层维表仅仅是多个按地址取值的时间，和单层维表时的关联性能基本相当。\n\n类似的，如果事实表也不大可以全部读入内存时，也可以通过预关联的方式解决事实表与维表的关联问题，提升关联效率。\n\n预关联可以在系统启动时一次性读入并做好，以后直接使用即可。\n\n当事实表较大无法全内存时，SPL 提供了**外键序号化**方法：将事实表中的外键字段值转换为维表对应记录的序号。关联计算时，用序号取出对应维表记录，这样可以获得和外键地址化类似的效果，同样能避免HASH值的计算和比对，大幅提升关联性能。\n\n#### 主键关联\n\n有的事实表还有明细表，比如订单和订单明细，二者通过主键和部分主键进行关联，前者作为主表后者作为子表（还有通过全部主键关联的称为同维表，可以看做主子表的特例）。主子表都是事实表，涉及的数据量都比较大。\n\nSPL为此采用了**有序归并**方法：预先将外存表按照主键有序存储，关联时顺序取出数据做归并，不需要产生临时缓存，只用很小的内存就可以完成计算。而SQL采用的HASH分堆算法复杂度较高，不仅要计算HASH值进行对比，还会产生临时缓存的读写动作，运算性能很差。\n\nHASH 分堆技术实现并行困难，多线程要同时向某个分堆缓存数据，造成共享资源冲突；某个分堆关联时又会消费大量内存，无法实施较大的并行数量。而有序归则易于分段并行。数据有序时，子表就可以根据主表键值进行同步对齐分段以保证正确性，无需缓存，且因为占用内存很少可以采用较大的并行数，从而获得更高性能。\n\n预先排序的成本虽高，但是一次性做好即可，以后就总能使用归并算法实现 JOIN，性能可以提高很多。同时，SPL 也提供了在有追加数据时仍然保持数据整体有序的方案。\n\n对于主子表关联SPL还可以采用更有效的存储形式将主子表一体化存储，子表作为主表的集合字段，其取值是由与该主表数据相关的多条子表记录构成。这相当于预先实现了关联，再计算时直接取数计算即可，不需要比对，存储量也更少，性能更高。\n\n#### 存储机制\n\n高性能离不开有效的存储。SPL也提供了**列式存储**，在BI计算中可以大幅降低数据读取量以提升读取效率。SPL列存采用了独有的**倍增分段**技术，相对传统列存分块并行方案要在很大数据量时（否则并行会受到限制）才会发挥优势不同，这个技术可以使SPL列存在数据量不很大时也能获得良好的并行分段效果，充分发挥并行优势。\n\nSPL还提供了针对数据类型的优化机制，可以显著提升多维分析中的切片运算性能。比如将枚举型维度转换成整数，在查询时将切片条件转换成布尔值构成的对位序列，在比较时就可以直接从序列指定位置取出切片判断结果。还有将多个标签维度（取值是或否的维度，这种维度在多维分析中大量存在）存储在一个整数字段中的**标签位维度**技术（一个整数字段可以存储16个标签），不仅大幅减少存储量，在计算时还可以针对多个标签同时做按位计算从而大幅提升计算性能。\n\n有了这些高效机制以后，我们就可以在BI分析中不再使用宽表，转而基于SPL存储和算法做实时关联，性能比宽表还更高（没有冗余数据读取量更小，更快）。\n\n不过，只有这些还不够，SPL原生语法还不适合BI前端直接访问，这就需要适合的语义转换技术，通过适合的方式将用户操作转换成SPL语法进行查询。\n\n这就需要DQL了。\n\n### DQL：关联描述技术\n\nDQL是SPL之上的语义层构建工具，在这一层完成对于SPL数据关联关系的描述（建模）再为上层应用服务。即将SPL存储映射成DQL表，再基于表来描述数据关联关系。\n\n![image-20230708101729124](https://presenter.oss-cn-shanghai.aliyuncs.com/wordpress/image-20230708101729124.png)\n\n通过对数据表关系描述以后形成了一种以维度为中心的总线式结构（不同于E-R图中的网状结构），中间是维度，表与表之间不直接相关都通过维度过渡。\n\n![image-20230708101757697](https://presenter.oss-cn-shanghai.aliyuncs.com/wordpress/image-20230708101757697.png)\n\n基于这种结构下的关联查询（DQL语句）会很好表达。比如要根据订单表（orders）、客户表（customer）、销售员表（employee）以及城市表（city）查询：**本年度华东的销售人员，在全国各销售区的销售额**。\n\n用SQL写起来是这样的：\n\n```sql\nSELECT\n ct1.area,o.emp_id,sum(o.amount) somt\nFROM\n orders o\n JOIN customer c ON o.cus_id = c.cus_id\n JOIN city ct1 ON c.city_id = ct1.city_id\n JOIN employee e ON o.emp_id = e.emp_id\n JOIN city ct2 ON e.city_id = ct2.city_id\nWHERE\n ct2.area = 'east' AND year(o.order_date)= 2022\nGROUP BY\n ct1.area,  o.emp_id\n```\n\n多个表关联要JOIN多次，同一个地区表要反复关联两次才能查到销售员和客户的所在区域，对于这种情况BI前端表达起来会很吃力，如果将关联开放出来，用户又很难理解。\n\n那么DQL是怎么处理的呢？\n\n**DQL写法：**\n\n```sql\nSELECT\n cus_id.city_id.area,emp_id,sum(amount) somt\nFROM\n orders\nWHERE\n emp_id.city_id.area == \"east\" AND year(order_date)== 2022\nBY\n cus_id.city_id.area,emp_id\n```\n\nDQL不需要JOIN多个表，只基于orders单表查询就可以了，外键指向表的字段当成属性直接使用，有多少层都可以引用下去，很好表达。像查询客户所在地区通过cus_id.city_id.area一直写下去就可以了，这样就消除了关联，将多表关联查询转化成单表查询。\n\n更进一步，我们再基于DQL开发BI前端界面就很容易，比如可以做成这样：\n\n![image-20230708101910349](https://presenter.oss-cn-shanghai.aliyuncs.com/wordpress/image-20230708101910349.png)\n\n用树结构分多级表达多层维表关联，这样的多维分析页面不仅容易开发，普通业务用户使用时也很容易理解，这就是DQL的效力。\n\n## SPL资料\n\n- [SPL下载](https://link.juejin.cn/?target=http%3A%2F%2Fc.raqsoft.com.cn%2Farticle%2F1595816810031)\n- [SPL源代码](https://link.juejin.cn/?target=https%3A%2F%2Fgithub.com%2FSPLWare%2FesProc)\n\n\n\n原文：[宽表为什么横行](https://juejin.cn/post/7200033099752554553)\n","tags":["sql"],"categories":["数据库"]},{"title":"selenium的基本使用和常用方法","url":"/2023/07/07/selenium的基本使用和常用方法/","content":"\n## 前言\n\nselenium同时适配了很多语言，比如java，python，R等等，本次测试使用python进行测试，需要准备下载pip\n\n## webdriver\n\n#### 1、下载WebDriver\n\n- Chrome浏览器驱动下载地址：[chromedriver.storage.googleapis.com/index.html](https://link.juejin.cn/?target=https%3A%2F%2Fchromedriver.storage.googleapis.com%2Findex.html)\n- Edge浏览器驱动下载地址：[developer.microsoft.com/zh-cn/micro…](https://link.juejin.cn/?target=https%3A%2F%2Fdeveloper.microsoft.com%2Fzh-cn%2Fmicrosoft-edge%2Ftools%2Fwebdriver) 或 [msedgewebdriverstorage.z22.web.core.windows.net](https://link.juejin.cn/?target=https%3A%2F%2Fmsedgewebdriverstorage.z22.web.core.windows.net)\n- Mozilla浏览器驱动下载地址：[github.com/mozilla/gec…](https://link.juejin.cn/?target=https%3A%2F%2Fgithub.com%2Fmozilla%2Fgeckodriver%2Ftags)\n- Opera浏览器驱动下载地址：[github.com/operasoftwa…](https://link.juejin.cn/?target=https%3A%2F%2Fgithub.com%2Foperasoftware%2Foperachromiumdriver%2Ftags)\n- Safari浏览器驱动下载地址：[webkit.org/blog/6900/w…](https://link.juejin.cn/?target=https%3A%2F%2Fwebkit.org%2Fblog%2F6900%2Fwebdriver-support-in-safari-10)\n\n#### 2、安装WebDriver\n\n将下载好的developer.exe驱动文件解压后，复制移动到Python解释器所在的文件夹（就是Python的安装目录，和python.exe同级目录）就完成安装了。\n\n![image-20230707124141448](https://presenter.oss-cn-shanghai.aliyuncs.com/wordpress/image-20230707124141448.png)\n\n## 安装selenium\n\n> Selenium是一个用于Web应用程序测试的自动化集成测试操作框架。由thoughtworks 公司推出，它可以直接在浏览器中运行，模拟真实用户直接在浏览器中模拟用户操作。在自动化测试中，可用于单元测试、冒烟测试、集成测试、回归测试、系统测试等，并且可以运行在不同类型的浏览器和操作系统上。利用Selenium，可以驱动浏览器执行特定的动作，比如：点击、下拉等等，还可以获取浏览器当前呈现的页面的源代码。支持包括Microsoft Edge(IE之后)、Google Chrome、Opera、Mozilla Firefox、Apple Safari、等浏览器。\n\n#### 1、全局安装\n\n要查看全局安装的selenium包存放路径（一般同Python的安装路径） 如：D:\\Program Files (x86)\\Python311\\lib\\site-packages\\selenium\n\n```shell\n# 格式 pip install 要安装的包名\npip install selenium\n    \n    \n# 或（-U 安装或升级）\npip install -U selenium\n\n\n# 如果要安装指定的selenium版本（安装其他包的操作也相同）\n# 格式 pip install 要安装的包名 == 要指定安装的版本号\npip install selenium == 4.8.0\n\n\n# 在输入pip install selenium命令后 按回车确认键，就开始显示以下安装过程\nPS E:\\AutoTest> pip install selenium\nDefaulting to user installation because normal site-packages is not writeable\nCollecting selenium\nDownloading selenium-4.8.3-py3-none-any.whl (6.5 MB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸━━━━ 5.8/6.5 MB 86.6 kB/s eta 0:00:16 \n```\n\n#### 2、局部安装\n\n局部安装需要指定安装目录，可通过--target参数来指定\n\n```bash\n# 格式：\npip install --target=path_name package_name # path_name表示安装的路径， package_name表示安装包名\n\n# 例如\npip install --target=./lib selenium # 表示将selenium包安装在，当前目录下的lib文件夹中（./表示当前目录）\n```\n\n### 3、在python虚拟环境中安装\n\n例如在pycharm中，安装在这个虚拟环境中，不会影响其他项目。可以再venv/lib中查看\n\n![image-20230707125021035](https://presenter.oss-cn-shanghai.aliyuncs.com/wordpress/image-20230707125021035.png)\n\n## 实例\n\n```python\n# 导入selenium框架\nfrom selenium import webdriver\nfrom selenium.webdriver.common.by import By\nimport time\n\n# 开启浏览器测试会话\ndriver = webdriver.Chrome()\n\n# 注：如果不在PyCharm编辑器中运行代码，侧需要指定Edge WebDriver驱动路径\n# driver = webdriver.Edge(r'D:/Program Files (x86)/Python311/msedgedriver.exe')\n\n# 指定加载浏览器RUL（要测试的网址）\ndriver.get(\"https://blog.ilpvc.cf\")\n\n# 最大化浏览器窗口\ndriver.maximize_window()\n\n# 强制延时等待5秒钟\ntime.sleep(5)\n\n# 退出测试会话\ndriver.quit()\n```\n\n## 六、扩展\n\n> 想了解更多Selenium框架的使用方法，可去这里查看 [selenium-python.readthedocs.io/api.html](https://link.juejin.cn/?target=https%3A%2F%2Fselenium-python.readthedocs.io%2Fapi.html)\n\n```python\n# 引入selenium操作框架\nfrom selenium import webdriver\n\n# 开启浏览器会话\ndriver = webdriver.Edge()\n\n# 显示driver对象提供的所有方法关键字\nprint('driver对象中的关键字：', dir(driver))\n\n# 在下面的各个关键字前 加上 driver. 就可以访问对应的方法和常量了，如：driver.get_window_size()\n\n'__abstractmethods__', '__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__enter__', '__eq__', '__exit__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_abc_impl', '_authenticator_id', '_file_detector', '_get_cdp_details', '_is_remote', '_mobile', '_shadowroot_cls', '_switch_to', '_unwrap_value', '_web_element_cls', '_wrap_value', 'add_cookie', 'add_credential', 'add_virtual_authenticator', 'application_cache', 'back', 'bidi_connection', 'capabilities', 'caps', 'close', 'command_executor', 'create_options', 'create_web_element', 'current_url', 'current_window_handle', 'delete_all_cookies', 'delete_cookie', 'delete_network_conditions', 'desired_capabilities', 'error_handler', 'execute', 'execute_async_script', 'execute_cdp_cmd', 'execute_script', 'file_detector', 'file_detector_context', 'find_element', 'find_elements', 'forward', 'fullscreen_window', 'get', 'get_cookie', 'get_cookies', 'get_credentials', 'get_issue_message', 'get_log', 'get_network_conditions', 'get_pinned_scripts', 'get_screenshot_as_base64', 'get_screenshot_as_file', 'get_screenshot_as_png', 'get_sinks', 'get_window_position', 'get_window_rect', 'get_window_size', 'implicitly_wait', 'launch_app', 'log_types', 'maximize_window', 'minimize_window', 'mobile', 'name', 'orientation', 'page_source', 'pin_script', 'pinned_scripts', 'port', 'print_page', 'quit', 'refresh', 'remove_all_credentials', 'remove_credential', 'remove_virtual_authenticator', 'save_screenshot', 'service', 'session_id', 'set_network_conditions', 'set_page_load_timeout', 'set_permissions', 'set_script_timeout', 'set_sink_to_use', 'set_user_verified', 'set_window_position', 'set_window_rect', 'set_window_size', 'start_client', 'start_desktop_mirroring', 'start_session', 'start_tab_mirroring', 'stop_casting', 'stop_client', 'switch_to', 'timeouts', 'title', 'unpin', 'vendor_prefix', 'virtual_authenticator_id', 'window_handles'\n```\n\n#### 1、Selenium常用的浏览器操作API\n\n```python\n# 引入selenium操作框架\nfrom selenium import webdriver\nfrom selenium.webdriver.common.by import By\n\n# 开启浏览器会话\ndriver = webdriver.Chrome()\n# driver = webdriver.Edge()\n\n# 指定加载浏览器RUL\ndriver.get(\"http://www.muguilin.com\")\n\n# 打开新页面\ndriver.navigate().to(\"http://www.muguilin.com/blog\")\n\n# 最大化窗口（有时候执行某些按扭、事件等无效时，就是没有最大化浏览器窗口【不在可视区】导致的！）\ndriver.maximize_window()\n\n# 最小化窗口\ndriver.minimize_window()\n\n# 保存屏幕截图\ndriver.save_screenshot('fileName')\n\n# 获取当前浏览器窗口可视区宽高\ndriver.get_window_size()\n\n# 获取当前窗口坐标\ndriver.get_window_position()\n\n# 设置窗口大小\ndriver.set_window_size(1920, 1080)\n\n# 刷新页面\ndriver.refresh()\n\n# 前进页面\ndriver.forward()\n\n# 后退页面\ndriver.back()\n\n# 关闭窗口\ndriver.close()\n\n# 关闭浏览器会话（关闭session等）\ndriver.quit()\n```\n\n#### 2、Selenium常用的元素选择器（元素定位）\n\n```python\n# 引入selenium操作框架\nfrom selenium import webdriver\nfrom selenium.webdriver.common.by import By\n\n# 开启浏览器会话\ndriver = webdriver.Chrome()\n\n# 其他浏览器会话方法\n# webdriver.Firefox()\n# webdriver.FirefoxProfile()\n# webdriver.FirefoxOptions()\n# webdriver.Chrome()\n# webdriver.ChromeOptions()\n# webdriver.Ie()\n# webdriver.IeOptions()\n# webdriver.Edge()\n# webdriver.ChromiumEdge()\n# webdriver.EdgeOptions()\n# webdriver.Safari()\n# webdriver.WebKitGTK()\n# webdriver.WebKitGTKOptions()\n# webdriver.WPEWebKit()\n# webdriver.WPEWebKitOptions()\n# webdriver.Remote()\n# webdriver.DesiredCapabilities()\n# webdriver.ActionChains()\n# webdriver.Proxy()\n# webdriver.Keys()\n\n# 最大化窗口\ndriver.maximize_window()  \n\n# 指定加载浏览器RUL\ndriver.get(\"http://www.muguilin.com\")\n\n# 选择input元素并设置值\nusername = driver.find_element(by=By.ID, value='username').send_keys('admin')\npasswerd = driver.find_element(by=By.ID, value='passwerd').send_keys('123456')\n\n# 选择button元素并模拟点击事件\ndriver.find_element(by=By.ID, value='login-button').click()\n\n# 设置取username输入框文本内容\nusername.sendKeys('root')\n\n# 获取username输入框文本内容\nusername.getText()\n\n# 清空username输入框文本内容\nusername.clear()\n\n# driver.find_element(By.ID, 'xxxid') // 单个DOM元素选择器方法\n# driver.find_elements(By.CLASS_NAME, 'xxxClassName') // 多个DOM元素选择器方法\n\n# 其他DOM元素选择器方法\n# ID = \"id\"\n# NAME = \"name\"\n# TAG_NAME = \"tag name\"\n# CLASS_NAME = \"class name\"\n# LINK_TEXT = \"link text\"\n# PARTIAL_LINK_TEXT = \"partial link text\"\n# XPATH = \"xpath\"\n# CSS_SELECTOR = \"css selector\"\n\n# 关闭浏览器会话\ndriver.quit()\n```\n\n#### 3、Selenium鼠标模拟操作（ActionChains类）\n\nSelenium框架中的ActionChains类供了很多，如：右击，双击，悬停，滑动、以及拖放等鼠标模拟操作。\n\n##### (1)、ActionChains类\n\n```python\n\"\"\"The ActionChains implementation,\"\"\"\n\nclass ActionChains:\n\n    def __init__(self, driver, duration=250)\n\n    def perform(self)\n       \n    def reset_actions(self)\n\n    def click(self, on_element=None)\n\n    def click_and_hold(self, on_element=None)\n        \n    def context_click(self, on_element=None)\n       \n    def double_click(self, on_element=None)\n       \n    def drag_and_drop(self, source, target)\n       \n    def drag_and_drop_by_offset(self, source, xoffset, yoffset)\n      \n    def key_down(self, value, element=None)\n       \n    def key_up(self, value, element=None)\n        \n    def move_by_offset(self, xoffset, yoffset)\n        \n    def move_to_element(self, to_element)\n       \n    def move_to_element_with_offset(self, to_element, xoffset, yoffset)\n        \n    def pause(self, seconds)\n        \n    def release(self, on_element=None)\n        \n    def send_keys(self, *keys_to_send)\n        \n    def send_keys_to_element(self, element, *keys_to_send)\n        \n    def scroll_to_element(self, element: WebElement)\n     \n    def scroll_by_amount(self, delta_x: int, delta_y: int)\n       \n    def scroll_from_origin(self, scroll_origin: ScrollOrigin, delta_x: int, delta_y: int)\n       \n    def scroll(self, x: int, y: int, delta_x: int, delta_y: int, duration: int = 0, origin: str = \"viewport\")\n       \n    def __enter__(self)\n        \n    def __exit__(self, _type, _value, _traceback)\n    \n```\n\n##### (2)、ActionChains类的基本使用\n\n在使用前，需要先导入ActionChains类，通过ActionChains类提供的相关方法来模拟鼠标操作，在调用ActionChains的方法时，并不是立即执行的，而是把所有的操作，按顺序存放在一个队列里，当调用perform()方法时，队列中的事件会依次执行。\n\n```python\n# 引入selenium操作框架\nfrom selenium import webdriver\nfrom selenium.webdriver.common.by import By\nfrom selenium.webdriver import ActionChains\nfrom time import sleep\n\n# 开启浏览器会话\ndriver = webdriver.Chrome()\n\n# 指定加载浏览器RUL\ndriver.get(\"http://www.baidu.com\")\n\n# 装载ActionChains类\naction = ActionChains(driver)\n\nsleep(1)\n\n# 模拟右键点击\naction.context_click().perform()\n\n# 在选择ID为kw的input元素上 模拟右键点击\nelement = driver.find_element(by=By.ID, value='kw')\naction.context_click(element).perform()\n\nsleep(10)\n```\n\n#### 4、Selenium键盘模拟操作（Keys类）\n\n在自动化测试开发过程中，除了模拟鼠标操作以外，有时还需要借助模拟键盘操作一起来配合使用，Selenium的Keys类供了很多复制、粘贴、全选，以及触发回车键、删除键甚至组合式快捷键等。\n\n##### (1)、Keys类\n\n```python\n\"\"\"The Keys implementation.\"\"\"\nclass Keys:\n    \"\"\"Set of special keys codes.\"\"\"\n\n    NULL = \"\\ue000\"\n    CANCEL = \"\\ue001\"  # ^break\n    HELP = \"\\ue002\"\n    BACKSPACE = \"\\ue003\"\n    BACK_SPACE = BACKSPACE\n    TAB = \"\\ue004\"\n    CLEAR = \"\\ue005\"\n    RETURN = \"\\ue006\"\n    ENTER = \"\\ue007\"\n    SHIFT = \"\\ue008\"\n    LEFT_SHIFT = SHIFT\n    CONTROL = \"\\ue009\"\n    LEFT_CONTROL = CONTROL\n    ALT = \"\\ue00a\"\n    LEFT_ALT = ALT\n    PAUSE = \"\\ue00b\"\n    ESCAPE = \"\\ue00c\"\n    SPACE = \"\\ue00d\"\n    PAGE_UP = \"\\ue00e\"\n    PAGE_DOWN = \"\\ue00f\"\n    END = \"\\ue010\"\n    HOME = \"\\ue011\"\n    LEFT = \"\\ue012\"\n    ARROW_LEFT = LEFT\n    UP = \"\\ue013\"\n    ARROW_UP = UP\n    RIGHT = \"\\ue014\"\n    ARROW_RIGHT = RIGHT\n    DOWN = \"\\ue015\"\n    ARROW_DOWN = DOWN\n    INSERT = \"\\ue016\"\n    DELETE = \"\\ue017\"\n    SEMICOLON = \"\\ue018\"\n    EQUALS = \"\\ue019\"\n\n    NUMPAD0 = \"\\ue01a\"  # number pad keys\n    NUMPAD1 = \"\\ue01b\"\n    NUMPAD2 = \"\\ue01c\"\n    NUMPAD3 = \"\\ue01d\"\n    NUMPAD4 = \"\\ue01e\"\n    NUMPAD5 = \"\\ue01f\"\n    NUMPAD6 = \"\\ue020\"\n    NUMPAD7 = \"\\ue021\"\n    NUMPAD8 = \"\\ue022\"\n    NUMPAD9 = \"\\ue023\"\n    MULTIPLY = \"\\ue024\"\n    ADD = \"\\ue025\"\n    SEPARATOR = \"\\ue026\"\n    SUBTRACT = \"\\ue027\"\n    DECIMAL = \"\\ue028\"\n    DIVIDE = \"\\ue029\"\n\n    F1 = \"\\ue031\"  # function  keys\n    F2 = \"\\ue032\"\n    F3 = \"\\ue033\"\n    F4 = \"\\ue034\"\n    F5 = \"\\ue035\"\n    F6 = \"\\ue036\"\n    F7 = \"\\ue037\"\n    F8 = \"\\ue038\"\n    F9 = \"\\ue039\"\n    F10 = \"\\ue03a\"\n    F11 = \"\\ue03b\"\n    F12 = \"\\ue03c\"\n\n    META = \"\\ue03d\"\n    COMMAND = \"\\ue03d\"\n    ZENKAKU_HANKAKU = \"\\ue040\"\n    \n```\n\n##### (2)、Keys类的基本使用\n\n在使用前，需要先导入Keys类，在选择好DOM元素后，配合send_keys()方法一起模拟键盘操作\n\n```python\n# 引入selenium操作框架\nfrom selenium import webdriver\nfrom selenium.webdriver.common.by import By\nfrom selenium.webdriver.common.keys import Keys\nfrom time import sleep\n\n# 开启浏览器会话\ndriver = webdriver.Chrome()\n\n# 指定加载浏览器RUL\ndriver.get(\"http://www.baidu.com\")\n\nsleep(1)\n\n# 在选择ID为kw的input元素上 模拟按回车键\ndriver.find_element(by=By.ID, value='kw').send_keys('沐枫', Keys.ENTER) # 回车键(ENTER)\n#driver.switch_to.active_element.send_keys(Keys.ENTER)\n\nsleep(10)\n\"\"\"\n单个键 模拟\nelement.send_keys(Keys.F1)\t\t\t\t# 键盘F1\nelement.send_keys(Keys.F5)\t\t\t\t# 键盘F5(页面刷新)\nelement.send_keys(Keys.F12)\t\t\t\t# 键盘F2(页面调试)\nelement.send_keys(Keys.TAB)\t\t\t\t# 制表键(TAB)\nelement.send_keys(Keys.BACK_SPACE)\t\t# 退格键(BackSpace)\nelement.send_keys(Keys.DELETE)\t\t    # 删除键(DELETE)\nelement.send_keys(Keys.ENTER)\t\t\t# 回车键(ENTER)\nelement.send_keys(Keys.SPACE)\t\t\t# 空格键(SPACE)\n\"\"\"\n\n\"\"\"\n组合键 模拟\nelement.send_keys(Keys.CONTROL,'a')\t\t# 全选(Ctrl+A)\nelement.send_keys(Keys.CONTROL,'x')\t\t# 剪切(Ctrl+X)\nelement.send_keys(Keys.CONTROL,'c')\t\t# 复制(Ctrl+C)\nelement.send_keys(Keys.CONTROL,'s')\t\t# 保存(Ctrl+S)\nelement.send_keys(Keys.CONTROL,'v')\t\t# 粘贴(Ctrl+V)\n\"\"\"\n```\n\n\n\n\n\n引用：[Python自动化测试 环境搭建 Selenium、WebDriver下载、安装、配置、基本使用详解](https://juejin.cn/post/7245632566996107321#heading-6)\n","tags":["自动化测试"],"categories":["测试"]},{"title":"边界值分析法","url":"/2023/07/05/边界值分析法/","content":"\n## 概述\n\n（**1**）边界值分析法是对软件的输入或输出边界进行测试的一种方法，它通常作为等价类划分法的一种补充测试。\n\n（**2**）在等价类划分法中，无论是输入等价类还是输出等价类，都会有**多个边界**，而边界值分析法就是在这些边界附近寻找**某些点**作为测试数据，而不是在等价类内部选择测试数据。\n\n## 设计测试用例\n\n**设计测试用例步骤**：\n\n（**1**）首先划分**等价类**，根据等价类划分情况确定**边界情况**。\n\n（**2**）选取**正好等于**、**刚刚大于**、**刚刚小于**边界的值作为测试数据，而不是选取等价类中的典型值或任意值。\n\n## 边界值设计原则\n\n**原则1**：如果输入条件规定了**值的范围**，则应取刚达到这个范围的边界的值，以及刚刚超越这个范围边界的值作为测试输入数据\n\n**原则2**：如果输入条件规定了**值的个数**，则用最大个数、最小个数、比最小个数少1、比最大个数多1的数作为测试数据\n\n**原则3**：根据规格说明的每个输出条件，使用前面的原则1。\n\n**原则4**：根据规格说明的每个输出条件，使用前面的原则2。\n\n**原则5**：如果程序的规格说明给出的输入域或输出域是**有序集合**，则应选取集合的**第一个元素**和**最后一个元素**作为测试用例。\n\n**原则6**：如果程序中使用了一个**内部数据结构**，则应该选择这个内部数据结构边界上的值作为测试用例。\n\n**原则7**：分析规格说明，找出**其他可能的边界条件**。\n\n## 例子\n\n假设我们要设计一个简单的计算器，它接受两个整数作为输入，并执行四个基本的算术运算：加法、减法、乘法和除法。计算器的设计要求输入的整数在-100到100的范围内。\n\n根据边界值分析法，我们应该测试以下情况：\n\n| 输入值  | 范围          | 结果                             |\n| ------- | ------------- | -------------------------------- |\n| -100，2 | -100          | 计算器应正确执行运算并显示结果。 |\n| 100，5  | 100           | 计算器应正确执行运算并显示结果。 |\n| -101，7 | 小于-100      | 计算器应拒绝输入并显示错误消息。 |\n| 101，3  | 大于100       | 计算器应拒绝输入并显示错误消息。 |\n| 0,99    | -100到100之间 | 计算器应正确执行运算并显示结果。 |\n\n## 引用\n\n[软件测试](https://juejin.cn/post/6968484121735594021)\n","tags":["测试"],"categories":["测试"]},{"title":"等价类划分法","url":"/2023/07/05/等价类划分法/","content":"\n## 定义\n\n一个程序可以有多个输入，等价类划分就是将这些**输入数据**按照输入需求进行分类，将它们划分为若干个子集，这些子集即为等价类（**某个输入域的子集合**），在每个**等价类**中选择有代表性的数据设计测试用例。\n\n*例如：电源，主板，cpu，cad，idea划分等价类，可以将前三个划在一起，后两个划在一起。分别为电脑硬件和软件。*\n\n## 划分步骤\n\n（1）先从程序**规格说明书**中找出各个**输入条件**； \n\n（2）再为每个输入条件划分**等价类**，形成若干**互不相交的子集**； \n\n（3）列出等价表\n\n## 设计测试用例步骤\n\n等价类划分法设计测试用例要经历**划分等价类**（列出等价类表）和**选取测试用例**两步。\n\n**（1）划分等价类**\n\n> 等价类是指某个输入域的子集合。在该子集合中，**各个输入数据对于揭露程序中的错误都是等效的**。测试代表值就等价于这一类其他值的测试。\n\n那在划分等价类的时候，会出现有效等价类和无效等价类，这个时候我们需要怎么判断呢？\n\n> **有效等价类**就是有效值的集合，它们是符合程序要求、合理且有意义的输入数据。\n>\n> **无效等价类**就是无效值的集合，它们是不符合程序要求、不合理或无意义的输入数据。\n\n因此，在设计测试用例时，要**同时考虑**有效等价类和无效等价类的设计。\n\n同时，在划分等价类的时候，需要遵循一定的划分原则：\n\n> **等价类划分原则**：\n>\n> **原则1**：如果输入条件规定了**取值范围**或**值的个数**的情况下，可以确定一个有效等价类和两个无效等价类。\n>\n> **原则2**：如果输入条件规定了**输入值的集合**或者规定了 **“必须如何”的条件** 的情况下，可以确立一个有效等价类和一个无效等价类。\n>\n> **原则3**：如果输入条件是一个**布尔量**的情况下，可确定一个有效等价类和一个无效等价类。\n>\n> **原则4**：如果规定了**输入数据的一组值**（假定n个），并且程序要对每一个输入值分别处理的情况下，可确定n个有效等价类和一个无效等价类。\n>\n> **原则5**：如果规定了**输入数据必须遵守**的规则，可确定一个有效等价类（符合规则）和若干个无效等价类（从不同角度违反规则）。\n>\n> **原则6**：在确知已划分的等价类中，各元素在程序处理中的方式不同的情况下，则应再将该等价类进一步地划分为更小的等价类。\n\n> 同一个等价类中的数据发现程序缺陷的能力是相同的，如果使用等价类中的其中一个数据不能捕获缺陷，那么使用等价类中的其他数据也不能捕获缺陷；同样，如果等价类中的其中一个数据能够捕获缺陷，那么该等价类中的其他数据也能捕获缺陷，即**等价类中的所有输入数据都是等效的**。\n\n**（2）设计测试用例**\n\n- 在确立了等价类之后，建立等价类列表，列出所有划分出的等价类。\n- 为每个等价类规定一个**唯一编号**。\n- 设计一个新的测试用例，使其**尽可能多地覆盖**尚未被覆盖的有效等价类。重复这一步，直到所有的有效等价类都被覆盖为止。\n- 设计一个新的测试用例，使其**仅覆盖一个**尚未被覆盖的无效等价类。重复这一步，直到所有的无效等价类都被覆盖为止。\n\n## 案例\n\n某连锁酒店集团实行积分奖励计划，会员每次入住集团旗下酒店均可以获得一定积分，积分由欢迎积分加消费积分构成。其中欢迎积分跟酒店等级有关，具体标准如表1-1所示；消费积分跟每次入住消费金额有关，具体标准为每消费1元获得2积分（不足1元的部分不给分）。此外，集团会员分为优先会员、金会员、白金会员三个级别，金会员和白金会员在入住酒店时可获得消费积分的额外奖励，奖励规则如表1-2所示。\n\n**表1-1** 集团不同等级酒店的欢迎积分标准\n\n![](https://presenter.oss-cn-shanghai.aliyuncs.com/wordpress/20230705205615.png)\n\n**表1-2** 额外积分奖励规则\n\n![](https://presenter.oss-cn-shanghai.aliyuncs.com/wordpress/20230705205635.png)\n\n该酒店集团开发了一个程序来计算会员每次入住后所累积的积分，程序的输入包括会员级别L、酒店等级C和消费金额A（单位：元），程序的输出为本次积分S。其中，L为单个字母且大小写不敏感，C为取值1到6的整数，A为正浮点数且最多保留两位小数，S为整数。\n\n【**问题一**】采用等价类划分法对该程序进行测试，等价类表如表1-3所示，请补充表中空（1）-（7）。 \n\n![](https://presenter.oss-cn-shanghai.aliyuncs.com/wordpress/20230705205648.png)\n\n【**问题二**】根据以上等价类表设计的测试用例如下表所示，请补充表2-4中空（1）-（13）。\n\n![](https://presenter.oss-cn-shanghai.aliyuncs.com/wordpress/20230705205713.png)\n\n## 引用\n\n[软件测试](https://juejin.cn/post/6968484121735594021)\n","tags":["测试"],"categories":["测试"]},{"title":"测试用例设计","url":"/2023/07/04/测试用例设计/","content":"\n# 定义\n\n测试用例(Test Case)是指对特定的软件产品进行测试任务的描述，体现测试方案、方法、技术和策略。测试用例内容包括测试目标、测试环境、输入数据、测试步骤、预期结果、测试脚本等，最终形成文档类的输出。简而言之，测试用例是为某个目标而设计的一组测试输入、执行条件以及预期结果，用于核实是否满足某个软件需求。\n\n# 基本原则\n\n- 正确性：设计的测试用例必须是正确的，必要时需要经过评审。\n- 代表性：在设计测试用例时，数据的选取需要有代表性，我个人认为部分的设计冗余是可以接受的，但是覆盖要全，数据能覆盖设计方法划分的范围。\n- 可判定性：用例的测试结果必须可量化，这样测试完成之后才能将测试结果与预期结果进行比较，判定是否存在BUG。\n- 可重现性：测试用例执行可复现性保证问题定位的准确性。\n- 可操作性：详细、准确和清晰的步骤是测试用例执行的必要条件，也是测试用例可重现的基础。\n\n# 常用测试用例设计方法\n\n**测试包括黑白盒测试，这里的设计方法就是黑盒测试方法。**先在这里简单介绍各种方法，对常用的测试用例设计方法有个粗浅的了解，后续对每个方法进行详细介绍（实际是想划水，多划几篇文章出来）。\n\n- 等价类划分\n- 边界值分析\n- 场景法\n- 错误推测法\n- 因果图和判定表（这个就合在一起写吧）\n- 正交实验法\n\n# 实际工作中的测试用例\n\n实际工作中，如果按照理论上的测试用例设计方法去设计执行，测试的时间和成本都会增加，就是在用时间换取高覆盖率。更多情况下，用例设计时应该遵守精益测试策略，不能一味的追求测试覆盖率，有效的测试更有价值。利用测试四象限等信息指导的精益测试，追求以业务价值为目标，以尽量少的成本交付高质量的软件，做到有效覆盖，减少浪费。不管是手工测试还是自动化测试，都要先搞清楚业务价值和质量目标，测试用例设计和执行过程都需要做出相对应的考量（如测试用例的优先级）。\n\n![测试四象限](https://presenter.oss-cn-shanghai.aliyuncs.com/wordpress/20230704180312.png)\n","tags":["测试"],"categories":["测试"]},{"title":"关于protobuf","url":"/2023/07/03/关于protobuf/","content":"\n ## 前言\n\n最近在看一本书，google的测试之道，里面提到了一个protocol buffer名词。\n\n> Protocol Buffer是Google提供的一种数据序列化协议，下面是我从网上找到的Google官方对protobuf的定义：\n> Protocol Buffers 是一种轻便高效的结构化数据存储格式，可以用于结构化数据序列化，很适合做数据存储或 RPC 数据交换格式。它可用于通讯协议、数据存储等领域的语言无关、平台无关、可扩展的序列化结构数据格式。\n\n## 简单使用\n\n首先在github下载protocol的编译器[直达]([Releases · protocolbuffers/protobuf (github.com)](https://github.com/protocolbuffers/protobuf/releases))\n\n解压之后设置环境变量或者讲protoc.exe文件放在windows/system32目录下。\n\n先安装protocol buffers\n\n```bash\nnpm install google-protobuf\n```\n\n编写一个.proto文件\n\n```protobuf\npackage zxwj;\nsyntax = \"proto3\";\nmessage helloworld \n{ \n   string zzuid = 123;  \n   string zzstatus = 0;\n}\n```\n\n## 编译.proto文件\n\n> *使用protobuf.js命令行工具编译*\n\n```bash\nprotoc --js_out=import_style=commonjs,binary:. messages.proto\n```\n\nprotoc会编译输入文件，并且构建messages_pb，在sever中，可以以以下方式引用\n\n```js\nvar messages = require('./messages_pb');\nvar message = new messages.MyMessage();\n```\n\n## 编写server.js\n\n```js\nvar basepb = require('./messages_pb');\nconsole.log(basepb);\n\nvar message = new basepb.SearchRequest();\nconsole.log(message);\n\nmessage.setName(\"TS\");\nmessage.setPassword(\"123456\");\n\nvar bytes = message.serializeBinary(); //对象序列化\nconsole.log(bytes);\n\nvar message2 = basepb.SearchRequest.deserializeBinary(bytes); //进制序列化\nconsole.log(message2);\n```\n\n## 运行\n\n```bash\nnode sever.js\n```\n\n\n\n# 补充\n\n### 定义消息类型\n\n`protobuf`里最基本的类型就是`message`，每一个`message`都会有一个或者多个字段(`field`)，其中字段包含如下元素\n\n![image-20230708102536853](https://presenter.oss-cn-shanghai.aliyuncs.com/wordpress/image-20230708102536853.png)\n\n- 类型：类型不仅可以是标量类型（`int`、`string`等），也可以是复合类型（`enum`等），也可以是其他`message`\n- 字段名：字段名比较推荐的是使用下划线/分隔名称\n- 字段编号：一个message内每一个字段编号都必须唯一的，在编码后其实传递的是这个编号而不是字段名\n- 字段规则：消息字段可以是以下字段之一\n  - `singular`：格式正确的消息可以有零个或一个字段（但不能超过一个）。使用 proto3 语法时，如果未为给定字段指定其他字段规则，则这是默认字段规则\n  - `optional`：与 `singular` 相同，不过您可以检查该值是否明确设置\n  - `repeated`：在格式正确的消息中，此字段类型可以重复零次或多次。系统会保留重复值的顺序\n  - `map`：这是一个成对的键值对字段\n- 保留字段：为了避免再次使用到已移除的字段可以设定保留字段。如果任何未来用户尝试使用这些字段标识符，编译器就会报错\n\n### 标量值类\n\n| .proto Type | Go Type | Notes                                                        |\n| ----------- | ------- | ------------------------------------------------------------ |\n| double      | float64 |                                                              |\n| float       | float32 |                                                              |\n| int32       | int32   | 使用可变长度的编码。对负数的编码效率低下 - 如果您的字段可能包含负值，请改用 sint32。 |\n| int64       | int64   | 使用可变长度的编码。对负数的编码效率低下 - 如果字段可能有负值，请改用 sint64。 |\n| uint32      | uint32  | 使用可变长度的编码。                                         |\n| uint64      | uint64  | 使用可变长度的编码。                                         |\n| sint32      | int32   | 使用可变长度的编码。有符号整数值。与常规 int32 相比，这些函数可以更高效地对负数进行编码。 |\n| sint64      | int64   | 使用可变长度的编码。有符号整数值。与常规 int64 相比，这些函数可以更高效地对负数进行编码。 |\n| fixed32     | uint32  | 始终为 4 个字节。如果值通常大于 2^28，则比 uint32 更高效。   |\n| fixed64     | uint64  | 始终为 8 个字节。如果值通常大于 2^56，则比 uint64 更高效。   |\n| sfixed32    | int32   | 始终为 4 个字节。                                            |\n| sfixed64    | int64   | 始终为 8 个字节。                                            |\n| bool        | bool    |                                                              |\n| string      | string  | 字符串必须始终包含 UTF-8 编码或 7 位 ASCII 文本，并且长度不得超过 232。 |\n| bytes       | []byte  | 可以包含任意长度的 2^32 字节。                               |\n\n### 复合类型\n\n#### 数组\n\n```protobuf\nmessage SearchResponse {\n  repeated Result results = 1;\n}\n\nmessage Result {\n  string url = 1;\n  string title = 2;\n  repeated string snippets = 3;\n}\n```\n\n#### 枚举\n\n```protobuf\nmessage SearchRequest {\n  string query = 1;\n  int32 page_number = 2;\n  int32 result_per_page = 3;\n  enum Corpus {\n    UNIVERSAL = 0;\n    WEB = 1;\n    IMAGES = 2;\n    LOCAL = 3;\n    NEWS = 4;\n    PRODUCTS = 5;\n    VIDEO = 6;\n  }\n  Corpus corpus = 4;\n}\n```\n\n#### 服务\n\n定义的method仅能有一个入参和出参数。如果需要传递多个参数需要定义成message\n\n```protobuf\nprotobuf复制代码service SearchService {\n  rpc Search(SearchRequest) returns (SearchResponse);\n}\n```\n\n### 使用其他消息类型\n\n使用import引用另外一个文件的pb\n\n```protobuf\nsyntax = \"proto3\";\n\nimport \"google/protobuf/wrappers.proto\";\n\npackage ecommerce;\n\nmessage Order {\n  string id = 1;\n  repeated string items = 2;\n  string description = 3;\n  float price = 4;\n  google.protobuf.StringValue destination = 5;\n}\n```\n\n## protoc使用\n\nprotoc就是protobuf的编译器，它把proto文件编译成不同的语言\n\n### 📖 安装\n\n[grpc.io/docs/protoc…](https://link.juejin.cn/?target=https%3A%2F%2Fgrpc.io%2Fdocs%2Fprotoc-installation%2F)\n\n- Linux, using `apt` or `apt-get`, for example:\n\n  ```sh\n  $ apt install -y protobuf-compiler\n  $ protoc --version  # Ensure compiler version is 3+\n  ```\n\n### 📖 使用\n\n```shell\nshell复制代码$ protoc --help\nUsage: protoc [OPTION] PROTO_FILES\n\n  -IPATH, --proto_path=PATH   指定搜索路径\n  --plugin=EXECUTABLE:\n  \n  ....\n \n  --cpp_out=OUT_DIR           Generate C++ header and source.\n  --csharp_out=OUT_DIR        Generate C# source file.\n  --java_out=OUT_DIR          Generate Java source file.\n  --js_out=OUT_DIR            Generate JavaScript source.\n  --objc_out=OUT_DIR          Generate Objective C header and source.\n  --php_out=OUT_DIR           Generate PHP source file.\n  --python_out=OUT_DIR        Generate Python source file.\n  --ruby_out=OUT_DIR          Generate Ruby source file\n  \n   @<filename>                proto文件的具体位置\n```\n\n#### 1.搜索路径参数\n\n第一个比较重要的参数就是`搜索路径参数`，即上述展示的`-IPATH, --proto_path=PATH`。它表示的是我们要在哪个路径下搜索`.proto`文件，这个参数既可以用`-I`指定，也可以使用`--proto_path=`指定。\n\n如果不指定该参数，则默认在**当前路径**下进行搜索；另外，该参数也可以指定多次，这也意味着我们可以指定**多个路径**进行搜索。\n\n#### 2.语言插件参数\n\n语言参数即上述的`--cpp_out=`，`--python_out=`等，protoc支持的语言长达13种，且都是比较常见的\n\n运行help出现的语言参数，说明protoc本身已经内置该语言对应的编译插件，我们无需安装\n\n| Language                             | Generated Code                                               | Source                                                       |\n| ------------------------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ |\n| C++ (include C++ runtime and protoc) | [C++](https://link.juejin.cn/?target=https%3A%2F%2Fdevelopers.google.com%2Fprotocol-buffers%2Fdocs%2Freference%2Fcpp-generated%23invocation) | [src](https://link.juejin.cn/?target=https%3A%2F%2Fgithub.com%2Fprotocolbuffers%2Fprotobuf%2Fblob%2Fmain%2Fsrc) |\n| Java                                 | [Java](https://link.juejin.cn/?target=https%3A%2F%2Fdevelopers.google.com%2Fprotocol-buffers%2Fdocs%2Freference%2Fjava-generated%23invocation) | [java](https://link.juejin.cn/?target=https%3A%2F%2Fgithub.com%2Fprotocolbuffers%2Fprotobuf%2Fblob%2Fmain%2Fjava) |\n| Python                               | [Python](https://link.juejin.cn/?target=https%3A%2F%2Fdevelopers.google.com%2Fprotocol-buffers%2Fdocs%2Freference%2Fpython-generated%23invocation) | [python](https://link.juejin.cn/?target=https%3A%2F%2Fgithub.com%2Fprotocolbuffers%2Fprotobuf%2Fblob%2Fmain%2Fpython) |\n| Objective-C                          | [Objective-C](https://link.juejin.cn/?target=https%3A%2F%2Fdevelopers.google.com%2Fprotocol-buffers%2Fdocs%2Freference%2Fobjective-c-generated%23invocation) | [objectivec](https://link.juejin.cn/?target=https%3A%2F%2Fgithub.com%2Fprotocolbuffers%2Fprotobuf%2Fblob%2Fmain%2Fobjectivec) |\n| C#                                   | [C#](https://link.juejin.cn/?target=https%3A%2F%2Fdevelopers.google.com%2Fprotocol-buffers%2Fdocs%2Freference%2Fcsharp-generated%23invocation) | [csharp](https://link.juejin.cn/?target=https%3A%2F%2Fgithub.com%2Fprotocolbuffers%2Fprotobuf%2Fblob%2Fmain%2Fcsharp) |\n| Ruby                                 | [Ruby](https://link.juejin.cn/?target=https%3A%2F%2Fdevelopers.google.com%2Fprotocol-buffers%2Fdocs%2Freference%2Fruby-generated%23invocation) | [ruby](https://link.juejin.cn/?target=https%3A%2F%2Fgithub.com%2Fprotocolbuffers%2Fprotobuf%2Fblob%2Fmain%2Fruby) |\n| PHP                                  | [PHP](https://link.juejin.cn/?target=https%3A%2F%2Fdevelopers.google.com%2Fprotocol-buffers%2Fdocs%2Freference%2Fphp-generated%23invocation) | [php](https://link.juejin.cn/?target=https%3A%2F%2Fgithub.com%2Fprotocolbuffers%2Fprotobuf%2Fblob%2Fmain%2Fphp) |\n","tags":["protobuf"],"categories":["前端"]},{"title":"无聊时在想黑洞是啥","url":"/2023/06/30/关于无聊时的思考/","content":"\n## 主题1：黑洞\n\n- 黑洞是由巨大恒星坍缩形成的极其密集的天体。\n- 黑洞的高密度是由于巨大的引力将物质压缩到奇点。\n- 在奇点处，我们目前所理解的物理定律失效，其微观结构仍然未知。\n\n## 主题2：黑洞的形成\n\n- 当一个巨大物体在自身的引力作用下坍缩时，就会形成黑洞，将质量集中到一个小体积内。\n- 压缩到一个关键半径，即事件视界，会形成一个连光都无法逃脱的区域。\n- 事件视界和黑洞的形成概念是由爱因斯坦的广义相对论推导出来的。\n\n## 主题3：光速\n\n- 在宇宙中，光速被选择为一个基本常量，并非巧合，而是时空本质的结果。\n- 光速，表示为 \"c\"，在物理定律的一致性和信息传播中起着关键作用。\n\n## 主题4：物质的压缩\n\n- 如果将一堆中子和质子压缩在一起，会受到电磁力、核力和泡利不相容原理等反作用力的影响。\n- 当物体被极度压缩时，会达到高密度状态，但不一定会形成黑洞。黑洞的形成需要达到一定的质量和压缩条件。","tags":["黑洞"],"categories":["瞎想"]},{"title":"递归算法结构","url":"/2023/06/29/递归算法结构/","content":"\n### 1.递归原理\n\n### **1.1.什么是递归，它是如何工作的？**\n\n我们先来看一下递归（recursion）的定义：\n\n> 递归是一种解决问题的有效方法，在递归过程中，函数将自身作为子例程调用。\n\n简单说程序调用自身的编程技巧叫递归。递归的思想是**把一个大型复杂问题层层转化为一个与原问题规模更小的问题，问题被拆解成子问题后，递归调用继续进行，直到子问题无需进一步递归就可以解决的地步为止**。\n\n使用递归需要避免出现死循环，为了确保递归正确工作，递归程序应该包含2个属性：\n\n1. 基本情况（bottom cases），基本情况用于保证程序调用及时返回，不在继续递归，保证了程序可终止。\n2. 递推关系（recurrentce relation），可将所有其他情况拆分到基本案例。\n\n**示例**\n\n让我们从一个简单的编程问题开始：\n\n> 以相反的顺序打印字符串。\n\n你可以使用迭代的办法轻而易举地解决这个问题，即从字符串的最后一个字符开始遍历字符串。但是如何递归地解决它呢？\n\n首先，我们可以将所需的函数定义为 printReverse(str[0...n-1])，其中 str[0] 表示字符串中的第一个字符。然后我们可以分两步完成给定的任务：\n\n1. printReverse(str[1...n-1])：以相反的顺序打印子字符串 str[1...n-1] 。\n2. print(str[0])：打印字符串中的第一个字符。\n\n请注意，我们在第一步中调用函数本身，根据定义，它使函数递归。\n\n下面给出了代码片段：\n\n```java\nprivate static void printReverse(char [] str) {\n  helper(0, str);\n}\n\n\nprivate static void helper(int index, char [] str) {\n if (str == null || index >= str.length) {\n return;\n  }\n  helper(index + 1, str);\n  System.out.print(str[index]);\n}\n```\n\n### 1.2.递归的程序特征\n\n**优雅性**\n\n相比其他解法（比如迭代法），使用递归法，你会发现只需少量程序就可描述出解题过程，大大减少了程序的代码量，而且很好理解。递归的能力在于用有限的语句来定义对象的无限集合。\n\n**反向性**\n\n由于递归调用程序需要维护调用栈，而栈（我们在上文提过）具有后进先出的特征，因此递归程序适合满足取反类需求。我们在第五部分有一些编程实践，比如字符串取反，链表取反等相关有趣的算法问题。\n\n**递推关系**\n\n递归程序可以较明显的发现递推关系，反过来也可以这么说，具有递推关系的问题基本都可以通过递归求解（当然也许有性能更佳的解法，但递归绝对是一种选择）。递推关系常见问题有杨辉三角、阶乘计算（见本文第五小节）。下一节重点讨论一下递推关系。\n\n### 1.3.什么时候考虑递归\n\n具有以下特征的问题可考虑递归求解：\n\n- 当问题和子问题具有递推关系，比如杨辉三角、计算阶乘（后文讨论）。\n- 具有递归性质的数据结构，比如链表、树、图。\n- 反向性问题，比如取反。\n\n总结下来，最根本的还是要**抓住问题本身是否可以通过层层拆解到最小粒度来得解。**\n\n### 2.递归的递推性质\n\n上一节我们说了，在实现递归函数之前，我们需要弄明白2件事：\n\n- 递推关系： 一个问题的结果与其子问题的结果之间的关系。\n- 基本情况: 不需要进一步的递归调用就可以直接计算答案的情况。 它们往往是问题被减少到最小规模的情况，*也就是*如果我们认为将问题划分为子问题是一种自上而下的方式的最下层。\n\n一旦我们计算出以上两个元素，再想要实现一个递归函数，就只需要根据递推关系调用函数本身，直到其抵达基本情况。\n\n为了解释以上几点，我们来看一个经典问题：杨辉三角（也叫帕斯卡三角）。\n\n### 2.1.帕斯卡三角\n\n帕斯卡三角形是排列成三角形的一系列数字。 在帕斯卡三角形中，每一行的最左边和最右边的数字总是 1。 对于其余的每个数字都是前一行中直接位于它上面的两个数字之和。\n\n下面的插图给出了一个 5 行的帕斯卡三角：\n\n![动图封面](https://presenter.oss-cn-shanghai.aliyuncs.com/wordpress/v2-99fd119be3ca7616ae635b28e7181f7e_b.jpg)\n\n\n\n根据上面的定义，我们生成一个具有确定行数的帕斯卡三角形。\n\n**递推关系**\n\n让我们从帕斯卡三角形内的递推关系开始。\n\n首先，我们定义一个函数 *f*(*i*,*j*)，它将会返回帕斯卡三角形第 i 行、第 j 列的数字。\n\n我们可以用下面的公式来表示这一递推关系：\n\n*f*(*i*,*j*)=*f*(*i*−1,*j*−1)+*f*(*i*−1,*j*)\n\n**基本情况**\n\n可以看到，每行的最左边和最右边的数字是基本情况，在这个问题中，它总是等于 1。\n\n因此，我们可以将基本情况定义如下:\n\n*f*(*i*,*j*)=1*wherej*=1*orj*=*i*\n\n**演示**\n\n正如我们所看到的，一旦我们定义了 递推关系 和 基本情况，递归函数的实现变得更加直观，特别是在我们用数学公式表示出这两个元素之后。\n\n下面给出一个例子，展示我们如何用这个公式递归地计算 *f*(5,3), *也就是* 帕斯卡三角形第 5 行中的第 3 个数。\n\n![动图封面](https://presenter.oss-cn-shanghai.aliyuncs.com/wordpress/v2-99fd119be3ca7616ae635b28e7181f7e_b.jpg)\n\n\n\n\n\n我们可以将 *f*(5,3) 分解为 *f*(5,3)=*f*(4,2)+*f*(4,3)，然后递归地调用 *f*(4,2) 和 *f*(4,3)：\n\n- 对于调用的 *f*(4,2)，我们可以进一步展开它，直到到达基本情况，正如下面所描述的：\n\n*f*(4,2)=*f*(3,1)+*f*(3,2)=*f*(3,1)+(*f*(2,1)+*f*(2,2))=1+(1+1)=3\n\n- 对于调用的 *f*(4,3)，类似地，我们可以将其分解为：\n\n*f*(4,3)=*f*(3,2)+*f*(3,3)=(*f*(2,1)+*f*(2,2))+*f*(3,3)=(1+1)+1=3\n\n- 最后，我们结合上述子问题的结果：\n\n*f*(5,3)=*f*(4,2)+*f*(4,3)=3+3=6\n\n您可能已经注意到递归解决方案可能会导致一些重复的计算，例如，我们重复计算相同的中间数以获得最后一行中的数字。 举例说明，为了得到 *f*(5,3) 的结果，我们在 *f*(4,2) 和 *f*(4,3) 的调用中计算了 *f*(3,2) 两次，这样重复计算效率肯定不高，下一节我们会给出优化方案来避免重复计算（即记忆术）。\n\n### 3.递归复杂性分析\n\n### 3.1.递归时间复杂度计算\n\n给出一个递归算法，其时间复杂度 O(*T*) 通常是**递归调用的数量**（记作 *R*） 和计算的时间复杂度的乘积（表示为 O(*s*)）的乘积：\n\nO(*T*)=*R*∗O(*s*)\n\n**示例**\n\n在反转字符串问题中，我们需要以相反的顺序打印字符串，解决问题的递归关系可以表示如下：\n\nprintReverse(str) = printReverse(str[1...n]) + print(str[0])\n\n其中 str[1...n] 是输入字符串 str 的子串，仅不含前导字符 str[0]。\n\n如您所见，该函数将被递归调用 n 次，其中 n 是输入字符串的大小。在每次递归结束时，我们只是打印前导字符，因此该特定操作的时间复杂度是恒定的，即 O(1)。\n\n总而言之，我们的递归函数 printReverse(str) 的总体时间复杂度为 O(*printReverse*)=*n*∗O(1)=O(*n*)。\n\n**执行树分析递归调用数量**\n\n在分析递归的时间复杂度时，递归调用的数量不一定和N成线性关系，比如斐波那契数的计算（见第五部分），其递推关系被定义为f(n) = f(n-1) + f(n-2)。乍一看，在执行斐波那契函数期间计算递归调用的数量似乎并不简单。\n\n执行树定义\n\n> **执行树**是一个用于表示递归函数的执行流程的树。树中的每个节点都表示递归函数的调用。因此，树中的节点总数对应于执行期间的递归调用的数量。\n\n递归函数的执行树将形成 n 叉树，其中 n 作为递推关系中出现递归的次数。例如，斐波那契函数的执行将形成二叉树，下面的图示展现了用于计算斐波纳契数 f(4) 的执行树。\n\n![img](https://presenter.oss-cn-shanghai.aliyuncs.com/wordpress/v2-92d5e67cc69e6599cf921e90fb63d3f9_720w.webp)\n\n\n在 n 层的完全二叉树中，节点的总数为 2*n*−1。因此 ​f(n)​ 中递归数目的上限（尽管不严格）也是 2*n*−1。那么我们可以估计 ​f(n)​ 的时间复杂度为 O(2*n*)。\n\n### 3.2.递归空间复杂性分析\n\n在计算递归算法的空间复杂度时，应该考虑造成空间消耗的两个部分：递归相关空间（recursion related space）和非递归相关空间（non-recursion related space）。\n\n**递归相关空间**\n\n递归相关空间是指由递归直接引起的内存开销，即用于跟踪递归函数调用的堆栈。为了完成典型的函数调用，系统应该在栈中分配一些空间来保存三个重要信息：\n\n1. 函数调用的返回地址。一旦函数调用完成，程序应该知道返回的位置，即函数调用之前的点。\n2. 传递给函数调用的参数。\n3. 函数调用中的局部变量。\n\n栈中的这个空间是函数调用期间产生的最小成本。然而，一旦完成函数调用，就会释放该空间。\n\n对于递归算法，函数调用将连续链接直到它们到达基本情况（*也称为* 底层情况）。这意味着用于每个函数调用的空间也会累积。\n\n对于递归算法，如果没有产生其他内存消耗，则此递归引起的空间将是算法的空间上限。\n\n例如，在本文一开始我们提到了反转字符串示例中，我们没有使用额外的内存，因为我们仅仅是打印一个字符。对于每个递归调用，我们假设它可能需要一个最大为某一常量值的空间。并且递归调用最多可以链接 n 次，其中 n 是输入字符串的大小。因此，该递归算法的空间复杂度就是 O(*n*)。\n\n为了更好地说明这一点，接下来我们将会展示递归调用 f(x1) -> f(x2) -> f(x3) 的执行顺序以及栈空间的分配情况。\n\n![img](https://presenter.oss-cn-shanghai.aliyuncs.com/wordpress/v2-3822068d611d10cf97f681d458bbd0e4_720w.webp)\n\n栈中的空间将会分配给 f(x1) 来调用 f(x2)。类似的情况也同样发生在 f(x2) 中，系统会为 f(x3) 的调用分配另一个空间，最后在 f(x3) 中，我们到达基本情况，因此在 f(x3) 中没有进行进一步的递归调用。\n\n正是由于这些与递归相关的空间消耗，有时可能会遇到称为[堆栈溢出](https://link.zhihu.com/?target=https%3A//baike.baidu.com/item/%E5%A0%86%E6%A0%88%E6%BA%A2%E5%87%BA/1231765%3Ffr%3Daladdin)的情况，其中为程序分配的堆栈达到其最大空间限制并导致程序最终失败。在设计递归算法时，应该仔细评估在输入规模扩大时是否存在堆栈溢出的可能性，栈溢出是非常容易出错的点，我们在下一节将讨论优化策略。\n\n**非递归相关空间**\n\n正如名称所示，非递归相关空间指的是与递归过程没有直接关系的内存空间，通常包括为全局变量分配的空间（通常在堆中）。\n\n不管是否递归，你都可能需要在任何函数调用之前将问题的输入存储为全局变量。你可能还需要保存递归调用的中间结果（也就是我们即将讨论的**记忆化技术**）。例如，在使用带有记忆化技术的递归算法解决斐波那契数问题时,我们使用映射（map）来跟踪在递归调用期间产生的所有中间斐波那契数。因此，在分析空间复杂度时，我们应该考虑到因采用记忆化技术所导致的空间成本。\n\n\n\n### 4.递归的优化策略\n\n### 4.1.时间优化策略：记忆化\n\n递归是一种直观而有效的实现算法的方法。 但是，如果我们不明智地使用它，可能会给性能带来一些不希望的损失，*例如*重复计算。 在前面我们提到了帕斯卡三角的重复计算问题，其中一些中间结果被多次计算。\n\n在本文中，我们将进一步研究递归可能出现的重复计算问题。 然后我们将提出一种常用的技术，称为记忆化（memoization），可以用来避免这个问题。\n\n为了演示重复计算的另一个问题，让我们看一个大多数人可能都很熟悉的例子，[斐波那契数](https://link.zhihu.com/?target=https%3A//baike.baidu.com/item/%E6%96%90%E6%B3%A2%E9%82%A3%E5%A5%91%E6%95%B0)。 如果我们定义函数 F(n) 表示在索引 n 处的斐波那契数，那么你可以推导出如下的递推关系：\n\nF(n) = F(n - 1) + F(n - 2)\n\n基本情况：\n\nF(0) = 0, F(1) = 1\n\n根据斐波那契数列的定义，可以实现下面的函数：\n\n```java\npublic static int fibonacci(int n) {\n if (n < 2) {\n return n;\n  } else {\n return fibonacci(n-1) + fibonacci(n-2);\n  }\n}\n```\n\n现在，如果你想知道 F(4) 是多少，你可以应用上面的公式并进行展开：\n\nF(4) = F(3) + F(2) = (F(2) + F(1)) + F(2)\n\n正如你所看到的，为了得到 f (4)的结果，我们需要在上述推导之后计算两次数 F(2) : 第一次在 F(4) 的第一次展开中，第二次在中间结果 F(3) 中。\n\n下面的树显示了在计算 F(4) 时发生的所有重复计算（按颜色分组）。\n\n![img](https://presenter.oss-cn-shanghai.aliyuncs.com/wordpress/v2-92d5e67cc69e6599cf921e90fb63d3f9_720w.webp)\n\n\n\n为了消除上述情况中的重复计算，正如许多人已经指出的那样，其中一个想法是将中间结果**存储**在缓存中，以便我们以后可以重用它们，而不需要重新计算。\n\n这个想法也被称为*记忆化*，这是一种经常与递归一起使用的技术。\n\n**记忆化定义**\n\n> [记忆化](https://link.zhihu.com/?target=https%3A//baike.so.com/doc/4953402-5174974.html) 是一种优化技术，主要用于**加快**计算机程序的速度，方法是**存储**昂贵的函数调用的结果，并在相同的输入再次出现时返回缓存的结果。 (来源: 维基百科)\n\n回到斐波那契函数 F(n)。 我们可以使用哈希表来跟踪每个以 n 为键的 F(n) 的结果。 散列表作为一个缓存，可以避免重复计算。 记忆化技术是一个很好的例子，它演示了如何通过增加额外的空间以减少计算时间。\n\n为了便于比较，我们在下面提供了带有记忆化功能的斐波那契数列解决方案的实现。\n\n作为一种练习，您可以尝试使记忆化更加通用和非侵入性，即应用记忆化技术而不改变原来的功能。\n\n```java\nimport java.util.HashMap;\n\npublic class Main {\n\n  HashMap<Integer, Integer> cache = new HashMap<Integer, Integer>();\n\n private int fib(int N) {\n if (cache.containsKey(N)) {\n return cache.get(N);\n    }\n int result;\n if (N < 2) {\n      result = N;\n    } else {\n      result = fib(N-1) + fib(N-2);\n    }\n // keep the result in cache.\n    cache.put(N, result);\n return result;\n  }\n}\n```\n\n斐波那契数应用的一个经典问题是爬楼梯，我们在第五节再分析。\n\n通过记忆化技术，我们保存每个索引 n 对应的的斐波那契数的结果。我们确信每个斐波那契数的计算只会发生一次。而从递推关系来看，斐波纳契数 f(n) 将取决于其所有 n-1 个先验斐波纳契数。结果，计算 f(n) 的递归将被调用 n-1 次以计算它所依赖的所有先验数字。\n\n现在，我们可以计算一下采用了记忆化技术优化后的时间复杂度，即 O(1)∗*n*=O(*n*)。可以得出记忆化技术不仅可以优化算法的时间复杂度，还可以简化时间复杂度的计算。\n\n### 4.2.空间优化策略：尾递归\n\n上一节我们讨论了递归空间复杂性分析话题，从中我们了解到递归调用在系统调用栈上会产生额外空间，如果递归调用层级很深，程序执行过程中很可能导致栈溢出。针对这种情况，有一种称为尾递归的特殊递归，它可以控制递归导致空间开销的影响。\n\n**尾递归定义**\n\n> 尾递归函数是递归函数的一种，其中递归调用是递归函数中的最后一条指令。并且在函数中应该只有一次递归调用。\n\n尾递归的好处是，它可以避免递归调用期间栈空间开销的累积，因为系统可以为每个递归调用重用栈中的固定空间。可以理解为，在程序执行到递归函数最后一条递归调用指令时回收了当前的栈空间（其实是复用了当前的栈空间），爽歪歪。\n\n我们在第五部分将看到尾递归优化阶乘运算的例子。\n\n### 5.采用递归解法的几个经典问题\n\n递归在递推关系的数学问题上应用广泛，使用递归法可以解决很多趣味问题，下面我们来看看都有哪些经典问题。\n\n### 5.1.反转字符串\n\n编写一个函数，其作用是将输入的字符串反转过来。输入字符串以字符数组 char[] 的形式给出。\n\n不要给另外的数组分配额外的空间，你必须**[原地](https://link.zhihu.com/?target=https%3A//baike.baidu.com/item/%E5%8E%9F%E5%9C%B0%E7%AE%97%E6%B3%95)修改输入数组**、使用 O(1) 的额外空间解决这一问题。\n\n你可以假设数组中的所有字符都是 [ASCII](https://link.zhihu.com/?target=https%3A//baike.baidu.com/item/ASCII) 码表中的可打印字符。\n\n**示例 1：**\n\n**输入：**[\"h\",\"e\",\"l\",\"l\",\"o\"]\n\n**输出：**[\"o\",\"l\",\"l\",\"e\",\"h\"]\n\n**示例 2：**\n\n**输入：**[\"H\",\"a\",\"n\",\"n\",\"a\",\"h\"]\n\n**输出：**[\"h\",\"a\",\"n\",\"n\",\"a\",\"H\"]\n\n\n\n分析：此问题是根据递归调用栈的特性做后进先出反转。\n\n代码：\n\n```java\n public void reverseString(char[] s) {\n        help(s, 0, s.length - 1);\n    }\n\n\n private void help(char[] s, int left, int right) {\n if (left >= right) return;\n        exch(s, left, right);\n        help(s, ++left, --right);\n    }\n\n\n private void exch(char[] a, int i, int j) {\n char swap = a[i];\n        a[i] = a[j];\n        a[j] = swap;\n    }\n```\n\n### 5.2.两两交换链表中的节点\n\n给定一个链表，两两交换其中相邻的节点，并返回交换后的链表。\n\n**你不能只是单纯的改变节点内部的值**，而是需要实际的进行节点交换。\n\n**示例:**\n\n给定\n\n```\n1->2->3->4\n```\n\n, 你应该返回\n\n```\n2->1->4->3\n```\n\n\n\n代码：\n\n```java\n public ListNode swapPairs(ListNode head) {\n    if (head == null || head.next == null) return head;\n        int temp = head.val;\n        head.val = head.next.val;\n        head.next.val = temp;\n \n        ListNode nextHead = swapPairs(head.next.next);\n        head.next.next = nextHead;\n \n return head;\n    }\n```\n\n\n\n### 5.3.杨辉三角\n\n给定一个非负整数 *numRows，*生成杨辉三角的前 *numRows* 行。\n\n\n\n![动图封面](https://presenter.oss-cn-shanghai.aliyuncs.com/wordpress/v2-99fd119be3ca7616ae635b28e7181f7e_b.jpg)\n\n\n\n\n\n在杨辉三角中，每个数是它左上方和右上方的数的和。\n\n**示例:**\n\n**输入:** 5\n\n**输出:**\n\n[\n\n[1],\n\n[1,1],\n\n[1,2,1],\n\n[1,3,3,1],\n\n[1,4,6,4,1]\n\n]\n\n\n\n分析：典型的具有递推关系的数据问题，注意通过记忆化优化。\n\n代码：\n\n```java\n public List<List<Integer>> generate(int numRows) {\n if (numRows == 0) return Collections.emptyList();\n \n int[][] mem = new int[numRows][numRows];\n        List<List<Integer>> res = new ArrayList<>(numRows);\n for (int i = 0; i < numRows; i++) {\n            List<Integer> subList = new ArrayList<>(i + 1); \n for (int j = 0; j <=i; j++)\n                subList.add(f(i, j, mem));\n            res.add(subList);\n        }\n return res;\n    }\n \n private int f(int i, int j, int[][] mem) {\n if (mem[i][j] != 0) return mem[i][j];\n if (j == 0 || j == i) {\n            mem[i][j] = 1;\n return mem[i][j];\n        }\n        mem[i][j] = f(i - 1, j - 1, mem) + f(i - 1, j, mem);\n return mem[i][j];\n    }\n```\n\n### 5.4.反转链表\n\n反转一个单链表。\n\n**示例:**\n\n**输入:** 1->2->3->4->5->NULL\n\n**输出:** 5->4->3->2->1->NULL\n\n**进阶:**\n\n你可以迭代或递归地反转链表。你能否用两种方法解决这道题？\n\n分析：链表和树是具有递归结构的数据结构。\n\n代码：\n\n```java\n    public ListNode reverseList(ListNode head) {\n if (head == null || head.next == null) return head;\n        ListNode p = reverseList(head.next);\n        head.next.next = head;\n        head.next = null;\n return p;\n    }\n```\n\n\n\n### 5.5.合并两个有序链表\n\n将两个升序链表合并为一个新的 **升序** 链表并返回。新链表是通过拼接给定的两个链表的所有节点组成的。\n\n**示例：**\n\n**输入：**1->2->4, 1->3->4\n\n**输出：**1->1->2->3->4->4\n\n\n\n分析：链表是典型的具有递归属性的数据结构，链表操作问题一般都可以将问题本身拆分成子问题，直到不能拆解为止，通过递归得解。\n\n代码：\n\n```java\n public ListNode mergeTwoLists(ListNode l1, ListNode l2) {\n if (l1 == null) return l2;\n if (l2 == null) return l1;\n \n if (l1.val < l2.val) {\n            ListNode subList = mergeTwoLists(l1.next, l2);\n            l1.next = subList;\n return l1;\n        }\n else { \n            ListNode subList = mergeTwoLists(l1, l2.next);\n            l2.next = subList;\n return l2;\n        }\n    }\n```\n\n\n\n### 5.6.**斐波那契数**\n\n**斐波那契数**，通常用 F(n) 表示，形成的序列称为**斐波那契数列**。该数列由 0 和 1 开始，后面的每一项数字都是前面两项数字的和。也就是：\n\nF(0) = 0, F(1) = 1\n\nF(N) = F(N - 1) + F(N - 2), 其中 N > 1.\n\n给定 N，计算 F(N)。\n\n**示例 1：**\n\n**输入：**2\n\n**输出：**1\n\n**解释：**F(2) = F(1) + F(0) = 1 + 0 = 1.\n\n**示例 2：**\n\n**输入：**3\n\n**输出：**2\n\n**解释：**F(3) = F(2) + F(1) = 1 + 1 = 2.\n\n**示例 3：**\n\n**输入：**4\n\n**输出：**3\n\n**解释：**F(4) = F(3) + F(2) = 2 + 1 = 3.\n\n**提示：**\n\n- 0 ≤ N ≤ 30\n\n\n\n分析：递归考虑记忆化优化\n\n代码：\n\n```java\n public int fib(int N) {\n if (N <= 0) return 0;\n int[] memory = new int[N + 1];\n return help(N, memory);\n    }\n \n private int help(int n, int[] memory) {\n if (n == 1 || n == 2) return 1;\n if (memory[n] != 0) return memory[n];\n else memory[n] = help(n - 1, memory) + help(n - 2, memory);\n return memory[n];\n    }  \n```\n\n\n\n### 5.7.爬楼梯\n\n假设你正在爬楼梯。需要 *n* 阶你才能到达楼顶。\n\n每次你可以爬 1 或 2 个台阶。你有多少种不同的方法可以爬到楼顶呢？\n\n**注意：**给定 *n* 是一个正整数。\n\n**示例 1：**\n\n**输入：** 2\n\n**输出：** 2\n\n**解释：** 有两种方法可以爬到楼顶。\n\n\\1. 1 阶 + 1 阶\n\n\\2. 2 阶\n\n**示例 2：**\n\n**输入：** 3\n\n**输出：** 3\n\n**解释：** 有三种方法可以爬到楼顶。\n\n\\1. 1 阶 + 1 阶 + 1 阶\n\n\\2. 1 阶 + 2 阶\n\n\\3. 2 阶 + 1 阶\n\n\n\n分析：该问题通过规律发现递推关系就是斐波那契数。\n\n代码：\n\n```java\n public int climbStairs(int n) {\n int[] mem = new int[n + 1];\n return help(n, mem);\n    }\n \n private int help(int n, int[] mem) {\n if (n <= 0) return 0;\n if (mem[n] > 0) return mem[n];\n \n if (n < 4) {\n            mem[n] = n;\n        }\n else {\n            mem[n] = help(n - 1, mem) + help(n - 2, mem);\n        }\n return mem[n];\n    }\n```\n\n### 5.8.二叉树的最大深度\n\n给定一个二叉树，找出其最大深度。\n\n二叉树的深度为根节点到最远叶子节点的最长路径上的节点数。\n\n**说明:** 叶子节点是指没有子节点的节点。\n\n**示例：**\n\n给定二叉树 [3,9,20,null,null,15,7]，\n\n3\n\n/ \\\n\n9 20\n\n/ \\\n\n15 7\n\n返回它的最大深度 3 。\n\n\n\n分析：二叉树是典型的具有递归属性的数据结构。\n\n代码：\n\n```java\n public int maxDepth(TreeNode root) {\n if (root == null) return 0;\n if (root.left == null && root.right == null) return 1;\n return Math.max(maxDepth(root.left), maxDepth(root.right)) + 1;\n    }\n```\n\n\n\n### 5.9. 计算 x 的 n 次幂函数。\n\n实现 [pow(](https://link.zhihu.com/?target=https%3A//www.cplusplus.com/reference/valarray/pow/)*[x](https://link.zhihu.com/?target=https%3A//www.cplusplus.com/reference/valarray/pow/)*[, ](https://link.zhihu.com/?target=https%3A//www.cplusplus.com/reference/valarray/pow/)*[n](https://link.zhihu.com/?target=https%3A//www.cplusplus.com/reference/valarray/pow/)*[)](https://link.zhihu.com/?target=https%3A//www.cplusplus.com/reference/valarray/pow/) ，即计算 x 的 n 次幂函数。\n\n**示例 1:**\n\n**输入:** 2.00000, 10\n\n**输出:** 1024.00000\n\n**示例 2:**\n\n**输入:** 2.10000, 3\n\n**输出:** 9.26100\n\n**示例 3:**\n\n**输入:** 2.00000, -2\n\n**输出:** 0.25000\n\n**解释:** 2-2 = 1/22 = 1/4 = 0.25\n\n**说明:**\n\n- -100.0 < *x* < 100.0\n- *n* 是 32 位有符号整数，其数值范围是 [−231, 231 − 1] 。\n\n\n\n分析：n可能很大，需要防止栈溢出，可思考尾递归实现。\n\n代码：\n\n```java\n public double myPow(double x, int n) {\n return n > 0 ? help(x, n) : 1.0 / help(x, -n);\n    }\n \n private double help(double x, int n) {\n if (n == 0) return 1;\n return n % 2 == 0 ? help(x * x, n / 2) : x * help(x * x, n / 2);\n    }\n```\n\n\n\n### 5.10.第K个语法符号\n\n在第一行我们写上一个 0。接下来的每一行，将前一行中的0替换为01，1替换为10。\n\n给定行数 N 和序数 K，返回第 N 行中第 K个字符。（K从1开始）\n\n\n\n**例子:**\n\n**输入:** N = 1, K = 1\n\n**输出:** 0\n\n\n\n**输入:** N = 2, K = 1\n\n**输出:** 0\n\n\n\n**输入:** N = 2, K = 2\n\n**输出:** 1\n\n\n\n**输入:** N = 4, K = 5\n\n**输出:** 1\n\n\n\n**解释:**\n\n第一行: 0\n\n第二行: 01\n\n第三行: 0110\n\n第四行: 01101001\n\n\n\n**注意：**\n\n1. N 的范围 [1, 30].\n2. K 的范围 [1, 2^(N-1)].\n\n\n\n分析：识别具有递归关系问题\n\n代码：\n\n```java\n public int kthGrammar(int N, int K) {\n if (N == 1 && K == 1) return 0;\n \n int rmd = K % 2;  \n int p = kthGrammar(N - 1, rmd == 0 ? K / 2 : (K + 1) / 2);\n if (p == 0) return rmd == 0 ? 1 : 0;\n else return rmd == 0 ? 0 : 1;\n    }\n```\n\n\n\n### 总结\n\n现在，我们更加相信递归是一种强大的技术，它使我们能够以一种优雅而有效的方式解决许多问题。同时，它也不是解决任务问题的灵丹妙药。由于时间或空间的限制，并不是所有的问题都可以用递归来解决。递归本身可能会带来一些不希望看到的副作用，如栈溢出。\n\n有时，在解决实际问题时乍一看，我们并不清楚是否可以应用递归算法来解决问题。然而，由于递归的递推性质与我们所熟悉的数学非常接近，用数学公式来推导某些关系总是有帮助的，也就是说**写出递推关系和基本情况**是使用递归算法的前置条件。\n\n只要有可能，就应用**记忆化**。在起草递归算法时，可以从最简单的策略开始。有时，在递归过程中，可能会出现重复计算的情况，例如斐波纳契数（Fibonacci）。在这种情况下，你可以尝试应用 Memoization 技术，它将中间结果存储在缓存中供以后重用，它可以在空间复杂性上稍加折中，从而极大地提高时间复杂性，因为它可以避免代价较高的重复计算。\n\n当堆栈溢出时，**尾递归**可能会有所帮助。\n\n使用递归实现算法通常有几种方法。尾递归是我们可以实现的递归的一种特殊形式。与记忆化技术不同的是，尾递归通过消除递归带来的堆栈开销，优化了算法的空间复杂度。更重要的是，有了尾递归，就可以避免经常伴随一般递归而来的堆栈溢出问题，而尾递归的另一个优点是，与非尾递归相比，尾部递归更容易阅读和理解。这是由于尾递归不存在调用后依赖（即递归调用是函数中的最后一个动作），这一点不同于非尾递归，因此，只要有可能，就应该尽量运用尾递归。\n\n转载来自知乎: [全面理解递归](https://zhuanlan.zhihu.com/p/150562212)","tags":["算法"],"categories":["算法"]},{"title":"java中spi的理解","url":"/2023/06/28/java中spi的理解/","content":"\n# 简介\n\n`spi`可以理解为一种接口，和`api`类似，但是和`api`有不同。在实现接口的接口调用这个过程中，有接口的实现方和接口的调用方，不同点就在于`api`中的接口是按照实现方实现的，然后调用者调用接口方法。`spi`是按照调用方设计的接口协议，实现方按照这个协议完成接口方法。\n\n![img](https://presenter.oss-cn-shanghai.aliyuncs.com/wordpress/1ebd1df862c34880bc26b9d494535b3dtplv-k3u1fbpfcp-watermark.png)\n\n\n\n# 实战演示\n\nSLF4J （Simple Logging Facade for Java）是 Java 的一个日志门面（接口），其具体实现有几种，比如：Logback、Log4j、Log4j2 等等，而且还可以切换，在切换日志具体实现的时候我们是不需要更改项目代码的，只需要在 Maven 依赖里面修改一些 pom 依赖就好了。\n\n![img](https://oss.javaguide.cn/github/javaguide/java/basis/spi/image-20220723213306039-165858318917813.png)\n\n这就是依赖 SPI 机制实现的，那我们接下来就实现一个简易版本的日志框架。\n\n## Service Provider Interface\n\n新建一个 Java 项目 `service-provider-interface` 目录结构如下：（注意直接新建 Java 项目就好了，不用新建 Maven 项目，Maven 项目会涉及到一些编译配置，如果有私服的话，直接 deploy 会比较方便，但是没有的话，在过程中可能会遇到一些奇怪的问题。）\n\n\n\n```text\n│  service-provider-interface.iml\n│\n├─.idea\n│  │  .gitignore\n│  │  misc.xml\n│  │  modules.xml\n│  └─ workspace.xml\n│\n└─src\n    └─edu\n        └─jiangxuan\n            └─up\n                └─spi\n                        Logger.java\n                        LoggerService.java\n                        Main.class\n```\n\n新建 `Logger` 接口，这个就是 SPI ， 服务提供者接口，后面的服务提供者就要针对这个接口进行实现。\n\n\n\n```java\npackage edu.jiangxuan.up.spi;\n\npublic interface Logger {\n    void info(String msg);\n    void debug(String msg);\n}\n```\n\n接下来就是 `LoggerService` 类，这个主要是为服务使用者（调用方）提供特定功能的。这个类也是实现 Java SPI 机制的关键所在，如果存在疑惑的话可以先往后面继续看。\n\n\n\n```java\npackage edu.jiangxuan.up.spi;\n\nimport java.util.ArrayList;\nimport java.util.List;\nimport java.util.ServiceLoader;\n\npublic class LoggerService {\n    private static final LoggerService SERVICE = new LoggerService();\n\n    private final Logger logger;\n\n    private final List<Logger> loggerList;\n\n    private LoggerService() {\n        ServiceLoader<Logger> loader = ServiceLoader.load(Logger.class);\n        List<Logger> list = new ArrayList<>();\n        for (Logger log : loader) {\n            list.add(log);\n        }\n        // LoggerList 是所有 ServiceProvider\n        loggerList = list;\n        if (!list.isEmpty()) {\n            // Logger 只取一个\n            logger = list.get(0);\n        } else {\n            logger = null;\n        }\n    }\n\n    public static LoggerService getService() {\n        return SERVICE;\n    }\n\n    public void info(String msg) {\n        if (logger == null) {\n            System.out.println(\"info 中没有发现 Logger 服务提供者\");\n        } else {\n            logger.info(msg);\n        }\n    }\n\n    public void debug(String msg) {\n        if (loggerList.isEmpty()) {\n            System.out.println(\"debug 中没有发现 Logger 服务提供者\");\n        }\n        loggerList.forEach(log -> log.debug(msg));\n    }\n}\n```\n\n新建 `Main` 类（服务使用者，调用方），启动程序查看结果。\n\n\n\n```java\npackage org.spi.service;\n\npublic class Main {\n    public static void main(String[] args) {\n        LoggerService service = LoggerService.getService();\n\n        service.info(\"Hello SPI\");\n        service.debug(\"Hello SPI\");\n    }\n}\n```\n\n程序结果：\n\n> info 中没有发现 Logger 服务提供者 debug 中没有发现 Logger 服务提供者\n\n此时我们只是空有接口，并没有为 `Logger` 接口提供任何的实现，所以输出结果中没有按照预期打印相应的结果。\n\n你可以使用命令或者直接使用 IDEA 将整个程序直接打包成 jar 包。\n\n## Service Provider\n\n接下来新建一个项目用来实现 `Logger` 接口\n\n新建项目 `service-provider` 目录结构如下：\n\n\n\n```text\n│  service-provider.iml\n│\n├─.idea\n│  │  .gitignore\n│  │  misc.xml\n│  │  modules.xml\n│  └─ workspace.xml\n│\n├─lib\n│      service-provider-interface.jar\n|\n└─src\n    ├─edu\n    │  └─jiangxuan\n    │      └─up\n    │          └─spi\n    │              └─service\n    │                      Logback.java\n    │\n    └─META-INF\n        └─services\n                edu.jiangxuan.up.spi.Logger\n```\n\n新建 `Logback` 类\n\n\n\n```java\npackage edu.jiangxuan.up.spi.service;\n\nimport edu.jiangxuan.up.spi.Logger;\n\npublic class Logback implements Logger {\n    @Override\n    public void info(String s) {\n        System.out.println(\"Logback info 打印日志：\" + s);\n    }\n\n    @Override\n    public void debug(String s) {\n        System.out.println(\"Logback debug 打印日志：\" + s);\n    }\n}\n```\n\n将 `service-provider-interface` 的 jar 导入项目中.\n\n> 实现 `Logger` 接口，在 `src` 目录下新建 `META-INF/services` 文件夹，然后新建文件 `edu.jiangxuan.up.spi.Logger` （SPI 的全类名），文件里面的内容是：`edu.jiangxuan.up.spi.service.Logback` （Logback 的全类名，即 SPI 的实现类的包名 + 类名）。\n\n**这是 JDK SPI 机制 ServiceLoader 约定好的标准。**\n\n这里先大概解释一下：Java 中的 SPI 机制就是在每次类加载的时候会先去找到 class 相对目录下的 `META-INF` 文件夹下的 services 文件夹下的文件，将这个文件夹下面的所有文件先加载到内存中，然后根据这些文件的文件名和里面的文件内容找到相应接口的具体实现类，找到实现类后就可以通过反射去生成对应的对象，保存在一个 list 列表里面，所以可以通过迭代或者遍历的方式拿到对应的实例对象，生成不同的实现。\n\n所以会提出一些规范要求：文件名一定要是接口的全类名，然后里面的内容一定要是实现类的全类名，实现类可以有多个，直接换行就好了，多个实现类的时候，会一个一个的迭代加载。\n\n接下来同样将 `service-provider` 项目打包成 jar 包，这个 jar 包就是服务提供方的实现。通常我们导入 maven 的 pom 依赖就有点类似这种，只不过我们现在没有将这个 jar 包发布到 maven 公共仓库中，所以在需要使用的地方只能手动的添加到项目中。\n\n新建 Main 方法测试：\n\n\n\n```java\npackage edu.jiangxuan.up.service;\n\nimport edu.jiangxuan.up.spi.LoggerService;\n\npublic class TestJavaSPI {\n    public static void main(String[] args) {\n        LoggerService loggerService = LoggerService.getService();\n        loggerService.info(\"你好\");\n        loggerService.debug(\"测试Java SPI 机制\");\n    }\n}\n```\n\n运行结果如下：\n\n> Logback info 打印日志：你好 Logback debug 打印日志：测试 Java SPI 机制\n\n说明导入 jar 包中的实现类生效了。\n\n如果我们不导入具体的实现类的 jar 包，那么此时程序运行的结果就会是：\n\n> info 中没有发现 Logger 服务提供者 debug 中没有发现 Logger 服务提供者\n\n通过使用 SPI 机制，可以看出服务（`LoggerService`）和 服务提供者两者之间的耦合度非常低，如果说我们想要换一种实现，那么其实只需要修改 `service-provider` 项目中针对 `Logger` 接口的具体实现就可以了，只需要换一个 jar 包即可，也可以有在一个项目里面有多个实现，这不就是 SLF4J 原理吗？\n\n如果某一天需求变更了，此时需要将日志输出到消息队列，或者做一些别的操作，这个时候完全不需要更改 Logback 的实现，只需要新增一个服务实现（service-provider）可以通过在本项目里面新增实现也可以从外部引入新的服务实现 jar 包。我们可以在服务(LoggerService)中选择一个具体的 服务实现(service-provider) 来完成我们需要的操作。\n\n那么接下来我们具体来说说 Java SPI 工作的重点原理—— **ServiceLoader** 。\n\n## [#](#serviceloader) ServiceLoader\n\n### [#](#serviceloader-具体实现) ServiceLoader 具体实现\n\n想要使用 Java 的 SPI 机制是需要依赖 `ServiceLoader` 来实现的，那么我们接下来看看 `ServiceLoader` 具体是怎么做的：\n\n`ServiceLoader` 是 JDK 提供的一个工具类， 位于`package java.util;`包下。\n\n\n\n```text\nA facility to load implementations of a service.\n```\n\n这是 JDK 官方给的注释：**一种加载服务实现的工具。**\n\n再往下看，我们发现这个类是一个 `final` 类型的，所以是不可被继承修改，同时它实现了 `Iterable` 接口。之所以实现了迭代器，是为了方便后续我们能够通过迭代的方式得到对应的服务实现。\n\n\n\n```java\npublic final class ServiceLoader<S> implements Iterable<S>{ xxx...}\n```\n\n可以看到一个熟悉的常量定义：\n\n```\nprivate static final String PREFIX = \"META-INF/services/\";\n```\n\n下面是 `load` 方法：可以发现 `load` 方法支持两种重载后的入参；\n\n\n\n```java\npublic static <S> ServiceLoader<S> load(Class<S> service) {\n    ClassLoader cl = Thread.currentThread().getContextClassLoader();\n    return ServiceLoader.load(service, cl);\n}\n\npublic static <S> ServiceLoader<S> load(Class<S> service,\n                                        ClassLoader loader) {\n    return new ServiceLoader<>(service, loader);\n}\n\nprivate ServiceLoader(Class<S> svc, ClassLoader cl) {\n    service = Objects.requireNonNull(svc, \"Service interface cannot be null\");\n    loader = (cl == null) ? ClassLoader.getSystemClassLoader() : cl;\n    acc = (System.getSecurityManager() != null) ? AccessController.getContext() : null;\n    reload();\n}\n\npublic void reload() {\n    providers.clear();\n    lookupIterator = new LazyIterator(service, loader);\n}\n```\n\n根据代码的调用顺序，在 `reload()` 方法中是通过一个内部类 `LazyIterator` 实现的。先继续往下面看。\n\n`ServiceLoader` 实现了 `Iterable` 接口的方法后，具有了迭代的能力，在这个 `iterator` 方法被调用时，首先会在 `ServiceLoader` 的 `Provider` 缓存中进行查找，如果缓存中没有命中那么则在 `LazyIterator` 中进行查找。\n\n\n\n```java\npublic Iterator<S> iterator() {\n    return new Iterator<S>() {\n\n        Iterator<Map.Entry<String, S>> knownProviders\n                = providers.entrySet().iterator();\n\n        public boolean hasNext() {\n            if (knownProviders.hasNext())\n                return true;\n            return lookupIterator.hasNext(); // 调用 LazyIterator\n        }\n\n        public S next() {\n            if (knownProviders.hasNext())\n                return knownProviders.next().getValue();\n            return lookupIterator.next(); // 调用 LazyIterator\n        }\n\n        public void remove() {\n            throw new UnsupportedOperationException();\n        }\n\n    };\n}\n```\n\n在调用 `LazyIterator` 时，具体实现如下：\n\n\n\n```java\npublic boolean hasNext() {\n    if (acc == null) {\n        return hasNextService();\n    } else {\n        PrivilegedAction<Boolean> action = new PrivilegedAction<Boolean>() {\n            public Boolean run() {\n                return hasNextService();\n            }\n        };\n        return AccessController.doPrivileged(action, acc);\n    }\n}\n\nprivate boolean hasNextService() {\n    if (nextName != null) {\n        return true;\n    }\n    if (configs == null) {\n        try {\n            //通过PREFIX（META-INF/services/）和类名 获取对应的配置文件，得到具体的实现类\n            String fullName = PREFIX + service.getName();\n            if (loader == null)\n                configs = ClassLoader.getSystemResources(fullName);\n            else\n                configs = loader.getResources(fullName);\n        } catch (IOException x) {\n            fail(service, \"Error locating configuration files\", x);\n        }\n    }\n    while ((pending == null) || !pending.hasNext()) {\n        if (!configs.hasMoreElements()) {\n            return false;\n        }\n        pending = parse(service, configs.nextElement());\n    }\n    nextName = pending.next();\n    return true;\n}\n\n\npublic S next() {\n    if (acc == null) {\n        return nextService();\n    } else {\n        PrivilegedAction<S> action = new PrivilegedAction<S>() {\n            public S run() {\n                return nextService();\n            }\n        };\n        return AccessController.doPrivileged(action, acc);\n    }\n}\n\nprivate S nextService() {\n    if (!hasNextService())\n        throw new NoSuchElementException();\n    String cn = nextName;\n    nextName = null;\n    Class<?> c = null;\n    try {\n        c = Class.forName(cn, false, loader);\n    } catch (ClassNotFoundException x) {\n        fail(service,\n                \"Provider \" + cn + \" not found\");\n    }\n    if (!service.isAssignableFrom(c)) {\n        fail(service,\n                \"Provider \" + cn + \" not a subtype\");\n    }\n    try {\n        S p = service.cast(c.newInstance());\n        providers.put(cn, p);\n        return p;\n    } catch (Throwable x) {\n        fail(service,\n                \"Provider \" + cn + \" could not be instantiated\",\n                x);\n    }\n    throw new Error();          // This cannot happen\n}\n```\n\n可能很多人看这个会觉得有点复杂，没关系，我这边实现了一个简单的 `ServiceLoader` 的小模型，流程和原理都是保持一致的，可以先从自己实现一个简易版本的开始学：\n\n### [#](#自己实现一个-serviceloader) 自己实现一个 ServiceLoader\n\n我先把代码贴出来：\n\n\n\n```java\npackage edu.jiangxuan.up.service;\n\nimport java.io.BufferedReader;\nimport java.io.InputStream;\nimport java.io.InputStreamReader;\nimport java.lang.reflect.Constructor;\nimport java.net.URL;\nimport java.net.URLConnection;\nimport java.util.ArrayList;\nimport java.util.Enumeration;\nimport java.util.List;\n\npublic class MyServiceLoader<S> {\n\n    // 对应的接口 Class 模板\n    private final Class<S> service;\n\n    // 对应实现类的 可以有多个，用 List 进行封装\n    private final List<S> providers = new ArrayList<>();\n\n    // 类加载器\n    private final ClassLoader classLoader;\n\n    // 暴露给外部使用的方法，通过调用这个方法可以开始加载自己定制的实现流程。\n    public static <S> MyServiceLoader<S> load(Class<S> service) {\n        return new MyServiceLoader<>(service);\n    }\n\n    // 构造方法私有化\n    private MyServiceLoader(Class<S> service) {\n        this.service = service;\n        this.classLoader = Thread.currentThread().getContextClassLoader();\n        doLoad();\n    }\n\n    // 关键方法，加载具体实现类的逻辑\n    private void doLoad() {\n        try {\n            // 读取所有 jar 包里面 META-INF/services 包下面的文件，这个文件名就是接口名，然后文件里面的内容就是具体的实现类的路径加全类名\n            Enumeration<URL> urls = classLoader.getResources(\"META-INF/services/\" + service.getName());\n            // 挨个遍历取到的文件\n            while (urls.hasMoreElements()) {\n                // 取出当前的文件\n                URL url = urls.nextElement();\n                System.out.println(\"File = \" + url.getPath());\n                // 建立链接\n                URLConnection urlConnection = url.openConnection();\n                urlConnection.setUseCaches(false);\n                // 获取文件输入流\n                InputStream inputStream = urlConnection.getInputStream();\n                // 从文件输入流获取缓存\n                BufferedReader bufferedReader = new BufferedReader(new InputStreamReader(inputStream));\n                // 从文件内容里面得到实现类的全类名\n                String className = bufferedReader.readLine();\n\n                while (className != null) {\n                    // 通过反射拿到实现类的实例\n                    Class<?> clazz = Class.forName(className, false, classLoader);\n                    // 如果声明的接口跟这个具体的实现类是属于同一类型，（可以理解为Java的一种多态，接口跟实现类、父类和子类等等这种关系。）则构造实例\n                    if (service.isAssignableFrom(clazz)) {\n                        Constructor<? extends S> constructor = (Constructor<? extends S>) clazz.getConstructor();\n                        S instance = constructor.newInstance();\n                        // 把当前构造的实例对象添加到 Provider的列表里面\n                        providers.add(instance);\n                    }\n                    // 继续读取下一行的实现类，可以有多个实现类，只需要换行就可以了。\n                    className = bufferedReader.readLine();\n                }\n            }\n        } catch (Exception e) {\n            System.out.println(\"读取文件异常。。。\");\n        }\n    }\n\n    // 返回spi接口对应的具体实现类列表\n    public List<S> getProviders() {\n        return providers;\n    }\n}\n```\n\n关键信息基本已经通过代码注释描述出来了，\n\n主要的流程就是：\n\n1. 通过 URL 工具类从 jar 包的 `/META-INF/services` 目录下面找到对应的文件，\n2. 读取这个文件的名称找到对应的 spi 接口，\n3. 通过 `InputStream` 流将文件里面的具体实现类的全类名读取出来，\n4. 根据获取到的全类名，先判断跟 spi 接口是否为同一类型，如果是的，那么就通过反射的机制构造对应的实例对象，\n5. 将构造出来的实例对象添加到 `Providers` 的列表中。\n\n## [#](#总结) 总结\n\n其实不难发现，SPI 机制的具体实现本质上还是通过反射完成的。即：**我们按照规定将要暴露对外使用的具体实现类在 `META-INF/services/` 文件下声明。**\n\n另外，SPI 机制在很多框架中都有应用：Spring 框架的基本原理也是类似的方式。还有 Dubbo 框架提供同样的 SPI 扩展机制，只不过 Dubbo 和 spring 框架中的 SPI 机制具体实现方式跟咱们今天学得这个有些细微的区别，不过整体的原理都是一致的，相信大家通过对 JDK 中 SPI 机制的学习，能够一通百通，加深对其他高深框的理解。\n\n通过 SPI 机制能够大大地提高接口设计的灵活性，但是 SPI 机制也存在一些缺点，比如：\n\n1. 遍历加载所有的实现类，这样效率还是相对较低的；\n2. 当多个 `ServiceLoader` 同时 `load` 时，会有并发问题。\n\n","tags":["java"]},{"title":"java反射","url":"/2023/06/28/java反射/","content":"\n##  何为反射？\n\n如果说大家研究过框架的底层原理或者咱们自己写过框架的话，一定对反射这个概念不陌生。\n\n反射之所以被称为框架的灵魂，主要是因为它赋予了我们在运行时分析类以及执行类中方法的能力。\n\n通过反射你可以获取任意一个类的所有属性和方法，你还可以调用这些方法和属性。\n\n## [#](#反射的应用场景了解么) 反射的应用场景了解么？\n\n像咱们平时大部分时候都是在写业务代码，很少会接触到直接使用反射机制的场景。\n\n但是，这并不代表反射没有用。相反，正是因为反射，你才能这么轻松地使用各种框架。像 Spring/Spring Boot、MyBatis 等等框架中都大量使用了反射机制。\n\n**这些框架中也大量使用了动态代理，而动态代理的实现也依赖反射。**\n\n比如下面是通过 JDK 实现动态代理的示例代码，其中就使用了反射类 `Method` 来调用指定的方法。\n\n\n\n```java\npublic class DebugInvocationHandler implements InvocationHandler {\n    /**\n     * 代理类中的真实对象\n     */\n    private final Object target;\n\n    public DebugInvocationHandler(Object target) {\n        this.target = target;\n    }\n\n\n    public Object invoke(Object proxy, Method method, Object[] args) throws InvocationTargetException, IllegalAccessException {\n        System.out.println(\"before method \" + method.getName());\n        Object result = method.invoke(target, args);\n        System.out.println(\"after method \" + method.getName());\n        return result;\n    }\n}\n```\n\n另外，像 Java 中的一大利器 **注解** 的实现也用到了反射。\n\n为什么你使用 Spring 的时候 ，一个`@Component`注解就声明了一个类为 Spring Bean 呢？为什么你通过一个 `@Value`注解就读取到配置文件中的值呢？究竟是怎么起作用的呢？\n\n这些都是因为你可以基于反射分析类，然后获取到类/属性/方法/方法的参数上的注解。你获取到注解之后，就可以做进一步的处理。\n\n## [#](#谈谈反射机制的优缺点) 谈谈反射机制的优缺点\n\n**优点**：可以让咱们的代码更加灵活、为各种框架提供开箱即用的功能提供了便利\n\n**缺点**：让我们在运行时有了分析操作类的能力，这同样也增加了安全问题。比如可以无视泛型参数的安全检查（泛型参数的安全检查发生在编译时）。另外，反射的性能也要稍差点，不过，对于框架来说实际是影响不大的。相关阅读：[Java Reflection: Why is it so slow?open in new window](https://stackoverflow.com/questions/1392351/java-reflection-why-is-it-so-slow)\n\n## [#](#反射实战) 反射实战\n\n### [#](#获取-class-对象的四种方式) 获取 Class 对象的四种方式\n\n如果我们动态获取到这些信息，我们需要依靠 Class 对象。Class 类对象将一个类的方法、变量等信息告诉运行的程序。Java 提供了四种方式获取 Class 对象:\n\n**1. 知道具体类的情况下可以使用：**\n\n\n\n```java\nClass alunbarClass = TargetObject.class;\n```\n\n但是我们一般是不知道具体类的，基本都是通过遍历包下面的类来获取 Class 对象，通过此方式获取 Class 对象不会进行初始化\n\n**2. 通过 `Class.forName()`传入类的全路径获取：**\n\n\n\n```java\nClass alunbarClass1 = Class.forName(\"cn.javaguide.TargetObject\");\n```\n\n**3. 通过对象实例`instance.getClass()`获取：**\n\n\n\n```java\nTargetObject o = new TargetObject();\nClass alunbarClass2 = o.getClass();\n```\n\n**4. 通过类加载器`xxxClassLoader.loadClass()`传入类路径获取:**\n\n\n\n```java\nClassLoader.getSystemClassLoader().loadClass(\"cn.javaguide.TargetObject\");\n```\n\n通过类加载器获取 Class 对象不会进行初始化，意味着不进行包括初始化等一系列步骤，静态代码块和静态对象不会得到执行\n\n### [#](#反射的一些基本操作) 反射的一些基本操作\n\n1. 创建一个我们要使用反射操作的类 `TargetObject`。\n\n\n\n```java\npackage cn.javaguide;\n\npublic class TargetObject {\n    private String value;\n\n    public TargetObject() {\n        value = \"JavaGuide\";\n    }\n\n    public void publicMethod(String s) {\n        System.out.println(\"I love \" + s);\n    }\n\n    private void privateMethod() {\n        System.out.println(\"value is \" + value);\n    }\n}\n```\n\n1. 使用反射操作这个类的方法以及参数\n\n\n\n```java\npackage cn.javaguide;\n\nimport java.lang.reflect.Field;\nimport java.lang.reflect.InvocationTargetException;\nimport java.lang.reflect.Method;\n\npublic class Main {\n    public static void main(String[] args) throws ClassNotFoundException, NoSuchMethodException, IllegalAccessException, InstantiationException, InvocationTargetException, NoSuchFieldException {\n        /**\n         * 获取 TargetObject 类的 Class 对象并且创建 TargetObject 类实例\n         */\n        Class<?> targetClass = Class.forName(\"cn.javaguide.TargetObject\");\n        TargetObject targetObject = (TargetObject) targetClass.newInstance();\n        /**\n         * 获取 TargetObject 类中定义的所有方法\n         */\n        Method[] methods = targetClass.getDeclaredMethods();\n        for (Method method : methods) {\n            System.out.println(method.getName());\n        }\n\n        /**\n         * 获取指定方法并调用\n         */\n        Method publicMethod = targetClass.getDeclaredMethod(\"publicMethod\",\n                String.class);\n\n        publicMethod.invoke(targetObject, \"JavaGuide\");\n\n        /**\n         * 获取指定参数并对参数进行修改\n         */\n        Field field = targetClass.getDeclaredField(\"value\");\n        //为了对类中的参数进行修改我们取消安全检查\n        field.setAccessible(true);\n        field.set(targetObject, \"JavaGuide\");\n\n        /**\n         * 调用 private 方法\n         */\n        Method privateMethod = targetClass.getDeclaredMethod(\"privateMethod\");\n        //为了调用private方法我们取消安全检查\n        privateMethod.setAccessible(true);\n        privateMethod.invoke(targetObject);\n    }\n}\n```\n\n输出内容：\n\n```text\npublicMethod\nprivateMethod\nI love JavaGuide\nvalue is JavaGuide\n```\n\n**注意** : 有读者提到上面代码运行会抛出 `ClassNotFoundException` 异常,具体原因是你没有下面把这段代码的包名替换成自己创建的 `TargetObject` 所在的包 。\n\n```java\nClass<?> targetClass = Class.forName(\"cn.javaguide.TargetObject\");\n```\n\n","tags":["java"]},{"title":"关于java异常","url":"/2023/06/28/关于java异常/","content":"\n# 概述\n\n在`java`中，所有异常都由一个`Throwable`类延伸出来的。`Throwable` 类有两个重要的子类:\n\n- **`Exception`** :程序本身可以处理的异常，可以通过 `catch` 来进行捕获。`Exception` 又可以分为 Checked Exception (受检查异常，必须处理) 和 Unchecked Exception (不受检查异常，可以不处理)。\n- **`Error`**：`Error` 属于程序无法处理的错误 ，我们没办法通过 `catch` 来进行捕获不建议通过`catch`捕获 。例如 Java 虚拟机运行错误（`Virtual MachineError`）、虚拟机内存不够错误(`OutOfMemoryError`)、类定义错误（`NoClassDefFoundError`）等 。这些异常发生时，Java 虚拟机（JVM）一般会选择线程终止。\n\n其中`Exception`中有受检查异常（Java 代码在编译过程中，如果受检查异常没有被 `catch`或者`throws` 关键字处理的话，就没办法通过编译。）和非受检查异常（Java 代码在编译过程中 ，我们即使不处理不受检查异常也可以正常通过编译。）。除了`RuntimeException`及其子类以外，其他的`Exception`类及其子类都属于受检查异常 。常见的受检查异常有：IO 相关的异常、`ClassNotFoundException`、`SQLException`...。\n\n`RuntimeException` 及其子类都统称为非受检查异常，常见的有：\n\n- `NullPointerException`(空指针错误)\n- `IllegalArgumentException`(参数错误比如方法入参类型错误)\n- `NumberFormatException`（字符串转换为数字格式错误，`IllegalArgumentException`的子类）\n- `ArrayIndexOutOfBoundsException`（数组越界错误）\n- `ClassCastException`（类型转换错误）\n- `ArithmeticException`（算术错误）\n- `SecurityException` （安全错误比如权限不够）\n- `UnsupportedOperationException`(不支持的操作错误比如重复创建同一用户)\n\n- ...\n\n# 关于try-with-resource的使用\n\n1. **适用范围（资源的定义）：** 任何实现 `java.lang.AutoCloseable`或者 `java.io.Closeable` 的对象\n2. **关闭资源和 finally 块的执行顺序：** 在 `try-with-resources` 语句中，任何 catch 或 finally 块在声明的资源关闭后运行\n\n《Effective Java》中明确指出：\n\n> 面对必须要关闭的资源，我们总是应该优先使用 `try-with-resources` 而不是`try-finally`。随之产生的代码更简短，更清晰，产生的异常对我们也更有用。`try-with-resources`语句让我们更容易编写必须要关闭的资源的代码，若采用`try-finally`则几乎做不到这点。\n\nJava 中类似于`InputStream`、`OutputStream`、`Scanner`、`PrintWriter`等的资源都需要我们调用`close()`方法来手动关闭，一般情况下我们都是通过`try-catch-finally`语句来实现这个需求，如下：\n\n\n\n```java\n//读取文本文件的内容\nScanner scanner = null;\ntry {\n    scanner = new Scanner(new File(\"D://read.txt\"));\n    while (scanner.hasNext()) {\n        System.out.println(scanner.nextLine());\n    }\n} catch (FileNotFoundException e) {\n    e.printStackTrace();\n} finally {\n    if (scanner != null) {\n        scanner.close();\n    }\n}\n```\n\n使用 Java 7 之后的 `try-with-resources` 语句改造上面的代码:\n\n```java\ntry (Scanner scanner = new Scanner(new File(\"test.txt\"))) {\n    while (scanner.hasNext()) {\n        System.out.println(scanner.nextLine());\n    }\n} catch (FileNotFoundException fnfe) {\n    fnfe.printStackTrace();\n}\n```\n\n**注意**：从Java 9开始，没有必要在*try-with-resources*语句中声明*资源*。我们可以这样做：\n\n```java\nBufferedWriter writer = new BufferedWriter(new FileWriter(fileName));\ntry (writer) {\n    writer.write(str); // do something with the file we've opened\n}\ncatch(IOException e) {\n    // handle the exception\n}\n```\n","tags":["java"]},{"title":"java泛型","url":"/2023/06/28/java泛型/","content":"\n## 泛型\n\n### 什么是泛型？有什么作用？\n\n**Java 泛型（Generics）** 是 JDK 5 中引入的一个新特性。使用泛型参数，可以增强代码的可读性以及稳定性。\n\n编译器可以对泛型参数进行检测，并且通过泛型参数可以指定传入的对象类型。比如 `ArrayList<Person> persons = new ArrayList<Person>()` 这行代码就指明了该 `ArrayList` 对象只能传入 `Person` 对象，如果传入其他类型的对象就会报错。\n\n\n\n```java\nArrayList<E> extends AbstractList<E>\n```\n\n并且，原生 `List` 返回类型是 `Object` ，需要手动转换类型才能使用，使用泛型后编译器自动转换。\n\n### 泛型的使用方式有哪几种？\n\n泛型一般有三种使用方式:**泛型类**、**泛型接口**、**泛型方法**。\n\n**1.泛型类**：\n\n\n\n```java\n//此处T可以随便写为任意标识，常见的如T、E、K、V等形式的参数常用于表示泛型\n//在实例化泛型类时，必须指定T的具体类型\npublic class Generic<T>{\n\n    private T key;\n\n    public Generic(T key) {\n        this.key = key;\n    }\n\n    public T getKey(){\n        return key;\n    }\n}\n```\n\n如何实例化泛型类：\n\n\n\n```java\nGeneric<Integer> genericInteger = new Generic<Integer>(123456);\n```\n\n**2.泛型接口**：\n\n\n\n```java\npublic interface Generator<T> {\n    public T method();\n}\n```\n\n实现泛型接口，不指定类型：\n\n\n\n```java\nclass GeneratorImpl<T> implements Generator<T>{\n    @Override\n    public T method() {\n        return null;\n    }\n}\n```\n\n实现泛型接口，指定类型：\n\n\n\n```java\nclass GeneratorImpl<T> implements Generator<String>{\n    @Override\n    public String method() {\n        return \"hello\";\n    }\n}\n```\n\n**3.泛型方法**：\n\n\n\n```java\n   public static < E > void printArray( E[] inputArray )\n   {\n         for ( E element : inputArray ){\n            System.out.printf( \"%s \", element );\n         }\n         System.out.println();\n    }\n```\n\n使用：\n\n```java\n// 创建不同类型数组：Integer, Double 和 Character\nInteger[] intArray = { 1, 2, 3 };\nString[] stringArray = { \"Hello\", \"World\" };\nprintArray( intArray  );\nprintArray( stringArray  );\n```\n\n> 注意: `public static < E > void printArray( E[] inputArray )` 一般被称为静态泛型方法;在 java 中泛型只是一个占位符，必须在传递类型后才能使用。类在实例化时才能真正的传递类型参数，由于静态方法的加载先于类的实例化，也就是说类中的泛型还没有传递真正的类型参数，静态的方法的加载就已经完成了，所以静态泛型方法是没有办法使用类上声明的泛型的。只能使用自己声明的 `<E>`\n","tags":["java"]},{"title":"mybatis缓存详解和实现","url":"/2023/06/26/mybatis缓存详解和实现/","content":"\n# 介绍\n\n​\t\t在日常工作中，我们大多使用MyBatis的默认缓存配置，但是MyBatis缓存机制也有一些不足之处，一不留神就会出现脏数据，形成一些潜在的隐患，后续排查问题容易浪费时间精力。所以，如何用好MyBatis的缓存，是重中之重的。这里主要介绍MyBatis 的一级缓存和二级缓存。在默认的情况下， 只开启一级缓存（一级缓存是对同一个 SqlSession 而言的）。\n\n# 一级缓存\n\n每当我们使用MyBatis开启一次和数据库的会话，MyBatis会创建出一个SqlSession对象表示一次数据库会话。\n\n在对数据库的一次会话中，我们有可能会反复地执行完全相同的查询语句，如果不采取一些措施的话，每一次查询都会查询一次数据库,而我们在极短的时间内做了完全相同的查询，那么它们的结果极有可能完全相同，由于查询一次数据库的代价很大，这有可能造成很大的资源浪费。\n\n为了解决这一问题，减少资源的浪费，MyBatis会在表示会话的SqlSession对象中建立一个简单的缓存，将每次查询到的结果结果缓存起来，当下次查询的时候，如果判断先前有个完全一样的查询，会直接从缓存中直接将结果取出，返回给用户，不需要再进行一次数据库查询了。\n\n如下图所示，MyBatis一次会话: 一个SqlSession对象中创建一个本地缓存(local cache)，对于每一次查询，都会尝试根据查询的条件去本地缓存中查找是否在缓存中，如果在缓存中，就直接从缓存中取出，然后返回给用户；否则，从数据库读取数据，将查询结果存入缓存并返回给用户。\n\n![img](https://presenter.oss-cn-shanghai.aliyuncs.com/wordpress/mybatis-y-cache-1.png)\n\n## SqlSession 一级缓存的工作流程\n\n- 对于某个查询，根据statementId,params,rowBounds来构建一个key值，根据这个key值去缓存Cache中取出对应的key值存储的缓存结果；\n- 判断从Cache中根据特定的key值取的数据数据是否为空，即是否命中；\n- 如果命中，则直接将缓存结果返回；\n- 如果没命中： \n  - 去数据库中查询数据，得到查询结果；\n  - 将key和查询到的结果分别作为key,value对存储到Cache中；\n  - 将查询结果返回；\n- 结束。\n\n## 例子\n\n方法开启事务，然后先进行一次查询，在修改，在查询。\n\n```java\n @GetMapping(\"/{id}\")\n @Transactional //开启事务\n public User getUserOne(@PathVariable int id) {\n    User id1 = userService.getById(id);\n    User user = new User(id,\"修改后的名字\");\n    userService.updateById(user);\n    User user1 = userService.getById(id);\n    return user1;\n}\n```\n\n控制台打印结果,可以看到执行了三次，就是没有命中缓存\n\n```bash\nRegistering transaction synchronization for SqlSession [org.apache.ibatis.session.defaults.DefaultSqlSession@35e9562f]\nJDBC Connection [com.mysql.cj.jdbc.ConnectionImpl@60260b7d] will be managed by Spring\n==>  Preparing: SELECT id,username FROM USER WHERE id=?\n==> Parameters: 5(Integer)\n<==    Columns: id, username\n<==        Row: 5, Daniel Henderson\n<==      Total: 1\nReleasing transactional SqlSession [org.apache.ibatis.session.defaults.DefaultSqlSession@35e9562f]\nFetched SqlSession [org.apache.ibatis.session.defaults.DefaultSqlSession@35e9562f] from current transaction\n==>  Preparing: UPDATE USER SET username=? WHERE id=?\n==> Parameters: 修改后的名字(String), 5(Integer)\n<==    Updates: 1\nReleasing transactional SqlSession [org.apache.ibatis.session.defaults.DefaultSqlSession@35e9562f]\nFetched SqlSession [org.apache.ibatis.session.defaults.DefaultSqlSession@35e9562f] from current transaction\n==>  Preparing: SELECT id,username FROM USER WHERE id=?\n==> Parameters: 5(Integer)\n<==    Columns: id, username\n<==        Row: 5, 修改后的名字\n<==      Total: 1\n```\n\n接下来将update语句注释掉。可以看到两次查询只执行了一次查询，因为第二次直接在缓存中进行查询\n\n```bash\nRegistering transaction synchronization for SqlSession [org.apache.ibatis.session.defaults.DefaultSqlSession@7a108803]\nJDBC Connection [com.mysql.cj.jdbc.ConnectionImpl@44ab6956] will be managed by Spring\n==>  Preparing: SELECT id,username FROM USER WHERE id=?\n==> Parameters: 5(Integer)\n<==    Columns: id, username\n<==        Row: 5, 修改后的名字\n<==      Total: 1\nReleasing transactional SqlSession [org.apache.ibatis.session.defaults.DefaultSqlSession@7a108803]\n```\n\n\n\n# 二级缓存\n\n> MyBatis的二级缓存是Application级别的缓存，它可以提高对数据库查询的效率，以提高应用的性能。MyBatis并不是简单地对整个Application就只有一个Cache缓存对象，它将缓存划分的更细，即是Mapper级别的，即每一个Mapper都可以拥有一个Cache对象，具体如下：\n\n![img](https://presenter.oss-cn-shanghai.aliyuncs.com/wordpress/mybatis-y-cache-7.png)\n\n- **为每一个Mapper分配一个Cache缓存对象**（使用`<cache>`节点配置）\n\nMyBatis将Application级别的二级缓存细分到Mapper级别，即对于每一个Mapper.xml,如果在其中使用了`<cache>` 节点，则MyBatis会为这个Mapper创建一个Cache缓存对象，\n\n- **多个Mapper共用一个Cache缓存对象**（使用`<cache-ref>`节点配置）\n\n如果你想让多个Mapper公用一个Cache的话，你可以使用`<cache-ref namespace=\"\">`节点，来指定你的这个Mapper使用到了哪一个Mapper的Cache缓存。\n\n- MyBatis对二级缓存的支持粒度很细，它会指定某一条查询语句是否使用二级缓存。\n\n虽然在Mapper中配置了`<cache>`,并且为此Mapper分配了Cache对象，这并不表示我们使用Mapper中定义的查询语句查到的结果都会放置到Cache对象之中，我们必须指定Mapper中的某条选择语句是否支持缓存，即如下所示，在`<select>` 节点中配置useCache=\"true\"，Mapper才会对此Select的查询支持缓存特性，否则，不会对此Select查询，不会经过Cache缓存。如下所示，Select语句配置了useCache=\"true\"，则表明这条Select语句的查询会使用二级缓存。\n\n```xml\n<select id=\"selectByMinSalary\" resultMap=\"BaseResultMap\" parameterType=\"java.util.Map\" useCache=\"true\">\n```\n\n总之，要想使某条Select查询支持二级缓存，你需要保证：\n\n- MyBatis支持二级缓存的总开关：全局配置变量参数 cacheEnabled=true\n- 该select语句所在的Mapper，配置了`<cache>` 或`<cached-ref>`节点，并且有效\n- 该select语句的参数 useCache=true\n\n### 二级缓存实现的选择\n\nMyBatis对二级缓存的设计非常灵活，它自己内部实现了一系列的Cache缓存实现类，并提供了各种缓存刷新策略如LRU，FIFO等等；另外，MyBatis还允许用户自定义Cache接口实现，用户是需要实现org.apache.ibatis.cache.Cache接口，然后将Cache实现类配置在`<cache type=\"\">`节点的type属性上即可；除此之外，MyBatis还支持跟第三方内存缓存库如Memecached的集成，总之，使用MyBatis的二级缓存有三个选择:\n\n- MyBatis自身提供的缓存实现；\n- 用户自定义的Cache接口实现；\n- 跟第三方内存缓存库的集成;\n\n\n\n### 实现（简单配置）\n\n```yml\nmybatis-plus:\n  mapper-locations: classpath:com/example/cachetest/mapper/*.xml # 加载xml文件\n  configuration:\n    cache-enabled: true  #开启全局二级缓存\n```\n\n开启全局缓存之后，只需要在mapper上开启mapper的缓存就能对单个mapper实现缓存。\n\n```java\n@Mapper\n@CacheNamespace(eviction = FifoCache.class) //这里FifoCache缓存清除机制。\npublic interface UserMapper extends BaseMapper<User> {\n\n}\n```\n\n开启缓存后连续访问多次同一个数据,可以看到以下提示，缓存命中率，并且没有在发起对数据库发起新的查询。\n\n```bash\nCache Hit Ratio [com.example.cachetest.mapper.UserMapper]: 0.5\n```\n\n\n\n## Redis实现二级缓存\n\n### 配置redis，这里需要对redisTemplate进行序列化配置\n\n```java\n@Configuration\npublic class RedisConfig {\n\n    @Bean\n    public RedisTemplate<String,Object > redisTemplate(RedisConnectionFactory factory){\n        RedisTemplate<String,Object> redisTemplate=new RedisTemplate<>();\n        RedisSerializer<String > redisSerializer = new StringRedisSerializer();\n        //使用Jackson的序列化器，在后面对value进行序列化，是对Object类序列化\n          /*\n        设置objectMapper；转换java对象的时候使用的\n         */\n        ObjectMapper objectMapper = new ObjectMapper();\n        objectMapper.setVisibility(PropertyAccessor.ALL, JsonAutoDetect.Visibility.ANY);\n        objectMapper.enableDefaultTyping(ObjectMapper.DefaultTyping.NON_FINAL);\n\n        Jackson2JsonRedisSerializer<Object> serializer = new Jackson2JsonRedisSerializer<Object>(objectMapper,Object.class);\n        redisTemplate.setConnectionFactory(factory);\n        redisTemplate.setKeySerializer(redisSerializer);\n        //value序列化\n        redisTemplate.setValueSerializer(serializer);\n        //value hashmap序列化\n        redisTemplate.setHashKeySerializer(redisSerializer);\n        //key hashmap序列化\n        redisTemplate.setHashValueSerializer(serializer);\n\n        redisTemplate.afterPropertiesSet();\n\n        return redisTemplate;\n    }\n}\n```\n\n### application.yml中关于redis的配置\n\n```yml\nspring:\n  data:\n    redis:\n      host: 192.168.137.111\n      port: 6379\n      password: 123456\n      database: 0\n      timeout: 3000\n```\n\n### 自定义Mybatis缓存\n\n**在这里有个重点，MybatisRedisCache中必须要一个只有id的构造器（我这里是nameSpace）。**\n\n需要使用redisTemplate可以用一个类实现ApplicationContextAware接口，调用Applicationcontext.getBean()方法获取redisTemplate。\n\n```java\n/**\n * Description:\n *\n * @date:2023/6/26 14:24\n * @author: ilpvc\n */\n\n@Slf4j\npublic class MybatisRedisCache implements Cache {\n\n    private final ReadWriteLock readWriteLock = new ReentrantReadWriteLock();\n    private RedisTemplate<String,Object> redisTemplate;\n\n    private final String nameSpace;\n\n    private RedisTemplate<String,Object> getRedisTemplate(){\n        this.redisTemplate = SpringUtils.getBean(\"redisTemplate\",RedisTemplate.class);\n        return redisTemplate;\n    }\n\n    public MybatisRedisCache(String nameSpace){\n        if (nameSpace==null) {\n            throw new IllegalArgumentException(\"Cache instances require an ID\");\n        }\n        this.nameSpace = nameSpace;\n\n    }\n\n    @Override\n    public String getId() {\n        return this.nameSpace;\n    }\n\n    @Override\n    public void putObject(Object key, Object value) {\n        getRedisTemplate().opsForValue().set(String.valueOf(key),value,10, TimeUnit.MINUTES);\n    }\n\n    @Override\n    public Object getObject(Object o) {\n        return getRedisTemplate().opsForValue().get(String.valueOf(o));\n    }\n\n    @Override\n    public Object removeObject(Object o) {\n        return getRedisTemplate().opsForValue().getAndDelete(String.valueOf(o));\n    }\n\n    @Override\n    public void clear() {\n        Set<String> keys = getRedisTemplate().keys(\"*\");\n        if (keys!=null){\n            getRedisTemplate().delete(keys);\n        }\n    }\n\n    @Override\n    public int getSize() {\n        Set<String> keys = getRedisTemplate().keys(\"*\");\n        if (keys==null){\n            throw new NullPointerException();\n        }\n        return keys.size();\n    }\n\n    @Override\n    public ReadWriteLock getReadWriteLock() {\n        return this.readWriteLock;\n    }\n}\n\n```\n\n自定义的SpringUtils实现ApplicationContextAware\n\n```java\n@Component\npublic class SpringUtils implements ApplicationContextAware {\n    private static ApplicationContext applicationContext;\n\n    @Override\n    public void setApplicationContext(ApplicationContext applicationContext) throws BeansException {\n        SpringUtils.applicationContext = applicationContext;\n    }\n\n    //根据bean name 获取实例\n    // 通过name获取 Bean.\n    public static Object getBean(String name) {\n        return applicationContext.getBean(name);\n    }\n    // 通过class获取Bean.\n    public static <T> T getBean(Class<T> clazz) {\n        return applicationContext.getBean(clazz);\n    }\n    // 通过name,以及Clazz返回指定的Bean\n    public static <T> T getBean(String name, Class<T> clazz) {\n        return applicationContext.getBean(name, clazz);\n    }\n}\n```\n\n然后在UserMapper上加上注解`@CacheNamespace(implementation = MybatisRedisCache.class)`\n\n","tags":["mybatis","java"]},{"title":"关于ObjectMapper","url":"/2023/06/26/关于ObjectMapper/","content":"\n## 前提\n\njackson并没有类似fastjson的`JSON.parseObjec`这样的，确实看起来很快的方法。要想解析json，你不得不new一个ObjectMapper，来处理真正的解析动作。\n\n就像下面这样。\n\n```java\npublic String getCarString(Car car){\n    ObjectMapper objectMapper = new ObjectMapper();\n    String str = objectMapper.writeValueAsString(car);\n    return str;\n}\n```\n\n这种代码就在CV工程师手中遍地开了花。\n\n## 这代码有问题么？\n\n你要说它有问题，它确实能正确的执行。你要说它没问题，在追求性能的同学眼里，这肯定是一段十恶不赦的代码。\n\n一般的工具类，都是单例的，同时是线程安全的。ObjectMapper也不例外，它也是线程安全的，你可以并发的执行它，不会产生任何问题。\n\n这段代码，ObjectMapper在每次方法调用的时候，都会生成一个。那它除了造成一定的年轻代内存浪费之外，在执行时间上有没有什么硬伤呢？\n\nJMH(the Java Microbenchmark Harness) 是这样一个能够做基准测试的工具。如果你通过我们一系列的工具，定位到了热点代码，要测试它的性能数据，评估改善情况，就可以交给JMH。它的测量精度非常高，最高可达到纳秒的级别。\n\n`JMH`是一个jar包，它和单元测试框架`JUnit`非常的像，可以通过注解进行一些基础配置。这部分配置有很多是可以通过main方法的`OptionsBuilder`进行设置的。\n\n![JMH](https://presenter.oss-cn-shanghai.aliyuncs.com/wordpress/20230626141615.png)\n\n上图是一个典型的JMH程序执行的内容。通过开启多个进程，多个线程，首先执行预热，然后执行迭代，最后汇总所有的测试数据进行分析。在执行前后，还可以根据粒度处理一些前置和后置操作。\n\n## JMH测试结果\n\n为了测试上面的场景，我们创造了下面的基准测试类。分为三个测试场景：\n\n1. 直接在方法里new ObjectMapper\n2. 在全局共享一个ObjectMapper\n3. 使用ThreadLocal，每个线程一个ObjectMapper\n\n这样的测试属于cpu密集型的。我的cpu有10核，直接就分配了10个线程的并发，cpu在测试期间跑的满满的。\n\n```java\n@BenchmarkMode({Mode.Throughput})\n@OutputTimeUnit(TimeUnit.SECONDS)\n@State(Scope.Thread)\n@Warmup(iterations = 5, time = 1, timeUnit = TimeUnit.SECONDS)\n@Measurement(iterations = 5, time = 1, timeUnit = TimeUnit.SECONDS)\n@Fork(1)\n@Threads(10)\npublic class ObjectMapperTest {\n    String json = \"{ \\\"color\\\" : \\\"Black\\\", \\\"type\\\" : \\\"BMW\\\" }\";\n\n    @State(Scope.Benchmark)\n    public static class BenchmarkState {\n        ObjectMapper GLOBAL_MAP = new ObjectMapper();\n        ThreadLocal<ObjectMapper> GLOBAL_MAP_THREAD = new ThreadLocal<>();\n    }\n\n    @Benchmark\n    public Map globalTest(BenchmarkState state) throws Exception{\n        Map map = state.GLOBAL_MAP.readValue(json, Map.class);\n        return map;\n    }\n\n\n    @Benchmark\n    public Map globalTestThreadLocal(BenchmarkState state) throws Exception{\n        if(null == state.GLOBAL_MAP_THREAD.get()){\n            state.GLOBAL_MAP_THREAD.set(new ObjectMapper());\n        }\n        Map map = state.GLOBAL_MAP_THREAD.get().readValue(json, Map.class);\n        return map;\n    }\n\n    @Benchmark\n    public Map localTest() throws Exception{\n        ObjectMapper objectMapper = new ObjectMapper();\n        Map map = objectMapper.readValue(json, Map.class);\n        return map;\n    }\n\n    public static void main(String[] args) throws Exception {\n        Options opts = new OptionsBuilder()\n                .include(ObjectMapperTest.class.getSimpleName())\n                .resultFormat(ResultFormatType.CSV)\n                .build();\n\n        new Runner(opts).run();\n    }\n}\n```\n\n测试结果如下。\n\n```bash\nbash复制代码Benchmark                                Mode  Cnt         Score         Error  Units\nObjectMapperTest.globalTest             thrpt    5  25125094.559 ± 1754308.010  ops/s\nObjectMapperTest.globalTestThreadLocal  thrpt    5  31780573.549 ± 7779240.155  ops/s\nObjectMapperTest.localTest              thrpt    5   2131394.345 ±  216974.682  ops/s\n```\n\n从测试结果可以看出，如果我们每次调用都new一个ObjectMapper，每秒可以执行200万次JSON解析；如果全局使用一个ObjectMapper，则每秒可以执行2000多万次，速度足足快了10倍。\n\n如果使用ThreadLocal的方式，每个线程给它分配一个解析器，则性能会有少许上升，但也没有达到非常夸张的地步。\n\n所以在项目中写代码的时候，我们只需要保证有一个全局的ObjectMapper就可以了。\n\n当然，由于ObjectMapper有很多的特性需要配置，你可能会为不同的应用场景分配一个单独使用的ObjectMapper。总之，它的数量不需要太多，因为它是线程安全的。\n\n## End\n\n所以结论就比较清晰了，我们只需要在整个项目里使用一个ObjectMapper就可以了，没必要傻不拉几的每次都new一个，毕竟性能差了10倍。如果你的JSON有很多自定义的配置，使用全局的变量更能凸显它的优势。\n","tags":["java"]},{"title":"关于数据库连接池","url":"/2023/06/25/关于数据库连接池/","content":"\n# 数据库连接池的概念\n\n- 数据库连接背景数据库连接是一种关键的、有限的、昂贵的资源，这一点在多用户的网页应用程序中体现得尤为突出。对数据库连接的管理能显著影响到整个应用程序的伸缩性和健壮性，影响到程序的性能指标。数据库连接池正是针对这个问题提出来的。\n- 数据库连接池数据库连接池负责分配、管理和释放数据库连接，它允许应用程序重复使用一个现有的数据库连接，而不是再重新建立一个。这项技术能明显提高对数据库操作的性能。\n- 数据库连接池的原理没有使用数据库连接池：一个访问创建一个连接，使用完关闭连接。而频繁的创建和关闭连接非常耗时\n\n- 使用数据库连接池之后：提前准备一些数据库连接，使用时从池中取出，用完归还连接池\n\n\n\n# 自定义连接池\n\n## 初探连接池\n\n### 自定义JDBC工具类\n\n配置文件 config.properties\n\n```ini\nini复制代码driverClass=com.mysql.jdbc.Driver\nurl=jdbc:mysql://主机名:3306/数据库名\nusername=用户名\npassword=密码\n```\n\nJDBCUtils工具类\n\n```java\npublic class JDBCUtils {\n    private JDBCUtils() {}  //构造函数私有化\n\n    private static String driverClass;\n    private static String url;\n    private static String username;\n    private static String password;\n    private static Connection con;\n\n    static {\n        try {\n            InputStream is = JDBCUtils.class.getClassLoader().getResourceAsStream(\"config.properties\");\n            Properties properties = new Properties();\n            properties.load(is);\n            driverClass = properties.getProperty(\"driverClass\");\n            url = properties.getProperty(\"url\");\n            username = properties.getProperty(\"username\");\n            password = properties.getProperty(\"password\");\n            Class.forName(driverClass);\n\n        } catch (IOException e) {\n            e.printStackTrace();\n        } catch (ClassNotFoundException e) {\n            e.printStackTrace();\n        }\n    }\n\n    public static Connection getConnection() {  //获取连接对象\n        try {\n            con = DriverManager.getConnection(url, username, password);\n        } catch (SQLException e) {\n            e.printStackTrace();\n        }\n        return con;\n    }\n    //关闭连接（有查询结果集）\n    public static void close(Connection con, Statement stat, ResultSet res) {\n        if (con != null) {\n            try {\n                con.close();\n            } catch (SQLException e) {\n                e.printStackTrace();\n            }\n        }\n        if (stat != null) {\n            try {\n                stat.close();\n            } catch (SQLException e) {\n                e.printStackTrace();\n            }\n        }\n        if (res != null) {\n            try {\n                res.close();\n            } catch (SQLException e) {\n                e.printStackTrace();\n            }\n        }\n    }\n    //关闭连接（无查询结果集）\n    public static void close(Connection con, Statement stat) {\n        close(con, stat, null);\n    }\n}\n```\n\n### 实现连接池类\n\n定义一个连接池类并实现 java.sql.DataSource 接口。\n\n```java\nConnection getConnection();  //获取数据库连接对象\n\npublic class MyDataSource implements DataSource{\n    //定义集合容器，用于保存多个数据库连接对象\n    //使用Collections 工具类实现集合的线程同步\n    private static List<Connection> pool = Collections.synchronizedList(new ArrayList<Connection>());\n\n    //静态代码块，生成10个数据库连接保存到集合中\n    static {\n        for (int i = 0; i < 10; i++) {\n            Connection con = JDBCUtils.getConnection();\n            pool.add(con);\n        }\n    }\n\n    //返回连接池的大小\n    public int getSize() {\n        return pool.size();\n    }\n\n    //从池中返回一个数据库连接\n    @Override\n    public Connection getConnection() {\n        if(pool.size() > 0) {\n            //从池中获取数据库连接\n            return pool.remove(0);\n        }else {\n            throw new RuntimeException(\"连接数量已用尽\");\n        }\n    }\n\n    @Override\n    public Connection getConnection(String username, String password) throws SQLException {\n        return null;\n    }\n\n    @Override\n    public <T> T unwrap(Class<T> iface) throws SQLException {\n        return null;\n    }\n\n    @Override\n    public boolean isWrapperFor(Class<?> iface) throws SQLException {\n        return false;\n    }\n\n    @Override\n    public PrintWriter getLogWriter() throws SQLException {\n        return null;\n    }\n\n    @Override\n    public void setLogWriter(PrintWriter out) throws SQLException {\n\n    }\n\n    @Override\n    public void setLoginTimeout(int seconds) throws SQLException {\n\n    }\n\n    @Override\n    public int getLoginTimeout() throws SQLException {\n        return 0;\n    }\n\n    @Override\n    public Logger getParentLogger() throws SQLFeatureNotSupportedException {\n        return null;\n    }\n}\n```\n\n### 自定义连接池的测试\n\n```java\npublic class MyDataSourceTest {\n    public static void main(String[] args) throws SQLException {\n        MyDataSource dataSource = new MyDataSource();\n        System.out.println(\"使用前连接池数量：\" + dataSource.getSize());\n\n        Connection con = dataSource.getConnection();\n\n        String sql = \"select * from emp\";\n\n        PreparedStatement pst = con.prepareStatement(sql);\n\n        ResultSet res = pst.executeQuery();\n        while (res.next()) {\n            String ename = res.getString(\"ename\");\n            String job = res.getString(\"job\");\n            String hiredate = res.getString(\"hiredate\");\n            System.out.println(\"ename:\" + ename + \"\\t job:\" + job + \"\\t hiredate:\" + hiredate);\n        }\n\n        res.close();\n        pst.close();\n        con.close();\n        System.out.println(\"使用后连接池数量：\" + dataSource.getSize());\n    }\n}\n```\n\n输出：\n\n```bash\n使用前连接池数量：10\nename:SMITH\t job:CLERK\t hiredate:1980-12-17\nename:ALLEN\t job:SALESMAN\t hiredate:1981-02-20\nename:WARD\t job:SALESMAN\t hiredate:1981-02-22\nename:JONES\t job:MANAGER\t hiredate:1981-04-02\nename:MARTIN\t job:SALESMAN\t hiredate:1981-09-28\nename:BLAKE\t job:MANAGER\t hiredate:1981-05-01\nename:CLARK\t job:MANAGER\t hiredate:1981-06-09\nename:SCOTT\t job:ANALYST\t hiredate:1987-04-19\nename:KING\t job:PRESIDENT\t hiredate:1981-11-17\nename:TURNER\t job:SALESMAN\t hiredate:1981-09-08\nename:ADAMS\t job:CLERK\t hiredate:1987-05-23\nename:JAMES\t job:CLERK\t hiredate:1981-12-03\nename:FORD\t job:ANALYST\t hiredate:1981-12-03\nename:MILLER\t job:CLERK\t hiredate:1982-01-23\n使用后连接池数量：9\n```\n\n问题：虽然我们自定义了数据库连接池，但是连接关闭以后并没有归还给数据库连接池，还需要改进 归还连接 的问题\n\n### 继承方式改进连接池\n\n```java\nSystem.out.println(JDBCUtils.getConnection());\n//com.mysql.jdbc.JDBC4Connection@470e2030\n```\n\n通过输出 Connection 的地址发现 Connection 类的实现类是 JDBC4Connection ，是否能够通过编写一个类继承 JDBC4Connection ，然后重写 close() 方法，在关闭连接的同时归还连接？\n\n```java\n/*\n      自定义Connection类\n   */\n  public class MyConnection1 extends JDBC4Connection {\n      //声明连接对象和连接池集合对象\n      private Connection con;\n      private List<Connection> pool;\n  \n      //通过构造方法给成员变量赋值\n      public MyConnection1(String hostToConnectTo, int portToConnectTo, Properties info, String databaseToConnectTo, String url,Connection con,List<Connection> pool) throws SQLException {\n          super(hostToConnectTo, portToConnectTo, info, databaseToConnectTo, url);\n          this.con = con;\n          this.pool = pool;\n      }\n  \n      //重写close()方法，将连接归还给池中\n      @Override\n      public void close() throws SQLException {\n          pool.add(con);\n      }\n  }\n```\n\n但是这种方式行不通，通过查看JDBC工具类获取连接的方法我们发现：我们虽然自定义了一个子类，完成了归还连接的操作。但是 DriverManager 获取的还是 JDBC4Connection 这个对象，并不是我们的子类对象。而我们又不能整体去修改驱动包中类的功能！\n\n```java\n//将之前的连接对象换成自定义的子类对象\n  private static MyConnection1 con;\n  \n  public static Connection getConnection() {\n      try {\n          //等效于：MyConnection1 con = new JDBC4Connection();  子类引用指向父类对象，语法错误！\n          con = DriverManager.getConnection(url,username,password);\n      } catch (SQLException e) {\n          e.printStackTrace();\n      }\n  \n      return con;\n  }\n```\n\n### 装饰设计模式改进连接池\n\n自定义Connection类。通过装饰设计模式，实现和mysql驱动包中的Connection实现类相同的功能！\n\n实现步骤：\n\n- 定义一个类，实现Connection接口\n\n- 定义Connection连接对象和连接池容器对象的变量\n\n- 提供有参构造方法，接收连接对象和连接池对象，对变量赋值\n\n- 在close()方法中，完成连接的归还\n\n- 剩余方法，只需要调用mysql驱动包的连接对象完成即可\n\n  public class MyConnection2 implements Connection {\n\n  ```java\n    //2.定义Connection连接对象和连接池容器对象的变量\n    private Connection con;\n    private List<Connection> pool;\n  \n    //3.提供有参构造方法，接收连接对象和连接池对象，对变量赋值\n    public MyConnection2(Connection con,List<Connection> pool) {\n        this.con = con;\n        this.pool = pool;\n    }\n  \n    //4.在close()方法中，完成连接的归还\n    @Override\n    public void close() throws SQLException {\n        pool.add(con);\n    }\n  \n  \n    @Override\n    public Statement createStatement() throws SQLException {\n        return con.createStatement();\n    }\n  \n    @Override\n    public PreparedStatement prepareStatement(String sql) throws SQLException {\n        return con.prepareStatement(sql);\n    }\n  \n    @Override\n    public CallableStatement prepareCall(String sql) throws SQLException {\n        return con.prepareCall(sql);\n    }\n  \n    @Override\n    public String nativeSQL(String sql) throws SQLException {\n        return con.nativeSQL(sql);\n    }\n  \n    @Override\n    public void setAutoCommit(boolean autoCommit) throws SQLException {\n        con.setAutoCommit(autoCommit);\n    }\n  \n    @Override\n    public boolean getAutoCommit() throws SQLException {\n        return con.getAutoCommit();\n    }\n  \n    @Override\n    public void commit() throws SQLException {\n        con.commit();\n    }\n  \n    @Override\n    public void rollback() throws SQLException {\n        con.rollback();\n    }\n  \n    @Override\n    public boolean isClosed() throws SQLException {\n        return con.isClosed();\n    }\n  \n    @Override\n    public DatabaseMetaData getMetaData() throws SQLException {\n        return con.getMetaData();\n    }\n  \n    @Override\n    public void setReadOnly(boolean readOnly) throws SQLException {\n        con.setReadOnly(readOnly);\n    }\n  \n    @Override\n    public boolean isReadOnly() throws SQLException {\n        return con.isReadOnly();\n    }\n  \n    @Override\n    public void setCatalog(String catalog) throws SQLException {\n        con.setCatalog(catalog);\n    }\n  \n    @Override\n    public String getCatalog() throws SQLException {\n        return con.getCatalog();\n    }\n  \n    @Override\n    public void setTransactionIsolation(int level) throws SQLException {\n        con.setTransactionIsolation(level);\n    }\n  \n    @Override\n    public int getTransactionIsolation() throws SQLException {\n        return con.getTransactionIsolation();\n    }\n  \n    @Override\n    public SQLWarning getWarnings() throws SQLException {\n        return con.getWarnings();\n    }\n  \n    @Override\n    public void clearWarnings() throws SQLException {\n        con.clearWarnings();\n    }\n  \n    @Override\n    public Statement createStatement(int resultSetType, int resultSetConcurrency) throws SQLException {\n        return con.createStatement(resultSetType,resultSetConcurrency);\n    }\n  \n    @Override\n    public PreparedStatement prepareStatement(String sql, int resultSetType, int resultSetConcurrency) throws SQLException {\n        return con.prepareStatement(sql,resultSetType,resultSetConcurrency);\n    }\n  \n    @Override\n    public CallableStatement prepareCall(String sql, int resultSetType, int resultSetConcurrency) throws SQLException {\n        return con.prepareCall(sql,resultSetType,resultSetConcurrency);\n    }\n  \n    @Override\n    public Map<String, Class<?>> getTypeMap() throws SQLException {\n        return con.getTypeMap();\n    }\n  \n    @Override\n    public void setTypeMap(Map<String, Class<?>> map) throws SQLException {\n        con.setTypeMap(map);\n    }\n  \n    @Override\n    public void setHoldability(int holdability) throws SQLException {\n        con.setHoldability(holdability);\n    }\n  \n    @Override\n    public int getHoldability() throws SQLException {\n        return con.getHoldability();\n    }\n  \n    @Override\n    public Savepoint setSavepoint() throws SQLException {\n        return con.setSavepoint();\n    }\n  \n    @Override\n    public Savepoint setSavepoint(String name) throws SQLException {\n        return con.setSavepoint(name);\n    }\n  \n    @Override\n    public void rollback(Savepoint savepoint) throws SQLException {\n        con.rollback(savepoint);\n    }\n  \n    @Override\n    public void releaseSavepoint(Savepoint savepoint) throws SQLException {\n        con.releaseSavepoint(savepoint);\n    }\n  \n    @Override\n    public Statement createStatement(int resultSetType, int resultSetConcurrency, int resultSetHoldability) throws SQLException {\n        return con.createStatement(resultSetType,resultSetConcurrency,resultSetHoldability);\n    }\n  \n    @Override\n    public PreparedStatement prepareStatement(String sql, int resultSetType, int resultSetConcurrency, int resultSetHoldability) throws SQLException {\n        return con.prepareStatement(sql,resultSetType,resultSetConcurrency,resultSetHoldability);\n    }\n  \n    @Override\n    public CallableStatement prepareCall(String sql, int resultSetType, int resultSetConcurrency, int resultSetHoldability) throws SQLException {\n        return con.prepareCall(sql,resultSetType,resultSetConcurrency,resultSetHoldability);\n    }\n  \n    @Override\n    public PreparedStatement prepareStatement(String sql, int autoGeneratedKeys) throws SQLException {\n        return con.prepareStatement(sql,autoGeneratedKeys);\n    }\n  \n    @Override\n    public PreparedStatement prepareStatement(String sql, int[] columnIndexes) throws SQLException {\n        return con.prepareStatement(sql,columnIndexes);\n    }\n  \n    @Override\n    public PreparedStatement prepareStatement(String sql, String[] columnNames) throws SQLException {\n        return con.prepareStatement(sql,columnNames);\n    }\n  \n    @Override\n    public Clob createClob() throws SQLException {\n        return con.createClob();\n    }\n  \n    @Override\n    public Blob createBlob() throws SQLException {\n        return con.createBlob();\n    }\n  \n    @Override\n    public NClob createNClob() throws SQLException {\n        return con.createNClob();\n    }\n  \n    @Override\n    public SQLXML createSQLXML() throws SQLException {\n        return con.createSQLXML();\n    }\n  \n    @Override\n    public boolean isValid(int timeout) throws SQLException {\n        return con.isValid(timeout);\n    }\n  \n    @Override\n    public void setClientInfo(String name, String value) throws SQLClientInfoException {\n        con.setClientInfo(name,value);\n    }\n  \n    @Override\n    public void setClientInfo(Properties properties) throws SQLClientInfoException {\n        con.setClientInfo(properties);\n    }\n  \n    @Override\n    public String getClientInfo(String name) throws SQLException {\n        return con.getClientInfo(name);\n    }\n  \n    @Override\n    public Properties getClientInfo() throws SQLException {\n        return con.getClientInfo();\n    }\n  \n    @Override\n    public Array createArrayOf(String typeName, Object[] elements) throws SQLException {\n        return con.createArrayOf(typeName,elements);\n    }\n  \n    @Override\n    public Struct createStruct(String typeName, Object[] attributes) throws SQLException {\n        return con.createStruct(typeName,attributes);\n    }\n  \n    @Override\n    public void setSchema(String schema) throws SQLException {\n        con.setSchema(schema);\n    }\n  \n    @Override\n    public String getSchema() throws SQLException {\n        return con.getSchema();\n    }\n  \n    @Override\n    public void abort(Executor executor) throws SQLException {\n        con.abort(executor);\n    }\n  \n    @Override\n    public void setNetworkTimeout(Executor executor, int milliseconds) throws SQLException {\n        con.setNetworkTimeout(executor,milliseconds);\n    }\n  \n    @Override\n    public int getNetworkTimeout() throws SQLException {\n        return con.getNetworkTimeout();\n    }\n  \n    @Override\n    public <T> T unwrap(Class<T> iface) throws SQLException {\n        return con.unwrap(iface);\n    }\n  \n    @Override\n    public boolean isWrapperFor(Class<?> iface) throws SQLException {\n        return con.isWrapperFor(iface);\n    }\n  ```\n\n  }\n\n自定义连接池类\n\n```java\npublic class MyDataSource implements DataSource{\n      //定义集合容器，用于保存多个数据库连接对象\n      private static List<Connection> pool = Collections.synchronizedList(new ArrayList<Connection>());\n  \n      //静态代码块，生成10个数据库连接保存到集合中\n      static {\n          for (int i = 0; i < 10; i++) {\n              Connection con = JDBCUtils.getConnection();\n              pool.add(con);\n          }\n      }\n  \n      //返回连接池的大小\n      public int getSize() {\n          return pool.size();\n      }\n  \n      //从池中返回一个数据库连接\n      @Override\n      public Connection getConnection() {\n          if(pool.size() > 0) {\n              //从池中获取数据库连接\n              Connection con = pool.remove(0);\n              //通过自定义连接对象进行包装\n              MyConnection2 mycon = new MyConnection2(con,pool);\n              //返回包装后的连接对象\n              return mycon;\n          }else {\n              throw new RuntimeException(\"连接数量已用尽\");\n          }\n      }\n  }\n```\n\n缺点： Connection 接口中要实现的方法太多了，代码繁杂\n\n### 适配器设计模式改进连接池\n\n提供一个适配器类，实现 Connection 接口，将所有功能进行实现(除了 close()方法)，作为中间类。自定义连接类只需要继承这个适配器类，重写需要改进的 close() 方法即可！\n\n适配器类不需要实现 close() 方法，所以定义为抽象类\n\n```java\npublic abstract class MyAdapter implements Connection {\n  \n      // 定义数据库连接对象的变量\n      private Connection con;\n  \n      // 通过构造方法赋值\n      public MyAdapter(Connection con) {\n          this.con = con;\n      }\n  \n      // 所有的方法，均调用mysql的连接对象实现\n      @Override\n      public Statement createStatement() throws SQLException {\n          return con.createStatement();\n      }\n  \n      @Override\n      public PreparedStatement prepareStatement(String sql) throws SQLException {\n          return con.prepareStatement(sql);\n      }\n  \n      @Override\n      public CallableStatement prepareCall(String sql) throws SQLException {\n          return con.prepareCall(sql);\n      }\n  \n      @Override\n      public String nativeSQL(String sql) throws SQLException {\n          return con.nativeSQL(sql);\n      }\n  \n      @Override\n      public void setAutoCommit(boolean autoCommit) throws SQLException {\n          con.setAutoCommit(autoCommit);\n      }\n  \n      @Override\n      public boolean getAutoCommit() throws SQLException {\n          return con.getAutoCommit();\n      }\n  \n      @Override\n      public void commit() throws SQLException {\n          con.commit();\n      }\n  \n      @Override\n      public void rollback() throws SQLException {\n          con.rollback();\n      }\n  \n      @Override\n      public boolean isClosed() throws SQLException {\n          return con.isClosed();\n      }\n  \n      @Override\n      public DatabaseMetaData getMetaData() throws SQLException {\n          return con.getMetaData();\n      }\n  \n      @Override\n      public void setReadOnly(boolean readOnly) throws SQLException {\n          con.setReadOnly(readOnly);\n      }\n  \n      @Override\n      public boolean isReadOnly() throws SQLException {\n          return con.isReadOnly();\n      }\n  \n      @Override\n      public void setCatalog(String catalog) throws SQLException {\n          con.setCatalog(catalog);\n      }\n  \n      @Override\n      public String getCatalog() throws SQLException {\n          return con.getCatalog();\n      }\n  \n      @Override\n      public void setTransactionIsolation(int level) throws SQLException {\n          con.setTransactionIsolation(level);\n      }\n  \n      @Override\n      public int getTransactionIsolation() throws SQLException {\n          return con.getTransactionIsolation();\n      }\n  \n      @Override\n      public SQLWarning getWarnings() throws SQLException {\n          return con.getWarnings();\n      }\n  \n      @Override\n      public void clearWarnings() throws SQLException {\n          con.clearWarnings();\n      }\n  \n      @Override\n      public Statement createStatement(int resultSetType, int resultSetConcurrency) throws SQLException {\n          return con.createStatement(resultSetType,resultSetConcurrency);\n      }\n  \n      @Override\n      public PreparedStatement prepareStatement(String sql, int resultSetType, int resultSetConcurrency) throws SQLException {\n          return con.prepareStatement(sql,resultSetType,resultSetConcurrency);\n      }\n  \n      @Override\n      public CallableStatement prepareCall(String sql, int resultSetType, int resultSetConcurrency) throws SQLException {\n          return con.prepareCall(sql,resultSetType,resultSetConcurrency);\n      }\n  \n      @Override\n      public Map<String, Class<?>> getTypeMap() throws SQLException {\n          return con.getTypeMap();\n      }\n  \n      @Override\n      public void setTypeMap(Map<String, Class<?>> map) throws SQLException {\n          con.setTypeMap(map);\n      }\n  \n      @Override\n      public void setHoldability(int holdability) throws SQLException {\n          con.setHoldability(holdability);\n      }\n  \n      @Override\n      public int getHoldability() throws SQLException {\n          return con.getHoldability();\n      }\n  \n      @Override\n      public Savepoint setSavepoint() throws SQLException {\n          return con.setSavepoint();\n      }\n  \n      @Override\n      public Savepoint setSavepoint(String name) throws SQLException {\n          return con.setSavepoint(name);\n      }\n  \n      @Override\n      public void rollback(Savepoint savepoint) throws SQLException {\n          con.rollback(savepoint);\n      }\n  \n      @Override\n      public void releaseSavepoint(Savepoint savepoint) throws SQLException {\n          con.releaseSavepoint(savepoint);\n      }\n  \n      @Override\n      public Statement createStatement(int resultSetType, int resultSetConcurrency, int resultSetHoldability) throws SQLException {\n          return con.createStatement(resultSetType,resultSetConcurrency,resultSetHoldability);\n      }\n  \n      @Override\n      public PreparedStatement prepareStatement(String sql, int resultSetType, int resultSetConcurrency, int resultSetHoldability) throws SQLException {\n          return con.prepareStatement(sql,resultSetType,resultSetConcurrency,resultSetHoldability);\n      }\n  \n      @Override\n      public CallableStatement prepareCall(String sql, int resultSetType, int resultSetConcurrency, int resultSetHoldability) throws SQLException {\n          return con.prepareCall(sql,resultSetType,resultSetConcurrency,resultSetHoldability);\n      }\n  \n      @Override\n      public PreparedStatement prepareStatement(String sql, int autoGeneratedKeys) throws SQLException {\n          return con.prepareStatement(sql,autoGeneratedKeys);\n      }\n  \n      @Override\n      public PreparedStatement prepareStatement(String sql, int[] columnIndexes) throws SQLException {\n          return con.prepareStatement(sql,columnIndexes);\n      }\n  \n      @Override\n      public PreparedStatement prepareStatement(String sql, String[] columnNames) throws SQLException {\n          return con.prepareStatement(sql,columnNames);\n      }\n  \n      @Override\n      public Clob createClob() throws SQLException {\n          return con.createClob();\n      }\n  \n      @Override\n      public Blob createBlob() throws SQLException {\n          return con.createBlob();\n      }\n  \n      @Override\n      public NClob createNClob() throws SQLException {\n          return con.createNClob();\n      }\n  \n      @Override\n      public SQLXML createSQLXML() throws SQLException {\n          return con.createSQLXML();\n      }\n  \n      @Override\n      public boolean isValid(int timeout) throws SQLException {\n          return con.isValid(timeout);\n      }\n  \n      @Override\n      public void setClientInfo(String name, String value) throws SQLClientInfoException {\n          con.setClientInfo(name,value);\n      }\n  \n      @Override\n      public void setClientInfo(Properties properties) throws SQLClientInfoException {\n          con.setClientInfo(properties);\n      }\n  \n      @Override\n      public String getClientInfo(String name) throws SQLException {\n          return con.getClientInfo(name);\n      }\n  \n      @Override\n      public Properties getClientInfo() throws SQLException {\n          return con.getClientInfo();\n      }\n  \n      @Override\n      public Array createArrayOf(String typeName, Object[] elements) throws SQLException {\n          return con.createArrayOf(typeName,elements);\n      }\n  \n      @Override\n      public Struct createStruct(String typeName, Object[] attributes) throws SQLException {\n          return con.createStruct(typeName,attributes);\n      }\n  \n      @Override\n      public void setSchema(String schema) throws SQLException {\n          con.setSchema(schema);\n      }\n  \n      @Override\n      public String getSchema() throws SQLException {\n          return con.getSchema();\n      }\n  \n      @Override\n      public void abort(Executor executor) throws SQLException {\n          con.abort(executor);\n      }\n  \n      @Override\n      public void setNetworkTimeout(Executor executor, int milliseconds) throws SQLException {\n          con.setNetworkTimeout(executor,milliseconds);\n      }\n  \n      @Override\n      public int getNetworkTimeout() throws SQLException {\n          return con.getNetworkTimeout();\n      }\n  \n      @Override\n      public <T> T unwrap(Class<T> iface) throws SQLException {\n          return con.unwrap(iface);\n      }\n  \n      @Override\n      public boolean isWrapperFor(Class<?> iface) throws SQLException {\n          return con.isWrapperFor(iface);\n      }\n  }\n```\n\n自定义连接类\n\n通过适配器设计模式。完成close()方法的重写\n\n- 定义一个类，继承适配器父类\n\n- 定义 Connection 连接对象和连接池容器对象的变量\n\n- 提供有参构造方法，接收连接对象和连接池对象，对变量赋值\n\n- 在 close() 方法中，完成连接的归还\n\n  public class MyConnection3 extends MyAdapter { //2.定义Connection连接对象和连接池容器对象的变量 private Connection con; private List pool;\n\n  ```java\n    //3.提供有参构造方法，接收连接对象和连接池对象，对变量赋值\n    public MyConnection3(Connection con,List<Connection> pool) {\n        super(con);    // 将接收的数据库连接对象给适配器父类传递\n        this.con = con;\n        this.pool = pool;\n    }\n  \n    //4.在close()方法中，完成连接的归还\n    @Override\n    public void close() throws SQLException {\n        pool.add(con);\n    }\n  ```\n\n  }\n\n自定义连接池类\n\n```java\npublic class MyDataSource implements DataSource{\n      //定义集合容器，用于保存多个数据库连接对象\n      private static List<Connection> pool = Collections.synchronizedList(new ArrayList<Connection>());\n  \n      //静态代码块，生成10个数据库连接保存到集合中\n      static {\n          for (int i = 0; i < 10; i++) {\n              Connection con = JDBCUtils.getConnection();\n              pool.add(con);\n          }\n      }\n  \n      //返回连接池的大小\n      public int getSize() {\n          return pool.size();\n      }\n  \n      //从池中返回一个数据库连接\n      @Override\n      public Connection getConnection() {\n          if(pool.size() > 0) {\n              //从池中获取数据库连接\n              Connection con = pool.remove(0);\n  \n              //通过自定义连接对象进行包装\n              MyConnection3 mycon = new MyConnection3(con,pool);\n  \n              //返回包装后的连接对象\n              return mycon;\n          }else {\n              throw new RuntimeException(\"连接数量已用尽\");\n          }\n      }\n  }\n```\n\n缺点：自定义连接类中的方法已经很简洁了。剩余所有的方法已经抽取到了适配器类中。但是适配器这个类还是我们自己编写的，也比较麻烦！所以可以使用动态代理的方式来改进。\n\n### 动态代理\n\n```java\npublic class MyDataSource implements DataSource{\n      //定义集合容器，用于保存多个数据库连接对象\n      private static List<Connection> pool = Collections.synchronizedList(new ArrayList<Connection>());\n  \n      //静态代码块，生成10个数据库连接保存到集合中\n      static {\n          for (int i = 0; i < 10; i++) {\n              Connection con = JDBCUtils.getConnection();\n              pool.add(con);\n          }\n      }\n  \n      //返回连接池的大小\n      public int getSize() {\n          return pool.size();\n      }\n  \n      //动态代理方式\n      @Override\n      public Connection getConnection() {\n          if(pool.size() > 0) {\n              //从池中获取数据库连接\n              Connection con = pool.remove(0);\n  \n              Connection proxyCon = (Connection)Proxy.newProxyInstance(con.getClass().getClassLoader(), new Class[]{Connection.class}, new InvocationHandler() {\n                  /*\n                      执行Connection实现类所有方法都会经过invoke\n                      如果是close方法，则将连接还回池中\n                      如果不是，直接执行实现类的原有方法\n                   */\n                  @Override\n                  public Object invoke(Object proxy, Method method, Object[] args) throws Throwable {\n                      if(method.getName().equals(\"close\")) {\n                          pool.add(con);\n                          return null;\n                      }else {\n                          return method.invoke(con,args);\n                      }\n                  }\n              });\n  \n              return proxyCon;\n          }else {\n              throw new RuntimeException(\"连接数量已用尽\");\n          }\n      }\n  \n  \n      //从池中返回一个数据库连接\n      /*@Override\n      public Connection getConnection() {\n          if(pool.size() > 0) {\n              //从池中获取数据库连接\n              Connection con = pool.remove(0);\n  \n              //通过自定义连接对象进行包装\n              //MyConnection2 mycon = new MyConnection2(con,pool);\n              MyConnection3 mycon = new MyConnection3(con,pool);\n  \n              //返回包装后的连接对象\n              return mycon;\n          }else {\n              throw new RuntimeException(\"连接数量已用尽\");\n          }\n      }*/\n  }\n```\n\n# 开源连接池的使用\n\n## C3P0连接池\n\n- 导入jar包\n- 导入配置文件到src目录下\n- 创建c3p0连接池对象\n- 获取数据库连接进行使用\n\n配置文件 c3p0-config.xml 注意该配置文件的名字是固定的不要改，否则无法识别\n\n- initialPoolSize ：初始化连接数量\n\n- maxPoolSize ：最大连接数量，当连接数量超过初始化连接数量时，会在连接池内继续创建连接，直到达到数据库连接池所能容纳的最大连接数量\n\n- checkoutTimeout ：超过时间。如果使用的连接数量超过最大连接数量，编译器会在 checkoutTimeout 时间以后报错并终止程序。\n\n  com.mysql.jdbc.Driver jdbc:mysql://主机名:3306/数据库名 用户名 密码\n\n  ```xml\n  <!-- 连接池参数 -->\n  <!-- 初始化连接数量 -->\n  <property name=\"initialPoolSize\">5</property>\n  <!--  最大连接数量  -->\n  <property name=\"maxPoolSize\">10</property>\n  <!--  超时时间  -->\n  <property name=\"checkoutTimeout\">3000</property>\n  ```\n\n  com.mysql.jdbc.Driver jdbc:mysql://主机名:3306/数据库名 用户名 密码\n\n  ```xml\n  <!-- 连接池参数 -->\n  <property name=\"initialPoolSize\">5</property>\n  <property name=\"maxPoolSize\">8</property>\n  <property name=\"checkoutTimeout\">1000</property>\n  ```\n\nC3P0数据库连接池的使用\n\n```java\npublic static void main(String[] args) throws SQLException {\n        //创建c3p0连接池对象\n        DataSource dataSource = new ComboPooledDataSource();\n        //获取数据库连接进行使用\n        Connection con = dataSource.getConnection();\n        String s = \"select *from emp\";\n        PreparedStatement pst = con.prepareStatement(s);\n        ResultSet rs = pst.executeQuery();\n        while (rs.next()) {\n            String ename = rs.getString(\"ename\");\n            String job = rs.getString(\"job\");\n            String hiredate = rs.getString(\"hiredate\");\n            System.out.println(\"ename:\" + ename + \" job:\" + job + \" hiredate:\" + hiredate);\n        }\n        rs.close();\n        pst.close();\n        con.close(); // 将连接对象归还池中\n    }\n```\n\n## Druid连接池\n\n- 导入jar包\n- 编写配置文件，放在src目录下\n- 通过Properties集合加载配置文件\n- 通过Druid连接池工厂类获取数据库连接池对象\n- 获取数据库连接，进行使用\n\n配置文件 druid.properties\n\n```properties\ndriverClassName=com.mysql.jdbc.Driver\nurl=jdbc:mysql://主机名:3306/数据库名\nusername:用户名\npassword:密码\n# 初始连接数量\ninitialSize=5\n# 最大连接数量\nmaxActive=10\n# 最长等待时间\nmaxWait=3000\n```\n\nDruid数据库的使用\n\n```java\n\tpublic static void main(String[] args) throws Exception {\n        //通过Properties集合加载配置文件\n        InputStream is = demo01.class.getClassLoader().getResourceAsStream(\"druid.properties\");\n        Properties prop = new Properties();\n        prop.load(is);\n        //通过Druid连接池工厂类获取数据库连接池对象\n        DataSource dataSource = DruidDataSourceFactory.createDataSource(prop);\n        //获取数据库连接，进行使用\n        Connection con = dataSource.getConnection();\n        PreparedStatement pst = con.prepareStatement(\"select *from emp\");\n        ResultSet rs = pst.executeQuery();\n        while (rs.next()) {\n            String ename = rs.getString(\"ename\");\n            String job = rs.getString(\"job\");\n            String hiredate = rs.getString(\"hiredate\");\n            System.out.println(\"ename:\" + ename + \" job:\" + job + \" hiredate:\" + hiredate);\n        }\n        rs.close();\n        pst.close();\n        con.close();\n\t}\n```\n\n# 抽取工具类\n\n```java\n/*\n      数据库连接池工具类\n   */\n  public class DataSourceUtils {\n      //1.私有构造方法\n      private DataSourceUtils(){}\n  \n      //2.定义DataSource数据源变量\n      private static DataSource dataSource;\n  \n      //3.提供静态代码块，完成配置文件的加载和获取连接池对象\n      static {\n          try{\n              //加载配置文件\n              InputStream is = DruidDemo1.class.getClassLoader().getResourceAsStream(\"druid.properties\");\n              Properties prop = new Properties();\n              prop.load(is);\n  \n              //获取数据库连接池对象\n              dataSource = DruidDataSourceFactory.createDataSource(prop);\n  \n          } catch(Exception e) {\n              e.printStackTrace();\n          }\n      }\n  \n      //4.提供获取数据库连接的方法\n      public static Connection getConnection() {\n          Connection con = null;\n          try {\n              con = dataSource.getConnection();\n          } catch (SQLException e) {\n              e.printStackTrace();\n          }\n          return con;\n      }\n  \n      //5.提供获取数据库连接池的方法\n      public static DataSource getDataSource() {\n          return dataSource;\n      }\n  \n      //6.提供释放资源的方法\n      public static void close(Connection con, Statement stat, ResultSet rs) {\n          if(con != null) {\n              try {\n                  con.close();\n              } catch (SQLException e) {\n                  e.printStackTrace();\n              }\n          }\n  \n          if(stat != null) {\n              try {\n                  stat.close();\n              } catch (SQLException e) {\n                  e.printStackTrace();\n              }\n          }\n  \n          if(rs != null) {\n              try {\n                  rs.close();\n              } catch (SQLException e) {\n                  e.printStackTrace();\n              }\n          }\n      }\n  \n      public static void close(Connection con, Statement stat) {\n          close(con,stat,null);\n      }\n  \n  }\n```\n\n工具类的使用\n\n```java\npublic static void main(String[] args) throws SQLException {\n        //利用工具类获取DataSoure\n        DataSource dataSource = DataSourceUtils.getDataSource();\n        //获取连接，并使用\n        Connection con = dataSource.getConnection();\n        String s = \"select *from emp\";\n        PreparedStatement pst = con.prepareStatement(s);\n        ResultSet rs = pst.executeQuery();\n        while (rs.next()) {\n            String ename = rs.getString(\"ename\");\n            String job = rs.getString(\"job\");\n            String hiredate = rs.getString(\"hiredate\");\n            System.out.println(\"ename:\" + ename + \" job:\" + job + \" hiredate:\" + hiredate);\n        }\n        DataSourceUtils.close(con, pst, rs);\n    }\n```\n","tags":["mysql"],"categories":["数据库"]},{"title":"CSS实现镜像反转","url":"/2023/06/24/CSS实现镜像反转/","content":"\n## 镜像翻转使用了webkit-box-reflect\n\n直接放代码：\n\n```html\n<!DOCTYPE html>\n<html lang=\"en\">\n<head>\n  <meta charset=\"UTF-8\">\n  <title>Title</title>\n  <link rel=\"stylesheet\" type=\"text/css\" href=\"index.css\">\n</head>\n<body>\n<div class=\"context\">\n  <div class=\"button\">镜像翻转</div>\n</div>\n</body>\n</html>\n```\n\ncss:\n\n```css\n.context {\n    height: 300px;\n    width: 300px;\n    display: flex;\n    background-color: black;\n    flex-direction: column;\n    align-items: center;\n    justify-content: center;\n}\n\n.button {\n    position: relative;\n    top: -30px;\n    padding: 1rem 2.5rem;\n    border-radius: 0.4rem;\n    background-color: rgb(14,14,26);\n    color: rgb(234,234,234);\n    box-shadow: 0px 0px 60px #1f4c55;\n    -webkit-box-reflect: below 10px linear-gradient(to bottom,rgba(0,0,0,0.0),rgba(0,0,0,0.4));\n}\n```\n\n最后效果图\n\n![image-20230624123307318](https://presenter.oss-cn-shanghai.aliyuncs.com/wordpress/image-20230624123307318.png)\n","tags":["CSS"]},{"title":"nginx基础","url":"/2023/06/23/nginx基础/","content":"\n# 介绍\n\nNginx是一款高性能的http 服务器/反向代理服务器及电子邮件（IMAP/POP3）代理服务器。\n\n由俄罗斯的程序设计师Igor Sysoev所开发，官方测试nginx能够支支撑5万并发链接，\n\n并且cpu、内存等资源消耗却非常低，运行非常稳定。\n\n# 应用场景\n\n1、http服务器。Nginx是一个http服务可以独立提供http服务。可以做网页静态服务器。\n\n2、虚拟主机。可以实现在一台服务器虚拟出多个网站。例如个人网站使用的虚拟主机。\n\n3、反向代理，负载均衡。当网站的访问量达到一定程度后，单台服务器不能满足用户的请求时，\n\n需要用多台服务器集群可以使用nginx做反向代理。并且多台服务器可以平均分担负载，\n\n不会因为某台服务器负载高宕机而某台服务器闲置的情况。\n\n# 配置文件\n\nNginx的主配置文件是nginx.conf，这个配置文件一共由三部分组成，分别为**全局块、events块和http块**。在http块中，又包含http全局块、多个server块。每个server块中，可以包含server全局块和多个location块。在同一配置块中嵌套的配置块，各个之间不存在次序关系。\n\n配置文件支持大量可配置的指令，绝大多数指令不是特定属于某一个块的。同一个指令放在不同层级的块中，其作用域也不同，一般情况下，高一级块中的指令可以作用于自身所在的块和此块包含的所有低层级块。如果某个指令在两个不同层级的块中同时出现，则采用“就近原则”，即以较低层级块中的配置为准。比如，某指令同时出现在http全局块中和server块中，并且配置不同，则应该以server块中的配置为准。\n\n整个配置文件的结构大致如下：\n\n```perl\n#全局块\n#user  nobody;\nworker_processes  1;\n\n#event块\nevents {\n    worker_connections  1024;\n}\n\n#http块\nhttp {\n    #http全局块\n    include       mime.types;\n    default_type  application/octet-stream;\n    sendfile        on;\n    keepalive_timeout  65;\n    #server块\n    server {\n        #server全局块\n        listen       8000;\n        server_name  localhost;\n        #location块\n        location / {\n            root   html;\n            index  index.html index.htm;\n        }\n        error_page   500 502 503 504  /50x.html;\n        location = /50x.html {\n            root   html;\n        }\n    }\n    #这边可以有多个server块\n    server {\n      ...\n    }\n}\n```\n\n## 全局块\n\n全局块是默认配置文件从开始到events块之间的一部分内容，主要设置一些影响Nginx服务器整体运行的配置指令，因此，这些指令的作用域是Nginx服务器全局。\n\n通常包括配置运行Nginx服务器的用户（组）、允许生成的worker process数、Nginx进程PID存放路径、日志的存放路径和类型以及配置文件引入等。\n\n```shell\n# 指定可以运行nginx服务的用户和用户组，只能在全局块配置\n# user [user] [group]\n# 将user指令注释掉，或者配置成nobody的话所有用户都可以运行\n# user nobody nobody;\n# user指令在Windows上不生效，如果你制定具体用户和用户组会报小面警告\n# nginx: [warn] \"user\" is not supported, ignored in D:\\software\\nginx-1.18.0/conf/nginx.conf:2\n\n# 指定工作线程数，可以制定具体的进程数，也可使用自动模式，这个指令只能在全局块配置\n# worker_processes number | auto；\n# 列子：指定4个工作线程，这种情况下会生成一个master进程和4个worker进程\n# worker_processes 4;\n\n# 指定pid文件存放的路径，这个指令只能在全局块配置\n# pid logs/nginx.pid;\n\n# 指定错误日志的路径和日志级别，此指令可以在全局块、http块、server块以及location块中配置。(在不同的块配置有啥区别？？)\n# 其中debug级别的日志需要编译时使用--with-debug开启debug开关\n# error_log [path] [debug | info | notice | warn | error | crit | alert | emerg] \n# error_log  logs/error.log  notice;\n# error_log  logs/error.log  info;\n```\n\n## events块\n\nevents块涉及的指令主要影响Nginx服务器与用户的网络连接。常用到的设置包括是否开启对多worker process下的网络连接进行序列化，是否允许同时接收多个网络连接，选取哪种事件驱动模型处理连接请求，每个worker process可以同时支持的最大连接数等。\n\n这一部分的指令对Nginx服务器的性能影响较大，在实际配置中应该根据实际情况灵活调整。\n\n```shell\n# 当某一时刻只有一个网络连接到来时，多个睡眠进程会被同时叫醒，但只有一个进程可获得连接。如果每次唤醒的进程数目太多，会影响一部分系统性能。在Nginx服务器的多进程下，就有可能出现这样的问题。\n# 开启的时候，将会对多个Nginx进程接收连接进行序列化，防止多个进程对连接的争抢\n# 默认是开启状态，只能在events块中进行配置\n# accept_mutex on | off;\n\n# 如果multi_accept被禁止了，nginx一个工作进程只能同时接受一个新的连接。否则，一个工作进程可以同时接受所有的新连接。 \n# 如果nginx使用kqueue连接方法，那么这条指令会被忽略，因为这个方法会报告在等待被接受的新连接的数量。\n# 默认是off状态，只能在event块配置\n# multi_accept on | off;\n\n# 指定使用哪种网络IO模型，method可选择的内容有：select、poll、kqueue、epoll、rtsig、/dev/poll以及eventport，一般操作系统不是支持上面所有模型的。\n# 只能在events块中进行配置\n# use method\n# use epoll\n\n# 设置允许每一个worker process同时开启的最大连接数，当每个工作进程接受的连接数超过这个值时将不再接收连接\n# 当所有的工作进程都接收满时，连接进入logback，logback满后连接被拒绝\n# 只能在events块中进行配置\n# 注意：这个值不能超过超过系统支持打开的最大文件数，也不能超过单个进程支持打开的最大文件数，具体可以参考这篇文章：https://cloud.tencent.com/developer/article/1114773\n# worker_connections  1024;\n```\n\n## http块\n\nhttp块是Nginx服务器配置中的重要部分，代理、缓存和日志定义等绝大多数的功能和第三方模块的配置都可以放在这个模块中。\n\n前面已经提到，http块中可以包含自己的全局块，也可以包含server块，server块中又可以进一步包含location块，在本书中我们使用“http全局块”来表示http中自己的全局块，即http块中不包含在server块中的部分。\n\n可以在http全局块中配置的指令包括文件引入、MIME-Type定义、日志自定义、是否使用sendfile传输文件、连接超时时间、单连接请求数上限等。\n\n```shell\n# 常用的浏览器中，可以显示的内容有HTML、XML、GIF及Flash等种类繁多的文本、媒体等资源，浏览器为区分这些资源，需要使用MIME Type。换言之，MIME Type是网络资源的媒体类型。Nginx服务器作为Web服务器，必须能够识别前端请求的资源类型。\n\n# include指令，用于包含其他的配置文件，可以放在配置文件的任何地方，但是要注意你包含进来的配置文件一定符合配置规范，比如说你include进来的配置是worker_processes指令的配置，而你将这个指令包含到了http块中，着肯定是不行的，上面已经介绍过worker_processes指令只能在全局块中。\n# 下面的指令将mime.types包含进来，mime.types和ngin.cfg同级目录，不同级的话需要指定具体路径\n# include  mime.types;\n\n# 配置默认类型，如果不加此指令，默认值为text/plain。\n# 此指令还可以在http块、server块或者location块中进行配置。\n# default_type  application/octet-stream;\n\n# access_log配置，此指令可以在http块、server块或者location块中进行设置\n# 在全局块中，我们介绍过errer_log指令，其用于配置Nginx进程运行时的日志存放和级别，此处所指的日志与常规的不同，它是指记录Nginx服务器提供服务过程应答前端请求的日志\n# access_log path [format [buffer=size]]\n# 如果你要关闭access_log,你可以使用下面的命令\n# access_log off;\n\n# log_format指令，用于定义日志格式，此指令只能在http块中进行配置\n# log_format  main '$remote_addr - $remote_user [$time_local] \"$request\" '\n#                  '$status $body_bytes_sent \"$http_referer\" '\n#                  '\"$http_user_agent\" \"$http_x_forwarded_for\"';\n# 定义了上面的日志格式后，可以以下面的形式使用日志\n# access_log  logs/access.log  main;\n\n# 开启关闭sendfile方式传输文件，可以在http块、server块或者location块中进行配置\n# sendfile  on | off;\n\n# 设置sendfile最大数据量,此指令可以在http块、server块或location块中配置\n# sendfile_max_chunk size;\n# 其中，size值如果大于0，Nginx进程的每个worker process每次调用sendfile()传输的数据量最大不能超过这个值(这里是128k，所以每次不能超过128k)；如果设置为0，则无限制。默认值为0。\n# sendfile_max_chunk 128k;\n\n# 配置连接超时时间,此指令可以在http块、server块或location块中配置。\n# 与用户建立会话连接后，Nginx服务器可以保持这些连接打开一段时间\n# timeout，服务器端对连接的保持时间。默认值为75s;header_timeout，可选项，在应答报文头部的Keep-Alive域设置超时时间：“Keep-Alive:timeout= header_timeout”。报文中的这个指令可以被Mozilla或者Konqueror识别。\n# keepalive_timeout timeout [header_timeout]\n# 下面配置的含义是，在服务器端保持连接的时间设置为120 s，发给用户端的应答报文头部中Keep-Alive域的超时时间设置为100 s。\n# keepalive_timeout 120s 100s\n\n# 配置单连接请求数上限，此指令可以在http块、server块或location块中配置。\n# Nginx服务器端和用户端建立会话连接后，用户端通过此连接发送请求。指令keepalive_requests用于限制用户通过某一连接向Nginx服务器发送请求的次数。默认是100\n# keepalive_requests number;\n```\n\n## server块\n\nserver块和“虚拟主机”的概念有密切联系。\n\n虚拟主机，又称虚拟服务器、主机空间或是网页空间，它是一种技术。该技术是为了节省互联网服务器硬件成本而出现的。这里的“主机”或“空间”是由实体的服务器延伸而来，硬件系统可以基于服务器群，或者单个服务器等。虚拟主机技术主要应用于HTTP、FTP及EMAIL等多项服务，将一台服务器的某项或者全部服务内容逻辑划分为多个服务单位，对外表现为多个服务器，从而充分利用服务器硬件资源。从用户角度来看，一台虚拟主机和一台独立的硬件主机是完全一样的。\n\n在使用Nginx服务器提供Web服务时，利用虚拟主机的技术就可以避免为每一个要运行的网站提供单独的Nginx服务器，也无需为每个网站对应运行一组Nginx进程。虚拟主机技术使得Nginx服务器可以在同一台服务器上只运行一组Nginx进程，就可以运行多个网站。\n\n在前面提到过，每一个http块都可以包含多个server块，而每个server块就相当于一台虚拟主机，它内部可有多台主机联合提供服务，一起对外提供在逻辑上关系密切的一组服务（或网站）。\n\n和http块相同，server块也可以包含自己的全局块，同时可以包含多个location块。在server全局块中，最常见的两个配置项是本虚拟主机的监听配置和本虚拟主机的名称或IP配置。\n\n### listen指令\n\nserver块中最重要的指令就是listen指令，这个指令有三种配置语法。这个指令默认的配置值是：listen *:80 | *:8000；只能在server块种配置这个指令。\n\n```less\n//第一种\nlisten address[:port] [default_server] [ssl] [http2 | spdy] [proxy_protocol] [setfib=number] [fastopen=number] [backlog=number] [rcvbuf=size] [sndbuf=size] [accept_filter=filter] [deferred] [bind] [ipv6only=on|off] [reuseport] [so_keepalive=on|off|[keepidle]:[keepintvl]:[keepcnt]];\n\n//第二种\nlisten port [default_server] [ssl] [http2 | spdy] [proxy_protocol] [setfib=number] [fastopen=number] [backlog=number] [rcvbuf=size] [sndbuf=size] [accept_filter=filter] [deferred] [bind] [ipv6only=on|off] [reuseport] [so_keepalive=on|off|[keepidle]:[keepintvl]:[keepcnt]];\n\n//第三种（可以不用重点关注）\nlisten unix:path [default_server] [ssl] [http2 | spdy] [proxy_protocol] [backlog=number] [rcvbuf=size] [sndbuf=size] [accept_filter=filter] [deferred] [bind] [so_keepalive=on|off|[keepidle]:[keepintvl]:[keepcnt]];\n```\n\nlisten指令的配置非常灵活，可以单独制定ip，单独指定端口或者同时指定ip和端口。\n\n```perl\nlisten 127.0.0.1:8000;  #只监听来自127.0.0.1这个IP，请求8000端口的请求\nlisten 127.0.0.1; #只监听来自127.0.0.1这个IP，请求80端口的请求（不指定端口，默认80）\nlisten 8000; #监听来自所有IP，请求8000端口的请求\nlisten *:8000; #和上面效果一样\nlisten localhost:8000; #和第一种效果一致\n```\n\n关于上面的一些重要参数做如下说明：\n\n- address：监听的IP地址（请求来源的IP地址），如果是IPv6的地址，需要使用中括号“[]”括起来，比如[fe80::1]等。\n- port：端口号，如果只定义了IP地址没有定义端口号，就使用80端口。**这边需要做个说明：要是你压根没配置listen指令，那么那么如果nginx以超级用户权限运行，则使用`\\*`:80，否则使用`\\*`:8000**。多个虚拟主机可以同时监听同一个端口,但是server_name需要设置成不一样；\n- default_server：假如通过Host没匹配到对应的虚拟主机，则通过这台虚拟主机处理。具体的可以参考这篇[文章](https://segmentfault.com/a/1190000015681272)，写的不错。\n- backlog=number：设置监听函数listen()最多允许多少网络连接同时处于挂起状态，在FreeBSD中默认为-1，其他平台默认为511。\n- accept_filter=filter，设置监听端口对请求的过滤，被过滤的内容不能被接收和处理。本指令只在FreeBSD和NetBSD 5.0+平台下有效。filter可以设置为dataready或httpready，感兴趣的读者可以参阅Nginx的官方文档。\n- bind：标识符，使用独立的bind()处理此address:port；一般情况下，对于端口相同而IP地址不同的多个连接，Nginx服务器将只使用一个监听命令，并使用bind()处理端口相同的所有连接。\n- ssl：标识符，设置会话连接使用SSL模式进行，此标识符和Nginx服务器提供的HTTPS服务有关。\n\nlisten指令的使用看起来比较复杂，但其实在一般的使用过程中，相对来说比较简单，并不会进行太复杂的配置。\n\n### server_name指令\n\n用于配置虚拟主机的名称。语法是：\n\n```makefile\nSyntax:\tserver_name name ...;\nDefault:\t\nserver_name \"\";\nContext:\tserver\n```\n\n对于name 来说，可以只有一个名称，也可以由多个名称并列，之间用空格隔开。每个名字就是一个域名，由两段或者三段组成，之间由点号“.”隔开。比如\n\n```undefined\nserver_name myserver.com www.myserver.com\n```\n\n在该例中，此虚拟主机的名称设置为myserver.com或www. myserver.com。Nginx服务器规定，第一个名称作为此虚拟主机的主要名称。\n\n在name 中可以使用通配符“*”，但通配符只能用在由三段字符串组成的名称的首段或尾段，或者由两段字符串组成的名称的尾段，如：\n\n```undefined\nserver_name myserver.* *.myserver.com\n```\n\n另外name还支持正则表达式的形式。这边就不详细展开了。\n\n由于server_name指令支持使用通配符和正则表达式两种配置名称的方式，因此在包含有多个虚拟主机的配置文件中，可能会出现一个名称被多个虚拟主机的server_name匹配成功。那么，来自这个名称的请求到底要交给哪个虚拟主机处理呢？Nginx服务器做出如下规定：\n\na. 对于匹配方式不同的，按照以下的优先级选择虚拟主机，排在前面的优先处理请求。\n\n- ① 准确匹配server_name\n- ② 通配符在开始时匹配server_name成功\n- ③ 通配符在结尾时匹配server_name成功\n- ④ 正则表达式匹配server_name成功\n\nb. 在以上四种匹配方式中，如果server_name被处于同一优先级的匹配方式多次匹配成功，则首次匹配成功的虚拟主机处理请求。\n\n有时候我们希望使用基于IP地址的虚拟主机配置，比如访问192.168.1.31有虚拟主机1处理，访问192.168.1.32由虚拟主机2处理。\n\n这时我们要先网卡绑定别名，比如说网卡之前绑定的IP是192.168.1.30，现在将192.168.1.31和192.168.1.32这两个IP都绑定到这个网卡上，那么请求这个两个IP的请求才会到达这台机器。\n\n绑定别名后进行以下配置即可：\n\n```css\nhttp\n{\n\t{\n\t   listen:  80;\n\t   server_name:  192.168.1.31;\n     ...\n\t}\n\t{\n\t   listen:  80;\n\t   server_name:  192.168.1.32;\n     ...\n\t}\n}\n```\n\n## location块\n\n每个server块中可以包含多个location块。在整个Nginx配置文档中起着重要的作用，而且Nginx服务器在许多功能上的灵活性往往在location指令的配置中体现出来。\n\nlocation块的主要作用是，基于Nginx服务器接收到的请求字符串（例如， server_name/uri-string），对除虚拟主机名称（也可以是IP别名，后文有详细阐述）之外的字符串（前例中“/uri-string”部分）进行匹配，对特定的请求进行处理。地址定向、数据缓存和应答控制等功能都是在这部分实现。许多第三方模块的配置也是在location块中提供功能。\n\n在Nginx的官方文档中定义的location的语法结构为：\n\n```css\nlocation [ = | ~ | ~* | ^~ ] uri { ... }\n```\n\n其中，uri变量是待匹配的请求字符串，可以是不含正则表达的字符串，如/myserver.php等；也可以是包含有正则表达的字符串，如 .php$（表示以.php结尾的URL）等。为了下文叙述方便，我们约定，不含正则表达的uri称为“标准uri”，使用正则表达式的uri称为“正则uri”。\n\n其中方括号里的部分，是可选项，用来改变请求字符串与 uri 的匹配方式。在介绍四种标识的含义之前，我们需要先了解不添加此选项时，Nginx服务器是如何在server块中搜索并使用location块的uri和请求字符串匹配的。\n\n在不添加此选项时，Nginx服务器首先在server块的多个location块中搜索是否有标准uri和请求字符串匹配，如果有多个可以匹配，就记录匹配度最高的一个。然后，服务器再用location块中的正则uri和请求字符串匹配，当第一个正则uri匹配成功，结束搜索，并使用这个location块处理此请求；如果正则匹配全部失败，就使用刚才记录的匹配度最高的location块处理此请求。\n\n了解了上面的内容，就可以解释可选项中各个标识的含义了：\n\n- “=”，用于标准uri前，要求请求字符串与uri严格匹配。如果已经匹配成功，就停止继续向下搜索并立即处理此请求。\n- “^～”，用于标准uri前，要求Nginx服务器找到标识uri和请求字符串匹配度最高的location后，立即使用此location处理请求，而不再使用location块中的正则uri和请求字符串做匹配。\n- “～”，用于表示uri包含正则表达式，并且区分大小写。\n- “～`*`”，用于表示uri包含正则表达式，并且不区分大小写。注意如果uri包含正则表达式，就必须要使用“～”或者“～*”标识。\n\n> 我们知道，在浏览器传送URI时对一部分字符进行URL编码，比如空格被编码为“%20”，问号被编码为“%3f”等。“～”有一个特点是，它对uri中的这些符号将会进行编码处理。比如，如果location块收到的URI为“/html/%20/data”，则当Nginx服务器搜索到配置为“～ /html/ /data”的location时，可以匹配成功。\n\n### root指令\n\n这个指令用于设置请求寻找资源的跟目录，此指令可以在http块、server块或者location块中配置。由于使用Nginx服务器多数情况下要配置多个location块对不同的请求分别做出处理，因此该指令通常在location块中进行设置。\n\n```lua\nroot path\n```\n\npath变量中可以包含Nginx服务器预设的大多数变量，只有documentroot和realpath_root不可以使用。\n\n## 一点说明[#](https://www.cnblogs.com/54chensongxia/p/12938929.html#一点说明)\n\n上面列举了Nignx中全局块、event块和http块的一些配置指令，但是Nginx的指令远远不止这些。其实这边最主要的还是讲解整个配置文件的结构，如果大家要看比较全的指令介绍、模块介绍的话，建议去Nginx的官网。\n\n\n\n# 示例\n\n##　配置两个服务器\n\n使用express轻量服务器进行配置\n\n```js\nconst express = require('express')\nconst app = express()\nconst port = 3001\n\napp.get('/1',(req,res)=>{\n    res.send({\n        server:'1',\n        name:'phone',\n        price:'888'\n    })\n    console.log(\"被访问了order1\")\n})\n\napp.listen(port,()=>{\n    console.log('正在监听'+port)\n})\n```\n\n分别启动一个3000端口和一个3001端口的服务器。\n\n启动命令：\n\n```bash\nnode order1.js\n```\n\n## 配置Nginx进行启动\n\n关键配置文件\n\n```nginx\n upstream order {\n        server 127.0.0.1:3000;\n        server 127.0.0.1:3001;\n    }\n\n    server {\n        listen       80;\n        server_name  localhost;\n\n        #charset koi8-r;\n\n        #access_log  logs/host.access.log  main;\n\n        location / {\n            # root   html;\n            proxy_pass http://order;\n            # index  index.html index.htm;\n        }\n}\n```\n\n\n\n# 在linux上安装配置nginx\n\n## 安装\n\n因为Nginx依赖于gcc的编译环境，所以，需要安装编译环境来使Nginx能够编译起来。\n\n命令：`yum install gcc-c++`\n\nNginx的http模块需要使用pcre来解析正则表达式，需要安装pcre。\n\n命令：`yum install -y pcre pcre-devel`\n\n安装依赖的解压包。\n\n命令：`yum install -y zlib zlib-devel`\n\nssl 功能需要 openssl 库，安装 openssl。\n\n命令：`yum install -y openssl openssl-devel`\n\n\n\n**然后去[nginx](https://nginx.org/en/download.html)官网下载nginx**\n\n- Mainline version：Mainline 是 Nginx 目前主力在做的版本，可以说是开发版\n- Stable version：最新稳定版，生产环境上建议使用的版本\n- Legacy versions：遗留的老版本的稳定版\n\n\n\n然后解压到一个目录，这里推荐解压到`/usr/local/`,然后将目录名称改为nginx\n\n进入到该目录，然后依次执行：\n\n```bash\n./configure --prefix=/usr/local/nginx\nmake\nmake install\n```\n\n**配置nginx.conf**\n\n在location的root中配置本地前端打包好的文件路径\n\n**启动Nginx**\n\n进入 `/usr/local/nginx/sbin` 目录，执行命令：`./nginx` 启动Nginx：\n","tags":["nginx"]},{"title":"JS原型","url":"/2023/06/21/JS原型/","content":"\n## 一、原型\n\n每个JS对象都有一个原型对象，在创建一个对象时，JS会自动为该对象关联一个原型。在ES5之前，我们通常将原型对象称为proto，因为没有实际的方法可以获取到对象的原型。但是在ES5中，我们可以通过Object.getPrototypeOf(obj)方法来获取对象的原型。\n\n### 1.1 原型的概念\n\n原型是一个对象，其他对象可以通过它来实现属性和方法的共享。一个对象的原型也是一个对象，如果它的原型不为空，则它就可以继承来自它原型的属性和方法。\n\n### 1.2 原型的构造\n\n在JS中，每个函数都有一个prototype属性，它代表了该函数的原型。当我们使用new运算符来创建一个新对象时，实际上就是将这个对象的原型指向了函数的prototype属性。例如：\n\n```javascript\nfunction Person(name, age) {\n  this.name = name;\n  this.age = age;\n}\n\nPerson.prototype.sayHello = function() {\n  console.log('Hello, my name is ' + this.name);\n}\n\nvar tom = new Person('Tom', 28);\ntom.sayHello(); // Hello, my name is Tom\n```\n\n在上面的例子中，我们定义了一个Person函数，并在它的原型上加上了sayHello方法。当我们用new运算符创建对象时，JS会自动为新对象分配一个原型，并将该原型指向Person函数的prototype属性。因此，新对象就可以继承Person原型上的sayHello方法。\n\n### 1.3 原型的应用\n\n原型的主要作用是实现继承。在JS中，我们可以通过原型链来实现继承。如果一个对象的原型不为空，则它就可以继承来自它原型的属性和方法。例如：\n\n```javascript\nfunction Animal() {}\n\nAnimal.prototype.eat = function() {\n  console.log('Animal is eating');\n}\n\nfunction Dog() {}\n\nDog.prototype = Object.create(Animal.prototype); // 继承Animal原型\n\nDog.prototype.bark = function() {\n  console.log('Dog is barking');\n}\n\nvar snoop = new Dog();\nsnoop.eat(); // Animal is eating\nsnoop.bark(); // Dog is barking\n```\n\n在上面的例子中，我们定义了一个Animal函数，其中定义了一个eat方法。然后我们定义了一个Dog函数，它的原型指向了Animal的原型。这样一来，Dog就可以继承Animal的原型上的属性和方法了。我们在Dog的原型上添加了bark方法，这样snoop对象就可以调用它们了。\n\n## 二、原型链\n\n原型链是由每个对象的原型隐式指向上一个原型，从而形成的链式结构。如果一个对象需要访问一个属性或方法，但该属性或方法找不到，JS会自动沿着原型链向上查找，直到找到为止。因此，原型链也是实现继承的另一个重要机制。\n\n### 2.1 原型链的概念\n\n在JS中，原型链由一系列原型对象组成。每个对象都有一个原型对象，而原型对象又有自己的原型对象。当我们调用一个对象的属性或方法时，JS会先在该对象本身查找，如果没有找到，就会沿着原型链向上查找，直到找到为止。如果整个原型链都没有找到该属性或方法，JS会返回undefined。\n\n### 2.2 原型链的构造\n\n在JS中，我们可以通过将一个构造函数的原型对象指向另一个对象的原型，来构造原型链。例如：\n\n```javascript\nfunction Animal() {}\n\nAnimal.prototype.eat = function() {\n  console.log('Animal is eating');\n}\n\nfunction Dog() {}\n\nDog.prototype = Object.create(Animal.prototype); // 继承Animal原型\n\nDog.prototype.bark = function() {\n  console.log('Dog is barking');\n}\n\nvar snoop = new Dog();\nconsole.log(snoop.__proto__); // Dog.prototype\nconsole.log(snoop.__proto__.__proto__); // Animal.prototype\nconsole.log(snoop.__proto__.__proto__.__proto__); // Object.prototype\n```\n\n在上面的例子中，我们定义了Animal和Dog两个函数。然后将Dog的原型指向了Animal的原型。这样一来，snoop对象就可以沿着原型链继承Animal原型上的eat方法。\n\n### 2.3 原型链的应用\n\n原型链的主要应用就是实现继承。在JS中，通过将一个构造函数的原型对象指向另一个对象的原型，我们就可以构造出一个原型链，从而实现继承。例如：\n\n```javascript\nfunction Animal(name) {\n  this.name = name;\n}\n\nAnimal.prototype.eat = function() {\n  console.log(this.name + ' is eating');\n}\n\nfunction Dog(name) {\n  Animal.call(this, name); // 调用父类构造函数\n}\n\nDog.prototype = Object.create(Animal.prototype); // 继承Animal原型\n\nDog.prototype.bark = function() {\n  console.log(this.name + ' is barking');\n}\n\nvar snoop = new Dog('Snoop');\nsnoop.eat(); // Snoop is eating\nsnoop.bark(); // Snoop is barking\n```\n\n在上面的例子中，我们定义了Animal和Dog两个函数。在Dog的构造函数内部，我们调用了Animal的构造函数，并传入了当前对象的this和name参数。这样一来，Dog就可以继承Animal的属性和方法了。我们通过将Dog的原型指向Animal的原型，来实现对Animal原型上eat方法的继承。最后，我们定义了Dog自己的bark方法，在snoop对象上即可调用到。\n\n> 在JS中，原型和原型链是非常重要的概念。它们可以让JS变得更加灵活和强大，使得继承和多态等面向对象编程的特性都可以得到很好的实现。熟练掌握原型和原型链，可以让我们更好地理解JS的面向对象机制，写出更加优雅、高效的代码。\n\n附：完整代码\n\n```javascript\nfunction Animal(name) {\n  this.name = name;\n}\n\nAnimal.prototype.eat = function() {\n  console.log(this.name + ' is eating');\n}\n\nfunction Dog(name) {\n  Animal.call(this, name); // 调用父类构造函数\n}\n\nDog.prototype = Object.create(Animal.prototype); // 继承Animal原型\n\nDog.prototype.bark = function() {\n  console.log(this.name + ' is barking');\n}\n\nvar snoop = new Dog('Snoop');\nsnoop.eat(); // Snoop is eating\nsnoop.bark(); // Snoop is barking\n\nconsole.log(snoop.__proto__); // Dog.prototype\nconsole.log(snoop.__proto__.__proto__); // Animal.prototype\nconsole.log(snoop.__proto__.__proto__.__proto__); // Object.prototype\n\nfunction Person(name, age) {\n  this.name = name;\n  this.age = age;\n}\n\nPerson.prototype.sayHello = function() {\n  console.log('Hello, my name is ' + this.name);\n}\n\nvar tom = new Person('Tom', 28);\ntom.sayHello(); // Hello, my name is Tom\n```\n\n**顺道讲解一下构造函数和类的概念，打牢基础，这对于理解 JavaScript 的面向对象编程非常重要。**\n\n## 三、构造函数\n\n在 JS 中，构造函数是一种特殊类型的函数，它们用于创建对象。与普通函数不同的是，构造函数通常首字母大写，而且必须使用 new 运算符来调用。当我们用 new 运算符来调用一个构造函数时，JS 会自动为我们创建一个对象，并将该对象的原型指向构造函数的原型。\n\n### 3.1 构造函数的概念\n\n构造函数是一种特殊类型的函数，它们用于创建对象。与普通函数不同的是，构造函数通常首字母大写，而且必须使用 new 运算符来调用。构造函数内部通常会定义一些属性和方法，这些属性和方法会在每个通过构造函数创建的对象中共享。\n\n```javascript\nfunction Person(name, age) {\n  this.name = name;\n  this.age = age;\n}\n\nvar tom = new Person('Tom', 28);\nconsole.log(tom.name); // Tom\nconsole.log(tom.age); // 28\n```\n\n在上面的例子中，我们定义了一个名为 Person 的构造函数，它接受两个参数 name 和 age，然后将它们保存到新创建的对象中。我们使用 new 运算符来调用该构造函数，并将返回值保存到变量 tom 中。此时，tom 就是一个通过 Person 构造函数创建的对象。\n\n### 3.2 构造函数的应用\n\n构造函数最常见的应用就是创建对象。通过定义一个构造函数，并使用它来创建对象，我们可以轻松地创建多个具有相同属性和方法的对象。例如，我们可以定义一个 Car 构造函数，并用它来创建多个汽车对象：\n\n```javascript\nfunction Car(brand, model, price) {\n  this.brand = brand;\n  this.model = model;\n  this.price = price;\n}\n\nvar car1 = new Car('Toyota', 'Camry', 25000);\nvar car2 = new Car('Honda', 'Accord', 28000);\nconsole.log(car1.brand); // Toyota\nconsole.log(car2.model); // Accord\n```\n\n在上面的例子中，我们定义了一个名为 Car 的构造函数，每个对象都会有 brand、model 和 price 属性。然后我们使用该构造函数来创建两个不同的汽车对象 car1 和 car2。\n\n## 四、类\n\n在 ES6 中，JS 引入了 class 关键字，使得 JS 变得更加接近传统的面向对象语言。使用 class 关键字可以轻松地定义一个类，并在该类中定义属性和方法。类也可以继承其他类，并重写父类的方法。将 class 与 constructor 和 prototype 结合使用，我们就可以完整地实现面向对象编程。\n\n### 4.1 类的概念\n\n在 JS 中，类是一种特殊类型的对象，它通常由属性和方法组成。类可以看作是一种模板或蓝图，它描述了对象应该具有的属性和方法。在我们创建一个类的实例时，JS 会根据该类的定义来为我们创建一个对象，并将其作为实例返回。\n\n```javascript\nclass Person {\n  constructor(name, age) {\n    this.name = name;\n    this.age = age;\n  }\n  \n  sayHello() {\n    console.log('Hello, my name is ' + this.name);\n  }\n}\n\nlet tom = new Person('Tom', 28);\ntom.sayHello(); // Hello, my name is Tom\n```\n\n在上面的例子中，我们使用 class 关键字定义了一个名为 Person 的类。Person 类有一个 constructor 方法，用于在创建新对象时初始化对象的属性。Person 类还有一个名为 sayHello 的方法，可以输出一个问候语。\n\n然后我们使用 new 运算符来创建一个 Person 类的实例，并将其保存到 tom 变量中。此时，tom 就是一个 Person 类的实例。\n\n### 4.2 类的应用\n\n类最常见的应用就是创建对象。通过定义一个类，并使用它来创建对象，我们可以轻松地创建多个具有相同属性和方法的对象。例如，我们可以定义一个 Car 类，并用它来创建多个汽车对象：\n\n```javascript\nclass Car {\n  constructor(brand, model, price) {\n    this.brand = brand;\n    this.model = model;\n    this.price = price;\n  }\n  \n  getFullName() {\n    return this.brand + ' ' + this.model;\n  }\n}\n\nlet car1 = new Car('Toyota', 'Camry', 25000);\nlet car2 = new Car('Honda', 'Accord', 28000);\nconsole.log(car1.getFullName()); // Toyota Camry\nconsole.log(car2.getFullName()); // Honda Accord\n```\n\n在上面的例子中，我们定义了一个名为 Car 的类，它有三个属性 brand、model 和 price，以及一个 getFullName 方法。最后，我们使用该类来创建两个不同的汽车对象 car1 和 car2，并调用它们的 getFullName 方法。\n","tags":["js"]},{"title":"python学习记录","url":"/2023/06/08/python学习记录/","content":"\n# 记录在python使用中遇到的问题\n\n## 类型转换\n\n**数字转换字符串**\n\n直接使用str()函数转化\n\n**字符串转数字**\n\n使用int()方法\n\n> 在python中类型转换在需要转换的值前面加上转换后的类型就行\n\n","tags":["python"]},{"title":"python OS包","url":"/2023/06/08/python-OS包/","content":"\n## 1. 简介\n\n`os`就是“operating system”的缩写，顾名思义，`os`模块提供的就是各种 Python 程序与操作系统进行交互的接口。通过使用`os`模块，一方面可以方便地与操作系统进行交互，另一方面页可以极大增强代码的可移植性。如果该模块中相关功能出错，会抛出`OSError`异常或其子类异常。\n\n> 注意，如果是读写文件的话，建议使用内置函数`open()`；如果是路径相关的操作，建议使用`os`的子模块`os.path`；如果要逐行读取多个文件，建议使用`fileinput`模块；要创建临时文件或路径，建议使用`tempfile`模块；要进行更高级的文件和路径操作则应当使用`shutil`模块。\n\n当然，使用`os`模块可以写出操作系统无关的代码并不意味着`os`无法调用一些特定系统的扩展功能，但要切记一点：一旦这样做就会极大**损害代码的可移植性**。\n\n此外，导入`os`模块时还要小心一点，千万**不要**为了图调用省事儿而将`os`模块解包导入，即不要使用`from os import *`来导入`os`模块；否则`os.open()`将会覆盖内置函数`open()`，从而造成预料之外的错误。\n\n## 2. 常见方法\n\n**`listdir`**:列出（当前）目录下的全部路径（及文件）。该函数存在一个参数，用以指定要列出子目录的路径，默认为`“.”`，即“当前路径。下例，批量修改文件后缀：\n\n```python\nimport os\nfor filename in os.listdir(\"D:\\\\static\\\\image\\\\\"):\n    newName = filename.replace(\"jpeg\",\"jpg\")\n    os.rename(\"D:\\\\static\\\\image\\\\\"+filename,\"D:\\\\static\\\\image\\\\\"+newName)\n```\n\n\n\n**`open` `write`**:文件的读写。\n\n```python\nfd = os.open(\"D:\\\\static\\\\image\\\\ceshi.txt\", os.O_CREAT | os.O_RDWR)\nos.write(fd, \"这是一个测试文件\".encode('utf-8'))\n```\n\n\n\n**`mkdir`**:即“make directory”，用处是“新建一个路径”。需要传入一个类路径参数用以指定新建路径的位置和名称，如果指定路径已存在，则会抛出`FileExistsError`异常。\n\n该函数只能在已有的路径下新建一级路径，否则（即新建多级路径）会抛出`FileNotFoundError`异常。\n\n相应地，在需要新建多级路径的场景下，可以使用`os.makedirs()`来完成任务。函数`os.makedirs()`执行的是递归创建，若有必要，会分别新建指定路径经过的中间路径，直到最后创建出末端的“叶子路径”。\n\n\n\n**`remove`**:用于删除文件，如果指定路径是目录而非文件的话，就会抛出`IsADirectoryError`异常。删除目录应该使用`os.rmdir()`函数。\n\n同样的，对应于`os.makedirs()`，删除路径操作`os.rmdir()`也有一个递归删除的函数`os.removedirs()`，该函数会尝试从最下级目录开始，逐级删除指定的路径，几乎就是一个`os.makedirs()`的逆过程；一旦遇到非空目录即停止。\n\n\n\n**`rename`**:该函数的作用是将文件或路径重命名，一般调用格式为`os.rename(src, dst)`，即将`src`指向的文件或路径重命名为`dst`指定的名称。\n\n注意，如果指定的目标路径在其他目录下，该函数还可实现文件或路径的“剪切并粘贴”功能。但无论直接原地重命名还是“剪切粘贴”，中间路径都必须要存在，否则就会抛出`FileNotFoundError`异常。如果目标路径已存在，Windows 下会抛出`FileExistsError`异常；Linux 下，如果目标路径为空且用户权限允许，则会静默覆盖原路径，否则抛出`OSError`异常，\n\n和上两个函数一样，该函数也有对应的递归版本`os.renames()`，能够创建缺失的中间路径。\n\n注意，这两种情况下，如果函数执行成功，都会调用`os.removedir()`函数来递归删除源路径的最下级目录。\n","tags":["python"]},{"title":"javascript技术","url":"/2023/04/16/javascript技术/","content":"\n## js中数组的map方法\n\n### 使用map格式化对象\n\n例如：\n\n```\nconst kvArray = [\n  { key: 1, value: 10 },\n  { key: 2, value: 20 },\n  { key: 3, value: 30 },\n];\n\nconst reformattedArray = kvArray.map(({ key, value}) => ({ [key]: value }));\n\n// reformattedArray 现在是 [{1: 10}, {2: 20}, {3: 30}],\n\n// kvArray 依然是：\n// [{key: 1, value: 10},\n//  {key: 2, value: 20},\n//  {key: 3, value: 30}]\n```\n\n## js中的箭头函数\n\n```\n()=>{}  //完整的语法形式\n//例如\n()=>{\n    return \"我很帅哦\"\n}\n()=>()  //一行的写法\n//例如\n()=>('我也很帅');\n()=>({message:'我也很帅'})\n\n//如果只有一句，可以省略括号,如果返回一个｛｝形式的对象，必须要加上（）\n()=>'我也很帅'\n```\n","tags":["js"],"categories":["js"]},{"title":"Lodash的使用","url":"/2023/04/14/lodash的使用/","content":"\n## debounce 防抖\n\n```\n//对点赞操作进行防抖\nconst handleThumb = debounce(()=>{\n  if (thumb.value) {\n    addLikes({userId: webInfoStore.getUser.id, postId: post.id}).then(res => {\n      if (res.code === 200) message.success('点赞成功')\n      else message.error('点赞失败')\n    })\n  } else {\n    deleteLikes({userId: webInfoStore.getUser.id, postId: post.id}).then(res => {\n      if (res.code === 200) message.warning('取消点赞')\n      else message.error('取消失败')\n    })\n  }\n}, 500)\n```\n","categories":["前端"]},{"title":"SpringBoot应用开发问题","url":"/2023/04/12/springboot应用开发问题/","content":"\n## 静态资源访问配置\n\n两种方式：\n\n1、利用config配置文件配置\n\n```\n@Configuration\n@Slf4j\npublic class WebConfig implements WebMvcConfigurer {\n\n    @Override\n    public void addResourceHandlers(ResourceHandlerRegistry registry) {\n        registry.addResourceHandler(\"/static/**\")  //匹配请求路径\n                .addResourceLocations(\"file:D:\\\\static\\\\\");  //实际本地资源路径\n    }\n}\n```\n\n2、利用application配置文件\n\n```\nspring.mvc.static-path-pattern= /**  #匹配请求路径\n\nspring.resources.static-locations= file:D:\\\\static\\\\  # 实际本地资源路径\nspring.resources.static-locations= classpath:/static/** # 实际本项目路径\n```\n\n注意项目中的各种拦截器对静态资源的放行（例如SpringSecurity）\n","tags":["springboot"],"categories":["springboot"]},{"title":"统一网关Gateway","url":"/2023/04/11/统一网关gateway/","content":"\n## 1、网关作用\n\n1-身份认证和权限校验\n\n2-服务路由、负载均衡\n\n3-请求限流\n\n## 2、实现\n\nSpringCloud实现网关包括两种\n\n- gateway\n\n- zuul\n\nzuul基于servlet实现，属于阻塞式编程。gateway是利用spring5中的webflux，属于响应式编程实现，具有更好的性能。\n\n## 3、使用\n\n### 一、引入依赖\n\n这里需要引入两个依赖，一个是gateway的stater，另一个是nacos的服务发现stater\n\n```xml\n<!--网关依赖-->\n<dependency>\n  <groupId>org.springframework.cloud</groupId>\n  <artifactId>spring-cloud-starter-gateway</artifactId>\n</dependency>\n<!--nac0S服务发现依赖-->\n<dependency>\n  <groupId>com.alibaba.cloud</groupId>\n  <artifactId>spring-cloud-starter-alibaba-nacos-discovery</artifactId>\n</dependency>\n```\n\n### 二、配置文件\n\n```yml\nserver:\n  port:10010 #网关端口\nspring:\n  application:\n    name: gateway #服务名称\n  cloud:\n    nacos:\n      server-addr: Localhost:8848 #nacos地址\n    gateway\n      routes: #网关路由配置\n        - id: User-service  #路由id,自定义，只要唯一即可\n          #Uri:http://127.0.0.1:8081 #路由的目标地址http就是固定地址\n          uri: lb://userservice #路由的目标地址lb就是负载均衡，后面限服务名称\n          predicates: #路由断言，也就是判断情求是否符合路由规则的条件\n            - Path= /user/**  #这个是按照路径匹配，只要以/user/开头就符合要求\n```\n\n**网关路由可以配置的内容包括：**  \n路由id: 路由唯一标示  \nuri: 路由目的地，支特b和http两种  \npredicates: 路由断言，判断请求是否符合要求，符合则转发到路由目的地  \nfilters: 路由过滤器，处理请求或响应\n\n**predicate工厂**\n\n1. `AfterRoutePredicateFactory`：用于检查请求时间是否在指定时间之后。\n\n3. `BeforeRoutePredicateFactory`：用于检查请求时间是否在指定时间之前。\n\n5. `BetweenRoutePredicateFactory`：用于检查请求时间是否在指定时间段内。\n\n7. `CookieRoutePredicateFactory`：用于检查请求中是否包含指定 Cookie。\n\n9. `HeaderRoutePredicateFactory`：用于检查请求头中是否包含指定的值。\n\n11. `HostRoutePredicateFactory`：用于检查请求的 Host 是否匹配指定的值。\n\n13. `MethodRoutePredicateFactory`：用于检查请求的方法是否匹配指定的值。\n\n15. `PathRoutePredicateFactory`：用于检查请求路径是否匹配指定的值。\n\n17. `QueryRoutePredicateFactory`：用于检查请求参数是否匹配指定的值。\n\n19. `ReadBodyRoutePredicateFactory`：用于检查请求体中是否包含指定的值。\n\n21. `RemoteAddrRoutePredicateFactory`：用于检查请求的远程地址是否匹配指定的值。\n","tags":["gateway"],"categories":["springcloud"]},{"title":"Feign学习记录","url":"/2023/04/06/feign学习记录/","content":"\n**Feign的主要作用：简化HTTP请求-Feign可以自动生成HTTP请求代码，无需手动编写。**\n\n**用在服务间的调用，替换RestTemplate的使用**\n\n**Feign里面集成了Ribbon负载均衡，自动实现负载均衡**\n\n## 1、引入依赖\n\n**这里默认引入了springboot父依赖**\n\n```\n<dependency>\n    <groupId>org.springframework.cloud</groupId>\n    <artifactId>spring-cloud-starter-openfeign</artifactId>\n</dependency>\n```\n\n## 2、在启动类添加注解开启Feign\n\n```\n//开启Feign\n@EnableFeignclients\n@Mapperscan(\"cn.itcast.order.mapper\")\n@SpringBootApplication\npublic class OrderApplication{\n    public static void main(String[]args){\n        SpringApplication.run(OrderApplication.class,args);\n}\n```\n\n## 3、编写Feign客户端\n\n```\n@Feignclient(\"userservice\")\npublic interface Userclient{\n    @GetMapping(\"/user/id]\")\n    User findById(@PathVariable(\"id\")Long id);\n}\n```\n\n## 4、Feign常用配置\n\n```\nfeign:\n  client:\n    config:\n      default:\n        connectTimeout: 5000 # 连接超时时间，单位为毫秒\n        readTimeout: 5000 # 读取超时时间，单位为毫秒\n        loggerLevel: basic # 日志级别，basic为记录请求方法、URL、响应状态码，full为记录请求和响应的所有信息\n        retryer: # 重试机制\n          retryMaxAttempts: 3 # 最大重试次数\n          retryInterval: 1000 # 重试间隔时间，单位为毫秒\n        decoder: # 响应解码器\n          default: # 默认解码器\n            feign:\n              autoconfiguration:\n                enabled: true # 是否启用自动配置\n              client:\n                httpclient:\n                  enabled: true # 是否启用HttpClient\n                okhttp:\n                  enabled: false # 是否启用OkHttp\n        encoder: # 请求编码器\n          default: # 默认编码器\n            feign:\n              autoconfiguration:\n                enabled: true # 是否启用自动配置\n              client:\n                httpclient:\n                  enabled: true # 是否启用HttpClient\n                okhttp:\n                  enabled: false # 是否启用OkHttp\n```\n\n## 5、Feign性能优化\n\n1. Feign底层客户端实现两种推荐\n\n- Apache HttpClient\n\n- OKHttp\n\n2\\. 日志级别最好是用basic或none\n\n### 具体使用\n\n添加HTTPClient依赖\n\n```\n<!--httpClient的依赖-->\n<dependency>\n    <groupId>io.github.openfeign</groupId>\n    <artifactId>feign-httpclient</artifactId>\n</dependency>\n```\n","tags":["feign"],"categories":["springcloud"]},{"title":"SpringSecurity6.0使用","url":"/2023/04/02/springsecurity6-0使用/","content":"\n## 前后端分离的基本使用\n\n### UserDetailsServiceImpl类\n\n```\n@Slf4j\n@Service\n@RequiredArgsConstructor\npublic class UserDetailsServiceImpl implements UserDetailsService {\n\n    //这是自定义用户安全类的Mapper,主要包含登陆需要的信息,比如用户名,密码,邮箱等\n    @Autowired\n    private UserSecurityMapper userSecurityMapper;\n\n    private QueryWrapper<UserSecurity> queryWrapper;\n\n\n    //根据用户邮箱查找用户,然后返回UserDetails\n    @Override\n    public UserDetails loadUserByUsername(String username) throws UsernameNotFoundException {\n        queryWrapper = new QueryWrapper<>();\n        queryWrapper.eq(\"email\",username);\n        UserSecurity userSecurity = userSecurityMapper.selectOne(queryWrapper);\n        if (userSecurity == null) {\n            throw new UsernameNotFoundException(\"username \" + username + \" is not found\");\n        }\n        return new MyUserDetails(userSecurity.getNickname(),userSecurity.getPassword(),userSecurity.getEmail());\n    }\n}\n```\n\n### UserSecurity实体类\n\n```\n\n@Getter\n@Setter\n@TableName(\"user_security\")\n@ApiModel(value = \"UserSecurity对象\", description = \"用户密码表\")\npublic class UserSecurity implements Serializable {\n\n    private static final long serialVersionUID = 1L;\n\n    @TableId(value = \"id\", type = IdType.AUTO)\n    private Integer id;\n\n    @ApiModelProperty(\"用户ID\")\n    @TableField(\"user_id\")\n    private Integer userId;\n\n    @ApiModelProperty(\"昵称\")\n    @TableField(\"nickname\")\n    private String nickname;\n\n    @ApiModelProperty(\"密码\")\n    @TableField(\"password\")\n    private String password;\n\n    @ApiModelProperty(\"用户邮箱\")\n    @TableField(\"email\")\n    private String email;\n}\n```\n\n### SecurityConfig配置类\n\n```\n@Configuration\n@EnableWebSecurity\n@Slf4j\npublic class SecurityConfig {\n\n    //自动注入UserDetailsService类,就是上面定义的UserDetailsServiceImpl\n    @Resource\n    UserDetailsService userDetailsService;\n\n    //拦截器,负责校验token\n    @Autowired\n    JwtAuthenticationTokenFilter jwtAuthenticationTokenFilter;\n\n    //主要配置\n    @Bean\n    public SecurityFilterChain filterChain(HttpSecurity http) throws Exception {\n        http\n                .cors().and().csrf().disable()  //关闭csrf\n                .sessionManagement()\n                .sessionCreationPolicy(SessionCreationPolicy.STATELESS)\n                .and()\n                .authorizeHttpRequests(authorize -> authorize\n                        .requestMatchers(new AntPathRequestMatcher(\"/lostandfound/**\")).permitAll()\n                        .requestMatchers(new AntPathRequestMatcher(\"/**\")).permitAll() //放行所有路径\n                ).formLogin((formLoginConfigurer)->{\n                    formLoginConfigurer.disable();  //禁止表单登陆\n                }).addFilterAt(jwtAuthenticationTokenFilter, UsernamePasswordAuthenticationFilter.class);   //放入拦截器token校验拦截器和UsernamePassword\n拦截器同位置\n\n        return http.build();\n    }\n\n    @Bean\n    public PasswordEncoder passwordEncoder() {\n        return new BCryptPasswordEncoder();\n    }\n\n\n    // 配置认证管理器\n    @Bean\n    public AuthenticationManager authenticationManager() {\n        DaoAuthenticationProvider daoAuthenticationProvider = new DaoAuthenticationProvider();\n        daoAuthenticationProvider.setUserDetailsService(userDetailsService);\n        return new ProviderManager(daoAuthenticationProvider);\n    }\n\n}\n```\n\n### UserDetails实现类\n\n```\n@Data\npublic class MyUserDetails extends User implements UserDetails {\n    private String password;\n    private final String username;\n    private final String email; // 扩展字段，手机号放入用户信息中\n\n\n    public MyUserDetails(String username, String password, String email) {\n        this.password = password;\n        this.email = email;\n        this.username = username;\n\n    }\n\n    @Override\n    public Collection<? extends GrantedAuthority> getAuthorities() {\n        return null;\n    }\n\n    @Override\n    public boolean isAccountNonExpired() {\n        return true;\n    }\n\n    @Override\n    public boolean isAccountNonLocked() {\n        return true;\n    }\n\n    @Override\n    public boolean isCredentialsNonExpired() {\n        return true;\n    }\n\n    @Override\n    public boolean isEnabled() {\n        return true;\n    }\n}\n```\n","categories":["springsecurity"]},{"title":"CSS不常见属性","url":"/2023/03/28/css不常见属性/","content":"\n`user-select` 禁止被选中（比如文字不能选中复制）\n\n在标签上加 tabindex=-1表示让非表单元素获得聚焦属性\n\n例如 :\n\n<li tabindex=\"-1\" class=\"nav-item\">全部学科</li>\n","tags":["css"],"categories":["css"]},{"title":"Vue中组合式pinia","url":"/2023/03/28/vue中组合式pinia/","content":"\n## 1、安装pinia\n\n```\nnpm i -d install pinia   //安装在dev\n```\n\n## 2、在项目中引入\n\n```\nimport {createApp} from \"vue\"\n//引入\nimport {createPinia} from \"pinia\";\nimport App from './App.vue'\n\nconst pinia = createPinia()\nconst app = createApp(App)\n//使用\napp.use(pinia)\n```\n\n## 3、创建store\n\n```\nimport {defineStore} from \"pinia\";\nimport {computed, ref} from \"vue\";\n\nexport const useWebStore = defineStore('web', () => {\n    const page = ref(0)\n\n    const getPage=computed(()=>{\n        return page.value\n    })\n\n    function changePage(p: number) {\n        page.value = p;\n    }\n\n    return {page, changePage,getPage}\n})\n```\n\n_这里使用的是组合式的pinia_\n\n## 4、在其他组件中引入就可以直接使用了\n\n```\nimport {useWebStore} from \"@/store/WebStore\";\n```\n","categories":["vue"]},{"title":"Mybatis-plus记录","url":"/2023/03/27/mybatis-plus记录/","content":"\n## 1、查询方法\n\n### 排序查询\n\n```\npublic R getRankingUser(){\n        queryWrapper = new QueryWrapper<>();\n\n        //对某个字段排序查询\n        queryWrapper.orderByDesc(\"find_num\");\n\n        //限制输出条数\n        queryWrapper.last(\"limit 10\");\n        List<User> users = userService.list(queryWrapper);\n        return R.ok().data(\"list\",users);\n    }\n```\n","tags":["mybatis-plus"],"categories":["mybatis-plus"]},{"title":"Vue学习","url":"/2023/03/27/使用vue时遇到的问题/","content":"\n## 1、在向后端获取数据时，向子组件传参\n\n```\nasync function init(){\n  //获取后端数据，将数据赋值，并且重新加载页面\n  await getAllPosts().then(res=>{\n    ports.value=res.data.list\n  })\n\n  await getLikeKey(\"complete\").then(res=>{\n    count.value = res.data.list\n  })\n  load=true\n  currentInstance?.proxy?.$forceUpdate()\n\n}\n```\n\n**_在这里，ports和count都是ref，但是如果改为普通对象，那么这两个参数的值不能在页面跳转之前传到子组件_**\n\n## 2、Vue页面刷新导致Store内数据丢失\n\n\\-**可以选择存在locaStorage里面。**\n\n\\-**可以使用Cookie存储**\n\n我使用Cookie存储信息\n\n```\n//Cookie的使用\nCookie.set([key],[value])\nCookei.get([key])\n```\n\n## 使用vue3中的ref获取dom元素,使用时为空\n\n实际上在setup的时候，dom元素还没有被创建，一切都处于混沌状态，只有setup完毕了HTML才能完整构建，才能真正访问到value值，所以自然无法获取到dom节点，要想解决这个问题，就要配合钩子函数\n\n例如:\n\n```\nconst defaultItem = ref()\n\n//在onMounted中使用,此时的dom已经创建\nonMounted(()=>{\n  console.log(defaultItem.value)\n})\n```\n\n## vue中h函数的使用\n\nh() 函数是一个用于创建 VNode 的实用程序。也许可以更准确地将其命名为 createVNode()，但由于频繁使用和简洁，它被称为 h() 。它接受三个参数：三个参数简单总结就是，标签，标签属性，标签内包含的（子标签和文字）\n\n```\n// @returns {VNode}\nh(\n    // {String | Object | Function} tag\n    // 一个 HTML 标签名、一个组件、一个异步组件、或\n    // 一个函数式组件。\n    //\n    // 必需的。\n    'div',\n\n    // {Object} props\n    // 与 attribute、prop 和事件相对应的对象。\n    // 这会在模板中用到。\n    //\n    // 可选的(在开发时。建议传，实在没有传的时候，传入 null)\n    {},\n\n    // {String | Array | Object} children\n    // 子 VNodes, 使用 `h()` 构建,\n    // 或使用字符串获取 \"文本 VNode\" 或者\n    // 有插槽的对象。\n    //\n    // 可选的。\n    [\n        'Some text comes first.',\n        h('h1', 'A headline'),\n        h(MyComponent, {\n            someProp: 'foobar'\n        })\n    ]\n)\n```\n\n## 使用vue实现一个简易的导航栏\n\n```\n<div class=\"nav\">\n\n      <ul ref=\"allItem\">\n        <li class=\"nav-item\" :class=\"{onFocus:isActive[0]}\" @click=\"changeNav(0)\">全部学科</li>\n        <li class=\"nav-item\" :class=\"{onFocus:isActive[1]}\" @click=\"changeNav(1)\">高等数学</li>\n        <li class=\"nav-item\" :class=\"{onFocus:isActive[2]}\" @click=\"changeNav(2)\">大学英语</li>\n        <li class=\"nav-item\" :class=\"{onFocus:isActive[3]}\" @click=\"changeNav(3)\">教资</li>\n        <li class=\"nav-item\" :class=\"{onFocus:isActive[4]}\" @click=\"changeNav(4)\">四六级</li>\n        <li class=\"nav-item\" :class=\"{onFocus:isActive[5]}\" @click=\"changeNav(5)\">C语言</li>\n        <li class=\"nav-item\" :class=\"{onFocus:isActive[6]}\" @click=\"changeNav(6)\">其他</li>\n      </ul>\n    </div>\n\n\nconst isActive = ref([\n  true,\n  false,\n  false,\n  false,\n  false,\n  false,\n  false,\n])\n\nfunction changeNav(nav: number) {\n  isActive.value = [false, false, false, false, false, false,false]\n  for (let i = 0; i < unref(isActive).length; i++) {\n    if (i === nav) {\n      unref(isActive).splice(i,1,true)\n    }\n  }\n}\n```\n\n## vue中阻止冒泡事件（@click的各种属性）\n\n1、@click.stop 阻止事件冒泡\n\n2、@click.prevent 阻止事件的默认行为 （提交事件不再重载页面）\n\n3、@click.capture 优先触发\n\n4、@click.self 只有自己能触发，子元素无法触发[](/#)\n\n5、@click.once 只能提交一次（.once 修饰符还能被用到自定义的组件事件上。）\n\n6、@click.native  \n7、@click.passive\n\n8、@keyup.enter //按键修饰符（按键码的别名：.enter ，.tab ，.delete ，.esc ，.space ，.up ，.down ，.left ，.right ）  \n9、系统修饰键（.ctrl , .alt , .shift ,.meta ）\n\n10、.exact修饰符\n","categories":["vue"]},{"title":"redis常用命令","url":"/2023/03/24/redis常用命令/","content":"\n## 连接\n\nRedis 客户端的基本语法为：\n\n```bash\n$ redis-cli\n```\n\n如果需要在远程 redis 服务上执行命令，同样我们使用的也是 **redis-cli** 命令。\n\n```bash\n$ redis-cli -h host -p port -a password\n```\n\n## 类型\n\n| 类型 | 简介 | 特性 | 场景 |\n| --- | --- | --- | --- |\n| String(字符串) | 二进制安全 | 可以包含任何数据,比如jpg图片或者序列化的对象,一个键最大能存储512M | \\--- |\n| Hash(字典) | 键值对集合,即编程语言中的Map类型 | 适合存储对象,并且可以像数据库中update一个属性一样只修改某一项属性值(Memcached中需要取出整个字符串反序列化成对象修改完再序列化存回去) | 存储、读取、修改用户属性 |\n| List(列表) | 链表(双向链表) | 增删快,提供了操作某一段元素的API | 1,最新消息排行等功能(比如朋友圈的时间线) 2,消息队列 |\n| Set(集合) | 哈希表实现,元素不重复 | 1、添加、删除,查找的复杂度都是O(1) 2、为集合提供了求交集、并集、差集等操作 | 1、共同好友 2、利用唯一性,统计访问网站的所有独立ip 3、好友推荐时,根据tag求交集,大于某个阈值就可以推荐 |\n| Sorted Set(有序集合) | 将Set中的元素增加一个权重参数score,元素按score有序排列 | 数据插入集合时,已经进行天然排序 | 1、排行榜 2、带权重的消息队列 |\n\n## 命令\n\n### 数据库操作\n\n```shell\nflushdb # 清除当前数据库\n```\n\n### 键操作（常用keys命令）\n\n```shell\nSET [key] [value] # 设置键值对\n\nDEL [key]  # 删除某个key和他的值\n\nEXISTS [key] # 检查某个key是否存在\n\nPTTL/TTL [key] # 返回某个key的剩余时间(毫秒/秒)\n\nRENAME [key] [newkey] # 修改某个key的名字\n\nTYPE [key] # 返回key所存储的类型\n```\n","tags":["redis"],"categories":["redis"]},{"title":"前端开发常用工具","url":"/2023/03/24/前端开发常用工具/","content":"\n## 1、free-swagger\n\n一个自动生成代码的前端工具\n\n![](https://presenter.oss-cn-shanghai.aliyuncs.com/wordpress/20230324103117.png)\n\n> 在google浏览器中搜索free-swagger插件，安装使用\n> \n> 这个插件能直接将后端的swagger接口生成interface和api代码，生成代码功能在下方。\n\n## 2、moment.js\n\n前端时间处理工具 [moment.js](http://momentjs.cn/)\n\n![](https://presenter.oss-cn-shanghai.aliyuncs.com/wordpress/20230324103640.png)\n\n### 使用：\n","tags":["前端"],"categories":["前端"]},{"title":"Redis+SpringBoot问题","url":"/2023/03/23/redisspringboot问题/","content":"\n### 配置类\n\n这里需要对java中的各种对象进行序列化，然后存放在redis中。如果不在config配置类中配置，需要每次调用手动转化，比较麻烦。\n\n另外新版本之后Jackson2JsonRedisSerializer应该在实例化时直接new Jackson2JsonRedisSerializer<Object>(objectMapper,Object.class)；这里这个objectMapper是重点\n\n```\n@Configuration\npublic class RedisConfig {\n\n    @Bean\n    public RedisTemplate<String,Object > redisTemplate(RedisConnectionFactory factory){\n        RedisTemplate<String,Object> redisTemplate=new RedisTemplate<>();\n        RedisSerializer<String > redisSerializer = new StringRedisSerializer();\n        //使用Jackson的序列化器，在后面对value进行序列化，是对Object类序列化\n          /*\n        设置objectMapper；转换java对象的时候使用的\n         */\n        ObjectMapper objectMapper = new ObjectMapper();\n        objectMapper.setVisibility(PropertyAccessor.ALL, JsonAutoDetect.Visibility.ANY);\n        objectMapper.enableDefaultTyping(ObjectMapper.DefaultTyping.NON_FINAL);\n\n        Jackson2JsonRedisSerializer<Object> serializer = new Jackson2JsonRedisSerializer<Object>(objectMapper,Object.class);\n\n\n        redisTemplate.setConnectionFactory(factory);\n        redisTemplate.setKeySerializer(redisSerializer);\n        //value序列化\n        redisTemplate.setValueSerializer(serializer);\n        //value hashmap序列化\n        redisTemplate.setHashKeySerializer(redisSerializer);\n        //key hashmap序列化\n        redisTemplate.setHashValueSerializer(serializer);\n\n        redisTemplate.afterPropertiesSet();\n\n        return redisTemplate;\n    }\n}\n```\n\n### Redis工具类\n\n```\n@SuppressWarnings(value = { \"unchecked\", \"rawtypes\" })\n@Component\npublic class RedisCache\n{\n    @Autowired\n    public RedisTemplate redisTemplate;\n\n    /**\n     * 缓存基本的对象，Integer、String、实体类等\n     *\n     * @param key 缓存的键值\n     * @param value 缓存的值\n     */\n    public <T> void setCacheObject(final String key, final T value)\n    {\n        redisTemplate.opsForValue().set(key, value);\n    }\n\n    /**\n     * 缓存基本的对象，Integer、String、实体类等\n     *\n     * @param key 缓存的键值\n     * @param value 缓存的值\n     * @param timeout 时间\n     * @param timeUnit 时间颗粒度\n     */\n    public <T> void setCacheObject(final String key, final T value, final Integer timeout, final TimeUnit timeUnit)\n    {\n        redisTemplate.opsForValue().set(key, value, timeout, timeUnit);\n    }\n\n    /**\n     * 设置有效时间\n     *\n     * @param key Redis键\n     * @param timeout 超时时间\n     * @return true=设置成功；false=设置失败\n     */\n    public boolean expire(final String key, final long timeout)\n    {\n        return expire(key, timeout, TimeUnit.SECONDS);\n    }\n\n    /**\n     * 设置有效时间\n     *\n     * @param key Redis键\n     * @param timeout 超时时间\n     * @param unit 时间单位\n     * @return true=设置成功；false=设置失败\n     */\n    public boolean expire(final String key, final long timeout, final TimeUnit unit)\n    {\n        return redisTemplate.expire(key, timeout, unit);\n    }\n\n    /**\n     * 获得缓存的基本对象。\n     *\n     * @param key 缓存键值\n     * @return 缓存键值对应的数据\n     */\n    public <T> T getCacheObject(final String key)\n    {\n        ValueOperations<String, T> operation = redisTemplate.opsForValue();\n        return operation.get(key);\n    }\n\n    /**\n     * 删除单个对象\n     *\n     * @param key\n     */\n    public boolean deleteObject(final String key)\n    {\n        return redisTemplate.delete(key);\n    }\n\n    /**\n     * 删除集合对象\n     *\n     * @param collection 多个对象\n     * @return\n     */\n    public long deleteObject(final Collection collection)\n    {\n        return redisTemplate.delete(collection);\n    }\n\n    /**\n     * 缓存List数据\n     *\n     * @param key 缓存的键值\n     * @param dataList 待缓存的List数据\n     * @return 缓存的对象\n     */\n    public <T> long setCacheList(final String key, final List<T> dataList)\n    {\n        Long count = redisTemplate.opsForList().rightPushAll(key, dataList);\n        return count == null ? 0 : count;\n    }\n\n    /**\n     * 获得缓存的list对象\n     *\n     * @param key 缓存的键值\n     * @return 缓存键值对应的数据\n     */\n    public <T> List<T> getCacheList(final String key)\n    {\n        return redisTemplate.opsForList().range(key, 0, -1);\n    }\n\n    /**\n     * 缓存Set\n     *\n     * @param key 缓存键值\n     * @param dataSet 缓存的数据\n     * @return 缓存数据的对象\n     */\n    public <T> BoundSetOperations<String, T> setCacheSet(final String key, final Set<T> dataSet)\n    {\n        BoundSetOperations<String, T> setOperation = redisTemplate.boundSetOps(key);\n        Iterator<T> it = dataSet.iterator();\n        while (it.hasNext())\n        {\n            setOperation.add(it.next());\n        }\n        return setOperation;\n    }\n\n    /**\n     * 获得缓存的set\n     *\n     * @param key\n     * @return\n     */\n    public <T> Set<T> getCacheSet(final String key)\n    {\n        return redisTemplate.opsForSet().members(key);\n    }\n\n    /**\n     * 缓存Map\n     *\n     * @param key\n     * @param dataMap\n     */\n    public <T> void setCacheMap(final String key, final Map<String, T> dataMap)\n    {\n        if (dataMap != null) {\n            redisTemplate.opsForHash().putAll(key, dataMap);\n        }\n    }\n\n    /**\n     * 获得缓存的Map\n     *\n     * @param key\n     * @return\n     */\n    public <T> Map<String, T> getCacheMap(final String key)\n    {\n        return redisTemplate.opsForHash().entries(key);\n    }\n\n    /**\n     * 往Hash中存入数据\n     *\n     * @param key Redis键\n     * @param hKey Hash键\n     * @param value 值\n     */\n    public <T> void setCacheMapValue(final String key, final String hKey, final T value)\n    {\n        redisTemplate.opsForHash().put(key, hKey, value);\n    }\n\n    /**\n     * 获取Hash中的数据\n     *\n     * @param key Redis键\n     * @param hKey Hash键\n     * @return Hash中的对象\n     */\n    public <T> T getCacheMapValue(final String key, final String hKey)\n    {\n        HashOperations<String, String, T> opsForHash = redisTemplate.opsForHash();\n        return opsForHash.get(key, hKey);\n    }\n\n    /**\n     * 删除Hash中的数据\n     *\n     * @param key\n     * @param hkey\n     */\n    public void delCacheMapValue(final String key, final String hkey)\n    {\n        HashOperations hashOperations = redisTemplate.opsForHash();\n        hashOperations.delete(key, hkey);\n    }\n\n    /**\n     * 获取多个Hash中的数据\n     *\n     * @param key Redis键\n     * @param hKeys Hash键集合\n     * @return Hash对象集合\n     */\n    public <T> List<T> getMultiCacheMapValue(final String key, final Collection<Object> hKeys)\n    {\n        return redisTemplate.opsForHash().multiGet(key, hKeys);\n    }\n\n    /**\n     * 获得缓存的基本对象列表\n     *\n     * @param pattern 字符串前缀\n     * @return 对象列表\n     */\n    public Collection<String> keys(final String pattern)\n    {\n        return redisTemplate.keys(pattern);\n    }\n}\n```\n","tags":["redis"],"categories":["redis"]},{"title":"常用API","url":"/2023/03/23/常用api/","content":"\n获取QQ头像：`http://q1.qlogo.cn/g?b=qq&nk=2693285351&s=640`\n","categories":["api","工具类"]},{"title":"SpringCloud学习记录","url":"/2023/03/16/springcloud学习记录/","content":"\n# SpringCloud01\n\n# 1.认识微服务\n\n随着互联网行业的发展，对服务的要求也越来越高，服务架构也从单体架构逐渐演变为现在流行的微服务架构。这些架构之间有怎样的差别呢？\n\n## 1.0.学习目标\n\n了解微服务架构的优缺点\n\n## 1.1.单体架构\n\n**单体架构**：将业务的所有功能集中在一个项目中开发，打成一个包部署。\n\n![image-20210713202807818](https://presenter.oss-cn-shanghai.aliyuncs.com/wordpress/image-20210713202807818.png)\n\n单体架构的优缺点如下：\n\n**优点：**\n\n- 架构简单\n\n- 部署成本低\n\n**缺点：**\n\n- 耦合度高（维护困难、升级困难）\n\n## 1.2.分布式架构\n\n**分布式架构**：根据业务功能对系统做拆分，每个业务功能模块作为独立项目开发，称为一个服务。\n\n![image-20210713203124797](https://presenter.oss-cn-shanghai.aliyuncs.com/wordpress/image-20210713203124797.png)\n\n分布式架构的优缺点：\n\n**优点：**\n\n- 降低服务耦合\n\n- 有利于服务升级和拓展\n\n**缺点：**\n\n- 服务调用关系错综复杂\n\n分布式架构虽然降低了服务耦合，但是服务拆分时也有很多问题需要思考：\n\n- 服务拆分的粒度如何界定？\n\n- 服务之间如何调用？\n\n- 服务的调用关系如何管理？\n\n人们需要制定一套行之有效的标准来约束分布式架构。\n\n## 1.3.微服务\n\n微服务的架构特征：\n\n- 单一职责：微服务拆分粒度更小，每一个服务都对应唯一的业务能力，做到单一职责\n\n- 自治：团队独立、技术独立、数据独立，独立部署和交付\n\n- 面向服务：服务提供统一标准的接口，与语言和技术无关\n\n- 隔离性强：服务调用做好隔离、容错、降级，避免出现级联问题\n\n![image-20210713203753373](https://presenter.oss-cn-shanghai.aliyuncs.com/wordpress/image-20210713203753373.png)\n\n微服务的上述特性其实是在给分布式架构制定一个标准，进一步降低服务之间的耦合度，提供服务的独立性和灵活性。做到高内聚，低耦合。\n\n因此，可以认为**微服务**是一种经过良好架构设计的**分布式架构方案** 。\n\n但方案该怎么落地？选用什么样的技术栈？全球的互联网公司都在积极尝试自己的微服务落地方案。\n\n其中在Java领域最引人注目的就是SpringCloud提供的方案了。\n\n## 1.4.SpringCloud\n\nSpringCloud是目前国内使用最广泛的微服务框架。官网地址：[https://spring.io/projects/spring-cloud](https://spring.io/projects/spring-cloud)。\n\nSpringCloud集成了各种微服务功能组件，并基于SpringBoot实现了这些组件的自动装配，从而提供了良好的开箱即用体验。\n\n其中常见的组件包括：\n\n![image-20210713204155887](https://presenter.oss-cn-shanghai.aliyuncs.com/wordpress/image-20210713204155887.png)\n\n另外，SpringCloud底层是依赖于SpringBoot的，并且有版本的兼容关系，如下：\n\n![image-20210713205003790](https://presenter.oss-cn-shanghai.aliyuncs.com/wordpress/image-20210713205003790.png)\n\n我们课堂学习的版本是 Hoxton.SR10，因此对应的SpringBoot版本是2.3.x版本。\n\n## 1.5.总结\n\n- 单体架构：简单方便，高度耦合，扩展性差，适合小型项目。例如：学生管理系统\n\n- 分布式架构：松耦合，扩展性好，但架构复杂，难度大。适合大型互联网项目，例如：京东、淘宝\n\n- 微服务：一种良好的分布式架构方案①优点：拆分粒度更小、服务更独立、耦合度更低②缺点：架构非常复杂，运维、监控、部署难度提高\n\n- SpringCloud是微服务架构的一站式解决方案，集成了各种优秀微服务功能组件\n\n# 2.服务拆分和远程调用\n\n任何分布式架构都离不开服务的拆分，微服务也是一样。\n\n## 2.1.服务拆分原则\n\n这里我总结了微服务拆分时的几个原则：\n\n- 不同微服务，不要重复开发相同业务\n\n- 微服务数据独立，不要访问其它微服务的数据库\n\n- 微服务可以将自己的业务暴露为接口，供其它微服务调用\n\n![image-20210713210800950](https://presenter.oss-cn-shanghai.aliyuncs.com/wordpress/image-20210713210800950.png)\n\n## 2.2.服务拆分示例\n\n以课前资料中的微服务cloud-demo为例，其结构如下：\n\n![image-20210713211009593](https://presenter.oss-cn-shanghai.aliyuncs.com/wordpress/image-20210713211009593.png)\n\ncloud-demo：父工程，管理依赖\n\n- order-service：订单微服务，负责订单相关业务\n\n- user-service：用户微服务，负责用户相关业务\n\n要求：\n\n- 订单微服务和用户微服务都必须有各自的数据库，相互独立\n\n- 订单服务和用户服务都对外暴露Restful的接口\n\n- 订单服务如果需要查询用户信息，只能调用用户服务的Restful接口，不能查询用户数据库\n\n### 2.2.1.导入Sql语句\n\n首先，将课前资料提供的`cloud-order.sql`和`cloud-user.sql`导入到mysql中：\n\n![image-20210713211417049](https://presenter.oss-cn-shanghai.aliyuncs.com/wordpress/image-20210713211417049.png)\n\ncloud-user表中初始数据如下：\n\n![image-20210713211550169](https://presenter.oss-cn-shanghai.aliyuncs.com/wordpress/image-20210713211550169.png)\n\ncloud-order表中初始数据如下：\n\n![image-20210713211657319](https://presenter.oss-cn-shanghai.aliyuncs.com/wordpress/image-20210713211657319.png)\n\ncloud-order表中持有cloud-user表中的id字段。\n\n### 2.2.2.导入demo工程\n\n用IDEA导入课前资料提供的Demo：\n\n![image-20210713211814094](https://presenter.oss-cn-shanghai.aliyuncs.com/wordpress/image-20210713211814094.png)\n\n项目结构如下：\n\n![image-20210713212656887](https://presenter.oss-cn-shanghai.aliyuncs.com/wordpress/image-20210713212656887.png)\n\n导入后，会在IDEA右下角出现弹窗：\n\n![image-20210713212349272](https://presenter.oss-cn-shanghai.aliyuncs.com/wordpress/image-20210713212349272.png)\n\n点击弹窗，然后按下图选择：\n\n![image-20210713212336185](https://presenter.oss-cn-shanghai.aliyuncs.com/wordpress/image-20210713212336185.png)\n\n会出现这样的菜单：\n\n![image-20210713212513324](https://presenter.oss-cn-shanghai.aliyuncs.com/wordpress/image-20210713212513324.png)\n\n配置下项目使用的JDK：\n\n![image-20210713220736408](https://presenter.oss-cn-shanghai.aliyuncs.com/wordpress/image-20210713220736408.png)\n\n## 2.3.实现远程调用案例\n\n在order-service服务中，有一个根据id查询订单的接口：\n\n![image-20210713212749575](https://presenter.oss-cn-shanghai.aliyuncs.com/wordpress/image-20210713212749575.png)\n\n根据id查询订单，返回值是Order对象，如图：\n\n![image-20210713212901725](https://presenter.oss-cn-shanghai.aliyuncs.com/wordpress/image-20210713212901725.png)\n\n其中的user为null\n\n在user-service中有一个根据id查询用户的接口：\n\n![image-20210713213146089](https://presenter.oss-cn-shanghai.aliyuncs.com/wordpress/image-20210713213146089.png)\n\n查询的结果如图：\n\n![image-20210713213213075](https://presenter.oss-cn-shanghai.aliyuncs.com/wordpress/image-20210713213213075.png)\n\n### 2.3.1.案例需求：\n\n修改order-service中的根据id查询订单业务，要求在查询订单的同时，根据订单中包含的userId查询出用户信息，一起返回。\n\n![image-20210713213312278](https://presenter.oss-cn-shanghai.aliyuncs.com/wordpress/image-20210713213312278.png)\n\n因此，我们需要在order-service中 向user-service发起一个http的请求，调用[http://localhost:8081/user/](http://localhost:8081/user/){userId}这个接口。\n\n大概的步骤是这样的：\n\n- 注册一个RestTemplate的实例到Spring容器\n\n- 修改order-service服务中的OrderService类中的queryOrderById方法，根据Order对象中的userId查询User\n\n- 将查询的User填充到Order对象，一起返回\n\n### 2.3.2.注册RestTemplate\n\n首先，我们在order-service服务中的OrderApplication启动类中，注册RestTemplate实例：\n\npackage cn.itcast.order;  \n​  \nimport org.mybatis.spring.annotation.MapperScan;  \nimport org.springframework.boot.SpringApplication;  \nimport org.springframework.boot.autoconfigure.SpringBootApplication;  \nimport org.springframework.context.annotation.Bean;  \nimport org.springframework.web.client.RestTemplate;  \n​  \n@MapperScan(\"cn.itcast.order.mapper\")  \n@SpringBootApplication  \npublic class OrderApplication {  \n​  \n    public static void main(String\\[\\] args) {  \n        SpringApplication.run(OrderApplication.class, args);  \n    }  \n​  \n    @Bean  \n    public RestTemplate restTemplate() {  \n        return new RestTemplate();  \n    }  \n}\n\n### 2.3.3.实现远程调用\n\n修改order-service服务中的cn.itcast.order.service包下的OrderService类中的queryOrderById方法：\n\n![image-20210713213959569](https://presenter.oss-cn-shanghai.aliyuncs.com/wordpress/image-20210713213959569.png)\n\n## 2.4.提供者与消费者\n\n在服务调用关系中，会有两个不同的角色：\n\n**服务提供者**：一次业务中，被其它微服务调用的服务。（提供接口给其它微服务）\n\n**服务消费者**：一次业务中，调用其它微服务的服务。（调用其它微服务提供的接口）\n\n![image-20210713214404481](https://presenter.oss-cn-shanghai.aliyuncs.com/wordpress/image-20210713214404481.png)\n\n但是，服务提供者与服务消费者的角色并不是绝对的，而是相对于业务而言。\n\n如果服务A调用了服务B，而服务B又调用了服务C，服务B的角色是什么？\n\n- 对于A调用B的业务而言：A是服务消费者，B是服务提供者\n\n- 对于B调用C的业务而言：B是服务消费者，C是服务提供者\n\n因此，服务B既可以是服务提供者，也可以是服务消费者。\n\n# 3.Eureka注册中心\n\n假如我们的服务提供者user-service部署了多个实例，如图：\n\n![image-20210713214925388](https://presenter.oss-cn-shanghai.aliyuncs.com/wordpress/image-20210713214925388.png)\n\n大家思考几个问题：\n\n- order-service在发起远程调用的时候，该如何得知user-service实例的ip地址和端口？\n\n- 有多个user-service实例地址，order-service调用时该如何选择？\n\n- order-service如何得知某个user-service实例是否依然健康，是不是已经宕机？\n\n## 3.1.Eureka的结构和作用\n\n这些问题都需要利用SpringCloud中的注册中心来解决，其中最广为人知的注册中心就是Eureka，其结构如下：\n\n![image-20210713220104956](https://presenter.oss-cn-shanghai.aliyuncs.com/wordpress/image-20210713220104956.png)\n\n回答之前的各个问题。\n\n问题1：order-service如何得知user-service实例地址？\n\n获取地址信息的流程如下：\n\n- user-service服务实例启动后，将自己的信息注册到eureka-server（Eureka服务端）。这个叫服务注册\n\n- eureka-server保存服务名称到服务实例地址列表的映射关系\n\n- order-service根据服务名称，拉取实例地址列表。这个叫服务发现或服务拉取\n\n问题2：order-service如何从多个user-service实例中选择具体的实例？\n\n- order-service从实例列表中利用负载均衡算法选中一个实例地址\n\n- 向该实例地址发起远程调用\n\n问题3：order-service如何得知某个user-service实例是否依然健康，是不是已经宕机？\n\n- user-service会每隔一段时间（默认30秒）向eureka-server发起请求，报告自己状态，称为心跳\n\n- 当超过一定时间没有发送心跳时，eureka-server会认为微服务实例故障，将该实例从服务列表中剔除\n\n- order-service拉取服务时，就能将故障实例排除了\n\n> 注意：一个微服务，既可以是服务提供者，又可以是服务消费者，因此eureka将服务注册、服务发现等功能统一封装到了eureka-client端\n\n因此，接下来我们动手实践的步骤包括：\n\n![image-20210713220509769](https://presenter.oss-cn-shanghai.aliyuncs.com/wordpress/image-20210713220509769.png)\n\n## 3.2.搭建eureka-server\n\n首先大家注册中心服务端：eureka-server，这必须是一个独立的微服务\n\n### 3.2.1.创建eureka-server服务\n\n在cloud-demo父工程下，创建一个子模块：\n\n![image-20210713220605881](https://presenter.oss-cn-shanghai.aliyuncs.com/wordpress/image-20210713220605881.png)\n\n填写模块信息：\n\n![image-20210713220857396](https://presenter.oss-cn-shanghai.aliyuncs.com/wordpress/image-20210713220857396.png)\n\n然后填写服务信息：\n\n![image-20210713221339022](https://presenter.oss-cn-shanghai.aliyuncs.com/wordpress/image-20210713221339022.png)\n\n### 3.2.2.引入eureka依赖\n\n引入SpringCloud为eureka提供的starter依赖：\n\n<dependency>  \n    <groupId>org.springframework.cloud</groupId>  \n    <artifactId>spring-cloud-starter-netflix-eureka-server</artifactId>  \n</dependency>\n\n### 3.2.3.编写启动类\n\n给eureka-server服务编写一个启动类，一定要添加一个@EnableEurekaServer注解，开启eureka的注册中心功能：\n\npackage cn.itcast.eureka;  \n​  \nimport org.springframework.boot.SpringApplication;  \nimport org.springframework.boot.autoconfigure.SpringBootApplication;  \nimport org.springframework.cloud.netflix.eureka.server.EnableEurekaServer;  \n​  \n@SpringBootApplication  \n@EnableEurekaServer  \npublic class EurekaApplication {  \n    public static void main(String\\[\\] args) {  \n        SpringApplication.run(EurekaApplication.class, args);  \n    }  \n}\n\n### 3.2.4.编写配置文件\n\n编写一个application.yml文件，内容如下：\n\nserver:  \n  port: 10086  \nspring:  \n  application:  \n    name: eureka-server  \neureka:  \n  client:  \n    service-url:   \n      defaultZone: http://127.0.0.1:10086/eureka\n\n### 3.2.5.启动服务\n\n启动微服务，然后在浏览器访问：[http://127.0.0.1:10086](http://127.0.0.1:10086/)\n\n看到下面结果应该是成功了：\n\n![image-20210713222157190](https://presenter.oss-cn-shanghai.aliyuncs.com/wordpress/image-20210713222157190.png)\n\n## 3.3.服务注册\n\n下面，我们将user-service注册到eureka-server中去。\n\n### 1）引入依赖\n\n在user-service的pom文件中，引入下面的eureka-client依赖：\n\n<dependency>  \n    <groupId>org.springframework.cloud</groupId>  \n    <artifactId>spring-cloud-starter-netflix-eureka-client</artifactId>  \n</dependency>\n\n### 2）配置文件\n\n在user-service中，修改application.yml文件，添加服务名称、eureka地址：\n\nspring:  \n  application:  \n    name: userservice  \neureka:  \n  client:  \n    service-url:  \n      defaultZone: http://127.0.0.1:10086/eureka\n\n### 3）启动多个user-service实例\n\n为了演示一个服务有多个实例的场景，我们添加一个SpringBoot的启动配置，再启动一个user-service。\n\n首先，复制原来的user-service启动配置：\n\n![image-20210713222656562](https://presenter.oss-cn-shanghai.aliyuncs.com/wordpress/image-20210713222656562.png)\n\n然后，在弹出的窗口中，填写信息：\n\n![image-20210713222757702](https://presenter.oss-cn-shanghai.aliyuncs.com/wordpress/image-20210713222757702.png)\n\n现在，SpringBoot窗口会出现两个user-service启动配置：\n\n![image-20210713222841951](https://presenter.oss-cn-shanghai.aliyuncs.com/wordpress/image-20210713222841951.png)\n\n不过，第一个是8081端口，第二个是8082端口。\n\n启动两个user-service实例：\n\n![image-20210713223041491](https://presenter.oss-cn-shanghai.aliyuncs.com/wordpress/image-20210713223041491.png)\n\n查看eureka-server管理页面：\n\n![image-20210713223150650](https://presenter.oss-cn-shanghai.aliyuncs.com/wordpress/image-20210713223150650.png)\n\n## 3.4.服务发现\n\n下面，我们将order-service的逻辑修改：向eureka-server拉取user-service的信息，实现服务发现。\n\n### 1）引入依赖\n\n之前说过，服务发现、服务注册统一都封装在eureka-client依赖，因此这一步与服务注册时一致。\n\n在order-service的pom文件中，引入下面的eureka-client依赖：\n\n<dependency>  \n    <groupId>org.springframework.cloud</groupId>  \n    <artifactId>spring-cloud-starter-netflix-eureka-client</artifactId>  \n</dependency>\n\n### 2）配置文件\n\n服务发现也需要知道eureka地址，因此第二步与服务注册一致，都是配置eureka信息：\n\n在order-service中，修改application.yml文件，添加服务名称、eureka地址：\n\nspring:  \n  application:  \n    name: orderservice  \neureka:  \n  client:  \n    service-url:  \n      defaultZone: http://127.0.0.1:10086/eureka\n\n### 3）服务拉取和负载均衡\n\n最后，我们要去eureka-server中拉取user-service服务的实例列表，并且实现负载均衡。\n\n不过这些动作不用我们去做，只需要添加一些注解即可。\n\n在order-service的OrderApplication中，给RestTemplate这个Bean添加一个@LoadBalanced注解：\n\n![image-20210713224049419](https://presenter.oss-cn-shanghai.aliyuncs.com/wordpress/image-20210713224049419.png)\n\n修改order-service服务中的cn.itcast.order.service包下的OrderService类中的queryOrderById方法。修改访问的url路径，用服务名代替ip、端口：\n\n![image-20210713224245731](https://presenter.oss-cn-shanghai.aliyuncs.com/wordpress/image-20210713224245731.png)\n\nspring会自动帮助我们从eureka-server端，根据userservice这个服务名称，获取实例列表，而后完成负载均衡。\n\n# 4.Ribbon负载均衡\n\n上一节中，我们添加了@LoadBalanced注解，即可实现负载均衡功能，这是什么原理呢？\n\n## 4.1.负载均衡原理\n\nSpringCloud底层其实是利用了一个名为Ribbon的组件，来实现负载均衡功能的。\n\n![image-20210713224517686](https://presenter.oss-cn-shanghai.aliyuncs.com/wordpress/image-20210713224517686.png)\n\n那么我们发出的请求明明是[http://userservice/user/1](http://userservice/user/1)，怎么变成了[http://localhost:8081](http://localhost:8081/)的呢？\n\n## 4.2.源码跟踪\n\n为什么我们只输入了service名称就可以访问了呢？之前还要获取ip和端口。\n\n显然有人帮我们根据service名称，获取到了服务实例的ip和端口。它就是`LoadBalancerInterceptor`，这个类会在对RestTemplate的请求进行拦截，然后从Eureka根据服务id获取服务列表，随后利用负载均衡算法得到真实的服务地址信息，替换服务id。\n\n我们进行源码跟踪：\n\n### 1）LoadBalancerIntercepor\n\n![1525620483637](https://presenter.oss-cn-shanghai.aliyuncs.com/wordpress/1525620483637.png)\n\n可以看到这里的intercept方法，拦截了用户的HttpRequest请求，然后做了几件事：\n\n- `request.getURI()`：获取请求uri，本例中就是 [http://user-service/user/8](http://user-service/user/8)\n\n- `originalUri.getHost()`：获取uri路径的主机名，其实就是服务id，`user-service`\n\n- `this.loadBalancer.execute()`：处理服务id，和用户请求。\n\n这里的`this.loadBalancer`是`LoadBalancerClient`类型，我们继续跟入。\n\n### 2）LoadBalancerClient\n\n继续跟入execute方法：\n\n![1525620787090](https://presenter.oss-cn-shanghai.aliyuncs.com/wordpress/1525620787090.png)\n\n代码是这样的：\n\n- getLoadBalancer(serviceId)：根据服务id获取ILoadBalancer，而ILoadBalancer会拿着服务id去eureka中获取服务列表并保存起来。\n\n- getServer(loadBalancer)：利用内置的负载均衡算法，从服务列表中选择一个。本例中，可以看到获取了8082端口的服务\n\n放行后，再次访问并跟踪，发现获取的是8081：\n\n![1525620835911](https://presenter.oss-cn-shanghai.aliyuncs.com/wordpress/1525620835911.png)\n\n果然实现了负载均衡。\n\n### 3）负载均衡策略IRule\n\n在刚才的代码中，可以看到获取服务使通过一个`getServer`方法来做负载均衡:\n\n![1525620835911](https://presenter.oss-cn-shanghai.aliyuncs.com/wordpress/1525620835911.png)\n\n我们继续跟入：\n\n![1544361421671](https://presenter.oss-cn-shanghai.aliyuncs.com/wordpress/1544361421671.png)\n\n继续跟踪源码chooseServer方法，发现这么一段代码：\n\n![1525622652849](https://presenter.oss-cn-shanghai.aliyuncs.com/wordpress/1525622652849.png)\n\n我们看看这个rule是谁：\n\n![1525622699666](https://presenter.oss-cn-shanghai.aliyuncs.com/wordpress/1525622699666.png)\n\n这里的rule默认值是一个`RoundRobinRule`，看类的介绍：\n\n![1525622754316](https://presenter.oss-cn-shanghai.aliyuncs.com/wordpress/1525622754316.png)\n\n这不就是轮询的意思嘛。\n\n到这里，整个负载均衡的流程我们就清楚了。\n\n### 4）总结\n\nSpringCloudRibbon的底层采用了一个拦截器，拦截了RestTemplate发出的请求，对地址做了修改。用一幅图来总结一下：\n\n![image-20210713224724673](https://presenter.oss-cn-shanghai.aliyuncs.com/wordpress/image-20210713224724673.png)\n\n基本流程如下：\n\n- 拦截我们的RestTemplate请求[http://userservice/user/1](http://userservice/user/1)\n\n- RibbonLoadBalancerClient会从请求url中获取服务名称，也就是user-service\n\n- DynamicServerListLoadBalancer根据user-service到eureka拉取服务列表\n\n- eureka返回列表，localhost:8081、localhost:8082\n\n- IRule利用内置负载均衡规则，从列表中选择一个，例如localhost:8081\n\n- RibbonLoadBalancerClient修改请求地址，用localhost:8081替代userservice，得到[http://localhost:8081/user/1](http://localhost:8081/user/1)，发起真实请求\n\n## 4.3.负载均衡策略\n\n### 4.3.1.负载均衡策略\n\n负载均衡的规则都定义在IRule接口中，而IRule有很多不同的实现类：\n\n![image-20210713225653000](https://presenter.oss-cn-shanghai.aliyuncs.com/wordpress/image-20210713225653000.png)\n\n不同规则的含义如下：\n\n| **内置负载均衡规则类** | **规则描述** |\n| --- | --- |\n| RoundRobinRule | 简单轮询服务列表来选择服务器。它是Ribbon默认的负载均衡规则。 |\n| AvailabilityFilteringRule | 对以下两种服务器进行忽略： （1）在默认情况下，这台服务器如果3次连接失败，这台服务器就会被设置为“短路”状态。短路状态将持续30秒，如果再次连接失败，短路的持续时间就会几何级地增加。 （2）并发数过高的服务器。如果一个服务器的并发连接数过高，配置了AvailabilityFilteringRule规则的客户端也会将其忽略。并发连接数的上限，可以由客户端的<clientName>.<clientConfigNameSpace>.ActiveConnectionsLimit属性进行配置。 |\n| WeightedResponseTimeRule | 为每一个服务器赋予一个权重值。服务器响应时间越长，这个服务器的权重就越小。这个规则会随机选择服务器，这个权重值会影响服务器的选择。 |\n| **ZoneAvoidanceRule** | 以区域可用的服务器为基础进行服务器的选择。使用Zone对服务器进行分类，这个Zone可以理解为一个机房、一个机架等。而后再对Zone内的多个服务做轮询。 |\n| BestAvailableRule | 忽略那些短路的服务器，并选择并发数较低的服务器。 |\n| RandomRule | 随机选择一个可用的服务器。 |\n| RetryRule | 重试机制的选择逻辑 |\n\n默认的实现就是ZoneAvoidanceRule，是一种轮询方案\n\n### 4.3.2.自定义负载均衡策略\n\n通过定义IRule实现可以修改负载均衡规则，有两种方式：\n\n1. 代码方式：在order-service中的OrderApplication类中，定义一个新的IRule：\n\n@Bean  \npublic IRule randomRule(){  \n    return new RandomRule();  \n}\n\n2. 配置文件方式：在order-service的application.yml文件中，添加新的配置也可以修改规则：\n\nuserservice: # 给某个微服务配置负载均衡规则，这里是userservice服务  \n  ribbon:  \n    NFLoadBalancerRuleClassName: com.netflix.loadbalancer.RandomRule # 负载均衡规则 \n\n> **注意**，一般用默认的负载均衡规则，不做修改。\n\n## 4.4.饥饿加载\n\nRibbon默认是采用懒加载，即第一次访问时才会去创建LoadBalanceClient，请求时间会很长。\n\n而饥饿加载则会在项目启动时创建，降低第一次访问的耗时，通过下面配置开启饥饿加载：\n\nribbon:  \n  eager-load:  \n    enabled: true  \n    clients: userservice\n\n# 5.Nacos注册中心\n\n国内公司一般都推崇阿里巴巴的技术，比如注册中心，SpringCloudAlibaba也推出了一个名为Nacos的注册中心。\n\n## 5.1.认识和安装Nacos\n\n[Nacos](https://nacos.io/)是阿里巴巴的产品，现在是[SpringCloud](https://spring.io/projects/spring-cloud)中的一个组件。相比[Eureka](https://github.com/Netflix/eureka)功能更加丰富，在国内受欢迎程度较高。\n\n![image-20210713230444308](https://presenter.oss-cn-shanghai.aliyuncs.com/wordpress/image-20210713230444308.png)\n\n安装方式可以参考课前资料《Nacos安装指南.md》\n\n## 5.2.服务注册到nacos\n\nNacos是SpringCloudAlibaba的组件，而SpringCloudAlibaba也遵循SpringCloud中定义的服务注册、服务发现规范。因此使用Nacos和使用Eureka对于微服务来说，并没有太大区别。\n\n主要差异在于：\n\n- 依赖不同\n\n- 服务地址不同\n\n### 1）引入依赖\n\n在cloud-demo父工程的pom文件中的`<dependencyManagement>`中引入SpringCloudAlibaba的依赖：\n\n<dependency>  \n    <groupId>com.alibaba.cloud</groupId>  \n    <artifactId>spring-cloud-alibaba-dependencies</artifactId>  \n    <version>2.2.6.RELEASE</version>  \n    <type>pom</type>  \n    <scope>import</scope>  \n</dependency>\n\n然后在user-service和order-service中的pom文件中引入nacos-discovery依赖：\n\n<dependency>  \n    <groupId>com.alibaba.cloud</groupId>  \n    <artifactId>spring-cloud-starter-alibaba-nacos-discovery</artifactId>  \n</dependency>\n\n> **注意**：不要忘了注释掉eureka的依赖。\n\n### 2）配置nacos地址\n\n在user-service和order-service的application.yml中添加nacos地址：\n\nspring:  \n  cloud:  \n    nacos:  \n      server-addr: localhost:8848\n\n> **注意**：不要忘了注释掉eureka的地址\n\n### 3）重启\n\n重启微服务后，登录nacos管理页面，可以看到微服务信息：\n\n![image-20210713231439607](https://presenter.oss-cn-shanghai.aliyuncs.com/wordpress/image-20210713231439607.png)\n\n## 5.3.服务分级存储模型\n\n一个**服务**可以有多个**实例**，例如我们的user-service，可以有:\n\n- 127.0.0.1:8081\n\n- 127.0.0.1:8082\n\n- 127.0.0.1:8083\n\n假如这些实例分布于全国各地的不同机房，例如：\n\n- 127.0.0.1:8081，在上海机房\n\n- 127.0.0.1:8082，在上海机房\n\n- 127.0.0.1:8083，在杭州机房\n\nNacos就将同一机房内的实例 划分为一个**集群**。\n\n也就是说，user-service是服务，一个服务可以包含多个集群，如杭州、上海，每个集群下可以有多个实例，形成分级模型，如图：\n\n![image-20210713232522531](https://presenter.oss-cn-shanghai.aliyuncs.com/wordpress/image-20210713232522531.png)\n\n微服务互相访问时，应该尽可能访问同集群实例，因为本地访问速度更快。当本集群内不可用时，才访问其它集群。例如：\n\n![image-20210713232658928](https://presenter.oss-cn-shanghai.aliyuncs.com/wordpress/image-20210713232658928.png)\n\n杭州机房内的order-service应该优先访问同机房的user-service。\n\n### 5.3.1.给user-service配置集群\n\n修改user-service的application.yml文件，添加集群配置：\n\nspring:  \n  cloud:  \n    nacos:  \n      server-addr: localhost:8848  \n      discovery:  \n        cluster-name: HZ # 集群名称\n\n重启两个user-service实例后，我们可以在nacos控制台看到下面结果：\n\n![image-20210713232916215](https://presenter.oss-cn-shanghai.aliyuncs.com/wordpress/image-20210713232916215.png)\n\n我们再次复制一个user-service启动配置，添加属性：\n\n\\-Dserver.port=8083 -Dspring.cloud.nacos.discovery.cluster-name=SH\n\n配置如图所示：\n\n![image-20210713233528982](https://presenter.oss-cn-shanghai.aliyuncs.com/wordpress/image-20210713233528982.png)\n\n启动UserApplication3后再次查看nacos控制台：\n\n![image-20210713233727923](https://presenter.oss-cn-shanghai.aliyuncs.com/wordpress/image-20210713233727923.png)\n\n### 5.3.2.同集群优先的负载均衡\n\n默认的`ZoneAvoidanceRule`并不能实现根据同集群优先来实现负载均衡。\n\n因此Nacos中提供了一个`NacosRule`的实现，可以优先从同集群中挑选实例。\n\n1）给order-service配置集群信息\n\n修改order-service的application.yml文件，添加集群配置：\n\nspring:  \n  cloud:  \n    nacos:  \n      server-addr: localhost:8848  \n      discovery:  \n        cluster-name: HZ # 集群名称\n\n2）修改负载均衡规则\n\n修改order-service的application.yml文件，修改负载均衡规则：\n\nuserservice:  \n  ribbon:  \n    NFLoadBalancerRuleClassName: com.alibaba.cloud.nacos.ribbon.NacosRule # 负载均衡规则 \n\n## 5.4.权重配置\n\n实际部署中会出现这样的场景：\n\n服务器设备性能有差异，部分实例所在机器性能较好，另一些较差，我们希望性能好的机器承担更多的用户请求。\n\n但默认情况下NacosRule是同集群内随机挑选，不会考虑机器的性能问题。\n\n因此，Nacos提供了权重配置来控制访问频率，权重越大则访问频率越高。\n\n在nacos控制台，找到user-service的实例列表，点击编辑，即可修改权重：\n\n![image-20210713235133225](https://presenter.oss-cn-shanghai.aliyuncs.com/wordpress/image-20210713235133225.png)\n\n在弹出的编辑窗口，修改权重：\n\n> **注意**：如果权重修改为0，则该实例永远不会被访问\n\n## 5.5.环境隔离\n\nNacos提供了namespace来实现环境隔离功能。\n\n- nacos中可以有多个namespace\n\n- namespace下可以有group、service等\n\n- 不同namespace之间相互隔离，例如不同namespace的服务互相不可见\n\n![image-20210714000101516](https://presenter.oss-cn-shanghai.aliyuncs.com/wordpress/image-20210714000101516.png)\n\n### 5.5.1.创建namespace\n\n默认情况下，所有service、data、group都在同一个namespace，名为public：\n\n![image-20210714000414781](https://presenter.oss-cn-shanghai.aliyuncs.com/wordpress/image-20210714000414781.png)\n\n我们可以点击页面新增按钮，添加一个namespace：\n\n![image-20210714000440143](https://presenter.oss-cn-shanghai.aliyuncs.com/wordpress/image-20210714000440143.png)\n\n然后，填写表单：\n\n![image-20210714000505928](https://presenter.oss-cn-shanghai.aliyuncs.com/wordpress/image-20210714000505928.png)\n\n就能在页面看到一个新的namespace：\n\n![image-20210714000522913](https://presenter.oss-cn-shanghai.aliyuncs.com/wordpress/image-20210714000522913.png)\n\n### 5.5.2.给微服务配置namespace\n\n给微服务配置namespace只能通过修改配置来实现。\n\n例如，修改order-service的application.yml文件：\n\nspring:  \n  cloud:  \n    nacos:  \n      server-addr: localhost:8848  \n      discovery:  \n        cluster-name: HZ  \n        namespace: 492a7d5d-237b-46a1-a99a-fa8e98e4b0f9 # 命名空间，填ID\n\n重启order-service后，访问控制台，可以看到下面的结果：\n\n![image-20210714000830703](https://presenter.oss-cn-shanghai.aliyuncs.com/wordpress/image-20210714000830703.png)\n\n![image-20210714000837140](https://presenter.oss-cn-shanghai.aliyuncs.com/wordpress/image-20210714000837140.png)\n\n此时访问order-service，因为namespace不同，会导致找不到userservice，控制台会报错：\n\n![image-20210714000941256](https://presenter.oss-cn-shanghai.aliyuncs.com/wordpress/image-20210714000941256.png)\n\n## 5.6.Nacos与Eureka的区别\n\nNacos的服务实例分为两种l类型：\n\n- 临时实例：如果实例宕机超过一定时间，会从服务列表剔除，默认的类型。\n\n- 非临时实例：如果实例宕机，不会从服务列表剔除，也可以叫永久实例。\n\n配置一个服务实例为永久实例：\n\nspring:  \n  cloud:  \n    nacos:  \n      discovery:  \n        ephemeral: false # 设置为非临时实例\n\nNacos和Eureka整体结构类似，服务注册、服务拉取、心跳等待，但是也存在一些差异：\n\n![image-20210714001728017](https://presenter.oss-cn-shanghai.aliyuncs.com/wordpress/image-20210714001728017.png)\n\n- Nacos与eureka的共同点\n    - 都支持服务注册和服务拉取\n    \n    - 都支持服务提供者心跳方式做健康检测\n\n- Nacos与Eureka的区别\n    - Nacos支持服务端主动检测提供者状态：临时实例采用心跳模式，非临时实例采用主动检测模式\n    \n    - 临时实例心跳不正常会被剔除，非临时实例则不会被剔除\n    \n    - Nacos支持服务列表变更的消息推送模式，服务列表更新更及时\n    \n    - Nacos集群默认采用AP方式，当集群中存在非临时实例时，采用CP模式；Eureka采用AP方式\n","tags":["springcloud"],"categories":["springcloud"]},{"title":"十大经典排序算法","url":"/2022/12/20/十大经典排序算法/","content":"\n### 0.算法复杂度\n\n![img](https://presenter.oss-cn-shanghai.aliyuncs.com/image/20210428140150.png)\n\n**相关概念：**\n\n- **稳定**：如果a原本在b前面，而a=b，排序之后a仍然在b的前面。\n\n- **不稳定**：如果a原本在b的前面，而a=b，排序之后 a 可能会出现在 b 的后面。\n\n- **时间复杂度**：对排序数据的总的操作次数。反映当n变化时，操作次数呈现什么规律。\n\n- **空间复杂度：**是指算法在计算机\n\n### 1.冒泡排序（Bubble Sort）\n\n**1.1算法描述**\n\n- 比较相邻的元素。如果第一个比第二个大，就交换它们两个；\n\n- 对每一对相邻元素作同样的工作，从开始第一对到结尾的最后一对，这样在最后的元素应该会是最大的数；\n\n- 针对所有的元素重复以上的步骤，除了最后一个；\n\n- 重复步骤1~3，直到排序完成\n\n**1.2 动画演示**\n\n![img](https://presenter.oss-cn-shanghai.aliyuncs.com/image/20210428140201.gif)\n\n**1.3 代码实现**\n\n```\nfunction bubbleSort(arr) {    var len = arr.length;    for (var i = 0; i < len - 1; i++) {//一共需要len-1次循环，每次循环就是找出最大的数        for (var j = 0; j < len - 1 - i; j++) {//从动画中看出只需要做len-1-i次            if (arr[j] > arr[j+1]) {        // 相邻元素两两对比                var temp = arr[j+1];        // 元素交换                arr[j+1] = arr[j];                arr[j] = temp;            }        }    }    return arr;}\n```\n\n### 2.选择排序（Selection Sort）\n\n**2.1算法描述**\n\nn个记录的直接选择排序可经过n-1趟直接选择排序得到有序结果。具体算法描述如下：\n\n- 初始状态：无序区为R\\[1..n\\]，有序区为空；\n\n- 第i趟排序(i=1,2,3…n-1)开始时，当前有序区和无序区分别为R\\[1..i-1\\]和R(i..n）。该趟排序从当前无序区中-选出关键字最小的记录 R\\[k\\]，将它与无序区的第1个记录R交换，使R\\[1..i\\]和R\\[i+1..n)分别变为记录个数增加1个的新有序区和记录个数减少1个的新无序区；\n\n- n-1趟结束，数组有序化了。\n\n**2.2动图演示**\n\n![img](https://presenter.oss-cn-shanghai.aliyuncs.com/image/20210428140211.gif)\n\n**2.3代码实现**\n\n```\nfunction selectionSort(arr) {    var len = arr.length;    var minIndex, temp;    for (var i = 0; i < len - 1; i++) {        minIndex = i;//无序部分的第一个        for (var j = i + 1; j < len; j++) {            if (arr[j] < arr[minIndex]) {     // 如果第j个比第一个小                minIndex = j;                 // 将最小数的索引保存            }     //一轮下来找出最小的数        }        //将最小的数和第一个交换位置        temp = arr[i];        arr[i] = arr[minIndex];        arr[minIndex] = temp;    }    return arr;} \n```\n\n### 3.插入排序\n\n**3.1算法描述**\n\n- 从第一个元素开始，该元素可以认为已经被排序；\n\n- 取出下一个元素，在已经排序的元素序列中从后向前扫描；\n\n- 如果该元素（已排序）大于新元素，将该元素移到下一位置；\n\n- 重复步骤3，直到找到已排序的元素小于或者等于新元素的位置；\n\n- 将新元素插入到该位置后；\n\n- 重复步骤2~5。\n\n**3.2动图演示**\n\n![](https://presenter.oss-cn-shanghai.aliyuncs.com/wordpress/849589-20171015225645277-1151100000.gif)\n\n**3.3代码实现**\n\n```\nfunction insertionSort(arr) {    var len = arr.length;    var preIndex, current;    for (var i = 1; i < len; i++) {        preIndex = i - 1;        current = arr[i];        //只要arr[preIndex]<=current就说明找到了位置        while (preIndex >= 0 && arr[preIndex] > current) {            arr[preIndex + 1] = arr[preIndex];//不匹配的数往后移一位            preIndex--; //向前找        }        arr[preIndex + 1] = current;    }    return arr;}\n```\n\n### 4.希尔排序（Shell Sort）\n\n**4.1算法描述**\n\n先将整个待排序的记录序列分割成为若干子序列分别进行直接插入排序，具体算法描述：\n\n- 选择一个增量序列t1，t2，…，tk，其中ti>tj，tk=1；\n\n- 按增量序列个数k，对序列进行k 趟排序；\n\n- 每趟排序，根据对应的增量ti，将待排序列分割成若干长度为m 的子序列，分别对各子表进行直接插入排序。仅增量因子为1 时，整个序列作为一个表来处理，表长度即为整个序列的长度。\n\n**4.2动图演示**\n\n![img](https://presenter.oss-cn-shanghai.aliyuncs.com/image/20210428140233.gif)\n\n**4.3代码实现**\n\n```\nfunction shellSort(arr) {    var len = arr.length;    for (var gap = Math.floor(len / 2); gap > 0; gap = Math.floor(gap / 2)) {        // 注意：这里和动图演示的不一样，动图是分组执行，实际操作是多个分组交替执行        for (var i = gap; i < len; i++) {            var j = i;            var current = arr[i];            while (j - gap >= 0 && current < arr[j - gap]) {                 arr[j] = arr[j - gap];                 j = j - gap;            }            arr[j] = current;        }    }    return arr;}\n```\n\n### 5.归并排序（Merge sort）\n\n**5.1算法描述**\n\n- 把长度为n的输入序列分成两个长度为n/2的子序列；\n\n- 对这两个子序列分别采用归并排序；\n\n- 将两个排序好的子序列合并成一个最终的排序序列。\n\n**5.2动图演示**\n\n![img](https://presenter.oss-cn-shanghai.aliyuncs.com/image/20210428140243.gif)\n\n**5.3代码实现**\n\n```\nfunction mergeSort(arr) {    var len = arr.length;    if (len < 2) {        return arr;    }    var middle = Math.floor(len / 2),        left = arr.slice(0, middle),        right = arr.slice(middle);    return merge(mergeSort(left), mergeSort(right));} function merge(left, right) {    var result = [];     while (left.length>0 && right.length>0) {        if (left[0] <= right[0]) {            result.push(left.shift());        } else {            result.push(right.shift());        }    }     while (left.length)        result.push(left.shift());     while (right.length)        result.push(right.shift());     return result;}\n```\n\n### 6.快速排序（Quick Sort）\n\n**6.1算法描述**\n\n快速排序使用分治法来把一个串（list）分为两个子串（sub-lists）。具体算法描述如下：\n\n- 从数列中挑出一个元素，称为 “基准”（pivot）；\n\n- 重新排序数列，所有元素比基准值小的摆放在基准前面，所有元素比基准值大的摆在基准的后面（相同的数可以到任一边）。在这个分区退出之后，该基准就处于数列的中间位置。这个称为分区（partition）操作；\n\n- 递归地（recursive）把小于基准值元素的子数列和大于基准值元素的子数列排序。\n\n**6.2动图演示**\n\n![img](https://presenter.oss-cn-shanghai.aliyuncs.com/image/20210428140255.gif)\n\n**6.3代码演示**\n\n```\nfunction quickSort(arr, left, right) {    var len = arr.length,        partitionIndex,        left = typeof left != 'number' ? 0 : left,        right = typeof right != 'number' ? len - 1 : right;     if (left < right) {        partitionIndex = partition(arr, left, right);        quickSort(arr, left, partitionIndex-1);        quickSort(arr, partitionIndex+1, right);    }    return arr;} function partition(arr, left ,right) {     // 分区操作    var pivot = left,                      // 设定基准值（pivot）        index = pivot + 1;    for (var i = index; i <= right; i++) {        if (arr[i] < arr[pivot]) {            swap(arr, i, index);            index++;        }           }    swap(arr, pivot, index - 1);    return index-1;} function swap(arr, i, j) {    var temp = arr[i];    arr[i] = arr[j];    arr[j] = temp;}\n```\n\n### 7.堆排序（Heap Sort）\n\n**7.1算法描述**\n\n- 将初始待排序关键字序列(R1,R2….Rn)构建成大顶堆，此堆为初始的无序区；\n\n- 将堆顶元素R\\[1\\]与最后一个元素R\\[n\\]交换，此时得到新的无序区(R1,R2,……Rn-1)和新的有序区(Rn),且满足R\\[1,2…n-1\\]<=R\\[n\\]；\n\n- 由于交换后新的堆顶R\\[1\\]可能违反堆的性质，因此需要对当前无序区(R1,R2,……Rn-1)调整为新堆，然后再次将R\\[1\\]与无序区最后一个元素交换，得到新的无序区(R1,R2….Rn-2)和新的有序区(Rn-1,Rn)。不断重复此过程直到有序区的元素个数为n-1，则整个排序过程完成。\n\n**7.2 动图演示**\n\n![img](https://presenter.oss-cn-shanghai.aliyuncs.com/image/20210428140300.gif)\n\n**7.3代码实现**\n\n```\nvar len;    // 因为声明的多个函数都需要数据长度，所以把len设置成为全局变量 function buildMaxHeap(arr) {   // 建立大顶堆    len = arr.length;    for (var i = Math.floor(len/2); i >= 0; i--) {        heapify(arr, i);    }} function heapify(arr, i) {     // 堆调整    var left = 2 * i + 1,        right = 2 * i + 2,        largest = i;     if (left < len && arr[left] > arr[largest]) {        largest = left;    }     if (right < len && arr[right] > arr[largest]) {        largest = right;    }     if (largest != i) {        swap(arr, i, largest);        heapify(arr, largest);    }} function swap(arr, i, j) {    var temp = arr[i];    arr[i] = arr[j];    arr[j] = temp;} function heapSort(arr) {    buildMaxHeap(arr);     for (var i = arr.length - 1; i > 0; i--) {        swap(arr, 0, i);        len--;        heapify(arr, 0);    }    return arr;}\n```\n\n### 8.计数排序（Counting Sort）\n\n计数排序不是基于比较的排序算法，其核心在于将输入的数据值转化为键存储在额外开辟的数组空间中。 作为一种线性时间复杂度的排序，计数排序要求输入的数据必须是有确定范围的整数。\n\n**8.1 算法描述**\n\n- 找出待排序的数组中最大和最小的元素；\n\n- 统计数组中每个值为i的元素出现的次数，存入数组C的第i项；\n\n- 对所有的计数累加（从C中的第一个元素开始，每一项和前一项相加）；\n\n- 反向填充目标数组：将每个元素i放在新数组的第C(i)项，每放一个元素就将C(i)减去1。\n\n**8.2 动图演示**\n\n![img](https://presenter.oss-cn-shanghai.aliyuncs.com/image/20210428140308.gif)\n\n**8.3 代码实现**\n\n```\nfunction countingSort(arr, maxValue) {    var bucket = new Array(maxValue + 1),        sortedIndex = 0;        arrLen = arr.length,        bucketLen = maxValue + 1;     for (var i = 0; i < arrLen; i++) {        if (!bucket[arr[i]]) {            bucket[arr[i]] = 0;        }        bucket[arr[i]]++;    }     for (var j = 0; j < bucketLen; j++) {        while(bucket[j] > 0) {            arr[sortedIndex++] = j;            bucket[j]--;        }    }     return arr;}\n```\n\n### 9.桶排序（Bucket Sort）\n\n桶排序是计数排序的升级版。它利用了函数的映射关系，高效与否的关键就在于这个映射函数的确定。桶排序 (Bucket sort)的工作的原理：假设输入数据服从均匀分布，将数据分到有限数量的桶里，每个桶再分别排序（有可能再使用别的排序算法或是以递归方式继续使用桶排序进行排）。\n\n**9.1 算法描述**\n\n- 设置一个定量的数组当作空桶；\n\n- 遍历输入数据，并且把数据一个一个放到对应的桶里去；\n\n- 对每个不是空的桶进行排序；\n\n- 从不是空的桶里把排好序的数据拼接起来。\n\n**9.2 图片演示**\n\n![img](https://presenter.oss-cn-shanghai.aliyuncs.com/image/20210428140315.png)\n\n**9.3 代码实现**\n\n```\nfunction bucketSort(arr, bucketSize) {    if (arr.length === 0) {      return arr;    }     var i;    var minValue = arr[0];    var maxValue = arr[0];    for (i = 1; i < arr.length; i++) {      if (arr[i] < minValue) {          minValue = arr[i];                // 输入数据的最小值      } else if (arr[i] > maxValue) {          maxValue = arr[i];                // 输入数据的最大值      }    }     // 桶的初始化    var DEFAULT_BUCKET_SIZE = 5;            // 设置桶的默认数量为5    bucketSize = bucketSize || DEFAULT_BUCKET_SIZE;    var bucketCount = Math.floor((maxValue - minValue) / bucketSize) + 1;      var buckets = new Array(bucketCount);    for (i = 0; i < buckets.length; i++) {        buckets[i] = [];    }     // 利用映射函数将数据分配到各个桶中    for (i = 0; i < arr.length; i++) {        buckets[Math.floor((arr[i] - minValue) / bucketSize)].push(arr[i]);    }     arr.length = 0;    for (i = 0; i < buckets.length; i++) {        insertionSort(buckets[i]);                      // 对每个桶进行排序，这里使用了插入排序        for (var j = 0; j < buckets[i].length; j++) {            arr.push(buckets[i][j]);                             }    }     return arr;}\n```\n\n### 10.基数排序（Radix Sort）\n\n基数排序是按照低位先排序，然后收集；再按照高位排序，然后再收集；依次类推，直到最高位。有时候有些属性是有优先级顺序的，先按低优先级排序，再按高优先级排序。最后的次序就是高优先级高的在前，高优先级相同的低优先级高的在前。\n\n**10.1 算法描述**\n\n- 取得数组中的最大数，并取得位数；\n\n- arr为原始数组，从最低位开始取每个位组成radix数组；\n\n- 对radix进行计数排序（利用计数排序适用于小范围数的特点）；\n\n**10.2 动图演示**\n\n![img](https://presenter.oss-cn-shanghai.aliyuncs.com/image/20210428140320.gif)\n\n**10.3 代码实现**\n\n```\nvar counter = [];function radixSort(arr, maxDigit) {    var mod = 10;    var dev = 1;    for (var i = 0; i < maxDigit; i++, dev *= 10, mod *= 10) {        for(var j = 0; j < arr.length; j++) {            var bucket = parseInt((arr[j] % mod) / dev);            if(counter[bucket]==null) {                counter[bucket] = [];            }            counter[bucket].push(arr[j]);        }        var pos = 0;        for(var j = 0; j < counter.length; j++) {            var value = null;            if(counter[j]!=null) {                while ((value = counter[j].shift()) != null) {                      arr[pos++] = value;                }          }        }    }    return arr;}\n```\n\n**10.4 算法分析**\n\n基数排序基于分别排序，分别收集，所以是稳定的。但基数排序的性能比桶排序要略差，每一次关键字的桶分配都需要O(n)的时间复杂度，而且分配之后得到新的关键字序列又需要O(n)的时间复杂度。假如待排数据可以分为d个关键字，则基数排序的时间复杂度将是O(d\\*2n) ，当然d要远远小于n，因此基本上还是线性级别的。\n\n基数排序的空间复杂度为O(n+k)，其中k为桶的数量。一般来说n>>k，因此额外空间需要大概n个左右。\n","tags":["算法"],"categories":["算法"]},{"title":"英语16种时态","url":"/2022/11/11/英语16种时态/","content":"\n![](https://presenter.oss-cn-shanghai.aliyuncs.com/wordpress/v2-fa0458291392a1d09e5c5f78d5b0aa6e_720w.webp)\n\n### 1.一般现在时 （do/does; is/am/are）\n\n①表示现在的情况、状态和特征。\n\n例：He is a student.\n\n他是一个学生。\n\n② 表示经常性、习惯性动作。\n\n例：He always helps others.\n\n他总是帮助别人。\n\n③ 客观事实和普遍真理。\n\n例：The earth moves the sun.\n\n地球绕着太阳转。\n\n④ 表示一个按规定、计划或安排要发生的动作。（常用于列车、客车、飞机或轮船时刻表）\n\n例：The next train leaves at 3 o'clock this afternoon.  \n下一趟火车今天下午3点开车。\n\n⑤ 主将从现：在时间、条件和让步状语从句中经常用一般现在表示将的来事情。\n\n例：If it rains tomorrow, we will stay at home.\n\n如果明天下雨，我们会待在家里。\n"},{"title":"汇编语言DEBUG命令","url":"/2022/10/28/汇编语言debug命令/","content":"\n## R命令\n\n作用：观看和修改寄存器的值。后面跟通用寄存器可以修改寄存器的值（ax,bx,cx,dx)\n\n![](https://presenter.oss-cn-shanghai.aliyuncs.com/wordpress/image.png)\n\n## H命令\n\nH命令作用：计算两个十六进制数的和与差。第一个值为和，第二个值为差\n\n![](https://presenter.oss-cn-shanghai.aliyuncs.com/wordpress/image-1.png)\n\n## D命令\n\nD命令作用：显示内存区域的内容。后面跟内存地址可以查看指定内存后128字节。\n\n还可以d \\[起始位置\\] \\[结束位置\\]。指定区间\n\n还可以：d \\[起始位置\\] \\[L长度\\]，长度以L参数为标识。DEBUG从起始位置开始显示指定长度的内容。在提示符“-”下执行命令d ds:100 L10。观看命令执行结果。\n\n（2000：0 的意思是2000段，偏移为0，对应寄存器cs，ip）\n\n![](https://presenter.oss-cn-shanghai.aliyuncs.com/wordpress/image-2.png)\n\n## E命令\n\nE命令作用：改变内存单位的内容。  \nE命令的使用方式为：E \\[起始位置\\]。\n\nDEBUG首先显示\\[1000:100\\]的内容01.，这时可以修改该字节的值。如果还要修改后续的内容，可以按空格键继续。当要跳过某个字节时，可以按连续的两个空格跳到后一个字节去。\n\n![](https://presenter.oss-cn-shanghai.aliyuncs.com/wordpress/image-3.png)\n\n![](https://presenter.oss-cn-shanghai.aliyuncs.com/wordpress/image-4.png)\n\n## F命令\n\nF命令作用：使用指定的值填充指定内存区域中的地址。  \nF命令的使用方式为：F \\[范围\\] \\[填充列表\\]。  \n在提示符“-”下输入以下命令：F 1AF5:100 L20 1 2 3 4 5。执行命令D 1AF5:100观看命令执行结果。\n\n![](https://presenter.oss-cn-shanghai.aliyuncs.com/wordpress/image-5.png)\n\n说明：该命令是用字节序列01、02、03、04、05轮流填充从1AF5:100开始长度为20H的内存区域。  \n在提示符“-”下输入以下命令：F 1AF5:100 13F 41 42 43 44。\n\n![](https://presenter.oss-cn-shanghai.aliyuncs.com/wordpress/image-6.png)\n\n说明：该命令是用字节序列41、42、43、44轮流填充从1AF5:100开始一直到1AF5:13F的内存区域。\n\n## M命令\n\nM命令作用：将指定内存区域的数据复制到指定的地址去。  \nM命令的使用方式为：M \\[范围\\] \\[指定地址\\]。  \n在提示符“-”下输入以下命令：M 1AF5:100 13F 1AF5:140。执行命令D 1AF5:100观看命令执行结果。\n\n![](https://presenter.oss-cn-shanghai.aliyuncs.com/wordpress/image-7.png)\n\n## C命令\n\nC命令作用：将两块内存的内容进行比较。  \nC命令的使用方式为：C \\[范围\\] \\[指定地址\\]，意思就是将指定范围的内存区域与从指定地址开始的相同长度的内存区域逐个字节进行比较，列出不同的内容。  \n在提示符“-”下输入以下命令：C 1AF5:100 13F 1AF5:140。由于两块内容完全相同，所以命令执行后没有任何显示。  \n在提示符“-”下输入以下命令：C 1AF5:100 107 1AF5:180，比较的区域长度为8个字节。命令执行后列出比较结果不同的各个字节。  \n\n![](https://presenter.oss-cn-shanghai.aliyuncs.com/wordpress/image-8.png)\n\n## S命令\n\nS命令作用：在指定的内存区域中搜索指定的串。  \nS命令的使用方式为：S \\[范围\\] \\[指定串\\]。  \n在提示符“-”下输入以下命令：D 1AF5:100 11F。显示该区域的内存值。  \n在提示符“-”下输入以下命令：S 1AF5:100 11F 41 42 43 44。搜索该区域是否存在字节串41 42 43 44，并将搜索结果一一列出。\n\n![](https://presenter.oss-cn-shanghai.aliyuncs.com/wordpress/image-9.png)\n\n## A命令\n\nA命令作用：输入汇编指令。  \n以下的程序要在屏幕上显示“ABCD”四个字符。  \n首先用E命令将“ABCD” 四 个 字 符 预 先 放 在 内 存 C S : 200 处 ， 然 后 执 行 A 100 命 令 输 入 汇 编 程 序 代 码 ： M O V A X , C S M O V D S , A X M O V D X , 200 M O V A H , 9 I N T 21 I N T 20 （ 说 明 ： 前 两 行 汇 编 指 令 用 于 将 段 寄 存 器 C S 的 值 赋 给 段 寄 存 器 D S 。 第 三 到 第 五 行 汇 编 代 码 的 作 用 是 显 示 以 “ ”四个字符预先放在内存CS:200处，然后执行A100命令输入汇编程序代码： MOV AX,CS MOV DS,AX MOV DX,200 MOV AH,9 INT 21 INT 20 （说明：前两行汇编指令用于将段寄存器CS的值赋给段寄存器DS。第三到第五行汇编代码的作用是显示以“”四个字符预先放在内存CS:200处，然后执行A100命令输入汇编程序代码：MOVAX,CSMOVDS,AXMOVDX,200MOVAH,9INT21INT20（说明：前两行汇编指令用于将段寄存器CS的值赋给段寄存器DS。第三到第五行汇编代码的作用是显示以“”为结尾的字符串。最后一行用于结束程序。）  \n\n![](https://presenter.oss-cn-shanghai.aliyuncs.com/wordpress/image-10.png)\n\n## G命令\n\nG命令作用：执行汇编指令。  \nG命令的使用方法是：G \\[=起始地址\\] \\[断点地址\\]，意思是从起始地址开始执行到断点地址。如果不设置断点，则程序一直运行到中止指令才停止。  \n在设置完示例九的的内存数据并且输入完示例九的程序后运行这些汇编代码。在DEBUG中执行命令G=100，观看运行结果。  \n\n![](https://presenter.oss-cn-shanghai.aliyuncs.com/wordpress/image-11.png)\n\n汇编程序运行后在屏幕上显示出“ABCD”四个字符。  \n接下来在DEBUG中执行G=100 10B，意思是从地址CS：100开始，一直运行到CS：10B停止。观看运行结果。  \n命令执行后，不但显示出字符串“ABCD”，而且列出当前寄存器和标志位的值。\n\n![](https://presenter.oss-cn-shanghai.aliyuncs.com/wordpress/image-12.png)\n\n![](https://presenter.oss-cn-shanghai.aliyuncs.com/wordpress/image-13.png)\n\ng命令在loop中的使用：  \n使用loop循环时，如果要跳出循环执行后面的代码，可以先用u命令查看代码的偏移地址，在用g命令跳转到此偏移到此代码处，如下：\n\n![](https://presenter.oss-cn-shanghai.aliyuncs.com/wordpress/image-14.png)\n\n用u命令可以看到循环的命令位于0b40:000b，所以要跳出循环就用 g 000b 即可。\n\n## U命令\n\nU命令作用：对机器代码反汇编显示。  \nU命令的使用方法是：U \\[范围\\]。如果范围参数只输入了起始地址，则只对20H个字节的机器代码反汇编。执行命令U100，观看反汇编结果\n\n![](https://presenter.oss-cn-shanghai.aliyuncs.com/wordpress/image-15.png)\n\n执行命令U100 10B，观看反汇编结果。该命令的作用是对从100到10B的机器代码进行反汇编。\n\n![](https://presenter.oss-cn-shanghai.aliyuncs.com/wordpress/image-16.png)\n\n## N命令\n\nN命令作用：设置文件名，为将刚才编写的汇编程序存盘做准备。  \n以下的DEBUG命令序列作用将刚才的汇编程序存为磁盘的COM可执行程序。  \nD200 20F  \nU100 10C  \nN E:\\\\FIRST.COM  \nRCX  \n:110  \nW  \n第一和第二条命令的作用是检查一下刚才编写的汇编指令。第三条命令的作用是设置存盘文件名为E:\\\\FIRST.COM，第四条命令的作用是设置存盘文件大小为110H个字节。最后一条命令是将文件存盘。  \n\n![](https://presenter.oss-cn-shanghai.aliyuncs.com/wordpress/image-17.png)\n\n## W命令\n\nW命令作用：将文件或者特定扇区写入磁盘。  \n在示例“N命令的使用”中已经实验了如何使用W命令将文件存盘。  \n在没有很好地掌握汇编语言和磁盘文件系统前，暂时不要使用W命令写磁盘扇区，否则很容易损坏磁盘文件，甚至破坏整个磁盘的文件系统。\n\n## L命令\n\nL命令作用：从磁盘中将文件或扇区内容读入内存。  \n将文件调入内存必须先用DEBUG的N命令设定文件名。以下例子是将E:\\\\FIRST.COM读入内容。  \nN FIRST.COM  \nL  \n观看调入程序的汇编代码可以使用DEBUG的U命令，用U100观看调入的COM文件。\n\n![](https://presenter.oss-cn-shanghai.aliyuncs.com/wordpress/image-18.png)\n\n读取磁盘扇区的方式是：L \\[内存地址\\] \\[磁盘驱动器号\\] \\[起始扇区\\] \\[扇区数\\]。“内存地址”指定要在其中加载文件或扇区内容的内存位置，如果不指定“内存地址”的话，DEBUG将使用CS寄存器中的当前地址。“磁盘驱动器号”指定包含读取指定扇区的磁盘的驱动器，该值是数值型：0=A，1=B，2=C等。“起始扇区”指定要加载其内容的第一个扇区的十六进制数。“扇区数”指定要加载其内容的连续扇区的十六进制数。  \n只有要加载特定扇区的内容而不是加载文件时，才能使用\\[磁盘驱动器号\\] \\[起始扇区\\] \\[扇区数\\]参数。  \n例如：要将C盘第一扇区读取到内存DS:300的位置，相应的DEBUG命令为L DS:300 2 1 1。但是由于Windows操作系统对文件系统的保护，这条命令可能会被操作系统禁止运行。\n\n## T命令\n\nT命令作用：执行汇编程序，单步跟踪。  \nT命令的使用方式是T \\[=地址\\] \\[指令数\\]。如果忽略“地址”的话，T命令从CS:IP处开始运行。“指令数”是要单步执行的指令的数量。  \n以下示例对E:\\\\FIRST.COM进行单步跟踪。  \nN E:\\\\FIRST.COM  \nL  \nU100 10B  \nR  \nT=100  \nT\n\n![](https://presenter.oss-cn-shanghai.aliyuncs.com/wordpress/image-19.png)\n\n第一、二条命令是装入文件，第三条命令是列出程序反汇编代码，第四条命令是显示当前寄存器值，第五条命令是从CS:100处开始单步跟踪，第六条命令是继续跟踪后续的指令。\n\n## P命令\n\nP命令作用：执行汇编程序，单步跟踪。与T命令不同的是：P命令不会跟踪进入子程序或软中断。  \nP命令的使用方式与T命令的使用方式完全相同。\n\n![](https://presenter.oss-cn-shanghai.aliyuncs.com/wordpress/image-20.png)\n\np命令还可以用于结束本次循环，进入下一次循环。\n\n## I命令的使用\n\nI命令作用：从计算机输入端口读取数据并显示。  \nI命令的用法是I \\[端口地址\\]。例如从3F8号端口读取数据并显示的命令为：I 3F8。这里不对该命令做解释。\n\n## O命令的使用\n\nO命令作用：向计算机输出端口送出数据。  \nO命令的用法是O \\[端口地址\\] \\[字节值\\]。例如向278号端口发出数据20H的命令为：I 278 20。这里不对该命令做解释。\n\n## Q命令的使用\n\nQ命令的作用是退出DEBUG，回到DOS状态。\n","tags":["汇编"],"categories":["汇编"]},{"title":"Ubuntu常见问题","url":"/2022/09/07/ubuntu常见问题/","content":"\nubuntu版本 21.10\n\n## 1、无法更新apt源，报以下错误\n\n无法安全的用该源更新，所以禁用该源\n\n后面有 NO\\_PUBKEY \\[这里就是密钥\\]\n\n> sudo apt-key adv --keyserver keyserver.ubuntu.com --recv-key C1CF6E31E6BADE8868B172B4F42ED6FBAB17C654\n> \n> C1CF6E31E6BADE8868B172B4F42ED6FBAB17C654就是上面出现的密钥\n\n然后继续执行\n\n```\nsudo apt-get update   \nsudo apt-get upgrade\n```\n","tags":["ubuntu"],"categories":["系统类"]},{"title":"TypeScript常用总结","url":"/2022/08/03/typescript常用总结/","content":"\n## 1、TypeScript简介\n\n1. TypeScript是JavaScript的超集。\n\n3. 它对JS进行了扩展，向JS中引入了类型的概念，并添加了许多新的特性。\n\n5. TS代码需要通过编译器编译为JS，然后再交由JS解析器执行。\n\n7. TS完全兼容JS，换言之，任何的JS代码都可以直接当成JS使用。\n\n9. 相较于JS而言，TS拥有了静态类型，更加严格的语法，更强大的功能；TS可以在代码执行前就完成代码的检查，减小了运行时异常的出现的几率；TS代码可以编译为任意版本的JS代码，可有效解决不同JS运行环境的兼容问题；同样的功能，TS的代码量要大于JS，但由于TS的代码结构更加清晰，变量类型更加明确，在后期代码的维护中TS却远远胜于JS。\n\n## 2、基本类型\n\n| 类型 | 例子 | 描述 |\n| --- | --- | --- |\n| number | 1, -33, 2.5 | 任意数字 |\n| string | 'hi', \"hi\", `hi` | 任意字符串 |\n| boolean | true、false | 布尔值true或false |\n| 字面量 | 其本身 | 限制变量的值就是该字面量的值 |\n| any | \\* | 任意类型 |\n| unknown | \\* | 类型安全的any |\n| void | 空值（undefined） | 没有值（或undefined） |\n| never | 没有值 | 不能是任何值 |\n| object | {name:'孙悟空'} | 任意的JS对象 |\n| array | \\[1,2,3\\] | 任意JS数组 |\n| tuple | \\[4,5\\] | 元素，TS新增类型，固定长度数组 |\n| enum | enum{A, B} | 枚举，TS中新增类型 |\n\n### 自动类型判断\n\n- TS拥有自动的类型判断机制\n\n- 当对变量的声明和赋值是同时进行的，TS编译器会自动判断变量的类型\n\n- 所以如果你的变量的声明和赋值时同时进行的，可以省略掉类型声明\n\n- 类型：类型例子描述number1, -33, 2.5任意数字string'hi', \"hi\", `hi`任意字符串booleantrue、false布尔值true或false字面量其本身限制变量的值就是该字面量的值any\\*任意类型unknown\\*类型安全的anyvoid空值（undefined）没有值（或undefined）never没有值不能是任何值object{name:'孙悟空'}任意的JS对象array\\[1,2,3\\]任意JS数组tuple\\[4,5\\]元素，TS新增类型，固定长度数组enumenum{A, B}枚举，TS中新增类型\n\n#### **number**\n\n```\nlet decimal: number = 6;\nlet hex: number = 0xf00d;\nlet binary: number = 0b1010;\nlet octal: number = 0o744;\nlet big: bigint = 100n;\n```\n\n#### boolean\n\n`let isDone: boolean = false;`\n\n#### **string**\n\n```\nlet color: string = \"blue\";\ncolor = 'red';\n\nlet fullName: string = `Bob Bobbington`;\nlet age: number = 37;\nlet sentence: string = `Hello, my name is ${fullName}.\n​\nI'll be ${age + 1} years old next month.`;\n```\n\n#### **字面量**\n\n也可以使用字面量去指定变量的类型，通过字面量可以确定变量的取值范围\n\n```\nlet color: 'red' | 'blue' | 'black';let num: 1 | 2 | 3 | 4 | 5;\n```\n\n#### **any**\n\n```\nlet d: any = 4;d = 'hello';d = true;\n```\n\n#### **unknown**\n\n`let notSure: unknown = 4;   notSure = 'hello';`\n\n#### **void**\n\n```\nlet unusable: void = undefined;\n```\n\n#### **never**\n\n```\nfunction error(message: string): never { throw new Error(message);}\n```\n\n#### **object（没啥用）**\n\n```\nlet obj: object = {};\n```\n\n#### **array**\n\n`let list: number[] = [1, 2, 3];   let list: Array<number> = [1, 2, 3];`\n\n#### **tuple**\n\n```\nlet x: [string, number];\nx = [\"hello\", 10];\n```\n\n#### **enum**\n\n```\nenum Color { Red, Green, Blue,}let c: Color = Color.Green;​enum Color { Red = 1, Green, Blue,}let c: Color = Color.Green;​enum Color { Red = 1, Green = 2, Blue = 4,}let c: Color = Color.Green;\n```\n\n类型断言\n\n有些情况下，变量的类型对于我们来说是很明确，但是TS编译器却并不清楚，此时，可以通过类型断言来告诉编译器变量的类型，断言有两种形式：\n\n第一种\n\n```\nlet someValue: unknown = \"this is a string\";let strLength: number = (someValue as string).length;\n```\n\n第二种\n\n```\nlet someValue: unknown = \"this is a string\";let strLength: number = (<string>someValue).length;\n```\n\n## 3、类（class）\n\n要想面向对象，操作对象，首先便要拥有对象，那么下一个问题就是如何创建对象。要创建对象，必须要先定义类，所谓的类可以理解为对象的模型，程序中可以根据类创建指定类型的对象，举例来说：可以通过Person类来创建人的对象，通过Dog类创建狗的对象，通过Car类来创建汽车的对象，不同的类可以用来创建不同的对象。\n\n### 定义类\n\n```\nclass 类名 {\n\t属性名: 类型;\n\t\n\tconstructor(参数: 类型){\n\t\tthis.属性名 = 参数;\n\t}\n\t\n\t方法名(){\n\t\t....\n\t}\n\n}\n\n//实例\nclass Person{\n    name: string;\n    age: number;\n\n    constructor(name: string, age: number){\n        this.name = name;\n        this.age = age;\n    }\n\n    sayHello(){\n        console.log(`大家好，我是${this.name}`);\n    }\n}\n\n//使用\nconst p = new Person('孙悟空', 18);\np.sayHello();\n```\n","categories":["typescript","前端"]},{"title":"Vue向后端请求数据","url":"/2022/08/01/vue向后端请求数据/","content":"\n1、在config文件下的index.js文件的proxyTable:{ }中写入\n\n```\n      '/api': {\n        target: 'http://localhost:8088/',//此处可以换成自己需要的地址\n        changeOrigin: true,\n        pathRewrite: {\n          '^/api': '/'\n        }\n      }\n```\n\n2、在main.js中写入\n\n```\nVue.prototype.HOST = \"/api\"\n```\n\n3、需要调用接口的方法：如login（）方法\n\n```\nthis.$axios({\n              url: this.HOST + '调用的接口',\n              method: '方法：如post、get',\n              headers: {\n             //请求头，可以将token放在这里\n                'key':value\n              },\n              params: {\n             //需要传过去的参数\n                'key':value\n              }\n            }).then(res => {\n                //res为后端传回来的数据\n            })\n```\n","categories":["vue","前端"]},{"title":"Docker搭建常用应用","url":"/2022/06/09/docker搭建wordpress/","content":"\n### 更换我的阿里源\n\n```\nsudo mkdir -p /etc/docker\nsudo tee /etc/docker/daemon.json <<-'EOF'\n{\n  \"registry-mirrors\": [\"https://man823kr.mirror.aliyuncs.com\"]\n}\nEOF\nsudo systemctl daemon-reload\nsudo systemctl restart docker\n```\n\n### 数据库MYSQL和wordpress\n\n```\ndocker run -d --name db.wordpress -v /work/mysql:/var/lib/mysql -p 3306:3306 -e MYSQL_ROOT_PASSWORD=admin mysql:8.0\n```\n\n\\-v /work/mysql:/var/lib/mysql\n\n`run`: 启动一个容器  \n`-d`: 启动的容器在后台运行  \n`--name`: 给启动的容器起个名字，这里叫做 db.wordpress  \n`-e MYSQL_ROOT_PASSWORD`: 这里是设置 MySQL 的 root 密码  \nmysql`:5.7`: 指定 镜像和 版本\n\n启动 MySQL 容器后可执行 `docker logs -f db.wordpress` 查看容器运行日志。\n\n之后，启动一个 WordPress 容器，将 db.wordpress 容器连接到 WordPress 容器即可：\n\n```\ndocker run -d -p 8080:80 --name wordpress --link db.wordpress:mysql wordpress\n```\n\n\\-v /work/www/html:/var/www/htm\n\n`-p`: 这里是指定 WordPress 容器的访问端口，在浏览器中打开 [http://localhost:8080/](http://localhost:8080/) 即可预览 WordPress 站点  \n`--link`: 意思是将 db.wordpress 容器挂载到 mysql，这样 WordPress 就能通过 mysql 访问到 db.wordpress 数据库了\n\n### 启动redis\n\n```\ndocker run --restart=always --log-opt max-size=100m --log-opt max-file=2 -p 6379:6379 --name myredis -v /home/redis/myredis/myredis.conf:/etc/redis/redis.conf -v /home/redis/myredis/data:/data -d redis redis-server /etc/redis/redis.conf  --appendonly yes  --requirepass 000415\n```\n\n1. `--restart=always` 总是开机启动\n\n3. `--log`是日志方面的\n\n5. `-p 6379:6379` 将6379端口挂载出去\n\n7. `--name` 给这个容器取一个名字\n\n9. `-v` 数据卷挂载  \n    `- /home/redis/myredis/myredis.conf:/etc/redis/redis.conf` 这里是将 liunx 路径下的myredis.conf 和redis下的redis.conf 挂载在一起。  \n    `- /home/redis/myredis/data:/data` 这个同上\n\n11. `-d redis` 表示后台启动redis\n\n13. `redis-server /etc/redis/redis.conf` 以配置文件启动redis，加载容器内的conf文件，最终找到的是挂载的目录 `/etc/redis/redis.conf` 也**就是liunx下的/home/redis/myredis/myredis.conf**\n\n15. **–appendonly yes 开启redis 持久化**\n\n17. –requirepass 000415 设置密码\n","tags":["docker"],"categories":["docker"]},{"title":"ResultMap及分页","url":"/2022/06/09/resultmap及分页/","content":"\n# ResultMap\n\n## 查询为null问题\n\n**要解决的问题：属性名和字段名不一致**\n\n环境：新建一个项目，将之前的项目拷贝过来\n\n1、查看之前的数据库的字段名\n\n![](http://192.168.5.54:8001/wp-content/uploads/2022/06/image-22.png)\n\n2、Java中的实体类设计\n\n```\npublic class User {\n\n   private int id;  //id\n   private String name;   //姓名\n   private String password;   //密码和数据库不一样！\n   \n   //构造\n   //set/get\n   //toString()\n}\n```\n\n3、接口\n\n```\n//根据id查询用户\nUser selectUserById(int id);\n```\n\n4、mapper映射文件\n\n```\n<select id=\"selectUserById\" resultType=\"user\">\n  select * from user where id = #{id}\n</select>\n```\n\n5、测试\n\n```\n@Test\npublic void testSelectUserById() {\n   SqlSession session = MybatisUtils.getSession();  //获取SqlSession连接\n   UserMapper mapper = session.getMapper(UserMapper.class);\n   User user = mapper.selectUserById(1);\n   System.out.println(user);\n   session.close();\n}\n```\n\n**结果:**\n\n- User{id=1, name='狂神', password='null'}\n- 查询出来发现 password 为空 . 说明出现了问题！\n\n**分析：**\n\n- select \\* from user where id = #{id} 可以看做select  id,name,pwd  from user where id = #{id}\n- mybatis会根据这些查询的列名(会将列名转化为小写,数据库不区分大小写) , 去对应的实体类中查找相应列名的set方法设值 , 由于找不到setPwd() , 所以password返回null ; 【自动映射】\n\n## 解决方案\n\n方案一：为列名指定别名 , 别名和java实体类的属性名一致 .\n\n```\n<select id=\"selectUserById\" resultType=\"User\">\n  select id , name , pwd as password from user where id = #{id}\n</select>\n```\n\n**方案二：使用结果集映射->ResultMap** 【推荐】\n\n```\n<resultMap id=\"UserMap\" type=\"User\">\n   <!-- id为主键 -->\n   <id column=\"id\" property=\"id\"/>\n   <!-- column是数据库表的列名 , property是对应实体类的属性名 -->\n   <result column=\"name\" property=\"name\"/>\n   <result column=\"pwd\" property=\"password\"/>\n</resultMap>\n\n<select id=\"selectUserById\" resultMap=\"UserMap\">\n  select id , name , pwd from user where id = #{id}\n</select>\n```\n\n## ResultMap\n\n**自动映射**\n\n- `resultMap` 元素是 MyBatis 中最重要最强大的元素。它可以让你从 90% 的 JDBC `ResultSets` 数据提取代码中解放出来。\n- 实际上，在为一些比如连接的复杂语句编写映射代码的时候，一份 `resultMap` 能够代替实现同等功能的长达数千行的代码。\n- ResultMap 的设计思想是，对于简单的语句根本不需要配置显式的结果映射，而对于复杂一点的语句只需要描述它们的关系就行了。\n\n你已经见过简单映射语句的示例了，但并没有显式指定 `resultMap`。比如：\n\n```\n<select id=\"selectUserById\" resultType=\"map\">\nselect id , name , pwd\n  from user\n  where id = #{id}\n</select>\n```\n\n上述语句只是简单地将所有的列映射到 `HashMap` 的键上，这由 `resultType` 属性指定。虽然在大部分情况下都够用，但是 HashMap 不是一个很好的模型。你的程序更可能会使用 JavaBean 或 POJO（Plain Old Java Objects，普通老式 Java 对象）作为模型。\n\n`ResultMap` 最优秀的地方在于，虽然你已经对它相当了解了，但是根本就不需要显式地用到他们。\n\n**手动映射**\n\n1、返回值类型为resultMap\n\n```\n<select id=\"selectUserById\" resultMap=\"UserMap\">\n  select id , name , pwd from user where id = #{id}\n</select>\n```\n\n2、编写resultMap，实现手动映射！\n\n```\n<resultMap id=\"UserMap\" type=\"User\">\n   <!-- id为主键 -->\n   <id column=\"id\" property=\"id\"/>\n   <!-- column是数据库表的列名 , property是对应实体类的属性名 -->\n   <result column=\"name\" property=\"name\"/>\n   <result column=\"pwd\" property=\"password\"/>\n</resultMap>\n```\n\n如果世界总是这么简单就好了。但是肯定不是的，数据库中，存在一对多，多对一的情况，我们之后会使用到一些高级的结果集映射，association，collection这些，我们将在之后讲解，今天你们需要把这些知识都消化掉才是最重要的！理解结果集映射的这个概念！\n\n# 分页的几种方式\n\n## 日志工厂\n\n思考：我们在测试SQL的时候，要是能够在控制台输出 SQL 的话，是不是就能够有更快的排错效率？\n\n如果一个 数据库相关的操作出现了问题，我们可以根据输出的SQL语句快速排查问题。\n\n对于以往的开发过程，我们会经常使用到debug模式来调节，跟踪我们的代码执行过程。但是现在使用Mybatis是基于接口，配置文件的源代码执行过程。因此，我们必须选择日志工具来作为我们开发，调节程序的工具。\n\nMybatis内置的日志工厂提供日志功能，具体的日志实现有以下几种工具：\n\n- SLF4J\n- Apache Commons Logging\n- Log4j 2\n- Log4j\n- JDK logging\n\n具体选择哪个日志实现工具由MyBatis的内置日志工厂确定。它会使用最先找到的（按上文列举的顺序查找）。如果一个都未找到，日志功能就会被禁用。\n\n**标准日志实现**\n\n指定 MyBatis 应该使用哪个日志记录实现。如果此设置不存在，则会自动发现日志记录实现。\n\n```\n<settings>\n       <setting name=\"logImpl\" value=\"STDOUT_LOGGING\"/>\n</settings>\n```\n\n测试，可以看到控制台有大量的输出！我们可以通过这些输出来判断程序到底哪里出了Bug\n\n## Log4j\n\n**简介：**\n\n- Log4j是Apache的一个开源项目\n- 通过使用Log4j，我们可以控制日志信息输送的目的地：控制台，文本，GUI组件....\n- 我们也可以控制每一条日志的输出格式；\n- 通过定义每一条日志信息的级别，我们能够更加细致地控制日志的生成过程。最令人感兴趣的就是，这些可以通过一个配置文件来灵活地进行配置，而不需要修改应用的代码。\n\n**使用步骤：**\n\n1、导入log4j的包\n\n```\n<dependency>\n   <groupId>log4j</groupId>\n   <artifactId>log4j</artifactId>\n   <version>1.2.17</version>\n</dependency>\n```\n\n2、配置文件编写\n\n```\n#将等级为DEBUG的日志信息输出到console和file这两个目的地，console和file的定义在下面的代码\nlog4j.rootLogger=DEBUG,console,file\n\n#控制台输出的相关设置\nlog4j.appender.console = org.apache.log4j.ConsoleAppender\nlog4j.appender.console.Target = System.out\nlog4j.appender.console.Threshold=DEBUG\nlog4j.appender.console.layout = org.apache.log4j.PatternLayout\nlog4j.appender.console.layout.ConversionPattern=[%c]-%m%n\n\n#文件输出的相关设置\nlog4j.appender.file = org.apache.log4j.RollingFileAppender\nlog4j.appender.file.File=./log/kuang.log\nlog4j.appender.file.MaxFileSize=10mb\nlog4j.appender.file.Threshold=DEBUG\nlog4j.appender.file.layout=org.apache.log4j.PatternLayout\nlog4j.appender.file.layout.ConversionPattern=[%p][%d{yy-MM-dd}][%c]%m%n\n\n#日志输出级别\nlog4j.logger.org.mybatis=DEBUG\nlog4j.logger.java.sql=DEBUG\nlog4j.logger.java.sql.Statement=DEBUG\nlog4j.logger.java.sql.ResultSet=DEBUG\nlog4j.logger.java.sql.PreparedStatement=DEBUG\n```\n\n3、setting设置日志实现\n\n```\n<settings>\n   <setting name=\"logImpl\" value=\"LOG4J\"/>\n</settings>\n```\n\n4、在程序中使用Log4j进行输出！\n\n```\n//注意导包：org.apache.log4j.Logger\nstatic Logger logger = Logger.getLogger(MyTest.class);\n\n@Test\npublic void selectUser() {\n   logger.info(\"info：进入selectUser方法\");\n   logger.debug(\"debug：进入selectUser方法\");\n   logger.error(\"error: 进入selectUser方法\");\n   SqlSession session = MybatisUtils.getSession();\n   UserMapper mapper = session.getMapper(UserMapper.class);\n   List<User> users = mapper.selectUser();\n   for (User user: users){\n       System.out.println(user);\n  }\n   session.close();\n}\n```\n\n5、测试，看控制台输出！\n\n- 使用Log4j 输出日志\n- 可以看到还生成了一个日志的文件 【需要修改file的日志级别】\n\n## limit实现分页\n\n**思考：为什么需要分页？**\n\n在学习mybatis等持久层框架的时候，会经常对数据进行增删改查操作，使用最多的是对数据库进行查询操作，如果查询大量数据的时候，我们往往使用分页进行查询，也就是每次处理小部分数据，这样对数据库压力就在可控范围内。\n\n**使用Limit实现分页**\n\n```\n#语法\nSELECT * FROM table LIMIT stratIndex，pageSize\n\nSELECT * FROM table LIMIT 5,10; // 检索记录行 6-15  \n\n#为了检索从某一个偏移量到记录集的结束所有的记录行，可以指定第二个参数为 -1：   \nSELECT * FROM table LIMIT 95,-1; // 检索记录行 96-last.  \n\n#如果只给定一个参数，它表示返回最大的记录行数目：   \nSELECT * FROM table LIMIT 5; //检索前 5 个记录行  \n\n#换句话说，LIMIT n 等价于 LIMIT 0,n。 \n```\n\n**步骤：**\n\n1、修改Mapper文件\n\n```\n<select id=\"selectUser\" parameterType=\"map\" resultType=\"user\">\n  select * from user limit #{startIndex},#{pageSize}\n</select>\n```\n\n2、Mapper接口，参数为map\n\n```\n//选择全部用户实现分页\nList<User> selectUser(Map<String,Integer> map);\n```\n\n3、在测试类中传入参数测试\n\n- 推断：起始位置 =  （当前页面 - 1 ） \\* 页面大小\n\n```\n\n//分页查询 , 两个参数startIndex , pageSize\n@Test\npublic void testSelectUser() {\n   SqlSession session = MybatisUtils.getSession();\n   UserMapper mapper = session.getMapper(UserMapper.class);\n\n   int currentPage = 1;  //第几页\n   int pageSize = 2;  //每页显示几个\n   Map<String,Integer> map = new HashMap<String,Integer>();\n   map.put(\"startIndex\",(currentPage-1)*pageSize);\n   map.put(\"pageSize\",pageSize);\n\n   List<User> users = mapper.selectUser(map);\n\n   for (User user: users){\n       System.out.println(user);\n  }\n\n   session.close();\n}\n```\n\n## RowBounds分页\n\n我们除了使用Limit在SQL层面实现分页，也可以使用RowBounds在Java代码层面实现分页，当然此种方式作为了解即可。我们来看下如何实现的！\n\n**步骤：**\n\n1、mapper接口\n\n```\n//选择全部用户RowBounds实现分页\nList<User> getUserByRowBounds();\n```\n\n2、mapper文件\n\n```\n<select id=\"getUserByRowBounds\" resultType=\"user\">\nselect * from user\n</select>\n```\n\n3、测试类\n\n在这里，我们需要使用RowBounds类\n\n```\n\n@Test\npublic void testUserByRowBounds() {\n   SqlSession session = MybatisUtils.getSession();\n\n   int currentPage = 2;  //第几页\n   int pageSize = 2;  //每页显示几个\n   RowBounds rowBounds = new RowBounds((currentPage-1)*pageSize,pageSize);\n\n   //通过session.**方法进行传递rowBounds，[此种方式现在已经不推荐使用了]\n   List<User> users = session.selectList(\"com.kuang.mapper.UserMapper.getUserByRowBounds\", null, rowBounds);\n\n   for (User user: users){\n       System.out.println(user);\n  }\n   session.close();\n}\n```\n\n## PageHelper\n\n![](http://192.168.5.54:8001/wp-content/uploads/2022/06/image-23.png)\n\n了解即可，可以自己尝试使用\n\n官方文档：[https://pagehelper.github.io/](https://pagehelper.github.io/)\n\n> 在MyBatisPlus中，我们也讲解到了分页实现，所以实现方式很多，看自己的理解和熟练程度进行掌握即可！\n\n会了简单的结果集映射，后面我们就可以实现一对多和多对一操作\n","tags":["mybatis"],"categories":["mybatis"]},{"title":"CRUD操作及配置解析","url":"/2022/06/08/crud操作/","content":"\n## namespace\n\n1. 将上面案例中的UserMapper接口改名为 UserDao；\n2. 将UserMapper.xml中的namespace改为为UserDao的路径 .\n3. 再次测试\n\n**结论：**\n\n配置文件中namespace中的名称为对应Mapper接口或者Dao接口的完整包名,必须一致！\n\n## select\n\n- select标签是mybatis中最常用的标签之一\n- select语句有很多属性可以详细配置每一条SQL语句\n    - SQL语句返回值类型。【完整的类名或者别名】\n    - 传入SQL语句的参数类型 。【万能的Map，可以多尝试使用】\n    - 命名空间中唯一的标识符\n    - 接口中的方法名与映射文件中的SQL语句ID 一一对应\n    - id\n    - parameterType\n    - resultType\n\n**需求：根据id查询用户**\n\n1、在UserMapper中添加对应方法\n\n```\npublic interface UserMapper {\n   //查询全部用户\n   List<User> selectUser();\n   //根据id查询用户\n   User selectUserById(int id);\n}\n```\n\n2、在UserMapper.xml中添加Select语句\n\n```\n<select id=\"selectUserById\" resultType=\"com.kuang.pojo.User\">\nselect * from user where id = #{id}\n</select>\n```\n\n3、测试类中测试\n\n```\n@Test\npublic void tsetSelectUserById() {\n   SqlSession session = MybatisUtils.getSession();  //获取SqlSession连接\n   UserMapper mapper = session.getMapper(UserMapper.class);\n   User user = mapper.selectUserById(1);\n   System.out.println(user);\n   session.close();\n}\n```\n\n**课堂练习**：根据 密码 和 名字 查询用户\n\n思路一：直接在方法中传递参数\n\n1、在接口方法的参数前加 @Param属性\n\n2、Sql语句编写的时候，直接取@Param中设置的值即可，不需要单独设置参数类型\n\n```\n//通过密码和名字查询用户\nUser selectUserByNP(@Param(\"username\") String username,@Param(\"pwd\") String pwd);\n\n/*\n   <select id=\"selectUserByNP\" resultType=\"com.kuang.pojo.User\">\n     select * from user where name = #{username} and pwd = #{pwd}\n   </select>\n*/\n```\n\n思路二：使用万能的Map\n\n1、在接口方法中，参数直接传递Map；\n\n```\nUser selectUserByNP2(Map<String,Object> map);\n```\n\n2、编写sql语句的时候，需要传递参数类型，参数类型为map\n\n```\n<select id=\"selectUserByNP2\" parameterType=\"map\" resultType=\"com.kuang.pojo.User\">\nselect * from user where name = #{username} and pwd = #{pwd}\n</select>\n```\n\n3、在使用方法的时候，Map的 key 为 sql中取的值即可，没有顺序要求！\n\n```\nMap<String, Object> map = new HashMap<String, Object>();\nmap.put(\"username\",\"小明\");\nmap.put(\"pwd\",\"123456\");\nUser user = mapper.selectUserByNP2(map);\n```\n\n总结：如果参数过多，我们可以考虑直接使用Map实现，如果参数比较少，直接传递参数即可\n\n## insert\n\n我们一般使用insert标签进行插入操作，它的配置和select标签差不多！\n\n**需求：给数据库增加一个用户**\n\n1、在UserMapper接口中添加对应的方法\n\n```\n//添加一个用户\nint addUser(User user);\n```\n\n2、在UserMapper.xml中添加insert语句\n\n```\n<insert id=\"addUser\" parameterType=\"com.kuang.pojo.User\">\n    insert into user (id,name,pwd) values (#{id},#{name},#{pwd})\n</insert>\n```\n\n3、测试\n\n```\n@Test\npublic void testAddUser() {\n   SqlSession session = MybatisUtils.getSession();\n   UserMapper mapper = session.getMapper(UserMapper.class);\n   User user = new User(5,\"王五\",\"zxcvbn\");\n   int i = mapper.addUser(user);\n   System.out.println(i);\n   session.commit(); //提交事务,重点!不写的话不会提交到数据库\n   session.close();\n}\n```\n\n**注意点：增、删、改操作需要提交事务！**\n\n## update\n\n我们一般使用update标签进行更新操作，它的配置和select标签差不多！\n\n**需求：修改用户的信息**\n\n1、同理，编写接口方法\n\n```\n//修改一个用户\nint updateUser(User user);\n```\n\n2、编写对应的配置文件SQL\n\n```\n<update id=\"updateUser\" parameterType=\"com.kuang.pojo.User\">\n  update user set name=#{name},pwd=#{pwd} where id = #{id}\n</update>\n```\n\n3、测试\n\n```\n\n@Test\npublic void testUpdateUser() {\n   SqlSession session = MybatisUtils.getSession();\n   UserMapper mapper = session.getMapper(UserMapper.class);\n   User user = mapper.selectUserById(1);\n   user.setPwd(\"asdfgh\");\n   int i = mapper.updateUser(user);\n   System.out.println(i);\n   session.commit(); //提交事务,重点!不写的话不会提交到数据库\n   session.close();\n}\n```\n\n## delete\n\n我们一般使用delete标签进行删除操作，它的配置和select标签差不多！\n\n**需求：根据id删除一个用户**\n\n1、同理，编写接口方法\n\n```\n//根据id删除用户\nint deleteUser(int id);\n```\n\n2、编写对应的配置文件SQL\n\n```\n<delete id=\"deleteUser\" parameterType=\"int\">\n  delete from user where id = #{id}\n</delete>\n```\n\n3、测试\n\n```\n@Test\npublic void testDeleteUser() {\n   SqlSession session = MybatisUtils.getSession();\n   UserMapper mapper = session.getMapper(UserMapper.class);\n   int i = mapper.deleteUser(5);\n   System.out.println(i);\n   session.commit(); //提交事务,重点!不写的话不会提交到数据库\n   session.close();\n}\n```\n\n**小结：**\n\n- 所有的增删改操作都需要提交事务！\n- 接口所有的普通参数，尽量都写上@Param参数，尤其是多个参数时，必须写上！\n- 有时候根据业务的需求，可以考虑使用map传递参数！\n- 为了规范操作，在SQL的配置文件中，我们尽量将Parameter参数和resultType都写上！\n\n## 思考题\n\n第1种：在Java代码中添加sql通配符。\n\n```\nstring wildcardname = “%smi%”;\nlist<name> names = mapper.selectlike(wildcardname);\n\n<select id=”selectlike”>\nselect * from foo where bar like #{value}\n</select>\n```\n\n第2种：在sql语句中拼接通配符，会引起sql注入\n\n```\nstring wildcardname = “smi”;\nlist<name> names = mapper.selectlike(wildcardname);\n\n<select id=”selectlike”>\n    select * from foo where bar like \"%\"#{value}\"%\"\n</select>\n```\n\n# 配置解析\n\n## 核心配置文件\n\n- mybatis-config.xml 系统核心配置文件\n- MyBatis 的配置文件包含了会深深影响 MyBatis 行为的设置和属性信息。\n- 能配置的内容如下：\n\n```\nconfiguration（配置）\nproperties（属性）\nsettings（设置）\ntypeAliases（类型别名）\ntypeHandlers（类型处理器）\nobjectFactory（对象工厂）\nplugins（插件）\nenvironments（环境配置）\nenvironment（环境变量）\ntransactionManager（事务管理器）\ndataSource（数据源）\ndatabaseIdProvider（数据库厂商标识）\nmappers（映射器）\n<!-- 注意元素节点的顺序！顺序不对会报错 -->\n```\n\n我们可以阅读 mybatis-config.xml 上面的dtd的头文件！\n\n## environments元素\n\n```\n<environments default=\"development\">\n <environment id=\"development\">\n   <transactionManager type=\"JDBC\">\n     <property name=\"...\" value=\"...\"/>\n   </transactionManager>\n   <dataSource type=\"POOLED\">\n     <property name=\"driver\" value=\"${driver}\"/>\n     <property name=\"url\" value=\"${url}\"/>\n     <property name=\"username\" value=\"${username}\"/>\n     <property name=\"password\" value=\"${password}\"/>\n   </dataSource>\n </environment>\n</environments>\n```\n\n- 配置MyBatis的多套运行环境，将SQL映射到多个不同的数据库上，必须指定其中一个为默认运行环境（通过default指定）\n- 子元素节点：**environment**\n    - dataSource 元素使用标准的 JDBC 数据源接口来配置 JDBC 连接对象的资源。\n    - 数据源是必须配置的。\n    - 有三种内建的数据源类型type=\"\\[UNPOOLED|POOLED|JNDI\\]\"）\n    - unpooled：这个数据源的实现只是每次被请求时打开和关闭连接。\n    - **pooled**：这种数据源的实现利用“池”的概念将 JDBC 连接对象组织起来 , 这是一种使得并发 Web 应用快速响应请求的流行处理方式。\n    - jndi：这个数据源的实现是为了能在如 Spring 或应用服务器这类容器中使用，容器可以集中或在外部配置数据源，然后放置一个 JNDI 上下文的引用。\n    - 数据源也有很多第三方的实现，比如dbcp，c3p0，druid等等....\n    - 详情：点击查看官方文档\n    - 这两种事务管理器类型都不需要设置任何属性。\n    - 具体的一套环境，通过设置id进行区别，id保证唯一！\n    - 子元素节点：transactionManager - \\[ 事务管理器 \\]<!-- 语法 -->  \n        <transactionManager type=\"\\[ JDBC | MANAGED \\]\"/>\n    - 子元素节点：**数据源（dataSource）**\n\n## mappers元素\n\n**mappers**\n\n- 映射器 : 定义映射SQL语句文件\n- 既然 MyBatis 的行为其他元素已经配置完了，我们现在就要定义 SQL 映射语句了。但是首先我们需要告诉 MyBatis 到哪里去找到这些语句。Java 在自动查找这方面没有提供一个很好的方法，所以最佳的方式是告诉 MyBatis 到哪里去找映射文件。你可以使用相对于类路径的资源引用， 或完全限定资源定位符（包括 `file:///` 的 URL），或类名和包名等。映射器是MyBatis中最核心的组件之一，在MyBatis 3之前，只支持xml映射器，即：所有的SQL语句都必须在xml文件中配置。而从MyBatis 3开始，还支持接口映射器，这种映射器方式允许以Java代码的方式注解定义SQL语句，非常简洁。\n\n**引入资源方式**\n\n```\n<!-- 使用相对于类路径的资源引用 -->\n<mappers>\n <mapper resource=\"org/mybatis/builder/PostMapper.xml\"/>\n</mappers>\n```\n\n```\n<!-- 使用完全限定资源定位符（URL） -->\n<mappers>\n <mapper url=\"file:///var/mappers/AuthorMapper.xml\"/>\n</mappers>\n```\n\n```\n<!--\n使用映射器接口实现类的完全限定类名\n需要配置文件名称和接口名称一致，并且位于同一目录下\n-->\n<mappers>\n <mapper class=\"org.mybatis.builder.AuthorMapper\"/>\n</mappers>\n```\n\n```\n<!--\n将包内的映射器接口实现全部注册为映射器\n但是需要配置文件名称和接口名称一致，并且位于同一目录下\n-->\n<mappers>\n <package name=\"org.mybatis.builder\"/>\n</mappers>\n```\n\n**Mapper文件**\n\n```\n<?xml version=\"1.0\" encoding=\"UTF-8\" ?>\n<!DOCTYPE mapper\n       PUBLIC \"-//mybatis.org//DTD Mapper 3.0//EN\"\n       \"http://mybatis.org/dtd/mybatis-3-mapper.dtd\">\n<mapper namespace=\"com.kuang.mapper.UserMapper\">\n   \n</mapper>\n```\n\n- namespace中文意思：命名空间，作用如下：\n    \n    - namespace的命名必须跟某个接口同名\n    - 接口中的方法与映射文件中sql语句id应该一一对应\n    \n    1. namespace和子元素的id联合保证唯一  , 区别不同的mapper\n    2. 绑定DAO接口\n    3. namespace命名规则 : 包名+类名\n\nMyBatis 的真正强大在于它的映射语句，这是它的魔力所在。由于它的异常强大，映射器的 XML 文件就显得相对简单。如果拿它跟具有相同功能的 JDBC 代码进行对比，你会立即发现省掉了将近 95% 的代码。MyBatis 为聚焦于 SQL 而构建，以尽可能地为你减少麻烦。\n\n## Properties优化\n\n数据库这些属性都是可外部配置且可动态替换的，既可以在典型的 Java 属性文件中配置，亦可通过 properties 元素的子元素来传递。具体的官方文档\n\n我们来优化我们的配置文件\n\n第一步 ; 在资源目录下新建一个db.properties\n\n```\ndriver=com.mysql.jdbc.Driver\nurl=jdbc:mysql://localhost:3306/mybatis?useSSL=true&useUnicode=true&characterEncoding=utf8\nusername=root\npassword=123456\n```\n\n第二步 : 将文件导入properties 配置文件\n\n```\n<configuration>\n   <!--导入properties文件-->\n   <properties resource=\"db.properties\"/>\n\n   <environments default=\"development\">\n       <environment id=\"development\">\n           <transactionManager type=\"JDBC\"/>\n           <dataSource type=\"POOLED\">\n               <property name=\"driver\" value=\"${driver}\"/>\n               <property name=\"url\" value=\"${url}\"/>\n               <property name=\"username\" value=\"${username}\"/>\n               <property name=\"password\" value=\"${password}\"/>\n           </dataSource>\n       </environment>\n   </environments>\n   <mappers>\n       <mapper resource=\"mapper/UserMapper.xml\"/>\n   </mappers>\n</configuration>\n```\n\n更多操作，可以查看官方文档！【演示带领学习】\n\n- 配置文件优先级问题\n- 新特性：使用占位符\n\n## typeAliases优化\n\n类型别名是为 Java 类型设置一个短的名字。它只和 XML 配置有关，存在的意义仅在于用来减少类完全限定名的冗余。\n\n```\n<!--配置别名,注意顺序-->\n<typeAliases>\n   <typeAlias type=\"com.kuang.pojo.User\" alias=\"User\"/>\n</typeAliases>\n```\n\n当这样配置时，`User`可以用在任何使用`com.kuang.pojo.User`的地方。\n\n也可以指定一个包名，MyBatis 会在包名下面搜索需要的 Java Bean，比如:\n\n```\n<typeAliases>\n   <package name=\"com.kuang.pojo\"/>\n</typeAliases>\n```\n\n每一个在包 `com.kuang.pojo` 中的 Java Bean，在没有注解的情况下，会使用 Bean 的首字母小写的非限定类名来作为它的别名。\n\n若有注解，则别名为其注解值。见下面的例子：\n\n```\n@Alias(\"user\")\npublic class User {\n  ...\n}\n```\n\n去官网查看一下Mybatis默认的一些类型别名！\n\n## 其他配置浏览\n\n**设置**\n\n- 设置（settings）相关 => 查看帮助文档\n    - 懒加载\n    - 日志实现\n    - 缓存开启关闭\n- 一个配置完整的 settings 元素的示例如\n\n```\n<settings>\n <setting name=\"cacheEnabled\" value=\"true\"/>\n <setting name=\"lazyLoadingEnabled\" value=\"true\"/>\n <setting name=\"multipleResultSetsEnabled\" value=\"true\"/>\n <setting name=\"useColumnLabel\" value=\"true\"/>\n <setting name=\"useGeneratedKeys\" value=\"false\"/>\n <setting name=\"autoMappingBehavior\" value=\"PARTIAL\"/>\n <setting name=\"autoMappingUnknownColumnBehavior\" value=\"WARNING\"/>\n <setting name=\"defaultExecutorType\" value=\"SIMPLE\"/>\n <setting name=\"defaultStatementTimeout\" value=\"25\"/>\n <setting name=\"defaultFetchSize\" value=\"100\"/>\n <setting name=\"safeRowBoundsEnabled\" value=\"false\"/>\n <setting name=\"mapUnderscoreToCamelCase\" value=\"false\"/>\n <setting name=\"localCacheScope\" value=\"SESSION\"/>\n <setting name=\"jdbcTypeForNull\" value=\"OTHER\"/>\n <setting name=\"lazyLoadTriggerMethods\" value=\"equals,clone,hashCode,toString\"/>\n</settings>\n```\n\n**类型处理器**\n\n- 无论是 MyBatis 在预处理语句（PreparedStatement）中设置一个参数时，还是从结果集中取出一个值时， 都会用类型处理器将获取的值以合适的方式转换成 Java 类型。\n- 你可以重写类型处理器或创建你自己的类型处理器来处理不支持的或非标准的类型。【了解即可】\n\n**对象工厂**\n\n- MyBatis 每次创建结果对象的新实例时，它都会使用一个对象工厂（ObjectFactory）实例来完成。\n- 默认的对象工厂需要做的仅仅是实例化目标类，要么通过默认构造方法，要么在参数映射存在的时候通过有参构造方法来实例化。\n- 如果想覆盖对象工厂的默认行为，则可以通过创建自己的对象工厂来实现。【了解即可】\n\n## 生命周期和作用域\n\n**作用域（Scope）和生命周期**\n\n理解我们目前已经讨论过的不同作用域和生命周期类是至关重要的，因为错误的使用会导致非常严重的并发问题。\n\n我们可以先画一个流程图，分析一下Mybatis的执行过程！\n\n![](http://192.168.5.54:8001/wp-content/uploads/2022/06/image-20.png)\n\n**作用域理解**\n\n- SqlSessionFactoryBuilder 的作用在于创建 SqlSessionFactory，创建成功后，SqlSessionFactoryBuilder 就失去了作用，所以它只能存在于创建 SqlSessionFactory 的方法中，而不要让其长期存在。因此 **SqlSessionFactoryBuilder 实例的最佳作用域是方法作用域**（也就是局部方法变量）。\n- SqlSessionFactory 可以被认为是一个数据库连接池，它的作用是创建 SqlSession 接口对象。因为 MyBatis 的本质就是 Java 对数据库的操作，所以 SqlSessionFactory 的生命周期存在于整个 MyBatis 的应用之中，所以一旦创建了 SqlSessionFactory，就要长期保存它，直至不再使用 MyBatis 应用，所以可以认为 SqlSessionFactory 的生命周期就等同于 MyBatis 的应用周期。\n- 由于 SqlSessionFactory 是一个对数据库的连接池，所以它占据着数据库的连接资源。如果创建多个 SqlSessionFactory，那么就存在多个数据库连接池，这样不利于对数据库资源的控制，也会导致数据库连接资源被消耗光，出现系统宕机等情况，所以尽量避免发生这样的情况。\n- 因此在一般的应用中我们往往希望 SqlSessionFactory 作为一个单例，让它在应用中被共享。所以说 **SqlSessionFactory 的最佳作用域是应用作用域。**\n- 如果说 SqlSessionFactory 相当于数据库连接池，那么 SqlSession 就相当于一个数据库连接（Connection 对象），你可以在一个事务里面执行多条 SQL，然后通过它的 commit、rollback 等方法，提交或者回滚事务。所以它应该存活在一个业务请求中，处理完整个请求后，应该关闭这条连接，让它归还给 SqlSessionFactory，否则数据库资源就很快被耗费精光，系统就会瘫痪，所以用 try...catch...finally... 语句来保证其正确关闭。\n- **所以 SqlSession 的最佳的作用域是请求或方法作用域。**\n\n![](http://192.168.5.54:8001/wp-content/uploads/2022/06/image-21.png)\n\n学会了Crud，和基本的配置及原理，后面就可以学习些业务开发\n","tags":["mybatis"],"categories":["mybatis"]},{"title":"MyBatis第一个程序","url":"/2022/06/08/mybatis简介/","content":"\n## 环境说明：\n\n- jdk 8 +\n- MySQL 5.7.19\n- maven-3.6.1\n- IDEA\n\n学习前需要掌握：\n\n- JDBC\n- MySQL\n- Java 基础\n- Maven\n- Junit\n\n## 什么是MyBatis\n\n- MyBatis 是一款优秀的**持久层框架**\n- MyBatis 避免了几乎所有的 JDBC 代码和手动设置参数以及获取结果集的过程\n- MyBatis 可以使用简单的 XML 或注解来配置和映射原生信息，将接口和 Java 的 实体类 【Plain Old Java Objects,普通的 Java对象】映射成数据库中的记录。\n- MyBatis 本是apache的一个开源项目ibatis, 2010年这个项目由apache 迁移到了google code，并且改名为MyBatis 。\n- 2013年11月迁移到**Github** .\n- Mybatis官方文档 : http://www.mybatis.org/mybatis-3/zh/index.html\n- 中文文档：[MyBatis中文网](https://mybatis.net.cn/)\n- GitHub : https://github.com/mybatis/mybatis-3\n\n## 持久化\n\n**持久化是将程序数据在持久状态和瞬时状态间转换的机制。**\n\n- 即把数据（如内存中的对象）保存到可永久保存的存储设备中（如磁盘）。持久化的主要应用是将内存中的对象存储在数据库中，或者存储在磁盘文件中、XML数据文件中等等。\n- JDBC就是一种持久化机制。文件IO也是一种持久化机制。\n- 在生活中 : 将鲜肉冷藏，吃的时候再解冻的方法也是。将水果做成罐头的方法也是。\n\n**为什么需要持久化服务呢？那是由于内存本身的缺陷引起的**\n\n- 内存断电后数据会丢失，但有一些对象是无论如何都不能丢失的，比如银行账号等，遗憾的是，人们还无法保证内存永不掉电。\n- 内存过于昂贵，与硬盘、光盘等外存相比，内存的价格要高2~3个数量级，而且维持成本也高，至少需要一直供电吧。所以即使对象不需要永久保存，也会因为内存的容量限制不能一直呆在内存中，需要持久化来缓存到外存。\n\n## 持久层\n\n**什么是持久层？**\n\n- 完成持久化工作的代码块 .  ---->  dao层 【DAO (Data Access Object)  数据访问对象】\n- 大多数情况下特别是企业级应用，数据持久化往往也就意味着将内存中的数据保存到磁盘上加以固化，而持久化的实现过程则大多通过各种**关系数据库**来完成。\n- 不过这里有一个字需要特别强调，也就是所谓的“层”。对于应用系统而言，数据持久功能大多是必不可少的组成部分。也就是说，我们的系统中，已经天然的具备了“持久层”概念？也许是，但也许实际情况并非如此。之所以要独立出一个“持久层”的概念,而不是“持久模块”，“持久单元”，也就意味着，我们的系统架构中，应该有一个相对独立的逻辑层面，专注于数据持久化逻辑的实现.\n- 与系统其他部分相对而言，这个层面应该具有一个较为清晰和严格的逻辑边界。【说白了就是用来操作数据库存在的！】\n\n## 为什么需要Mybatis\n\n- Mybatis就是帮助程序猿将数据存入数据库中 , 和从数据库中取数据 .\n- 传统的jdbc操作 , 有很多重复代码块 .比如 : 数据取出时的封装 , 数据库的建立连接等等... , 通过框架可以减少重复代码,提高开发效率 .\n- MyBatis 是一个半自动化的**ORM框架 (Object Relationship Mapping) -->对象关系映射**\n- 所有的事情，不用Mybatis依旧可以做到，只是用了它，所有实现会更加简单！**技术没有高低之分，只有使用这个技术的人有高低之别**\n- MyBatis的优点\n    - 简单易学：本身就很小且简单。没有任何第三方依赖，最简单安装只要两个jar文件+配置几个sql映射文件就可以了，易于学习，易于使用，通过文档和源代码，可以比较完全的掌握它的设计思路和实现。\n    - 灵活：mybatis不会对应用程序或者数据库的现有设计强加任何影响。sql写在xml里，便于统一管理和优化。通过sql语句可以满足操作数据库的所有需求。\n    - 解除sql与程序代码的耦合：通过提供DAO层，将业务逻辑和数据访问逻辑分离，使系统的设计更清晰，更易维护，更易单元测试。sql和代码的分离，提高了可维护性。\n    - 提供xml标签，支持编写动态sql。\n    - .......\n- 最重要的一点，使用的人多！公司需要！\n\n# MyBatis第一个程序\n\n**思路流程：搭建环境-->导入Mybatis--->编写代码--->测试**\n\n## 代码演示\n\n1、搭建实验数据库\n\n```\nCREATE DATABASE `mybatis`;\n\nUSE `mybatis`;\n\nDROP TABLE IF EXISTS `user`;\n\nCREATE TABLE `user` (\n`id` int(20) NOT NULL,\n`name` varchar(30) DEFAULT NULL,\n`pwd` varchar(30) DEFAULT NULL,\nPRIMARY KEY (`id`)\n) ENGINE=InnoDB DEFAULT CHARSET=utf8;\n\ninsert  into `user`(`id`,`name`,`pwd`) values (1,'狂神','123456'),(2,'张三','abcdef'),(3,'李四','987654');\n```\n\n2、导入MyBatis相关 jar 包\n\n- GitHub上找\n\n```\n<dependency>\n   <groupId>org.mybatis</groupId>\n   <artifactId>mybatis</artifactId>\n   <version>3.5.2</version>\n</dependency>\n<dependency>\n   <groupId>mysql</groupId>\n   <artifactId>mysql-connector-java</artifactId>\n   <version>5.1.47</version>\n</dependency>\n```\n\n3、编写MyBatis核心配置文件\n\n- 查看帮助文档\n\n```\n<?xml version=\"1.0\" encoding=\"UTF-8\" ?>\n<!DOCTYPE configuration\n       PUBLIC \"-//mybatis.org//DTD Config 3.0//EN\"\n       \"http://mybatis.org/dtd/mybatis-3-config.dtd\">\n<configuration>\n   <environments default=\"development\">\n       <environment id=\"development\">\n           <transactionManager type=\"JDBC\"/>\n           <dataSource type=\"POOLED\">\n               <property name=\"driver\" value=\"com.mysql.jdbc.Driver\"/>\n               <property name=\"url\" value=\"jdbc:mysql://localhost:3306/mybatis?useSSL=true&amp;useUnicode=true&amp;characterEncoding=utf8\"/>\n               <property name=\"username\" value=\"root\"/>\n               <property name=\"password\" value=\"123456\"/>\n           </dataSource>\n       </environment>\n   </environments>\n   <mappers>\n       <mapper resource=\"com/kuang/dao/userMapper.xml\"/>\n   </mappers>\n</configuration>\n```\n\n4、编写MyBatis工具类\n\n- 查看帮助文档\n\n```\nimport org.apache.ibatis.io.Resources;\nimport org.apache.ibatis.session.SqlSession;\nimport org.apache.ibatis.session.SqlSessionFactory;\nimport org.apache.ibatis.session.SqlSessionFactoryBuilder;\nimport java.io.IOException;\nimport java.io.InputStream;\n\npublic class MybatisUtils {\n\n   private static SqlSessionFactory sqlSessionFactory;\n\n   static {\n       try {\n           String resource = \"mybatis-config.xml\";\n           InputStream inputStream = Resources.getResourceAsStream(resource);\n           sqlSessionFactory = new SqlSessionFactoryBuilder().build(inputStream);\n      } catch (IOException e) {\n           e.printStackTrace();\n      }\n  }\n\n   //获取SqlSession连接\n   public static SqlSession getSession(){\n       return sqlSessionFactory.openSession();\n  }\n\n}\n```\n\n5、创建实体类\n\n```\npublic class User {\n   \n   private int id;  //id\n   private String name;   //姓名\n   private String pwd;   //密码\n   \n   //构造,有参,无参\n   //set/get\n   //toString()\n   \n}\n```\n\n6、编写Mapper接口类\n\n```\nimport com.kuang.pojo.User;\nimport java.util.List;\n\npublic interface UserMapper {\n   List<User> selectUser();\n}\n```\n\n7、编写Mapper.xml配置文件\n\n- namespace 十分重要，不能写错！\n\n```\n<?xml version=\"1.0\" encoding=\"UTF-8\" ?>\n<!DOCTYPE mapper\n       PUBLIC \"-//mybatis.org//DTD Mapper 3.0//EN\"\n       \"http://mybatis.org/dtd/mybatis-3-mapper.dtd\">\n<mapper namespace=\"com.kuang.dao.UserMapper\">\n <select id=\"selectUser\" resultType=\"com.kuang.pojo.User\">\n  select * from user\n </select>\n</mapper>\n```\n\n8、编写测试类\n\n- Junit 包测试\n\n```\npublic class MyTest {\n   @Test\n   public void selectUser() {\n       SqlSession session = MybatisUtils.getSession();\n       //方法一:\n       //List<User> users = session.selectList(\"com.kuang.mapper.UserMapper.selectUser\");\n       //方法二:\n       UserMapper mapper = session.getMapper(UserMapper.class);\n       List<User> users = mapper.selectUser();\n\n       for (User user: users){\n           System.out.println(user);\n      }\n       session.close();\n  }\n}\n```\n\n9、运行测试，成功的查询出来的我们的数据，ok！\n\n> 问题说明\n\n**可能出现问题说明：Maven静态资源过滤问题**\n\n```\n<resources>\n   <resource>\n       <directory>src/main/java</directory>\n       <includes>\n           <include>**/*.properties</include>\n           <include>**/*.xml</include>\n       </includes>\n       <filtering>false</filtering>\n   </resource>\n   <resource>\n       <directory>src/main/resources</directory>\n       <includes>\n           <include>**/*.properties</include>\n           <include>**/*.xml</include>\n       </includes>\n       <filtering>false</filtering>\n   </resource>\n</resources>\n```\n\n有了MyBatis以后再也不用写原生的JDBC代码了。\n","tags":["mybatis"],"categories":["mybatis"]},{"title":"MySQL的engine","url":"/2022/06/08/mysql的engine/","content":"\n**Engine：存储引擎**\n\n存储引擎是MySQL中具体的与文件打交道的子系统。也是MySQL最具有特色的一个地方。\n\nMySQL的存储引擎是插件式的。它根据MySQL AB公司提供的文件访问层的一个抽象接口来定制一种文件访问机制(这种访问机制就叫存储引擎)。\n\n现在有很多种存储引擎，各个存储引擎的优势各不一样，最常用的MyISAM,InnoDB,BDB。\n\n- **默认下MySQL是使用MyISAM引擎，它查询速度快，有较好的索引优化和数据压缩技术。但是它不支持事务。**\n- **InnoDB支持事务，并且提供行级的锁定，应用也相当广泛**。\n\nMySQL也支持自己定制存储引擎，甚至一个库中不同的表使用不同的存储引擎，这些都是允许的。\n","tags":["mysql"],"categories":["mysql"]},{"title":"AOP","url":"/2022/06/07/aop/","content":"\n## 什么是AOP\n\nAOP（Aspect Oriented Programming）意为：面向切面编程，通过预编译方式和运行期动态代理实现程序功能的统一维护的一种技术。AOP是OOP的延续，是软件开发中的一个热点，也是Spring框架中的一个重要内容，是函数式编程的一种衍生范型。利用AOP可以对业务逻辑的各个部分进行隔离，从而使得业务逻辑各部分之间的耦合度降低，提高程序的可重用性，同时提高了开发的效率。\n\n![](http://192.168.5.54:8001/wp-content/uploads/2022/06/image-17.png)\n\n## Aop在Spring中的作用\n\n提供声明式事务；允许用户自定义切面\n\n以下名词需要了解下：\n\n- 横切关注点：跨越应用程序多个模块的方法或功能。即是，与我们业务逻辑无关的，但是我们需要关注的部分，就是横切关注点。如日志 , 安全 , 缓存 , 事务等等 ....\n- 切面（ASPECT）：横切关注点 被模块化 的特殊对象。即，它是一个类。\n- 通知（Advice）：切面必须要完成的工作。即，它是类中的一个方法。\n- 目标（Target）：被通知对象。\n- 代理（Proxy）：向目标对象应用通知之后创建的对象。\n- 切入点（PointCut）：切面通知 执行的 “地点”的定义。\n- 连接点（JointPoint）：与切入点匹配的执行点。\n\n![](http://192.168.5.54:8001/wp-content/uploads/2022/06/image-18.png)\n\nSpringAOP中，通过Advice定义横切逻辑，Spring中支持5种类型的Advice:\n\n![](http://192.168.5.54:8001/wp-content/uploads/2022/06/image-19.png)\n\n即 Aop 在 不改变原有代码的情况下 , 去增加新的功能 .\n\n## 使用Spring实现Aop\n\n【重点】使用AOP织入，需要导入一个依赖包！\n\n```\n<!-- https://mvnrepository.com/artifact/org.aspectj/aspectjweaver -->\n<dependency>\n   <groupId>org.aspectj</groupId>\n   <artifactId>aspectjweaver</artifactId>\n   <version>1.9.4</version>\n</dependency>\n```\n\n**第一种方式**\n\n**通过 Spring API 实现**\n\n首先编写我们的业务接口和实现类\n\n```\npublic interface UserService {\n\n   public void add();\n\n   public void delete();\n\n   public void update();\n\n   public void search();\n\n}\n```\n\n```\npublic class UserServiceImpl implements UserService{\n\n   @Override\n   public void add() {\n       System.out.println(\"增加用户\");\n  }\n\n   @Override\n   public void delete() {\n       System.out.println(\"删除用户\");\n  }\n\n   @Override\n   public void update() {\n       System.out.println(\"更新用户\");\n  }\n\n   @Override\n   public void search() {\n       System.out.println(\"查询用户\");\n  }\n}\n```\n\n然后去写我们的增强类 , 我们编写两个 , 一个前置增强 一个后置增强\n\n```\npublic class Log implements MethodBeforeAdvice {\n\n   //method : 要执行的目标对象的方法\n   //objects : 被调用的方法的参数\n   //Object : 目标对象\n   @Override\n   public void before(Method method, Object[] objects, Object o) throws Throwable {\n       System.out.println( o.getClass().getName() + \"的\" + method.getName() + \"方法被执行了\");\n  }\n}\n```\n\n```\npublic class AfterLog implements AfterReturningAdvice {\n   //returnValue 返回值\n   //method被调用的方法\n   //args 被调用的方法的对象的参数\n   //target 被调用的目标对象\n   @Override\n   public void afterReturning(Object returnValue, Method method, Object[] args, Object target) throws Throwable {\n       System.out.println(\"执行了\" + target.getClass().getName()\n       +\"的\"+method.getName()+\"方法,\"\n       +\"返回值：\"+returnValue);\n  }\n}\n```\n\n最后去spring的文件中注册 , 并实现aop切入实现 , 注意导入约束 .\n\n```\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<beans xmlns=\"http://www.springframework.org/schema/beans\"\n      xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n      xmlns:aop=\"http://www.springframework.org/schema/aop\"\n      xsi:schemaLocation=\"http://www.springframework.org/schema/beans\n       http://www.springframework.org/schema/beans/spring-beans.xsd\n       http://www.springframework.org/schema/aop\n       http://www.springframework.org/schema/aop/spring-aop.xsd\">\n\n   <!--注册bean-->\n   <bean id=\"userService\" class=\"com.kuang.service.UserServiceImpl\"/>\n   <bean id=\"log\" class=\"com.kuang.log.Log\"/>\n   <bean id=\"afterLog\" class=\"com.kuang.log.AfterLog\"/>\n\n   <!--aop的配置-->\n   <aop:config>\n       <!--切入点 expression:表达式匹配要执行的方法-->\n       <aop:pointcut id=\"pointcut\" expression=\"execution(* com.kuang.service.UserServiceImpl.*(..))\"/>\n       <!--执行环绕; advice-ref执行方法 . pointcut-ref切入点-->\n       <aop:advisor advice-ref=\"log\" pointcut-ref=\"pointcut\"/>\n       <aop:advisor advice-ref=\"afterLog\" pointcut-ref=\"pointcut\"/>\n   </aop:config>\n\n</beans>\n```\n\n测试\n\n```\npublic class MyTest {\n   @Test\n   public void test(){\n       ApplicationContext context = new ClassPathXmlApplicationContext(\"beans.xml\");\n       UserService userService = (UserService) context.getBean(\"userService\");\n       userService.search();\n  }\n}\n```\n\nAop的重要性 : 很重要 . 一定要理解其中的思路 , 主要是思想的理解这一块 .\n\nSpring的Aop就是将公共的业务 (日志 , 安全等) 和领域业务结合起来 , 当执行领域业务时 , 将会把公共业务加进来 . 实现公共业务的重复利用 . 领域业务更纯粹 , 程序猿专注领域业务 , 其本质还是动态代理 .\n\n**第二种方式**\n\n**自定义类来实现Aop**\n\n目标业务类不变依旧是userServiceImpl\n\n第一步 : 写我们自己的一个切入类\n\n```\npublic class DiyPointcut {\n\n   public void before(){\n       System.out.println(\"---------方法执行前---------\");\n  }\n   public void after(){\n       System.out.println(\"---------方法执行后---------\");\n  }\n   \n}\n\n```\n\n去spring中配置\n\n```\n<!--第二种方式自定义实现-->\n<!--注册bean-->\n<bean id=\"diy\" class=\"com.kuang.config.DiyPointcut\"/>\n\n<!--aop的配置-->\n<aop:config>\n   <!--第二种方式：使用AOP的标签实现-->\n   <aop:aspect ref=\"diy\">\n       <aop:pointcut id=\"diyPonitcut\" expression=\"execution(* com.kuang.service.UserServiceImpl.*(..))\"/>\n       <aop:before pointcut-ref=\"diyPonitcut\" method=\"before\"/>\n       <aop:after pointcut-ref=\"diyPonitcut\" method=\"after\"/>\n   </aop:aspect>\n</aop:config>\n```\n\n测试：\n\n```\npublic class MyTest {\n   @Test\n   public void test(){\n       ApplicationContext context = new ClassPathXmlApplicationContext(\"beans.xml\");\n       UserService userService = (UserService) context.getBean(\"userService\");\n       userService.add();\n  }\n}\n```\n\n**第三种方式**\n\n**使用注解实现**\n\n第一步：编写一个注解实现的增强类\n\n```\npackage com.kuang.config;\n\nimport org.aspectj.lang.ProceedingJoinPoint;\nimport org.aspectj.lang.annotation.After;\nimport org.aspectj.lang.annotation.Around;\nimport org.aspectj.lang.annotation.Aspect;\nimport org.aspectj.lang.annotation.Before;\n\n@Aspect\npublic class AnnotationPointcut {\n   @Before(\"execution(* com.kuang.service.UserServiceImpl.*(..))\")\n   public void before(){\n       System.out.println(\"---------方法执行前---------\");\n  }\n\n   @After(\"execution(* com.kuang.service.UserServiceImpl.*(..))\")\n   public void after(){\n       System.out.println(\"---------方法执行后---------\");\n  }\n\n   @Around(\"execution(* com.kuang.service.UserServiceImpl.*(..))\")\n   public void around(ProceedingJoinPoint jp) throws Throwable {\n       System.out.println(\"环绕前\");\n       System.out.println(\"签名:\"+jp.getSignature());\n       //执行目标方法proceed\n       Object proceed = jp.proceed();\n       System.out.println(\"环绕后\");\n       System.out.println(proceed);\n  }\n}\n```\n\n第二步：在Spring配置文件中，注册bean，并增加支持注解的配置\n\n```\n<!--第三种方式:注解实现-->\n<bean id=\"annotationPointcut\" class=\"com.kuang.config.AnnotationPointcut\"/>\n<aop:aspectj-autoproxy/>\n```\n\naop:aspectj-autoproxy：说明\n\n```\n通过aop命名空间的<aop:aspectj-autoproxy />声明自动为spring容器中那些配置@aspectJ切面的bean创建代理，织入切面。当然，spring 在内部依旧采用AnnotationAwareAspectJAutoProxyCreator进行自动代理的创建工作，但具体实现的细节已经被<aop:aspectj-autoproxy />隐藏起来了\n\n<aop:aspectj-autoproxy />有一个proxy-target-class属性，默认为false，表示使用jdk动态代理织入增强，当配为<aop:aspectj-autoproxy  poxy-target-class=\"true\"/>时，表示使用CGLib动态代理技术织入增强。不过即使proxy-target-class设置为false，如果目标类没有声明接口，则spring将自动使用CGLib动态代理。\n```\n","tags":["spring"],"categories":["spring"]},{"title":"代理模式","url":"/2022/06/07/代理模式/","content":"\n为什么要学习代理模式，因为AOP的底层机制就是动态代理！\n\n代理模式：\n\n- 静态代理\n- 动态代理\n\n学习aop之前 , 我们要先了解一下代理模式！\n\n![](http://192.168.5.54:8001/wp-content/uploads/2022/06/image-11.png)\n\n## 静态代理\n\n**静态代理角色分析**\n\n- 抽象角色 : 一般使用接口或者抽象类来实现\n- 真实角色 : 被代理的角色\n- 代理角色 : 代理真实角色 ; 代理真实角色后 , 一般会做一些附属的操作 .\n- 客户  :  使用代理角色来进行一些操作 .\n\n**代码实现**\n\nRent . java 即抽象角色\n\n```\n//抽象角色：租房\npublic interface Rent {\n   public void rent();\n}\n```\n\nHost . java 即真实角色\n\n```\n//真实角色: 房东，房东要出租房子\npublic class Host implements Rent{\n   public void rent() {\n       System.out.println(\"房屋出租\");\n  }\n}\n```\n\nProxy . java 即代理角色\n\n```\n//代理角色：中介\npublic class Proxy implements Rent {\n\n   private Host host;\n   public Proxy() { }\n   public Proxy(Host host) {\n       this.host = host;\n  }\n\n   //租房\n   public void rent(){\n       seeHouse();\n       host.rent();\n       fare();\n  }\n   //看房\n   public void seeHouse(){\n       System.out.println(\"带房客看房\");\n  }\n   //收中介费\n   public void fare(){\n       System.out.println(\"收中介费\");\n  }\n}\n```\n\nClient . java 即客户\n\n```\n//客户类，一般客户都会去找代理！\npublic class Client {\n   public static void main(String[] args) {\n       //房东要租房\n       Host host = new Host();\n       //中介帮助房东\n       Proxy proxy = new Proxy(host);\n\n       //你去找中介！\n       proxy.rent();\n  }\n}\n```\n\n分析：在这个过程中，你直接接触的就是中介，就如同现实生活中的样子，你看不到房东，但是你依旧租到了房东的房子通过代理，这就是所谓的代理模式，程序源自于生活，所以学编程的人，一般能够更加抽象的看待生活中发生的事情。\n\n**静态代理的好处:**\n\n- 可以使得我们的真实角色更加纯粹 . 不再去关注一些公共的事情 .\n- 公共的业务由代理来完成 . 实现了业务的分工 ,\n- 公共业务发生扩展时变得更加集中和方便 .\n\n缺点 :\n\n- 类多了 , 多了代理类 , 工作量变大了 . 开发效率降低 .\n\n我们想要静态代理的好处，又不想要静态代理的缺点，所以 , 就有了动态代理 !\n\n## 静态代理再理解\n\n练习步骤：\n\n1、创建一个抽象角色，比如咋们平时做的用户业务，抽象起来就是增删改查！\n\n```\n//抽象角色：增删改查业务\npublic interface UserService {\n   void add();\n   void delete();\n   void update();\n   void query();\n}\n```\n\n2、我们需要一个真实对象来完成这些增删改查操作\n\n```\n//真实对象，完成增删改查操作的人\npublic class UserServiceImpl implements UserService {\n\n   public void add() {\n       System.out.println(\"增加了一个用户\");\n  }\n\n   public void delete() {\n       System.out.println(\"删除了一个用户\");\n  }\n\n   public void update() {\n       System.out.println(\"更新了一个用户\");\n  }\n\n   public void query() {\n       System.out.println(\"查询了一个用户\");\n  }\n}\n```\n\n3、需求来了，现在我们需要增加一个日志功能，怎么实现！\n\n- 思路1 ：在实现类上增加代码 【麻烦！】\n- 思路2：使用代理来做，能够不改变原来的业务情况下，实现此功能就是最好的了！\n\n4、设置一个代理类来处理日志！代理角色\n\n```\n//代理角色，在这里面增加日志的实现\npublic class UserServiceProxy implements UserService {\n   private UserServiceImpl userService;\n\n   public void setUserService(UserServiceImpl userService) {\n       this.userService = userService;\n  }\n\n   public void add() {\n       log(\"add\");\n       userService.add();\n  }\n\n   public void delete() {\n       log(\"delete\");\n       userService.delete();\n  }\n\n   public void update() {\n       log(\"update\");\n       userService.update();\n  }\n\n   public void query() {\n       log(\"query\");\n       userService.query();\n  }\n\n   public void log(String msg){\n       System.out.println(\"执行了\"+msg+\"方法\");\n  }\n\n}\n```\n\n5、测试访问类：\n\n```\npublic class Client {\n   public static void main(String[] args) {\n       //真实业务\n       UserServiceImpl userService = new UserServiceImpl();\n       //代理类\n       UserServiceProxy proxy = new UserServiceProxy();\n       //使用代理类实现日志功能！\n       proxy.setUserService(userService);\n\n       proxy.add();\n  }\n}\n```\n\nOK，到了现在代理模式大家应该都没有什么问题了，重点大家需要理解其中的思想；\n\n我们在不改变原来的代码的情况下，实现了对原有功能的增强，这是AOP中最核心的思想\n\n聊聊AOP：纵向开发，横向开发\n\n![](http://192.168.5.54:8001/wp-content/uploads/2022/06/image-12.png)\n\n## 动态代理\n\n- 动态代理的角色和静态代理的一样 .\n- 动态代理的代理类是动态生成的 . 静态代理的代理类是我们提前写好的\n- 动态代理分为两类 : 一类是基于接口动态代理 , 一类是基于类的动态代理\n    - 基于接口的动态代理----JDK动态代理\n    - 基于类的动态代理--cglib\n    - 现在用的比较多的是 javasist 来生成动态代理 . 百度一下javasist\n    - 我们这里使用JDK的原生代码来实现，其余的道理都是一样的！、\n\n**JDK的动态代理需要了解两个类**\n\n核心 : InvocationHandler     和     Proxy   ， 打开JDK帮助文档看看\n\n【InvocationHandler：调用处理程序】\n\n![](http://192.168.5.54:8001/wp-content/uploads/2022/06/image-13.png)\n\n```\nObject invoke(Object proxy, 方法 method, Object[] args)；\n//参数\n//proxy - 调用该方法的代理实例\n//method -所述方法对应于调用代理实例上的接口方法的实例。方法对象的声明类将是该方法声明的接口，它可以是代理类继承该方法的代理接口的超级接口。\n//args -包含的方法调用传递代理实例的参数值的对象的阵列，或null如果接口方法没有参数。原始类型的参数包含在适当的原始包装器类的实例中，例如java.lang.Integer或java.lang.Boolean 。\n```\n\n【Proxy  : 代理】\n\n![](http://192.168.5.54:8001/wp-content/uploads/2022/06/image-14.png)\n\n![](http://192.168.5.54:8001/wp-content/uploads/2022/06/image-15.png)\n\n![](http://192.168.5.54:8001/wp-content/uploads/2022/06/image-16.png)\n\n```\n//生成代理类\npublic Object getProxy(){\n   return Proxy.newProxyInstance(this.getClass().getClassLoader(),\n                                 rent.getClass().getInterfaces(),this);\n}\n```\n\n**代码实现**\n\n抽象角色和真实角色和之前的一样！\n\nRent . java 即抽象角色\n\n```\n//抽象角色：租房\npublic interface Rent {\n   public void rent();\n}\n```\n\nHost . java 即真实角色\n\n```\n//真实角色: 房东，房东要出租房子\npublic class Host implements Rent{\n   public void rent() {\n       System.out.println(\"房屋出租\");\n  }\n}\n```\n\nProxyInvocationHandler. java 即代理角色\n\n```\npublic class ProxyInvocationHandler implements InvocationHandler {\n   private Rent rent;\n\n   public void setRent(Rent rent) {\n       this.rent = rent;\n  }\n\n   //生成代理类，重点是第二个参数，获取要代理的抽象角色！之前都是一个角色，现在可以代理一类角色\n   public Object getProxy(){\n       return Proxy.newProxyInstance(this.getClass().getClassLoader(),\n               rent.getClass().getInterfaces(),this);\n  }\n\n   // proxy : 代理类 method : 代理类的调用处理程序的方法对象.\n   // 处理代理实例上的方法调用并返回结果\n   @Override\n   public Object invoke(Object proxy, Method method, Object[] args) throws Throwable {\n       seeHouse();\n       //核心：本质利用反射实现！\n       Object result = method.invoke(rent, args);\n       fare();\n       return result;\n  }\n\n   //看房\n   public void seeHouse(){\n       System.out.println(\"带房客看房\");\n  }\n   //收中介费\n   public void fare(){\n       System.out.println(\"收中介费\");\n  }\n\n}\n```\n\nClient . java\n\n```\n//租客\npublic class Client {\n\n   public static void main(String[] args) {\n       //真实角色\n       Host host = new Host();\n       //代理实例的调用处理程序\n       ProxyInvocationHandler pih = new ProxyInvocationHandler();\n       pih.setRent(host); //将真实角色放置进去！\n       Rent proxy = (Rent)pih.getProxy(); //动态生成对应的代理类！\n       proxy.rent();\n  }\n\n}\n```\n\n核心：**一个动态代理 , 一般代理某一类业务 , 一个动态代理可以代理多个类，代理的是接口！、**\n\n## 深化理解\n\n我们来使用动态代理实现代理我们后面写的UserService！\n\n我们也可以编写一个通用的动态代理实现的类！所有的代理对象设置为Object即可！\n\n```\npublic class ProxyInvocationHandler implements InvocationHandler {\n   private Object target;\n\n   public void setTarget(Object target) {\n       this.target = target;\n  }\n\n   //生成代理类\n   public Object getProxy(){\n       return Proxy.newProxyInstance(this.getClass().getClassLoader(),\n               target.getClass().getInterfaces(),this);\n  }\n\n   // proxy : 代理类\n   // method : 代理类的调用处理程序的方法对象.\n   public Object invoke(Object proxy, Method method, Object[] args) throws Throwable {\n       log(method.getName());\n       Object result = method.invoke(target, args);\n       return result;\n  }\n\n   public void log(String methodName){\n       System.out.println(\"执行了\"+methodName+\"方法\");\n  }\n\n}\n```\n\n测试！\n\n```\npublic class Test {\n   public static void main(String[] args) {\n       //真实对象\n       UserServiceImpl userService = new UserServiceImpl();\n       //代理对象的调用处理程序\n       ProxyInvocationHandler pih = new ProxyInvocationHandler();\n       pih.setTarget(userService); //设置要代理的对象\n       UserService proxy = (UserService)pih.getProxy(); //动态生成代理类！\n       proxy.delete();\n  }\n}\n```\n\n测试，增删改查，查看结果！\n\n##### 动态代理的好处\n\n静态代理有的它都有，静态代理没有的，它也有！\n\n- 可以使得我们的真实角色更加纯粹 . 不再去关注一些公共的事情 .\n- 公共的业务由代理来完成 . 实现了业务的分工 ,\n- 公共业务发生扩展时变得更加集中和方便 .\n- 一个动态代理 , 一般代理某一类业务\n- 一个动态代理可以代理多个类，代理的是接口！\n","tags":["spring"],"categories":["java全栈","spring"]},{"title":"Bean的自动装配","url":"/2022/06/06/bean的自动装配/","content":"\n## 自动装配说明\n\n- 自动装配是使用spring满足bean依赖的一种方法\n- spring会在应用上下文中为某个bean寻找其依赖的bean。\n\nSpring中bean有三种装配机制，分别是：\n\n1. 在xml中显式配置；\n2. 在java中显式配置；\n3. 隐式的bean发现机制和自动装配。\n\n这里我们主要讲第三种：自动化的装配bean。\n\nSpring的自动装配需要从两个角度来实现，或者说是两个操作：\n\n1. 组件扫描(component scanning)：spring会自动发现应用上下文中所创建的bean；\n2. 自动装配(autowiring)：spring自动满足bean之间的依赖，也就是我们说的IoC/DI；\n\n组件扫描和自动装配组合发挥巨大威力，使得显示的配置降低到最少。\n\n**推荐不使用自动装配xml配置 , 而使用注解 .**\n\n## 测试环境搭建\n\n1、新建一个项目\n\n2、新建两个实体类，Cat   Dog  都有一个叫的方法\n\n```\npublic class Cat {\n   public void shout() {\n       System.out.println(\"miao~\");\n  }\n}\n```\n\n```\npublic class Dog {\n   public void shout() {\n       System.out.println(\"wang~\");\n  }\n}\n```\n\n3、新建一个用户类 User\n\n```\npublic class User {\n   private Cat cat;\n   private Dog dog;\n   private String str;\n}\n```\n\n4、编写Spring配置文件\n\n```\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<beans xmlns=\"http://www.springframework.org/schema/beans\"\n      xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n      xsi:schemaLocation=\"http://www.springframework.org/schema/beans\n       http://www.springframework.org/schema/beans/spring-beans.xsd\">\n\n   <bean id=\"dog\" class=\"com.kuang.pojo.Dog\"/>\n   <bean id=\"cat\" class=\"com.kuang.pojo.Cat\"/>\n\n   <bean id=\"user\" class=\"com.kuang.pojo.User\">\n       <property name=\"cat\" ref=\"cat\"/>\n       <property name=\"dog\" ref=\"dog\"/>\n       <property name=\"str\" value=\"qinjiang\"/>\n   </bean>\n</beans>\n```\n\n5、测试\n\n```\npublic class MyTest {\n   @Test\n   public void testMethodAutowire() {\n       ApplicationContext context = new ClassPathXmlApplicationContext(\"beans.xml\");\n       User user = (User) context.getBean(\"user\");\n       user.getCat().shout();\n       user.getDog().shout();\n  }\n}\n```\n\n结果正常输出，环境OK\n\n## byName\n\n**autowire byName (按名称自动装配)**\n\n由于在手动配置xml过程中，常常发生字母缺漏和大小写等错误，而无法对其进行检查，使得开发效率降低。\n\n采用自动装配将避免这些错误，并且使配置简单化。\n\n测试：\n\n1、修改bean配置，增加一个属性  autowire=\"byName\"\n\n```\n<bean id=\"user\" class=\"com.kuang.pojo.User\" autowire=\"byName\">\n   <property name=\"str\" value=\"qinjiang\"/>\n</bean>\n```\n\n2、再次测试，结果依旧成功输出！\n\n3、我们将 cat 的bean id修改为 catXXX\n\n4、再次测试， 执行时报空指针java.lang.NullPointerException。因为按byName规则找不对应set方法，真正的setCat就没执行，对象就没有初始化，所以调用时就会报空指针错误。\n\n**小结：**\n\n当一个bean节点带有 autowire byName的属性时。\n\n1. 将查找其类中所有的set方法名，例如setCat，获得将set去掉并且首字母小写的字符串，即cat。\n2. 去spring容器中寻找是否有此字符串名称id的对象。\n3. 如果有，就取出注入；如果没有，就报空指针异常。\n\n## byType\n\n**autowire byType (按类型自动装配)**\n\n使用autowire byType首先需要保证：同一类型的对象，在spring容器中唯一。如果不唯一，会报不唯一的异常。\n\n```\nNoUniqueBeanDefinitionException\n```\n\n测试：\n\n1、将user的bean配置修改一下 ： autowire=\"byType\"\n\n2、测试，正常输出\n\n3、在注册一个cat 的bean对象！\n\n```\n<bean id=\"dog\" class=\"com.kuang.pojo.Dog\"/>\n<bean id=\"cat\" class=\"com.kuang.pojo.Cat\"/>\n<bean id=\"cat2\" class=\"com.kuang.pojo.Cat\"/>\n\n<bean id=\"user\" class=\"com.kuang.pojo.User\" autowire=\"byType\">\n   <property name=\"str\" value=\"qinjiang\"/>\n</bean>\n```\n\n4、测试，报错：NoUniqueBeanDefinitionException\n\n5、删掉cat2，将cat的bean名称改掉！测试！因为是按类型装配，所以并不会报异常，也不影响最后的结果。甚至将id属性去掉，也不影响结果。\n\n这就是按照类型自动装配！\n\n# 使用注解\n\n## 使用注解\n\njdk1.5开始支持注解，spring2.5开始全面支持注解。\n\n准备工作：利用注解的方式注入属性。\n\n1、在spring配置文件中引入context文件头\n\n```\nxmlns:context=\"http://www.springframework.org/schema/context\"\n\nhttp://www.springframework.org/schema/context\nhttp://www.springframework.org/schema/context/spring-context.xsd\n```\n\n2、开启属性注解支持！\n\n```\n<context:annotation-config/>\n```\n\n### @Autowired\n\n- @Autowired是按类型自动转配的，不支持id匹配。\n- 需要导入 spring-aop的包！\n\n测试：\n\n1、将User类中的set方法去掉，使用@Autowired注解\n\n```\npublic class User {\n   @Autowired\n   private Cat cat;\n   @Autowired\n   private Dog dog;\n   private String str;\n\n   public Cat getCat() {\n       return cat;\n  }\n   public Dog getDog() {\n       return dog;\n  }\n   public String getStr() {\n       return str;\n  }\n}\n```\n\n2、此时配置文件内容\n\n```\n<context:annotation-config/>\n\n<bean id=\"dog\" class=\"com.kuang.pojo.Dog\"/>\n<bean id=\"cat\" class=\"com.kuang.pojo.Cat\"/>\n<bean id=\"user\" class=\"com.kuang.pojo.User\"/>\n```\n\n3、测试，成功输出结果！\n\n**科普**\n\n@Autowired(required=false)  说明：false，对象可以为null；true，对象必须存对象，不能为null。\n\n```\n//如果允许对象为null，设置required = false,默认为true\n@Autowired(required = false)\nprivate Cat cat;\n```\n\n### @Qualifier\n\n- @Autowired是根据类型自动装配的，加上@Qualifier则可以根据byName的方式自动装配\n- @Qualifier不能单独使用。\n\n测试实验步骤：\n\n1、配置文件修改内容，保证类型存在对象。且名字不为类的默认名字！\n\n```\n<bean id=\"dog1\" class=\"com.kuang.pojo.Dog\"/>\n<bean id=\"dog2\" class=\"com.kuang.pojo.Dog\"/>\n<bean id=\"cat1\" class=\"com.kuang.pojo.Cat\"/>\n<bean id=\"cat2\" class=\"com.kuang.pojo.Cat\"/>\n```\n\n2、没有加Qualifier测试，直接报错\n\n3、在属性上添加Qualifier注解\n\n```\n@Autowired\n@Qualifier(value = \"cat2\")\nprivate Cat cat;\n@Autowired\n@Qualifier(value = \"dog2\")\nprivate Dog dog;\n```\n\n测试，成功输出！\n\n### @Resource\n\n- @Resource如有指定的name属性，先按该属性进行byName方式查找装配；\n- 其次再进行默认的byName方式进行装配；\n- 如果以上都不成功，则按byType的方式自动装配。\n- 都不成功，则报异常。\n\n实体类：\n\n```\npublic class User {\n   //如果允许对象为null，设置required = false,默认为true\n   @Resource(name = \"cat2\")\n   private Cat cat;\n   @Resource\n   private Dog dog;\n   private String str;\n}\n```\n\nbeans.xml\n\n```\n<bean id=\"dog\" class=\"com.kuang.pojo.Dog\"/>\n<bean id=\"cat1\" class=\"com.kuang.pojo.Cat\"/>\n<bean id=\"cat2\" class=\"com.kuang.pojo.Cat\"/>\n\n<bean id=\"user\" class=\"com.kuang.pojo.User\"/>\n```\n\n测试：结果OK\n\n配置文件2：beans.xml ， 删掉cat2\n\n```\n<bean id=\"dog\" class=\"com.kuang.pojo.Dog\"/>\n<bean id=\"cat1\" class=\"com.kuang.pojo.Cat\"/>\n```\n\n实体类上只保留注解\n\n```\n@Resource\nprivate Cat cat;\n@Resource\nprivate Dog dog;\n```\n\n结果：OK\n\n结论：先进行byName查找，失败；再进行byType查找，成功。\n\n## 小结\n\n@Autowired与@Resource异同：\n\n1、@Autowired与@Resource都可以用来装配bean。都可以写在字段上，或写在setter方法上。\n\n2、@Autowired默认按类型装配（属于spring规范），默认情况下必须要求依赖对象必须存在，如果要允许null 值，可以设置它的required属性为false，如：@Autowired(required=false) ，如果我们想使用名称装配可以结合@Qualifier注解进行使用\n\n3、@Resource（属于J2EE复返），默认按照名称进行装配，名称可以通过name属性进行指定。如果没有指定name属性，当注解写在字段上时，默认取字段名进行按照名称查找，如果注解写在setter方法上默认取属性名进行装配。当找不到与名称匹配的bean时才按照类型进行装配。但是需要注意的是，如果name属性一旦指定，就只会按照名称进行装配。\n\n它们的作用相同都是用注解方式注入对象，但执行顺序不同。@Autowired先byType，@Resource先byName。\n","tags":["spring"],"categories":["java全栈","spring"]},{"title":"使用注解开发","url":"/2022/06/06/使用注解开发/","content":"\n## 说明\n\n在spring4之后，想要使用注解形式，必须得要引入aop的包\n\n![](http://192.168.5.54:8001/wp-content/uploads/2022/06/image-10.png)\n\n在配置文件当中，还得要引入一个context约束\n\n```\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<beans xmlns=\"http://www.springframework.org/schema/beans\"\n      xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n      xmlns:context=\"http://www.springframework.org/schema/context\"\n      xsi:schemaLocation=\"http://www.springframework.org/schema/beans\n       http://www.springframework.org/schema/beans/spring-beans.xsd\n       http://www.springframework.org/schema/context\n       http://www.springframework.org/schema/context/spring-context.xsd\">\n\n</beans>\n```\n\n## Bean的实现\n\n我们之前都是使用 bean 的标签进行bean注入，但是实际开发中，我们一般都会使用注解！\n\n1、配置扫描哪些包下的注解\n\n```\n<!--指定注解扫描包-->\n<context:component-scan base-package=\"com.kuang.pojo\"/>\n```\n\n2、在指定包下编写类，增加注解\n\n```\n@Component(\"user\")\n// 相当于配置文件中 <bean id=\"user\" class=\"当前注解的类\"/>\npublic class User {\n   public String name = \"秦疆\";\n}\n```\n\n3、测试\n\n```\n@Test\npublic void test(){\n   ApplicationContext applicationContext =\n       new ClassPathXmlApplicationContext(\"beans.xml\");\n   User user = (User) applicationContext.getBean(\"user\");\n   System.out.println(user.name);\n}\n```\n\n## 属性注入\n\n使用注解注入属性\n\n1、可以不用提供set方法，直接在直接名上添加@value(\"值\")\n\n```\n@Component(\"user\")\n// 相当于配置文件中 <bean id=\"user\" class=\"当前注解的类\"/>\npublic class User {\n   @Value(\"秦疆\")\n   // 相当于配置文件中 <property name=\"name\" value=\"秦疆\"/>\n   public String name;\n}\n```\n\n2、如果提供了set方法，在set方法上添加@value(\"值\");\n\n```\n@Component(\"user\")\npublic class User {\n\n   public String name;\n\n   @Value(\"秦疆\")\n   public void setName(String name) {\n       this.name = name;\n  }\n}\n```\n\n## 衍生注解\n\n我们这些注解，就是替代了在配置文件当中配置步骤而已！更加的方便快捷！\n\n**@Component三个衍生注解**\n\n为了更好的进行分层，Spring可以使用其它三个注解，功能一样，目前使用哪一个功能都一样。\n\n- @Controller：web层\n- @Service：service层\n- @Repository：dao层\n\n写上这些注解，就相当于将这个类交给Spring管理装配了！\n\n## 自动装配注解\n\n在Bean的自动装配已经讲过了，可以回顾！\n\n## 作用域\n\n@scope\n\n- singleton：默认的，Spring会采用单例模式创建这个对象。关闭工厂 ，所有的对象都会销毁。\n- prototype：多例模式。关闭工厂 ，所有的对象不会销毁。内部的垃圾回收机制会回收\n\n```\n@Controller(\"user\")\n@Scope(\"prototype\")\npublic class User {\n   @Value(\"秦疆\")\n   public String name;\n}\n```\n\n## 小结\n\n**XML与注解比较**\n\n- XML可以适用任何场景 ，结构清晰，维护方便\n- 注解不是自己提供的类使用不了，开发简单方便\n\n**xml与注解整合开发** ：推荐最佳实践\n\n- xml管理Bean\n- 注解完成属性注入\n- 使用过程中， 可以不用扫描，扫描是为了类上的注解\n\n```\n<context:annotation-config/>  \n```\n\n作用：\n\n- 进行注解驱动注册，从而使注解生效\n- 用于激活那些已经在spring容器里注册过的bean上面的注解，也就是显示的向Spring注册\n- 如果不扫描包，就需要手动配置bean\n- 如果不加注解驱动，则注入的值为null！\n\n## 基于Java类进行配置\n\nJavaConfig 原来是 Spring 的一个子项目，它通过 Java 类的方式提供 Bean 的定义信息，在 Spring4 的版本， JavaConfig 已正式成为 Spring4 的核心功能 。\n\n测试：\n\n1、编写一个实体类，Dog\n\n```\n@Component  //将这个类标注为Spring的一个组件，放到容器中！\npublic class Dog {\n   public String name = \"dog\";\n}\n```\n\n2、新建一个config配置包，编写一个MyConfig配置类\n\n```\n@Configuration  //代表这是一个配置类\npublic class MyConfig {\n\n   @Bean //通过方法注册一个bean，这里的返回值就Bean的类型，方法名就是bean的id！\n   public Dog dog(){\n       return new Dog();\n  }\n\n}\n```\n\n3、测试\n\n```\n@Test\npublic void test2(){\n   ApplicationContext applicationContext =\n           new AnnotationConfigApplicationContext(MyConfig.class);\n   Dog dog = (Dog) applicationContext.getBean(\"dog\");\n   System.out.println(dog.name);\n}\n```\n\n4、成功输出结果！\n\n**导入其他配置如何做呢？**\n\n1、我们再编写一个配置类！\n\n```\n@Configuration  //代表这是一个配置类\npublic class MyConfig2 {\n}\n```\n\n2、在之前的配置类中我们来选择导入这个配置类\n\n```\n@Configuration\n@Import(MyConfig2.class)  //导入合并其他配置类，类似于配置文件中的 inculde 标签\npublic class MyConfig {\n\n   @Bean\n   public Dog dog(){\n       return new Dog();\n  }\n\n}\n```\n\n关于这种Java类的配置方式，我们在之后的SpringBoot 和 SpringCloud中还会大量看到，我们需要知道这些注解的作用即可！\n","tags":["spring"],"categories":["java全栈","spring"]},{"title":"Spring:依赖注入（DI）","url":"/2022/06/05/spring依赖注入（di）/","content":"\n- 依赖注入（Dependency Injection,DI）。\n- 依赖 : 指Bean对象的创建依赖于容器 . Bean对象的依赖资源 .\n- 注入 : 指Bean对象所依赖的资源 , 由容器来设置和装配\n\n## 构造器注入\n\n我们在之前的案例已经讲过了\n\n## Set 注入 （重点）\n\n要求被注入的属性 , 必须有set方法 , set方法的方法名由set + 属性首字母大写 , 如果属性是boolean类型 , 没有set方法 , 是 is .\n\n测试pojo类 :\n\nAddress.java\n\n```\n public class Address {\n \n     private String address;\n \n     public String getAddress() {\n         return address;\n    }\n \n     public void setAddress(String address) {\n         this.address = address;\n    }\n }\n```\n\nStudent.java\n\n```\n\n public class Student {\n \n     private String name;\n     private Address address;\n     private String[] books;\n     private List<String> hobbys;\n     private Map<String,String> card;\n     private Set<String> games;\n     private String wife;\n     private Properties info;\n \n     public void setName(String name) {\n         this.name = name;\n    }\n \n     public void setAddress(Address address) {\n         this.address = address;\n    }\n \n     public void setBooks(String[] books) {\n         this.books = books;\n    }\n \n     public void setHobbys(List<String> hobbys) {\n         this.hobbys = hobbys;\n    }\n \n     public void setCard(Map<String, String> card) {\n         this.card = card;\n    }\n \n     public void setGames(Set<String> games) {\n         this.games = games;\n    }\n \n     public void setWife(String wife) {\n         this.wife = wife;\n    }\n \n     public void setInfo(Properties info) {\n         this.info = info;\n    }\n \n     public void show(){\n         System.out.println(\"name=\"+ name\n                 + \",address=\"+ address.getAddress()\n                 + \",books=\"\n        );\n         for (String book:books){\n             System.out.print(\"<<\"+book+\">>\\t\");\n        }\n         System.out.println(\"\\n爱好:\"+hobbys);\n \n         System.out.println(\"card:\"+card);\n \n         System.out.println(\"games:\"+games);\n \n         System.out.println(\"wife:\"+wife);\n \n         System.out.println(\"info:\"+info);\n \n    }\n }\n```\n\n### 1、**常量注入**\n\n```\n <bean id=\"student\" class=\"com.kuang.pojo.Student\">\n     <property name=\"name\" value=\"小明\"/>\n </bean>\n```\n\n测试：\n\n```\n @Test\n public void test01(){\n     ApplicationContext context = new ClassPathXmlApplicationContext(\"applicationContext.xml\");\n \n     Student student = (Student) context.getBean(\"student\");\n \n     System.out.println(student.getName());\n \n }\n```\n\n### 2、**Bean注入**\n\n注意点：这里的值是一个引用，ref\n\n```\n <bean id=\"addr\" class=\"com.kuang.pojo.Address\">\n     <property name=\"address\" value=\"重庆\"/>\n </bean>\n \n <bean id=\"student\" class=\"com.kuang.pojo.Student\">\n     <property name=\"name\" value=\"小明\"/>\n     <property name=\"address\" ref=\"addr\"/>\n </bean>\n```\n\n### 3、数组注入\n\n```\n <bean id=\"student\" class=\"com.kuang.pojo.Student\">\n     <property name=\"name\" value=\"小明\"/>\n     <property name=\"address\" ref=\"addr\"/>\n     <property name=\"books\">\n         <array>\n             <value>西游记</value>\n             <value>红楼梦</value>\n             <value>水浒传</value>\n         </array>\n     </property>\n </bean>\n```\n\n### 4、**List注入**\n\n```\n <property name=\"hobbys\">\n     <list>\n         <value>听歌</value>\n         <value>看电影</value>\n         <value>爬山</value>\n     </list>\n </property>\n```\n\n### 5、**Map注入**\n\n```\n <property name=\"card\">\n     <map>\n         <entry key=\"中国邮政\" value=\"456456456465456\"/>\n         <entry key=\"建设\" value=\"1456682255511\"/>\n     </map>\n </property>\n```\n\n### 6、**set注入**\n\n```\n <property name=\"games\">\n     <set>\n         <value>LOL</value>\n         <value>BOB</value>\n         <value>COC</value>\n     </set>\n </property>\n```\n\n### 7、**Null注入**\n\n```\n <property name=\"wife\"><null/></property>\n```\n\n### 8、**Properties注入**\n\n```\n <property name=\"info\">\n     <props>\n         <prop key=\"学号\">20190604</prop>\n         <prop key=\"性别\">男</prop>\n         <prop key=\"姓名\">小明</prop>\n     </props>\n </property>\n```\n\n测试结果：\n\n![](http://192.168.5.54:8001/wp-content/uploads/2022/06/image-8.png)\n\n## p命名和c命名注入\n\nUser.java ：【注意：这里没有有参构造器！】\n\n```\n public class User {\n     private String name;\n     private int age;\n \n     public void setName(String name) {\n         this.name = name;\n    }\n \n     public void setAge(int age) {\n         this.age = age;\n    }\n \n     @Override\n     public String toString() {\n         return \"User{\" +\n                 \"name='\" + name + '\\'' +\n                 \", age=\" + age +\n                 '}';\n    }\n }\n```\n\n1、P命名空间注入 : 需要在头文件中加入约束文件\n\n```\n 导入约束 : xmlns:p=\"http://www.springframework.org/schema/p\"\n \n <!--P(属性: properties)命名空间 , 属性依然要设置set方法-->\n <bean id=\"user\" class=\"com.kuang.pojo.User\" p:name=\"狂神\" p:age=\"18\"/>\n```\n\n2、c 命名空间注入 : 需要在头文件中加入约束文件\n\n```\n 导入约束 : xmlns:c=\"http://www.springframework.org/schema/c\"\n <!--C(构造: Constructor)命名空间 , 属性依然要设置set方法-->\n <bean id=\"user\" class=\"com.kuang.pojo.User\" c:name=\"狂神\" c:age=\"18\"/>\n```\n\n发现问题：爆红了，刚才我们没有写有参构造！\n\n解决：把有参构造器加上，这里也能知道，c 就是所谓的构造器注入！\n\n测试代码：\n\n```\n @Test\n public void test02(){\n     ApplicationContext context = new ClassPathXmlApplicationContext(\"applicationContext.xml\");\n     User user = (User) context.getBean(\"user\");\n     System.out.println(user);\n }\n```\n\n## Bean的作用域\n\n在Spring中，那些组成应用程序的主体及由Spring IoC容器所管理的对象，被称之为bean。简单地讲，bean就是由IoC容器初始化、装配及管理的对象 .\n\n![](http://192.168.5.54:8001/wp-content/uploads/2022/06/image-9.png)\n\n几种作用域中，request、session作用域仅在基于web的应用中使用（不必关心你所采用的是什么web应用框架），只能用在基于web的Spring ApplicationContext环境。\n\n#### Singleton\n\n当一个bean的作用域为Singleton，那么Spring IoC容器中只会存在一个共享的bean实例，并且所有对bean的请求，只要id与该bean定义相匹配，则只会返回bean的同一实例。Singleton是单例类型，就是在创建起容器时就同时自动创建了一个bean的对象，不管你是否使用，他都存在了，每次获取到的对象都是同一个对象。注意，Singleton作用域是Spring中的缺省作用域。要在XML中将bean定义成singleton，可以这样配置：\n\n```\n <bean id=\"ServiceImpl\" class=\"cn.csdn.service.ServiceImpl\" scope=\"singleton\">\n```\n\n测试：\n\n```\n @Test\n public void test03(){\n     ApplicationContext context = new ClassPathXmlApplicationContext(\"applicationContext.xml\");\n     User user = (User) context.getBean(\"user\");\n     User user2 = (User) context.getBean(\"user\");\n     System.out.println(user==user2);\n }\n```\n\n#### Prototype\n\n当一个bean的作用域为Prototype，表示一个bean定义对应多个对象实例。Prototype作用域的bean会导致在每次对该bean请求（将其注入到另一个bean中，或者以程序的方式调用容器的getBean()方法）时都会创建一个新的bean实例。Prototype是原型类型，它在我们创建容器的时候并没有实例化，而是当我们获取bean的时候才会去创建一个对象，而且我们每次获取到的对象都不是同一个对象。根据经验，对有状态的bean应该使用prototype作用域，而对无状态的bean则应该使用singleton作用域。在XML中将bean定义成prototype，可以这样配置：\n\n```\n <bean id=\"account\" class=\"com.foo.DefaultAccount\" scope=\"prototype\"/>  \n  或者\n <bean id=\"account\" class=\"com.foo.DefaultAccount\" singleton=\"false\"/>\n```\n\n#### Request\n\n当一个bean的作用域为Request，表示在一次HTTP请求中，一个bean定义对应一个实例；即每个HTTP请求都会有各自的bean实例，它们依据某个bean定义创建而成。该作用域仅在基于web的Spring ApplicationContext情形下有效。考虑下面bean定义：\n\n```\n <bean id=\"loginAction\" class=cn.csdn.LoginAction\" scope=\"request\"/>\n```\n\n针对每次HTTP请求，Spring容器会根据loginAction bean的定义创建一个全新的LoginAction bean实例，且该loginAction bean实例仅在当前HTTP request内有效，因此可以根据需要放心的更改所建实例的内部状态，而其他请求中根据loginAction bean定义创建的实例，将不会看到这些特定于某个请求的状态变化。当处理请求结束，request作用域的bean实例将被销毁。\n\n#### Session\n\n当一个bean的作用域为Session，表示在一个HTTP Session中，一个bean定义对应一个实例。该作用域仅在基于web的Spring ApplicationContext情形下有效。考虑下面bean定义：\n\n```\n <bean id=\"userPreferences\" class=\"com.foo.UserPreferences\" scope=\"session\"/>\n```\n\n针对某个HTTP Session，Spring容器会根据userPreferences bean定义创建一个全新的userPreferences bean实例，且该userPreferences bean仅在当前HTTP Session内有效。与request作用域一样，可以根据需要放心的更改所创建实例的内部状态，而别的HTTP Session中根据userPreferences创建的实例，将不会看到这些特定于某个HTTP Session的状态变化。当HTTP Session最终被废弃的时候，在该HTTP Session作用域内的bean也会被废弃掉。\n","tags":["spring"],"categories":["java全栈","spring"]},{"title":"Spring:快速上手Spring","url":"/2022/06/05/spring快速上手spring/","content":"\n## HelloSpring\n\n> 导入Jar包\n\n注 : spring 需要导入commons-logging进行日志记录 . 我们利用maven , 他会自动下载对应的依赖项 .\n\n```\n<dependency>\n   <groupId>org.springframework</groupId>\n   <artifactId>spring-webmvc</artifactId>\n   <version>5.1.10.RELEASE</version>\n</dependency>\n```\n\n> 编写代码\n\n1、编写一个Hello实体类\n\n```\npublic class Hello {\n   private String name;\n   public String getName() {\n       return name;\n  }\n   public void setName(String name) {\n       this.name = name;\n  }\n   public void show(){\n       System.out.println(\"Hello,\"+ name );\n  }\n}\n```\n\n2、编写我们的spring文件 , 这里我们命名为beans.xml\n\n```\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<beans xmlns=\"http://www.springframework.org/schema/beans\"\n      xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n      xsi:schemaLocation=\"http://www.springframework.org/schema/beans\n       http://www.springframework.org/schema/beans/spring-beans.xsd\">\n   <!--bean就是java对象 , 由Spring创建和管理-->\n   <bean id=\"hello\" class=\"com.kuang.pojo.Hello\">\n       <property name=\"name\" value=\"Spring\"/>\n   </bean>\n\n</beans>\n```\n\n3、我们可以去进行测试了 .\n\n```\n@Test\npublic void test(){\n   //解析beans.xml文件 , 生成管理相应的Bean对象\n   ApplicationContext context = new ClassPathXmlApplicationContext(\"beans.xml\");\n   //getBean : 参数即为spring配置文件中bean的id .\n   Hello hello = (Hello) context.getBean(\"hello\");\n   hello.show();\n}\n```\n\n> 思考\n\n- Hello 对象是谁创建的 ?  【hello 对象是由Spring创建的\n- Hello 对象的属性是怎么设置的 ?  hello 对象的属性是由Spring容器设置的\n\n这个过程就叫控制反转 :\n\n- 控制 : 谁来控制对象的创建 , 传统应用程序的对象是由程序本身控制创建的 , 使用Spring后 , 对象是由Spring来创建的\n- 反转 : 程序本身不创建对象 , 而变成被动的接收对象 .\n\n依赖注入 : 就是利用set方法来进行注入的.\n\nIOC是一种编程思想，由主动的编程变成被动的接收\n\n可以通过newClassPathXmlApplicationContext去浏览一下底层源码 .\n\n> 修改案例一\n\n我们在案例一中， 新增一个Spring配置文件beans.xml\n\n```\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<beans xmlns=\"http://www.springframework.org/schema/beans\"\n      xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n      xsi:schemaLocation=\"http://www.springframework.org/schema/beans\n       http://www.springframework.org/schema/beans/spring-beans.xsd\">\n   <bean id=\"MysqlImpl\" class=\"com.kuang.dao.impl.UserDaoMySqlImpl\"/>\n   <bean id=\"OracleImpl\" class=\"com.kuang.dao.impl.UserDaoOracleImpl\"/>\n\n   <bean id=\"ServiceImpl\" class=\"com.kuang.service.impl.UserServiceImpl\">\n       <!--注意: 这里的name并不是属性 , 而是set方法后面的那部分 , 首字母小写-->\n       <!--引用另外一个bean , 不是用value 而是用 ref-->\n       <property name=\"userDao\" ref=\"OracleImpl\"/>\n   </bean>\n\n</beans>\n```\n\n测试！\n\n```\n@Test\npublic void test2(){\n   ApplicationContext context = new ClassPathXmlApplicationContext(\"beans.xml\");\n   UserServiceImpl serviceImpl = (UserServiceImpl) context.getBean(\"ServiceImpl\");\n   serviceImpl.getUser();\n}\n```\n\nOK , 到了现在 , 我们彻底不用再程序中去改动了 , 要实现不同的操作 , 只需要在xml配置文件中进行修改 , 所谓的IoC,一句话搞定 : 对象由Spring 来创建 , 管理 , 装配 !\n\n## IOC创建对象方式\n\n> 通过无参构造方法来创建\n\n1、User.java\n\n```\npublic class User {\n   private String name;\n   public User() {\n       System.out.println(\"user无参构造方法\");\n  }\n   public void setName(String name) {\n       this.name = name;\n  }\n   public void show(){\n       System.out.println(\"name=\"+ name );\n  }\n}\n```\n\n2、beans.xml\n\n```\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<beans xmlns=\"http://www.springframework.org/schema/beans\"\n      xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n      xsi:schemaLocation=\"http://www.springframework.org/schema/beans\n       http://www.springframework.org/schema/beans/spring-beans.xsd\">\n\n   <bean id=\"user\" class=\"com.kuang.pojo.User\">\n       <property name=\"name\" value=\"kuangshen\"/>\n   </bean>\n</beans>\n```\n\n3、测试类\n\n```\n@Test\npublic void test(){\n   ApplicationContext context = new ClassPathXmlApplicationContext(\"beans.xml\");\n   //在执行getBean的时候, user已经创建好了 , 通过无参构造\n   User user = (User) context.getBean(\"user\");\n   //调用对象的方法 .\n   user.show();\n}\n```\n\n结果可以发现，在调用show方法之前，User对象已经通过无参构造初始化了！\n\n> 通过有参构造方法来创建\n\n1、UserT . java\n\n```\npublic class UserT {\n\n   private String name;\n   public UserT(String name) {\n       this.name = name;\n  }\n\n   public void setName(String name) {\n       this.name = name;\n  }\n\n   public void show(){\n       System.out.println(\"name=\"+ name );\n  }\n\n}\n```\n\n2、beans.xml 有三种方式编写\n\n```\n<!-- 第一种根据index参数下标设置 -->\n<bean id=\"userT\" class=\"com.kuang.pojo.UserT\">\n   <!-- index指构造方法 , 下标从0开始 -->\n   <constructor-arg index=\"0\" value=\"kuangshen2\"/>\n</bean>\n```\n\n```\n<!-- 第二种根据参数名字设置 -->\n<bean id=\"userT\" class=\"com.kuang.pojo.UserT\">\n   <!-- name指参数名 -->\n   <constructor-arg name=\"name\" value=\"kuangshen2\"/>\n</bean>\n```\n\n```\n<!-- 第三种根据参数类型设置 -->\n<bean id=\"userT\" class=\"com.kuang.pojo.UserT\">\n   <constructor-arg type=\"java.lang.String\" value=\"kuangshen2\"/>\n</bean>\n```\n\n3、测试\n\n```\n@Test\npublic void testT(){\n   ApplicationContext context = new ClassPathXmlApplicationContext(\"beans.xml\");\n   UserT user = (UserT) context.getBean(\"userT\");\n   user.show();\n}\n```\n\n结论：在配置文件加载的时候。其中管理的对象都已经初始化了！\n\n## Spring配置\n\n> 别名\n\nalias 设置别名 , 为bean设置别名 , 可以设置多个别名\n\n```\n<!--设置别名：在获取Bean的时候可以使用别名获取-->\n<alias name=\"userT\" alias=\"userNew\"/>\n```\n\n> Bean的配置\n\n```\n<!--bean就是java对象,由Spring创建和管理-->\n\n<!--\n   id 是bean的标识符,要唯一,如果没有配置id,name就是默认标识符\n   如果配置id,又配置了name,那么name是别名\n   name可以设置多个别名,可以用逗号,分号,空格隔开\n   如果不配置id和name,可以根据applicationContext.getBean(.class)获取对象;\n\nclass是bean的全限定名=包名+类名\n-->\n<bean id=\"hello\" name=\"hello2 h2,h3;h4\" class=\"com.kuang.pojo.Hello\">\n   <property name=\"name\" value=\"Spring\"/>\n</bean>\n```\n\n> import\n\n团队的合作通过import来实现 .\n\n```\n<import resource=\"{path}/beans.xml\"/>\n```\n","tags":["spring"],"categories":["java全栈","spring"]},{"title":"Spring:概述及IOC理论推导","url":"/2022/06/05/spring概述及ioc理论推导/","content":"\n## 简介\n\nSpring : 春天 --->给软件行业带来了春天\n\n2002年，Rod Jahnson首次推出了Spring框架雏形interface21框架。\n\n2004年3月24日，Spring框架以interface21框架为基础，经过重新设计，发布了1.0正式版。\n\n很难想象Rod Johnson的学历 , 他是悉尼大学的博士，然而他的专业不是计算机，而是音乐学。\n\nSpring理念 : 使现有技术更加实用 . 本身就是一个大杂烩 , 整合现有的框架技术\n\n官网 : [http://spring.io/](http://spring.io/)\n\n官方下载地址 : [https://repo.spring.io/libs-release-local/org/springframework/spring/](https://repo.spring.io/libs-release-local/org/springframework/spring/)\n\n中文文档：[Spring Framework 中文文档 - Spring Framework 5.1.3.RELEASE Reference | Docs4dev](https://www.docs4dev.com/docs/zh/spring-framework/5.1.3.RELEASE/reference/)\n\nGitHub : [https://github.com/spring-project](https://github.com/spring-projects)\n\n## 优点\n\n1、Spring是一个开源免费的框架 , 容器  .\n\n2、Spring是一个轻量级的框架 , 非侵入式的 .\n\n**3、控制反转 IoC  , 面向切面 Aop**\n\n4、对事物的支持 , 对框架的支持\n\n.......\n\n一句话概括：\n\n**Spring是一个轻量级的控制反转(IoC)和面向切面(AOP)的容器（框架）。**\n\n## 组成\n\n![](http://192.168.5.54:8001/wp-content/uploads/2022/06/image-3.png)\n\nSpring 框架是一个分层架构，由 7 个定义良好的模块组成。Spring 模块构建在核心容器之上，核心容器定义了创建、配置和管理 bean 的方式 .\n\n![](http://192.168.5.54:8001/wp-content/uploads/2022/06/image-4.png)\n\n组成 Spring 框架的每个模块（或组件）都可以单独存在，或者与其他一个或多个模块联合实现。每个模块的功能如下：\n\n- **核心容器**：核心容器提供 Spring 框架的基本功能。核心容器的主要组件是 BeanFactory，它是工厂模式的实现。BeanFactory 使用_控制反转_（IOC） 模式将应用程序的配置和依赖性规范与实际的应用程序代码分开。\n- **Spring 上下文**：Spring 上下文是一个配置文件，向 Spring 框架提供上下文信息。Spring 上下文包括企业服务，例如 JNDI、EJB、电子邮件、国际化、校验和调度功能。\n- **Spring AOP**：通过配置管理特性，Spring AOP 模块直接将面向切面的编程功能 , 集成到了 Spring 框架中。所以，可以很容易地使 Spring 框架管理任何支持 AOP的对象。Spring AOP 模块为基于 Spring 的应用程序中的对象提供了事务管理服务。通过使用 Spring AOP，不用依赖组件，就可以将声明性事务管理集成到应用程序中。\n- **Spring DAO**：JDBC DAO 抽象层提供了有意义的异常层次结构，可用该结构来管理异常处理和不同数据库供应商抛出的错误消息。异常层次结构简化了错误处理，并且极大地降低了需要编写的异常代码数量（例如打开和关闭连接）。Spring DAO 的面向 JDBC 的异常遵从通用的 DAO 异常层次结构。\n- **Spring ORM**：Spring 框架插入了若干个 ORM 框架，从而提供了 ORM 的对象关系工具，其中包括 JDO、Hibernate 和 iBatis SQL Map。所有这些都遵从 Spring 的通用事务和 DAO 异常层次结构。\n- **Spring Web 模块**：Web 上下文模块建立在应用程序上下文模块之上，为基于 Web 的应用程序提供了上下文。所以，Spring 框架支持与 Jakarta Struts 的集成。Web 模块还简化了处理多部分请求以及将请求参数绑定到域对象的工作。\n- **Spring MVC 框架**：MVC 框架是一个全功能的构建 Web 应用程序的 MVC 实现。通过策略接口，MVC 框架变成为高度可配置的，MVC 容纳了大量视图技术，其中包括 JSP、Velocity、Tiles、iText 和 POI。\n\n## 拓展\n\n**Spring Boot与Spring Cloud**\n\n- Spring Boot 是 Spring 的一套快速配置脚手架，可以基于Spring Boot 快速开发单个微服务;\n- Spring Cloud是基于Spring Boot实现的；\n- Spring Boot专注于快速、方便集成的单个微服务个体，Spring Cloud关注全局的服务治理框架；\n- Spring Boot使用了约束优于配置的理念，很多集成方案已经帮你选择好了，能不配置就不配置 , Spring Cloud很大的一部分是基于Spring Boot来实现，Spring Boot可以离开Spring Cloud独立使用开发项目，但是Spring Cloud离不开Spring Boot，属于依赖的关系。\n- SpringBoot在SpringClound中起到了承上启下的作用，如果你要学习SpringCloud必须要学习SpringBoot。\n\n![](http://192.168.5.54:8001/wp-content/uploads/2022/06/image-5.png)\n\n## IOC基础\n\n新建一个空白的maven项目\n\n> 分析实现\n\n我们先用我们原来的方式写一段代码 .\n\n1、先写一个UserDao接口\n\n```\npublic interface UserDao {\n   public void getUser();\n}\n```\n\n2、再去写Dao的实现类\n\n```\npublic class UserDaoImpl implements UserDao {\n   @Override\n   public void getUser() {\n       System.out.println(\"获取用户数据\");\n  }\n}\n```\n\n3、然后去写UserService的接口\n\n```\npublic interface UserService {\n   public void getUser();\n}\n```\n\n4、最后写Service的实现类\n\n```\npublic class UserServiceImpl implements UserService {\n   private UserDao userDao = new UserDaoImpl();\n\n   @Override\n   public void getUser() {\n       userDao.getUser();\n  }\n}\n```\n\n5、测试一下\n\n```\n@Test\npublic void test(){\n   UserService service = new UserServiceImpl();\n   service.getUser();\n}\n```\n\n这是我们原来的方式 , 开始大家也都是这么去写的对吧 . 那我们现在修改一下 .\n\n把Userdao的实现类增加一个 .\n\n```\npublic class UserDaoMySqlImpl implements UserDao {\n   @Override\n   public void getUser() {\n       System.out.println(\"MySql获取用户数据\");\n  }\n}\n```\n\n紧接着我们要去使用MySql的话 , 我们就需要去service实现类里面修改对应的实现\n\n```\npublic class UserServiceImpl implements UserService {\n   private UserDao userDao = new UserDaoMySqlImpl();\n\n   @Override\n   public void getUser() {\n       userDao.getUser();\n  }\n}\n```\n\n在假设, 我们再增加一个Userdao的实现类 .\n\n```\npublic class UserDaoOracleImpl implements UserDao {\n   @Override\n   public void getUser() {\n       System.out.println(\"Oracle获取用户数据\");\n  }\n}\n```\n\n那么我们要使用Oracle , 又需要去service实现类里面修改对应的实现 . 假设我们的这种需求非常大 , 这种方式就根本不适用了, 甚至反人类对吧 , 每次变动 , 都需要修改大量代码 . 这种设计的耦合性太高了, 牵一发而动全身 .\n\n**那我们如何去解决呢 ?**\n\n我们可以在需要用到他的地方 , 不去实现它 , 而是留出一个接口 , 利用set , 我们去代码里修改下 .\n\n```\npublic class UserServiceImpl implements UserService {\n   private UserDao userDao;\n// 利用set实现\n   public void setUserDao(UserDao userDao) {\n       this.userDao = userDao;\n  }\n\n   @Override\n   public void getUser() {\n       userDao.getUser();\n  }\n}\n```\n\n现在去我们的测试类里 , 进行测试 ;\n\n```\n@Test\npublic void test(){\n   UserServiceImpl service = new UserServiceImpl();\n   service.setUserDao( new UserDaoMySqlImpl() );\n   service.getUser();\n   //那我们现在又想用Oracle去实现呢\n   service.setUserDao( new UserDaoOracleImpl() );\n   service.getUser();\n}\n```\n\n大家发现了区别没有 ? 可能很多人说没啥区别 . 但是同学们 , 他们已经发生了根本性的变化 , 很多地方都不一样了 . 仔细去思考一下 , 以前所有东西都是由程序去进行控制创建 , 而现在是由我们自行控制创建对象 , 把主动权交给了调用者 . 程序不用去管怎么创建,怎么实现了 . 它只负责提供一个接口 .\n\n这种思想 , 从本质上解决了问题 , 我们程序员不再去管理对象的创建了 , 更多的去关注业务的实现 . 耦合性大大降低 . 这也就是IOC的原型 !\n\n## IOC本质\n\n**控制反转IoC(Inversion of Control)，是一种设计思想，DI(依赖注入)是实现IoC的一种方法**，也有人认为DI只是IoC的另一种说法。没有IoC的程序中 , 我们使用面向对象编程 , 对象的创建与对象间的依赖关系完全硬编码在程序中，对象的创建由程序自己控制，控制反转后将对象的创建转移给第三方，个人认为所谓控制反转就是：获得依赖对象的方式反转了。\n\n![](http://192.168.5.54:8001/wp-content/uploads/2022/06/image-6.png)\n\n**IoC是Spring框架的核心内容**，使用多种方式完美的实现了IoC，可以使用XML配置，也可以使用注解，新版本的Spring也可以零配置实现IoC。\n\nSpring容器在初始化时先读取配置文件，根据配置文件或元数据创建与组织对象存入容器中，程序使用时再从Ioc容器中取出需要的对象。\n\n![](http://192.168.5.54:8001/wp-content/uploads/2022/06/image-7.png)\n\n采用XML方式配置Bean的时候，Bean的定义信息是和实现分离的，而采用注解的方式可以把两者合为一体，Bean的定义信息直接以注解的形式定义在实现类中，从而达到了零配置的目的。\n\n**控制反转是一种通过描述（XML或注解）并通过第三方去生产或获取特定对象的方式。在Spring中实现控制反转的是IoC容器，其实现方法是依赖注入（Dependency Injection,DI）。**\n","tags":["spring"],"categories":["java全栈","spring"]},{"title":"SpringBoot-HelloWorld!","url":"/2022/06/03/springboot-helloworld/","content":"\n## 什么是Spring\n\nSpring是一个开源框架，2003年兴起的一个轻量级的Java开发框架，作者：Rod Johnson。\n\n**Spring是为了解决企业级应用开发的复杂性而创建的，简化开发。**\n\n## Spring是如何简化Java开发的\n\n为了降低Java开发的复杂性，Spring采用了以下4种关键策略：\n\n1. 基于POJO的轻量级和最小侵入性编程；\n2. 通过IOC，依赖注入（DI）和面向接口实现轻松耦合；\n3. 基于切面（AOP）和惯例进行声明式编程；\n4. 通过切面和模板减少样式代码；\n\n## 什么是SpringBoot\n\n学过javaweb的同学就知道，开发一个web应用，从最初开始接触Servlet结合Tomcat, 跑出一个Hello Wolrld程序，是要经历特别多的步骤；后来就用了框架Struts，再后来是SpringMVC，到了现在的SpringBoot，过一两年又会有其他web框架出现；你们有经历过框架不断的演进，然后自己开发项目所有的技术也在不断的变化、改造吗？建议都可以去经历一遍；言归正传，什么是SpringBoot呢，就是一个javaweb的开发框架，和SpringMVC类似，对比其他javaweb框架的好处，官方说是简化开发，约定大于配置，  you can \"just run\"，能迅速的开发web应用，几行代码开发一个http接口。\n\n所有的技术框架的发展似乎都遵循了一条主线规律：从一个复杂应用场景 衍生 一种规范框架，人们只需要进行各种配置而不需要自己去实现它，这时候强大的配置功能成了优点；发展到一定程度之后，人们根据实际生产应用情况，选取其中实用功能和设计精华，重构出一些轻量级的框架；之后为了提高开发效率，嫌弃原先的各类配置过于麻烦，于是开始提倡“约定大于配置”，进而衍生出一些一站式的解决方案。\n\n是的这就是Java企业级应用->J2EE->spring->springboot的过程。\n\n随着 Spring 不断的发展，涉及的领域越来越多，项目整合开发需要配合各种各样的文件，慢慢变得不那么易用简单，违背了最初的理念，甚至人称配置地狱。Spring Boot 正是在这样的一个背景下被抽象出来的开发框架，目的为了让大家更容易的使用 Spring 、更容易的集成各种常用的中间件、开源软件；\n\nSpring Boot 基于 Spring 开发，Spirng Boot 本身并不提供 Spring 框架的核心特性以及扩展功能，只是用于快速、敏捷地开发新一代基于 Spring 框架的应用程序。也就是说，它并不是用来替代 Spring 的解决方案，而是和 Spring 框架紧密结合用于提升 Spring 开发者体验的工具。Spring Boot 以**约定大于配置的核心思想**，默认帮我们进行了很多设置，多数 Spring Boot 应用只需要很少的 Spring 配置。同时它集成了大量常用的第三方库配置（例如 Redis、MongoDB、Jpa、RabbitMQ、Quartz 等等），Spring Boot 应用中这些第三方库几乎可以零配置的开箱即用。\n\n简单来说就是SpringBoot其实不是什么新的框架，它默认配置了很多框架的使用方式，就像maven整合了所有的jar包，spring boot整合了所有的框架 。\n\nSpring Boot 出生名门，从一开始就站在一个比较高的起点，又经过这几年的发展，生态足够完善，Spring Boot 已经当之无愧成为 Java 领域最热门的技术。\n\n**Spring Boot的主要优点：**\n\n- 为所有Spring开发者更快的入门\n- **开箱即用**，提供各种默认配置来简化项目配置\n- 内嵌式容器简化Web项目\n- 没有冗余代码生成和XML配置的要求\n\n真的很爽，我们快速去体验开发个接口的感觉吧！\n\n## 微服务\n\n### 什么是微服务？\n\n微服务是一种单体架构风格，它要求我们在开发一个应用的时候，这个应用必须构建成一系列小服务的组合；可以通过http的方式进行互通。要说微服务架构，先得说说我们的单体应用架构。\n\n### 单体应用架构\n\n在项目中，我们通常将需求分为三个部分：数据库、服务器处理、前端展示。如果这些需求都实现在了同一个应用中，那么这个项目就是单体架构的。在项目发展初期，由于所有的业务逻辑写在一个应用中，开发、测试、部署变得简单高效。但是，随着业务不断扩大、需求不断增多，代码会越来越臃肿，系统变得难以维护。试想，当只需要修改一个很小的功能时，由于所以功能模块都写在同一个应用，重新部署会影响其他功能正常运行。另外，当项目太过庞大臃肿时，系统优化也是一道难题。每个功能模块的并发量、使用场景、消耗的资源类型都不同，但是它们都在同一个应用中，这就使得我们对各个功能模块的容量很难做出评估，难以对个别模块进行优化。\n\n### 微服务架构\n\n微服务架构是一项在云中部署应用和服务的新技术。大部分围绕微服务的争论都集中在容器或其他技术是否能很好的实施微服务，而红帽说API应该是重点。\n\n微服务可以在“自己的程序”中运行，并通过“轻量级设备与HTTP型API进行沟通”。关键在于该服务可以在自己的程序中运行。通过这一点我们就可以将服务公开与微服务架构（在现有系统中分布一个API）区分开来。在服务公开中，许多服务都可以被内部独立进程所限制。如果其中任何一个服务需要增加某种功能，那么就必须缩小进程范围。在微服务架构中，只需要在特定的某种服务中增加所需功能，而不影响整体进程的架构。\n\n## Hello World\n\n### 准备工作\n\n我们将学习如何快速的创建一个Spring Boot应用，并且实现一个简单的Http请求处理。通过这个例子对Spring Boot有一个初步的了解，并体验其结构简单、开发快速的特性。\n\n我的环境准备：\n\n- java version \"1.8.0\\_181\"\n- Maven-3.6.1\n- SpringBoot 2.x 最新版\n\n开发工具：\n\n- IDEA\n\n### 创建基础项目说明\n\nSpring官方提供了非常方便的工具让我们快速构建应用\n\nSpring Initializr：[https://start.spring.io/](https://start.spring.io/)\n\n**项目创建方式一：**使用Spring Initializr 的 Web页面创建项目\n\n1、打开  [https://start.spring.io/](https://start.spring.io/)\n\n2、填写项目信息\n\n3、点击”Generate Project“按钮生成项目；下载此项目\n\n4、解压项目包，并用IDEA以Maven项目导入，一路下一步即可，直到项目导入完毕。\n\n5、如果是第一次使用，可能速度会比较慢，包比较多、需要耐心等待一切就绪。\n\n**项目创建方式二：**使用 IDEA 直接创建项目\n\n1、创建一个新项目\n\n2、选择spring initalizr ， 可以看到默认就是去官网的快速构建工具那里实现\n\n3、填写项目信息\n\n4、选择初始化的组件（初学勾选 Web 即可）\n\n5、填写项目路径\n\n6、等待项目构建成功\n\n**项目结构分析：**\n\n通过上面步骤完成了基础项目的创建。就会自动生成以下文件。\n\n1、程序的主启动类\n\n2、一个 application.properties 配置文件\n\n3、一个 测试类\n\n4、一个 pom.xml\n\n### pom.xml分析\n\n打开pom.xml，看看Spring Boot项目的依赖：\n\n```\n\n<!-- 父依赖 -->\n<parent>\n    <groupId>org.springframework.boot</groupId>\n    <artifactId>spring-boot-starter-parent</artifactId>\n    <version>2.2.5.RELEASE</version>\n    <relativePath/>\n</parent>\n\n<dependencies>\n    <!-- web场景启动器 -->\n    <dependency>\n        <groupId>org.springframework.boot</groupId>\n        <artifactId>spring-boot-starter-web</artifactId>\n    </dependency>\n    <!-- springboot单元测试 -->\n    <dependency>\n        <groupId>org.springframework.boot</groupId>\n        <artifactId>spring-boot-starter-test</artifactId>\n        <scope>test</scope>\n        <!-- 剔除依赖 -->\n        <exclusions>\n            <exclusion>\n                <groupId>org.junit.vintage</groupId>\n                <artifactId>junit-vintage-engine</artifactId>\n            </exclusion>\n        </exclusions>\n    </dependency>\n</dependencies>\n\n<build>\n    <plugins>\n        <!-- 打包插件 -->\n        <plugin>\n            <groupId>org.springframework.boot</groupId>\n            <artifactId>spring-boot-maven-plugin</artifactId>\n        </plugin>\n    </plugins>\n</build>\n```\n\n### 编写一个http接口\n\n1、在主程序的同级目录下，新建一个controller包，一定要在同级目录下，否则识别不到\n\n2、在包中新建一个HelloController类\n\n```\n\n@RestController\npublic class HelloController {\n\n    @RequestMapping(\"/hello\")\n    public String hello() {\n        return \"Hello World\";\n    }\n    \n}\n```\n\n`3、编写完毕后，从主程序启动项目，浏览器发起请求，看页面返回；控制台输出了 Tomcat 访问的端口号！`\n\n![](http://192.168.5.54:8001/wp-content/uploads/2022/06/image-1024x191.png)\n\n简单几步，就完成了一个web接口的开发，SpringBoot就是这么简单。所以我们常用它来建立我们的微服务项目！\n\n### 将项目打成jar包，点击 maven的 package\n\n![](http://192.168.5.54:8001/wp-content/uploads/2022/06/image-1-1024x619.png)\n\n如果遇到以上错误，可以配置打包时 跳过项目运行测试用例\n\n```\n<!-- 在工作中,很多情况下我们打包是不想执行测试用例的    可能是测试用例不完事,或是测试用例会影响数据库数据    跳过测试用例执    --><plugin>    <groupId>org.apache.maven.plugins</groupId>    <artifactId>maven-surefire-plugin</artifactId>    <configuration>        <!--跳过项目运行测试用例-->        <skipTests>true</skipTests>    </configuration></plugin>\n```\n\n如果打包成功，则会在target目录下生成一个 jar 包\n\n![](http://192.168.5.54:8001/wp-content/uploads/2022/06/image-2-1024x590.png)\n\n打成了jar包后，就可以在任何地方运行了！O\n\n### 彩蛋\n\n如何更改启动时显示的字符拼成的字母，SpringBoot呢？也就是 banner 图案；\n\n只需一步：到项目下的 resources 目录下新建一个banner.txt 即可。\n\n图案可以到：https://www.bootschool.net/ascii 这个网站生成，然后拷贝到文件中即可！\n","tags":["springboot"],"categories":["springboot"]},{"title":"Android使用SQLite基础","url":"/2022/06/02/android使用sqlite基础/","content":"\n**SQLite 是一个软件库，实现了自给自足的、无服务器的、零配置的、事务性的 SQL 数据库引擎。SQLite 是在世界上最广泛部署的 SQL 数据库引擎。SQLite 源代码不受版权限制。**\n\n### SQLite数据库创建\n\nAndroid提供了一个SQLiteOpenHelper帮助类，用于对数据库进行创建和升级  \nSQLiteOpenHelper是一个抽象类，使用时需要创建自己的类去继承它。  \nSQLiteOpenHelper有两个抽象方法onCreate()和onUpgrade()，必须在自己的类中重写这两个方法，然后分别在这两个方法中实现创建和升级数据库的逻辑。\n\n```\npublic class MySQLiteOpenHelper extends SQLiteOpenHelper {\n\n    //使用静态数据定义数据库\n    private static final String SQL_NAME = \"mySQL.db\";\n    private static final String TABLE_NAME = \"myAccount\";\n    private static final String CREATE_TABLE_SQL = \"create table \"+TABLE_NAME+\" (id Integer primary key autoincrement, account text, password text); \\n\" ;\n\n    public MySQLiteOpenHelper(Context context){\n        super(context,SQL_NAME,null,1);\n    }\n//    public MySQLiteOpenHelper(@Nullable Context context, @Nullable String name, @Nullable SQLiteDatabase.CursorFactory factory, int version) {\n//        super(context, name, factory, version);\n//    }\n\n\n    //onCreate方法只执行一次\n    @Override\n    public void onCreate(SQLiteDatabase sqLiteDatabase) {\n        sqLiteDatabase.execSQL(CREATE_TABLE_SQL);\n    }\n\n    @Override\n    public void onUpgrade(SQLiteDatabase sqLiteDatabase, int i, int i1) {\n\n    }\n    //自己写的插入数据方法\n    public long insertData(MyAccount myAccount){\n\n        final SQLiteDatabase db = getWritableDatabase();\n        //ContentValues专门存储列名和数据，是键值对。\n        ContentValues values = new ContentValues();\n\n        values.put(\"account\",myAccount.getAccount_name());\n        values.put(\"password\",myAccount.getPassword());\n\n        return db.insert(TABLE_NAME,null,values);\n    }\n}\n```\n\n我自己写了一个注册页面，代码如下：\n\n```\npublic class RegisterActivity extends AppCompatActivity {\n\n\n    private MySQLiteOpenHelper mySQLiteOpenHelper;\n\n    private TextView login;\n    private Button commit;\n    private EditText account;\n    private EditText password;\n\n\n    @Override\n    protected void onCreate(Bundle savedInstanceState) {\n        super.onCreate(savedInstanceState);\n        setContentView(R.layout.activity_register);\n        mySQLiteOpenHelper = new MySQLiteOpenHelper(this);\n        initView();\n\n        login.setOnClickListener(new View.OnClickListener() {\n            @Override\n            public void onClick(View view) {\n                myStartActivity();\n                finish();\n            }\n        });\n\n\n        commit.setOnClickListener(new View.OnClickListener() {\n            @Override\n            public void onClick(View view) {\n                Handler handler = new Handler();\n                if (isValid(account,password)){\n                    String acc = account.getText().toString().trim();\n                    String pass = password.getText().toString().trim();\n                    MyAccount myAccount = new MyAccount();\n                    myAccount.setAccount_name(acc);\n                    myAccount.setPassword(pass);\n\n                    long rId = mySQLiteOpenHelper.insertData(myAccount);\n\n                    if (rId!=-1){\n                        Toast.makeText(getApplicationContext(),\"注册成功！！！\",Toast.LENGTH_SHORT).show();\n                    }else {\n                        Toast.makeText(getApplicationContext(),\"注册失败,数据库插入失败\",Toast.LENGTH_SHORT).show();\n                    }\n\n//                    Toast.makeText(getApplicationContext(),\"注册成功！！！\",Toast.LENGTH_SHORT).show();\n                    handler.postDelayed(new Runnable() {\n                        @Override\n                        public void run() {\n                            myStartActivity();\n                            handler.removeCallbacksAndMessages(null);\n                            finish();\n                        }\n                    },2000);\n\n\n\n                }else{\n                    Toast.makeText(getApplicationContext(),\"注册失败，账号长度大于4小于16，密码长度大于3小于16\",Toast.LENGTH_SHORT).show();\n                }\n            }\n        });\n    }\n\n    private boolean isValid(EditText account, EditText password) {\n        int acc_len =account.getText().toString().length();\n        int pass_len = password.getText().toString().length();\n        if (acc_len<16&&acc_len>4&&pass_len>3&&pass_len<16){\n            return true;\n        }\n        return false;\n    }\n\n    private void myStartActivity() {\n        Intent intent = new Intent(RegisterActivity.this,LoginActivity.class);\n        startActivity(intent);\n    }\n\n\n    private void initView() {\n        login = findViewById(R.id.login_login);\n        commit = findViewById(R.id.login_commit);\n        account = findViewById(R.id.login_account);\n        password = findViewById(R.id.login_password);\n    }\n}\n```\n\nandroid studio查看数据库：\n\n![image-20220430234915901](https://presenter.oss-cn-shanghai.aliyuncs.com/image-20220430234915901.png)\n\n在data/data/com.你的项目位置/databases 里面\n","tags":["android"],"categories":["android"]},{"title":"Android将图片插入数据库","url":"/2022/06/02/android将图片插入数据库/","content":"\n### 方法\n\n方法一：将图片解析为二进制的数据，然后放入到数据库中的一种BLOD类型中\n\n方法二：保存图片的URL路径\n\n方法三：其实还可以将图片存放到本地文件，那么就以后直接从本地文件进行获取就可以了，但是这就是需要注意下，就是要保证路径都是唯一的，这里可以用时间戳进行产生，或者用我上一篇的第18点中讲到的一些产生Token的方法。\n\n这里讲方法一：\n\n### 一：创建数据库\n\n```\n//表名friend，图像用blob存储，blob实际也是二进制存储\n\nprivate static final String CREATE_TABLE_FRIEND = \"create table friend ( id Integer primary key autoincrement, img blob, name text ); \\n\" ;\n\n\n @Override\n    public void onCreate(SQLiteDatabase sqLiteDatabase) {\n        //sqLiteDatabase.execSQL(createTable(TABLE_NAME));\n        //sqLiteDatabase.execSQL(CREATE_TABLE_SQL);\n\n\n        sqLiteDatabase.execSQL(CREATE_TABLE_FRIEND);\n\n    }\n\n\n//插入数据库方法，这里为了测试是否插入成功所以返回了long型。    \npublic long insertFriend(Friend friend){\n\n        final SQLiteDatabase db = getWritableDatabase();\n\n        ContentValues values = new ContentValues();\n\n        values.put(\"img\",friend.getHeadImg());\n        values.put(\"name\",friend.getName());\n\n        return db.insert(\"friend\",null,values);\n    }\n\n    //将图片转换为二进制数组，并且返回。\n    private byte[] getPicture(Drawable drawable) {\n        if(drawable == null) {\n            return null;\n        }\n        BitmapDrawable bd = (BitmapDrawable) drawable;\n        Bitmap bitmap = bd.getBitmap();\n        ByteArrayOutputStream os = new ByteArrayOutputStream();\n        bitmap.compress(Bitmap.CompressFormat.PNG, 100, os);\n        return os.toByteArray();\n    }\n\n\n        String[] columns = {\"img\", \"name\"};\n        Cursor cursor = sqLiteDatabase.query(\"friend\", columns, null, null, null, null, null);\n    //绑定Viewholder\n    @Override\n    public void onBindViewHolder(@NonNull MyViewHoder holder, int position) {\n        Friend friend = friends.get(position);\n        //将二进制重新加载为图片\n        Bitmap b = BitmapFactory.decodeByteArray(friend.getHeadImg(), 0, friend.getHeadImg().length);\n        //设置组件的图片\n        holder.img.setImageBitmap(b);\n        holder.name.setText(friend.name);\n    }\n    //给add组件设置监听事件，里面完成相关操作\n    add.setOnClickListener(new View.OnClickListener() {\n            @Override\n            public void onClick(View view) {\n                friend = new Friend();\n                //获取需要存进数据库的图片\n                Drawable drawable = getContext().getResources().getDrawable(R.drawable.login_header_img);\n                //将其转换为byte型。\n                byte[] a = getPicture(drawable);\n                //放进friend对象\n                friend.setHeadImg(a);\n                friend.setName(\"seawdawdaw\");\n                mySQLiteOpenHelper = new MySQLiteOpenHelper(getContext());\n                mySQLiteOpenHelper.insertFriend(friend);\n                //mMyAdapter.notifyDataSetChanged();\n            }\n        });\n```\n\n### 方法二\n\n从服务器上取到图片地址，比如image/XXX/1233455.JPG 然后自己定义一个字符串baseUrl = 10.0.2.2:8080/Demo/ ,和取到的地址拼起来。 总之意思就是你不是直接得到图片，而是得到图片的地址，然后根据地址取出来图片。比如：\n\n```\n    // 传输网络图片\n    public Bitmap getPic(String uriPic) {\n        URL imageUrl = null;\n        Bitmap bitmap = null;\n        try {\n            imageUrl = new URL(uriPic);\n        } catch (MalformedURLException e) {\n            e.printStackTrace();\n        }\n        try {\n            HttpURLConnection conn = (HttpURLConnection) imageUrl\n                    .openConnection();\n            conn.connect();\n            InputStream is = conn.getInputStream();\n            bitmap = BitmapFactory.decodeStream(is);\n            is.close();\n        } catch (IOException e) {\n            e.printStackTrace();\n        }\n        return bitmap;\n    }\n```\n\n取到后相对图片再做处理的话就 bmp = Bitmap.createScaledBitmap(bmp, 长,宽, true);\n","tags":["android"],"categories":["android"]},{"title":"Android的Fragment实现导航栏","url":"/2022/06/02/android的fragment实现导航栏/","content":"\n这里只粘贴关键代码，留作自己遗忘查看\n\n首先activity\\_main.xml\n\n```\n<?xml version=\"1.0\" encoding=\"utf-8\"?>\n<LinearLayout xmlns:android=\"http://schemas.android.com/apk/res/android\"\n    xmlns:app=\"http://schemas.android.com/apk/res-auto\"\n    xmlns:tools=\"http://schemas.android.com/tools\"\n    android:layout_width=\"match_parent\"\n    android:layout_height=\"match_parent\"\n    android:orientation=\"vertical\"\n    tools:context=\".MainActivity\"\n    android:background=\"@color/white\">\n\n    <FrameLayout\n        android:background=\"@color/background\"\n        android:id=\"@+id/main_frame\"\n        android:layout_weight=\"1\"\n        android:layout_width=\"match_parent\"\n        android:layout_height=\"0dp\"/>\n\n\n    <RadioGroup\n        android:id=\"@+id/rg_main\"\n        android:background=\"@color/white\"\n        android:padding=\"5dp\"\n        android:orientation=\"horizontal\"\n        android:layout_width=\"match_parent\"\n        android:layout_height=\"wrap_content\"\n        >\n        <RadioButton\n            style=\"@style/Bottom_tab_style\"\n            android:id=\"@+id/rb_index\"\n            android:drawableTop=\"@drawable/main_nav_index\"\n            android:text=\"首页\" />\n        <!--@drawable/main_nav_index：首页对应的图标图片-->\n        <RadioButton\n            style=\"@style/Bottom_tab_style\"\n            android:id=\"@+id/rb_message\"\n            android:drawableTop=\"@drawable/main_nav_message\"\n            android:text=\"消息\" />\n        <RadioButton\n            style=\"@style/Bottom_tab_style\"\n            android:id=\"@+id/rb_friend\"\n            android:drawableTop=\"@drawable/main_nav_friend\"\n            android:text=\"好友\" />\n        <RadioButton\n            style=\"@style/Bottom_tab_style\"\n            android:id=\"@+id/rb_friend_circle\"\n            android:drawableTop=\"@drawable/main_nav_friend_circle\"\n            android:text=\"生活圈\" />\n    </RadioGroup>\n\n</LinearLayout>\n```\n\n上述xml文件中的style.xml：\n\n```\n<?xml version=\"1.0\" encoding=\"utf-8\"?>\n<resources>\n    <style name=\"Bottom_tab_style\" >\n        <item name=\"android:layout_width\">wrap_content</item>\n        <item name=\"android:layout_height\">wrap_content</item>\n        <item name=\"android:layout_weight\">1</item>\n        <item name=\"android:textColor\">@drawable/main_nav_text_color</item>\n        <item name=\"android:gravity\">center</item>\n        <item name=\"android:button\">@null</item>\n        <item name=\"android:textSize\">14sp</item>\n    </style>\n</resources>\n```\n\nmain\\_nav\\_text\\_color.xml:\n\n其他三个也是同样的写法\n\n```\n<?xml version=\"1.0\" encoding=\"utf-8\"?>\n<selector xmlns:android=\"http://schemas.android.com/apk/res/android\">\n    <item\n        android:state_checked=\"false\"\n        android:color=\"@color/black\"\n        />\n    <item\n        android:state_checked=\"true\"\n        android:color=\"#ff8fdf\" />\n</selector>\n```\n\nIndexFragment：\n\n```\npublic class IndexFragment extends Fragment {\n    @Nullable\n    @Override\n    public View onCreateView(@NonNull LayoutInflater inflater, @Nullable ViewGroup container, @Nullable Bundle savedInstanceState) {\n        View view = inflater.inflate(R.layout.fragment_index,null);\n        return view;\n//        return super.onCreateView(inflater, container, savedInstanceState);\n    }\n}\n```\n\nMainActivity.java文件：\n\n```\npublic class MainActivity extends FragmentActivity {\n\n    private FragmentManager mFragmentManager;\n    //这四个分别是底部导航栏的四个分类，源文件在上方\n    private IndexFragment indexFragment;\n    private MessageFragment messageFragment;\n    private FriendCircleFragment friendCircleFragment;\n    private FriendFragment friendfragment;\n\n    private FragmentTransaction mTransaction;\n\n    private FrameLayout main_frame;\n    private RadioGroup rg_main;\n    private RadioButton rb_index;\n    private RadioButton rb_message;\n    private RadioButton rb_friend;\n    private RadioButton rb_friend_circle;\n\n    private int position;\n\n    private List<Fragment> fragments = new ArrayList<>();\n\n    @Override\n    protected void onCreate(Bundle savedInstanceState) {\n        super.onCreate(savedInstanceState);\n        setContentView(R.layout.activity_main);\n        main_frame = findViewById(R.id.main_frame);\n        rg_main = findViewById(R.id.rg_main);\n        rb_index = findViewById(R.id.rb_index);\n        rb_message = findViewById(R.id.rb_message);\n        rb_friend = findViewById(R.id.rb_friend);\n        rb_friend_circle = findViewById(R.id.rb_friend_circle);\n\n        initView();\n    }\n\n\n    //设置返回按钮不是退出软件，而是返回主页。\n    @Override\n    public boolean onKeyDown(int keyCode, KeyEvent event) {\n        if(keyCode == event.KEYCODE_BACK){\n            moveTaskToBack(false);\n            return true;\n        }\n        return super.onKeyDown(keyCode, event);\n    }\n    //初始化每个Fragment\n    private void initView(){\n        mFragmentManager = getSupportFragmentManager();\n        mTransaction = mFragmentManager.beginTransaction();\n        rg_main.check(R.id.rb_index);\n        indexFragment = new IndexFragment();\n        fragments.add(indexFragment);\n        hideOtherFragment(indexFragment,true);\n        rg_main.setOnCheckedChangeListener(new RadioGroup.OnCheckedChangeListener() {\n            @Override\n            public void onCheckedChanged(RadioGroup radioGroup, int i) {\n                switch (i){\n                    case R.id.rb_index:\n                        position = 0;\n                        hideOtherFragment(indexFragment,false);\n                        System.out.println(\"切换成功！！\");\n                        break;\n                    case R.id.rb_message:\n                        position = 1;\n                        if (messageFragment==null){\n                            messageFragment = new MessageFragment();\n                            fragments.add(messageFragment);\n                            hideOtherFragment(messageFragment,true);\n                            System.out.println(\"切换成功！！\");\n                        }else{\n                            hideOtherFragment(messageFragment,false);\n                            System.out.println(\"切换成功！！\");\n                        }\n                        break;\n                    case R.id.rb_friend:\n                        position = 2;\n                        if (friendfragment==null){\n                            friendfragment = new FriendFragment();\n                            fragments.add(friendfragment);\n                            hideOtherFragment(friendfragment,true);\n                            System.out.println(\"切换成功！！\");\n                        }else{\n                            hideOtherFragment(friendfragment,false);\n                            System.out.println(\"切换成功！！\");\n                        }\n                        break;\n                    case R.id.rb_friend_circle:\n                        position = 3;\n                        if(friendCircleFragment == null){\n                            friendCircleFragment = new FriendCircleFragment();\n                            fragments.add(friendCircleFragment);\n                            hideOtherFragment(friendCircleFragment,true);\n                            System.out.println(\"切换成功！！\");\n                        }else{\n                            hideOtherFragment(friendCircleFragment,false);\n                            System.out.println(\"切换成功！！\");\n                        }\n                        break;\n                }\n            }\n        });\n\n    }\n\n    private void hideOtherFragment(Fragment showFragment, boolean add) {\n        mTransaction = mFragmentManager.beginTransaction();\n        if (add){\n            mTransaction.add(R.id.main_frame,showFragment);\n        }\n        for (Fragment fragment:fragments){\n\n            if (showFragment.equals(fragment)){\n                mTransaction.show(fragment);\n                //打印当前fragment\n                System.out.println(showFragment);\n            }else{\n                mTransaction.hide(fragment);\n            }\n        }\n        mTransaction.commit();\n    }\n}\n```\n\n展示图片：\n\n![image-20220428223342959](https://presenter.oss-cn-shanghai.aliyuncs.com/image-20220428223342959.png)\n\n![image-20220428223356012](https://presenter.oss-cn-shanghai.aliyuncs.com/image-20220428223356012.png)\n","tags":["android"],"categories":["android"]},{"title":"bat批处理","url":"/2022/06/02/bat批处理/","content":"\n### 基本用法\n\n> **_pause_** :使脚本程序暂停，即会输出“请按任意键输出的字样”，主要用于需要打印一些数据，如果不加pause，脚本运行结束直接关闭，将无法看到结果。可以加 >nul把这个信息隐藏。\n> \n> **@**：它的作用是隐藏它后面这一行的命令本身（只能影响当前行）。\n> \n> **%** : %0表示这个文件本身，%1，%2（%\\[0-9\\]）分别是后面的参数\n\n**一、for循环**\n\n```\n#1.\n#输出ABC\n@echo off\nfor  %%I in (ABC) do echo %%I\npause\n#结果\n#ABC\n\n#2.\n@echo off\nfor  %%I in (A,B,C) do echo %%I\npause\n#结果\n#A\n#B\n#C\n```\n\n**高级用法：**\n\n```\n#搜索当前目录的所有文件\n\n@echo off\nfor %%i in (*.*) do echo \"%%i\"\npause\n\n#搜索当前目录的文本文件\n\n@echo off\nfor %%i in (*.txt) echo \"%%i\"\npause\n```\n\n### 批量处理文件\n\n**实例**\n\n```\n#批量修改文件名称\n\n@echo off\n\nset a=1\n\nsetlocal EnableDelayedExpansion\n\nfor %%n in (*.jpg) do (\n\nset /A a+=1\n\nren \"%%n\" \"动漫!a!.jpg\"\n\n)\n```\n","tags":["bat"],"categories":["工具类"]},{"title":"CentOS命令","url":"/2022/06/02/centos命令/","content":"\n# centos\n\n## 端口\n\nCentos升级到7之后，内置的防火墙已经从iptables变成了firewalld。所以，端口的开启还是要从两种情况来说明的，即iptables和firewalld。更多关于CentOs防火墙的最新内容，请参考Redhat官网\\[[4.5 使用防火墙](https://access.redhat.com/documentation/zh-CN/Red_Hat_Enterprise_Linux/7/html/Security_Guide/sec-Using_Firewalls.html)\\]。\n\n### 一、iptables(centos 6及以前)\n\n1.打开/关闭/重启防火墙\n\n```\n开启防火墙(重启后永久生效)：chkconfig iptables on\n\n关闭防火墙(重启后永久生效)：chkconfig iptables off\n\n开启防火墙(即时生效，重启后失效)：service iptables start\n\n关闭防火墙(即时生效，重启后失效)：service iptables stop\n\n重启防火墙:service iptables restartd\n```\n\n2.查看打开的端口\n\n```\n/etc/init.d/iptables status\n```\n\n3.打开某个端口(以8080为例)\n\n（1）开启端口\n\n```\niptables -A INPUT -p tcp --dport 8080 -j ACCEPT \n```\n\n（2）保存并重启防火墙\n\n```\n/etc/rc.d/init.d/iptables save\n/etc/init.d/iptables restart\n```\n\n4.打开49152~65534之间的端口\n\n```\niptables -A INPUT -p tcp --dport 49152:65534 -j ACCEPT  \n```\n\n同样，这里需要对设置进行保存，并重启防火墙。\n\n5.其他打开方式\n\n我们还可以通过修改/etc/sysconfig/iptables文件的方式开启端口，如下\n\n```\nvi /etc/sysconfig/iptables\n```\n\n然后在文件中增加一行\n\n```\n-A RH-Firewall-1-INPUT -m state –state NEW -m tcp -p tcp –dport 8080 -j ACCEPT\n```\n\n参数说明:\n\n- –A 参数就看成是添加一条规则\n- –p 指定是什么协议，我们常用的tcp 协议，当然也有udp，例如53端口的DNS\n- –dport 就是目标端口，当数据从外部进入服务器为目标端口\n- –sport 数据从服务器出去，则为数据源端口使用\n- –j 就是指定是 ACCEPT -接收 或者 DROP 不接收\n\n### 二、firewalld(centos7)\n\n1、开放端口\n\n**firewall-cmd --zone=public --add-port=5672/tcp --permanent** # 开放5672端口\n\n**firewall-cmd --zone=public --remove-port=5672/tcp --permanent** #关闭5672端口\n\n**firewall-cmd --reload** # 配置立即生效\n\n批量开启端口\n\n\\*\\*firewall-cmd --permanent --zone=public --add-port=100-500/tcp \\*\\*\n\n**firewall-cmd --permanent --zone=public --add-port=100-500/udp**\n\n2、查看防火墙所有开放的端口\n\n**firewall-cmd --zone=public --list-ports**\n\n3.、关闭防火墙\n\n如果要开放的端口太多，嫌麻烦，可以关闭防火墙，安全性自行评估\n\n**systemctl stop firewalld.service**\n\n4、查看防火墙状态\n\n**firewall-cmd --state**\n\nCentos7默认安装了firewalld，如果没有安装的话，可以使用 `yum install firewalld firewalld-config`进行安装。\n\n1.启动防火墙\n\n```\nsystemctl start firewalld \n```\n\n2.禁用防火墙\n\n```\nsystemctl stop firewalld\n```\n\n3.设置开机启动\n\n```\nsystemctl enable firewalld\n```\n\n4.停止并禁用开机启动\n\n```\nsytemctl disable firewalld\n```\n\n5.重启防火墙\n\n```\nfirewall-cmd --reload\n```\n\n6.查看状态\n\n```\nsystemctl status firewalld或者 firewall-cmd --state\n```\n\n7.查看版本\n\n```\nfirewall-cmd --version\n```\n\n8.查看帮助\n\n```\nfirewall-cmd --help\n```\n\n9.查看区域信息\n\n```\nfirewall-cmd --get-active-zones\n```\n\n10.查看指定接口所属区域信息\n\n```\nfirewall-cmd --get-zone-of-interface=eth0\n```\n\n11.拒绝所有包\n\n```\nfirewall-cmd --panic-on\n```\n\n12.取消拒绝状态\n\n```\nfirewall-cmd --panic-off\n```\n\n13.查看是否拒绝\n\n```\nfirewall-cmd --query-panic\n```\n\n14.将接口添加到区域(默认接口都在public)\n\n```\nfirewall-cmd --zone=public --add-interface=eth0(永久生效再加上 --permanent 然后reload防火墙)\n```\n\n15.设置默认接口区域\n\n```\nfirewall-cmd --set-default-zone=public(立即生效，无需重启)\n```\n\n16.更新防火墙规则\n\n```\nfirewall-cmd --reload或firewall-cmd --complete-reload(两者的区别就是第一个无需断开连接，就是firewalld特性之一动态\n添加规则，第二个需要断开连接，类似重启服务)\n```\n\n17.查看指定区域所有打开的端口\n\n```\nfirewall-cmd --zone=public --list-ports\n```\n\n18.在指定区域打开(关闭)端口（记得重启防火墙）\n\n```\nfirewall-cmd --zone=public --add-port=80/tcp(永久生效再加上 --permanent)\nfirewall-cmd --zone=public --remove-port=80/tcp\n```\n\n> 说明：  \n> –zone 作用域  \n> –add-port=8080/tcp 添加端口，格式为：端口/通讯协议  \n> –permanent #永久生效，没有此参数重启后失效\n\n## 服务\n\n### CentOS6\n\n```\nchkconfig / chkconfig --list显示开机启动服务列表\n\nchkconfig --level 3 服务名 on/off\n\nchkconfig 服务名 on/off\n\nchkconfig --del 服务名 删除（关闭）服务\n\nchkconfig --add 服务名 添加（开启）服务\n\n/var/log/messages核心系统日志文件\n\netc/logrotate.conf\n\nmessages由syslogd这个守护进程产生的，如果停掉这个服务则系统不会产生/var/log/messages\n\n/var/log/wtmp 查看用户登录历史 last\n\nlastlog 所有的用户登陆信息\n\n/var/log/btmp lastb 查看无效登录历史\n\n\n/var/log/maillog\n\n/var/log/secure\n\ndmesg\n\n/var/log/dmesg 系统启动产生的硬件信息\n\nscreen\n\nctrl a d 退出screen界面\n\nscreen -r 返回screen界面\n\nscreen -ls 查看screen 列表\n\nscreen -r screenID 返回选择的screen界面\n```\n\n### centos7+\n\n```\n2、如何启动/关闭、启用/禁用服务？\n\n启动一个服务：systemctl start postfix.service\n\n关闭一个服务：systemctl stop postfix.service\n\n重启一个服务：systemctl restart postfix.service\n\n显示一个服务的状态：systemctl status postfix.service\n\n在开机时启用一个服务：systemctl enable postfix.service\n\n在开机时禁用一个服务：systemctl disable postfix.service\n\n查看服务是否开机启动：systemctl is-enabled postfix.service;echo $?\n\n查看已启动的服务列表：systemctl list-unit-files|grep enabled\n```\n\n- 查看服务启动日志\n\n```\n journalctl -u docker.service\n```\n","tags":["centos"],"categories":["centos","系统类"]},{"title":"CentOS安装配置node","url":"/2022/06/02/centos安装配置node/","content":"\n#### 一、找好安装位置，我这里是：/home/node\n\n二、去[node](https://so.csdn.net/so/search?q=node&spm=1001.2101.3001.7020)官网下载Linux镜像或者通过命令直接下载\n\n```\nwget https://npm.taobao.org/mirrors/node/v12.16.1/node-v12.16.1-linux-x64.tar.gz\n```\n\n三、解压\n\n```\ntar -xvf node-v12.16.1-linux-x64.tar.gz\n```\n\n四、进入解压后的文件执行命令\n\n```\n#切换路径：\ncd node-v12.16.1-linux-x64.tar.gz\n\n#执行这个命令：\nyum install gcc gcc-c++\n```\n\n五、重命名文件名\n\n```\nmv node-v12.16.1-linux-x64.tar.gz Node\n```\n\n六、ln指令创建关联\n\n```\nln -s /home/node/node/bin/node /usr/bin/node\n\nln -s /home/node/node/bin/npm /usr/bin/npm\n\nln -s /home/node/node/bin/npx /usr/bin/npx\n```\n\n八、安装node守护进程 forever\n\n```\n// 全局安装forever\nnpm i -g forever\n// 通过forever启动应用\nforever start app.js\n// 关闭应用\nforever stop app.js\n// 关闭所有应用\nforever stopall\n// 重启所有应用\nforever restartall\n// 显示所有运行的服务\nforever list\n```\n\n```\nnpm i forever -g \n\nln -s /usr/local/temp/Node.js/bin/forever /usr/local/bin/forever\n```\n","tags":["centos"],"categories":["centos","系统类"]},{"title":"CentOS常用命令（更全）","url":"/2022/06/02/centos常用命令（更全）/","content":"\n## 系统服务管理\n\n### systemctl\n\n> `systemctl`命令是`service`和`chkconfig`命令的组合体，可用于管理系统。\n\n- 输出系统中各个服务的状态：\n\n```\nsystemctl list-units --type=service\n```\n\n![](https://presenter.oss-cn-shanghai.aliyuncs.com/linux_command_01.png)\n\n- 查看服务的运行状态：\n\n```\nsystemctl status firewalld\n```\n\n![](https://presenter.oss-cn-shanghai.aliyuncs.com/linux_command_02.png)\n\n- 关闭服务：\n\n```\nsystemctl stop firewalld\n```\n\n![](https://presenter.oss-cn-shanghai.aliyuncs.com/linux_command_03.png)\n\n- 启动服务：\n\n```\nsystemctl start firewalld\n```\n\n![](https://presenter.oss-cn-shanghai.aliyuncs.com/linux_command_04.png)\n\n- 重新启动服务（不管当前服务是启动还是关闭）：\n\n```\nsystemctl restart firewalld\n```\n\n- 重新载入配置信息而不中断服务：\n\n```\nsystemctl reload firewalld\n```\n\n- 禁止服务开机自启动：\n\n```\nsystemctl disable firewalld\n```\n\n![](https://presenter.oss-cn-shanghai.aliyuncs.com/linux_command_05.png)\n\n- 设置服务开机自启动：\n\n```\nsystemctl enable firewalld\n```\n\n![](https://presenter.oss-cn-shanghai.aliyuncs.com/linux_command_06.png)\n\n## 文件管理\n\n### ls\n\n列出指定目录下的所有文件，列出`/`目录下的文件：\n\n```\nls -l /\n```\n\n![](https://presenter.oss-cn-shanghai.aliyuncs.com/linux_command_07.png)\n\n### pwd\n\n获取目前所在工作目录的绝对路径：\n\n![](https://presenter.oss-cn-shanghai.aliyuncs.com/linux_command_08.png)\n\n### cd\n\n改变当前工作目录：\n\n```\ncd /usr/local\n```\n\n![](https://presenter.oss-cn-shanghai.aliyuncs.com/linux_command_09.png)\n\n### date\n\n显示或修改系统时间与日期；\n\n```\ndate '+%Y-%m-%d %H:%M:%S'\n```\n\n![](https://presenter.oss-cn-shanghai.aliyuncs.com/linux_command_10.png)\n\n### passwd\n\n用于设置用户密码：\n\n```\npasswd root\n```\n\n![](https://presenter.oss-cn-shanghai.aliyuncs.com/linux_command_11.png)\n\n### su\n\n改变用户身份（切换到超级用户）：\n\n```\nsu -\n```\n\n### clear\n\n用于清除屏幕信息\n\n### man\n\n显示指定命令的帮助信息：\n\n```\nman ls\n```\n\n### who\n\n- 查询系统处于什么运行级别：\n\n```\nwho -r\n```\n\n![](https://presenter.oss-cn-shanghai.aliyuncs.com/linux_command_12.png)\n\n- 显示目前登录到系统的用户：\n\n```\nwho -buT\n```\n\n![](https://presenter.oss-cn-shanghai.aliyuncs.com/linux_command_13.png)\n\n### free\n\n显示系统内存状态（单位MB）：\n\n```\nfree -m\n```\n\n![](https://presenter.oss-cn-shanghai.aliyuncs.com/linux_command_14.png)\n\n### ps\n\n- 显示系统进程运行动态：\n\n```\nps -ef\n```\n\n- 查看`sshd`进程的运行动态：\n\n```\nps -ef | grep sshd\n```\n\n![](https://presenter.oss-cn-shanghai.aliyuncs.com/linux_command_15.png)\n\n### top\n\n查看即时活跃的进程，类似Windows的任务管理器。\n\n![](https://presenter.oss-cn-shanghai.aliyuncs.com/linux_command_16.png)\n\n### mkdir\n\n创建目录：\n\n![](https://presenter.oss-cn-shanghai.aliyuncs.com/linux_command_17.png)\n\n### more\n\n用于分页查看文件，例如每页10行查看`boot.log`文件：\n\n```\nmore -c -10 /var/log/boot.log\n```\n\n![](https://presenter.oss-cn-shanghai.aliyuncs.com/linux_command_18.png)\n\n### cat\n\n用于查看文件，例如查看Linux启动日志文件文件，并标明行号：\n\n```\ncat -Ab /var/log/boot.log\n```\n\n![](https://presenter.oss-cn-shanghai.aliyuncs.com/linux_command_19.png)\n\n### touch\n\n用于创建文件，例如创建`text.txt`文件：\n\n```\ntouch text.txt\n```\n\n![](https://presenter.oss-cn-shanghai.aliyuncs.com/linux_command_20.png)\n\n### rm\n\n- 删除文件：\n\n```\nrm text.txt\n```\n\n- 强制删除某个目录及其子目录：\n\n```\nrm -rf testdir/\n```\n\n![](https://presenter.oss-cn-shanghai.aliyuncs.com/linux_command_21.png)\n\n### cp\n\n用于拷贝文件，例如将`test1`目录复制到`test2`目录\n\n```\ncp -r /mydata/tes1 /mydata/test2\n```\n\n### mv\n\n用于移动或覆盖文件：\n\n```\nmv text.txt text2.txt\n```\n\n## 压缩与解压\n\n### tar\n\n- 将`/etc`文件夹中的文件归档到文件`etc.tar`（并不会进行压缩）：\n\n```\ntar -cvf /mydata/etc.tar /etc\n```\n\n- 用`gzip`压缩文件夹`/etc`中的文件到文件`etc.tar.gz`：\n\n```\ntar -zcvf /mydata/etc.tar.gz /etc\n```\n\n- 用`bzip2`压缩文件夹`/etc`到文件`/etc.tar.bz2`：\n\n```\ntar -jcvf /mydata/etc.tar.bz2 /etc\n```\n\n![](https://presenter.oss-cn-shanghai.aliyuncs.com/linux_command_22.png)\n\n- 分页查看压缩包中内容（gzip）：\n\n```\ntar -ztvf /mydata/etc.tar.gz |more -c -10\n```\n\n![](https://presenter.oss-cn-shanghai.aliyuncs.com/linux_command_24.png)\n\n- 解压文件到当前目录（gzip）：\n\n```\ntar -zxvf /mydata/etc.tar.gz\n```\n\n- 解压文件到指定目录（gzip）：\n\n```\ntar -zxvf /mydata/etc.tar.gz -C /mydata/etc\n```\n\n## 磁盘和网络管理\n\n### df\n\n查看磁盘空间占用情况：\n\n```\ndf -hT\n```\n\n![](https://presenter.oss-cn-shanghai.aliyuncs.com/linux_command_25.png)\n\n### dh\n\n查看当前目录下的文件及文件夹所占大小：\n\n```\ndu -h --max-depth=1 ./*\n```\n\n![](https://presenter.oss-cn-shanghai.aliyuncs.com/linux_command_26.png)\n\n### ifconfig\n\n显示当前网络接口状态：\n\n![](https://presenter.oss-cn-shanghai.aliyuncs.com/linux_command_27.png)\n\n### netstat\n\n- 查看当前路由信息：\n\n```\nnetstat -rn\n```\n\n![](https://presenter.oss-cn-shanghai.aliyuncs.com/linux_command_28.png)\n\n- 查看所有有效TCP连接：\n\n```\nnetstat -an\n```\n\n- 查看系统中启动的监听服务：\n\n```\nnetstat -tulnp\n```\n\n![](https://presenter.oss-cn-shanghai.aliyuncs.com/linux_command_29.png)\n\n- 查看处于连接状态的系统资源信息：\n\n```\nnetstat -atunp\n```\n\n### wget\n\n从网络上下载文件\n\n![](https://presenter.oss-cn-shanghai.aliyuncs.com/linux_command_30.png)\n\n## 文件上传下载\n\n- 安装上传下载工具`lrzsz`；\n\n```\nyum install -y lrzsz\n```\n\n- 上传文件，输入以下命令`XShell`会弹出文件上传框；\n\n```\nrz\n```\n\n- 下载文件，输入以下命令`XShell`会弹出文件保存框；\n\n```\nsz fileName\n```\n\n## 软件的安装与管理\n\n### rpm\n\n> RPM是`Red-Hat Package Manager`的缩写，一种Linux下通用的软件包管理方式，可用于安装和管理`.rpm`结尾的软件包。\n\n- 安装软件包：\n\n```\nrpm -ivh nginx-1.12.2-2.el7.x86_64.rpm\n```\n\n- 模糊搜索软件包：\n\n```\nrpm -qa | grep nginx\n```\n\n- 精确查找软件包：\n\n```\nrpm -qa nginx\n```\n\n- 查询软件包的安装路径：\n\n```\nrpm -ql nginx-1.12.2-2.el7.x86_64\n```\n\n- 查看软件包的概要信息：\n\n```\nrpm -qi nginx-1.12.2-2.el7.x86_64\n```\n\n- 验证软件包内容和安装文件是否一致：\n\n```\nrpm -V nginx-1.12.2-2.el7.x86_64\n```\n\n- 更新软件包：\n\n```\nrpm -Uvh nginx-1.12.2-2.el7.x86_64\n```\n\n- 删除软件包：\n\n```\nrpm -e nginx-1.12.2-2.el7.x86_64\n```\n\n### yum\n\n> Yum是`Yellow dog Updater, Modified`的缩写，能够在线自动下载RPM包并安装，可以自动处理依赖性关系，并且一次安装所有依赖的软件包，非常方便！\n\n- 安装软件包：\n\n```\nyum install nginx\n```\n\n- 检查可以更新的软件包：\n\n```\nyum check-update\n```\n\n- 更新指定的软件包：\n\n```\nyum update nginx\n```\n\n- 在资源库中查找软件包信息：\n\n```\nyum info nginx*\n```\n\n- 列出已经安装的所有软件包：\n\n```\nyum info installed\n```\n\n- 列出软件包名称：\n\n```\nyum list nginx*\n```\n\n- 模糊搜索软件包：\n\n```\nyum search nginx\n```\n\n## 用户管理\n\n### 用户信息查看\n\n- 查看用户信息：\n\n```\ncat /etc/passwd\n```\n\n- 用户信息格式如下（密码已过滤）：\n\n```\n# 用户名:密码:用户标识号:组标识号:组注释性描述:主目录:默认shell\nroot:x:0:0:root:/root:/bin/bash\nmacro:x:1000:982:macro:/home/macro:/bin/bash\n```\n\n- 查看用户组信息：\n\n```\ncat /etc/group\n```\n\n- 用户组信息格式如下：\n\n```\n# 组名:密码:组标识号:组内用户列表\nroot:x:0:\ndocker:x:982:macro,andy\n```\n\n### passwd\n\n用于设置用户密码：\n\n```\npasswd root\n```\n\n### su\n\n改变用户身份（切换到超级用户）：\n\n```\n# 切换到root用户\nsu -\n# 切换到macro用户\nsu macro\n```\n\n### groupadd\n\n添加用户组，使用`-g`可以设置用户组的标志号：\n\n```\ngroupadd -g 1024 macrozheng\n```\n\n### groupdel\n\n删除用户组：\n\n```\ngroupdel macrozheng\n```\n\n### useradd\n\n添加用户，`-u`设置标志号，`-g`设置主用户组：\n\n```\nuseradd -u 1024 -g macrozheng macro\n```\n\n### usermod\n\n修改用户所属用户组：\n\n```\nusermod -g docker macro\n```\n\n### userdel\n\n删除用户，使用`-r`可以删除用户主目录：\n\n```\nuserdel macro -r\n```\n","tags":["centos"],"categories":["centos","系统类"]},{"title":"CentOS搭建本地服务器","url":"/2022/06/02/centos搭建本地服务器/","content":"\n### 第一步\n\n#### 更换国内yum源\n\n国内速度太慢，目前国内的大公司有许多开源镜像站，例如阿里云、网易、清华大学、华为等等，这里使用阿里云的yum源。\n\n参考官方文档https://developer.aliyun.com/mirror/centos?spm=a2c6h.13651102.0.0.3e221b11bXrW8A，依次执行\n\n```\n#备份原来的源文件\nmv /etc/yum.repos.d/CentOS-Base.repo /etc/yum.repos.d/CentOS-Base.repo.backup \n#修改\ncurl -o /etc/yum.repos.d/CentOS-Base.repo https://mirrors.aliyun.com/repo/Centos-7.repo\nyum clean all\nyum makecache\n```\n\n#### 安装ssh\n\n```\nsudo yum install openssh -y\n```\n\n启动ssh的服务：\n\n```\nsystemctl start sshd.service\n```\n\n设置开机自动启动ssh服务\n\n```\nsystemctl enable sshd.service\n```\n\n配置文件在`/etc/ssh/sshd_config`，一般不用修改。\n\n#### 安装ftp\n\n```\nsudo yum install ftp -y\n```\n\n### 安装宝塔面板\n\n宝塔面板可以更简单明了的进行网站的部署和服务器的监控，非常值得推荐。参考官方网站https://www.bt.cn/bbs/thread-19376-1-1.html\n\n#### 一键安装命令\n\n```\nsudo yum install -y wget && wget -O install.sh http://download.bt.cn/install/install_6.0.sh && sh install.sh\n```\n\n耐心等待其安装完成，之后会得到一个访问地址和账户密码，我们先使用内网访问地址进行操作。\n\n![image-20220504224253823](https://presenter.oss-cn-shanghai.aliyuncs.com/image-20220504224253823.png)\n\n如果发现登录不上。先进入Centos查看ip\n\n```\nip addr\n```\n\n![image-20220504224404341](https://presenter.oss-cn-shanghai.aliyuncs.com/image-20220504224404341.png)\n\n使用这个就能成功登录\n\n第一次进入宝塔面板可以进入设置修改用户名和密码\n\n![image-20220504224502759](https://presenter.oss-cn-shanghai.aliyuncs.com/image-20220504224502759.png)\n","tags":["centos"],"categories":["centos","系统类"]},{"title":"docker入门","url":"/2022/06/02/docker入门/","content":"\n### 官方文档位置[#](https://docs.docker.com/engine/install/centos/)\n\n![](https://presenter.oss-cn-shanghai.aliyuncs.com/image-20220518190929849.png)\n\n#### 1、卸载旧的版本\n\n```\n sudo yum remove docker \\\n                  docker-client \\\n                  docker-client-latest \\\n                  docker-common \\\n                  docker-latest \\\n                  docker-latest-logrotate \\\n                  docker-logrotate \\\n                  docker-engine\n```\n\n#### 2、需要的安装包\n\n```\nyum install -y yum-utils\n```\n\n#### 3、设置镜像仓库\n\n```\n sudo yum-config-manager \\\n    --add-repo \\\n    https://download.docker.com/linux/centos/docker-ce.repo #默认是国外的镜像源\n\n sudo yum-config-manager \\\n    --add-repo \\\n    https://registry.docker-cn.com      #国内官方源\n\nyum-config-manager \\\n    --add-repo \\\n    https://download.docker.com/linux/centos/docker-ce.repo  #国外的地址\n\n    # 设置阿里云的Docker镜像仓库\nyum-config-manager \\\n    --add-repo \\\n    https://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo  #国内的地址\n```\n\n#### 4、更新yum软件包索引\n\n```\n yum makecache fast\n```\n\n#### 5、安装docker相关的配置\n\ndocker-ce 是社区版，docker-ee 企业版\n\n```\n yum install docker-ce docker-ce-cli containerd.io\n```\n\n出现了completed即安装成功。\n\n#### 6、启动Docker\n\n```\n#启动docker服务\nsystemctl start docker\n# 查看当前版本号，是否启动成功\ndocker version\n# 设置开机自启动\nsystemctl enable docker\n```\n\n![](https://presenter.oss-cn-shanghai.aliyuncs.com/image-20220518193126040.png)\n\n查看下载的hello world镜像\n\n![](https://presenter.oss-cn-shanghai.aliyuncs.com/image-20220518193455731.png)\n\n### Docker的卸载\n\n```\n# 1. 卸载依赖\nyum remove docker-ce docker-ce-cli containerd.io\n# 2. 删除资源  . /var/lib/docker是docker的默认工作路径\nrm -rf /var/lib/docker\n```\n\n### 配置阿里云镜像加速\n\n**（1）进入阿里云官网，搜索容器镜像服务**\n\n![](https://presenter.oss-cn-shanghai.aliyuncs.com/image-20220519104612346.png)\n\n![](https://presenter.oss-cn-shanghai.aliyuncs.com/image-20220519110815790.png)\n\n**（2）依次执行官方的这四条命令**\n\n```\nsudo mkdir -p /etc/docker\nsudo tee /etc/docker/daemon.json <<-'EOF'\n{\n  \"registry-mirrors\": [\"https://man823kr.mirror.aliyuncs.com\"]\n}\nEOF\nsudo systemctl daemon-reload\nsudo systemctl restart docker\n```\n\n### Docker容器运行流程\n\n启动一个容器，Docker的运行流程如下图：\n\n![](https://presenter.oss-cn-shanghai.aliyuncs.com/image-20220519112112840.png)\n\n### 底层原理\n\nDocker是一个Client-Server结构的系统，Docker的守护进程运行在主机上，通过Socker从客户端访问！Docker Server接收到Docker-Client的指令，就会执行这个指令！\n\n![](https://presenter.oss-cn-shanghai.aliyuncs.com/image-20220519131002639.png)\n\nDocker为什么比VM Ware快？\n\n1、Docker比虚拟机更少的抽象层\n\n2、docker利用宿主机的内核，VM需要的是Guest OS\n\n![](https://presenter.oss-cn-shanghai.aliyuncs.com/20200112215511607.png)\n\nDocker新建一个容器的时候，不需要像虚拟机一样重新加载一个操作系统内核，直接利用宿主机的操作系统，而虚拟机是需要加载Guest OS。Docker和VM的对比如下：\n\n![](https://presenter.oss-cn-shanghai.aliyuncs.com/image-20220519131632278.png)\n\n### Docker常用命令\n\n#### 基础命令\n\n```\ndocker version          #查看docker的版本信息\ndocker info             #查看docker的系统信息,包括镜像和容器的数量\ndocker 命令 --help       #帮助命令(可查看可选的参数)\ndocker COMMAND --help\n```\n\n命令的帮助文档地址:[#](https://docs.docker.com/engine/reference/commandline/docker/)\n\n#### 镜像命令\n\n1.**docker images** 查看本地主机的所有镜像\n\n```\n[root@iZwz99sm8v95sckz8bd2c4Z ~]# docker images\nREPOSITORY    TAG       IMAGE ID       CREATED         SIZE\nhello-world   latest    bf756fb1ae65   11 months ago   13.3kB\n\n#解释:\n1.REPOSITORY  镜像的仓库源\n\n2.TAG  镜像的标签\n\n3.IMAGE ID 镜像的id\n\n4.CREATED 镜像的创建时间\n\n5.SIZE 镜像的大小\n\n\n# 可选参数\n\n-a/--all 列出所有镜像\n\n-q/--quiet 只显示镜像的id\n```\n\n2.**docker search** 搜索镜像\n\n```\n[root@iZwz99sm8v95sckz8bd2c4Z ~]# docker search mysql\nNAME                              DESCRIPTION                                     STARS     OFFICIAL   AUTOMATED\nmysql                             MySQL is a widely used, open-source relation…   10308     [OK]\nmariadb                           MariaDB is a community-developed fork of MyS…   3819      [OK]\nmysql/mysql-server                Optimized MySQL Server Docker images. Create…   754                  [OK]\npercona                           Percona Server is a fork of the MySQL relati…   517       [OK]\ncentos/mysql-57-centos7           MySQL 5.7 SQL database server                   86\nmysql/mysql-cluster               Experimental MySQL Cluster Docker images. Cr…   79\ncenturylink/mysql                 Image containing mysql. Optimized to be link…   60                   [OK]\n\n\n#可选参数\n\nSearch the Docker Hub for images\n\nOptions:\n  -f, --filter filter   Filter output based on conditions provided\n      --format string   Pretty-print search using a Go template\n      --limit int       Max number of search results (default 25)\n      --no-trunc        Don't truncate output\n\n\n#搜索收藏数大于3000的镜像\n[root@iZwz99sm8v95sckz8bd2c4Z ~]# docker search mysql --filter=STARS=3000\nNAME      DESCRIPTION                                     STARS     OFFICIAL   AUTOMATED\nmysql     MySQL is a widely used, open-source relation…   10308     [OK]\nmariadb   MariaDB is a community-developed fordockerk of MyS…   3819      [OK]\n```\n\n3.**docker pull 镜像名\\[:tag\\]** 下载镜像\n\n```\n[root@iZwz99sm8v95sckz8bd2c4Z ~]# docker pull mysql\nUsing default tag: latest            #如果不写tag默认就是latest\nlatest: Pulling from library/mysql\n6ec7b7d162b2: Pull complete          #分层下载,docker image的核心-联合文件系统\nfedd960d3481: Pull complete\n7ab947313861: Pull complete\n64f92f19e638: Pull complete\n3e80b17bff96: Pull complete\n014e976799f9: Pull complete\n59ae84fee1b3: Pull complete\nffe10de703ea: Pull complete\n657af6d90c83: Pull complete\n98bfb480322c: Pull complete\n6aa3859c4789: Pull complete\n1ed875d851ef: Pull complete\nDigest: sha256:78800e6d3f1b230e35275145e657b82c3fb02a27b2d8e76aac2f5e90c1c30873 #签名\nStatus: Downloaded newer image for mysql:latest\ndocker.io/library/mysql:latest  #下载来源的真实地址  #docker pull mysql等价于docker pull docker.io/library/mysql:latest\n123456789101112131415161718\n```\n\n指定版本下载\n\n```\n[root@iZwz99sm8v95sckz8bd2c4Z ~]# docker pull mysql:5.7\n5.7: Pulling from library/mysql\n6ec7b7d162b2: Already exists\nfedd960d3481: Already exists\n7ab947313861: Already exists\n64f92f19e638: Already exists\n3e80b17bff96: Already exists\n014e976799f9: Already exists\n59ae84fee1b3: Already exists\n7d1da2a18e2e: Pull complete\n301a28b700b9: Pull complete\n529dc8dbeaf3: Pull complete\nbc9d021dc13f: Pull complete\nDigest: sha256:c3a567d3e3ad8b05dfce401ed08f0f6bf3f3b64cc17694979d5f2e5d78e10173\nStatus: Downloaded newer image for mysql:5.7\ndocker.io/library/mysql:5.7\n12345678910111213141516\n```\n\n4.**docker rmi** 删除镜像\n\n```\n#1.删除指定的镜像id\n[root@iZwz99sm8v95sckz8bd2c4Z ~]# docker rmi -f  镜像id\n#2.删除多个镜像id\n[root@iZwz99sm8v95sckz8bd2c4Z ~]# docker rmi -f  镜像id 镜像id 镜像id\n#3.删除全部的镜像id\n[root@iZwz99sm8v95sckz8bd2c4Z ~]# docker rmi -f  $(docker images -aq)\n\n\n#  -f 是不询问的意思\n```\n\n#### 容器命令\n\n如拉取一个centos镜像\n\n```\ndocker pull centos \n```\n\n运行容器的命令说明：\n\n```\ndocker run [可选参数] image\n\n#参数说明\n--name=\"名字\"           指定容器名字\n-d                     后台方式运行\n-it                    使用交互方式运行,进入容器查看内容\n-p                     指定容器的端口\n(\n-p ip:主机端口:容器端口  配置主机端口映射到容器端口\n-p 主机端口:容器端口\n-p 容器端口\n)\n-P                     随机指定端口(大写的P)\n12345678910111213\n```\n\n运行并进入容器centos\n\n```\n[root@iZwz99sm8v95sckz8bd2c4Z ~]# docker run -it centos /bin/bash\n[root@bd1b8900c547 /]# ls      \nbin  dev  etc  home  lib  lib64  lost+found  media  mnt  opt  proc  root  run  sbin  srv  sys  tmp  usr  var\n123\n```\n\n退出容器命令：\n\n```\n#exit 停止并退出容器（后台方式运行则仅退出）\n#Ctrl+P+Q  不停止容器退出\n[root@bd1b8900c547 /]# exit\nexit\n[root@iZwz99sm8v95sckz8bd2c4Z ~]#\n12345\n\ndocker attach 容器ID  #进入容器\n```\n\n列出运行过的容器命令：\n\n```\n#docker ps \n     # 列出当前正在运行的容器\n-a   # 列出所有容器的运行记录\n-n=? # 显示最近创建的n个容器\n-q   # 只显示容器的编号\n\n\n[root@iZwz99sm8v95sckz8bd2c4Z ~]# docker ps\nCONTAINER ID   IMAGE     COMMAND   CREATED   STATUS    PORTS     NAMES\n[root@iZwz99sm8v95sckz8bd2c4Z ~]# docker ps -a\nCONTAINER ID   IMAGE          COMMAND       CREATED         STATUS                     PORTS     NAMES\nbca129320bb5   centos         \"/bin/bash\"   4 minutes ago   Exited (0) 3 minutes ago             optimistic_shtern\nbd1b8900c547   centos         \"/bin/bash\"   6 minutes ago   Exited (0) 5 minutes ago             cool_tesla\ncf6adbf1b506   bf756fb1ae65   \"/hello\"      5 hours ago     Exited (0) 5 hours ago               optimistic_darwin\n1234567891011121314\n```\n\n删除容器命令：\n\n```\ndocker rm 容器id                 #删除指定的容器,不能删除正在运行的容器,强制删除使用 rm -f\ndocker rm -f $(docker ps -aq)   #删除所有的容器\ndocker ps -a -q|xargs docker rm #删除所有的容器\n123\n```\n\n启动和停止容器命令：\n\n```\ndocker start 容器id          #启动容器\ndocker restart 容器id        #重启容器\ndocker stop 容器id           #停止当前运行的容器\ndocker kill 容器id           #强制停止当前容器\n```\n\n#### 其他常用命令\n\n##### 后台启动容器\n\n![image-20220520090621272](https://presenter.oss-cn-shanghai.aliyuncs.com/image-20220520090621272.png)\n\n##### 日志的查看\n\n```\n[root@iZwz99sm8v95sckz8bd2c4Z ~]# docker logs --help\n\nUsage:  docker logs [OPTIONS] CONTAINER\n\nFetch the logs of a container\n\nOptions:\n      --details        Show extra details provided to logs\n  -f, --follow         Follow log output\n      --since string   Show logs since timestamp (e.g. 2013-01-02T13:23:37Z) or relative (e.g. 42m for 42 minutes)\n  -n, --tail string    Number of lines to show from the end of the logs (default \"all\")\n  -t, --timestamps     Show timestamps\n      --until string   Show logs before a timestamp (e.g. 2013-01-02T13:23:37Z) or relative (e.g. 42m for 42 minutes)\n\n常用：\ndocker logs -tf 容器id\ndocker logs --tail number 容器id #num为要显示的日志条数\n\n#docker容器后台运行，必须要有一个前台的进程，否则会自动停止\n#编写shell脚本循环执行，使得centos容器保持运行状态\n[root@iZwz99sm8v95sckz8bd2c4Z ~]# docker run -d centos /bin/sh -c \"while true;do echo hi;sleep 5;done\"\nc703b5b1911ff84d584390263a35707b6024816e1f46542b61918a6327a570dc\n[root@iZwz99sm8v95sckz8bd2c4Z ~]# docker ps\nCONTAINER ID   IMAGE     COMMAND                  CREATED          STATUS          PORTS     NAMES\nc703b5b1911f   centos    \"/bin/sh -c 'while t…\"   13 seconds ago   Up 10 seconds             pedantic_banach\n[root@iZwz99sm8v95sckz8bd2c4Z ~]# docker logs -tf --tail 10 c703b5b1911f\n2020-12-27T03:34:07.255599560Z hi\n2020-12-27T03:34:12.257641517Z hi\n2020-12-27T03:34:17.259706294Z hi\n2020-12-27T03:34:22.261693707Z hi\n2020-12-27T03:34:27.262609289Z hi\n2020-12-27T03:34:32.267862677Z hi\n2020-12-27T03:34:37.270382873Z hi\n2020-12-27T03:34:42.272414182Z hi\n2020-12-27T03:34:47.274823243Z hi\n2020-12-27T03:34:52.277419274Z hi\n12345678910111213141516171819202122232425262728293031323334353637\n```\n\n##### 查看容器中进程信息\n\n```\n[root@iZwz99sm8v95sckz8bd2c4Z ~]# docker top c703b5b1911f\nUID                 PID                 PPID                C                   STIME               TTY                 TIME                CMD\nroot                11156               11135               0                   11:31               ?                   00:00:00            /bin/sh -c while true;do echo hi;sleep 5;done\nroot                11886               11156               0                   11:43               ?                   00:00:00            /usr/bin/coreutils --coreutils-prog-shebang=sleep /usr/bin/sleep 5\n1234\n```\n\n##### 查看容器的元数据\n\n```\n[root@iZwz99sm8v95sckz8bd2c4Z ~]# docker inspect 容器id\n[\n    {\n        \"Id\": \"853796e7728edb36d14e852365192328092f1be16ed411f4fc6c1105d745d905\",\n        \"Created\": \"2022-05-20T01:24:00.224710227Z\",\n        \"Path\": \"/bin/bash\",\n        \"Args\": [],\n        \"State\": {\n            \"Status\": \"exited\",\n            \"Running\": false,\n            \"Paused\": false,\n            \"Restarting\": false,\n            \"OOMKilled\": false,\n            \"Dead\": false,\n            \"Pid\": 0,\n            \"ExitCode\": 0,\n            \"Error\": \"\",\n            \"StartedAt\": \"2022-05-20T01:24:00.536472886Z\",\n            \"FinishedAt\": \"2022-05-20T01:24:00.544100162Z\"\n        },\n        \"Image\": \"sha256:5d0da3dc976460b72c77d94c8a1ad043720b0416bfc16c52c45d4847e53fadb6\",\n        \"ResolvConfPath\": \"/var/lib/docker/containers/853796e7728edb36d14e852365192328092f1be16ed411f4fc6c1105d745d905/resolv.conf\",\n        \"HostnamePath\": \"/var/lib/docker/containers/853796e7728edb36d14e852365192328092f1be16ed411f4fc6c1105d745d905/hostname\",\n        \"HostsPath\": \"/var/lib/docker/containers/853796e7728edb36d14e852365192328092f1be16ed411f4fc6c1105d745d905/hosts\",\n        \"LogPath\": \"/var/lib/docker/containers/853796e7728edb36d14e852365192328092f1be16ed411f4fc6c1105d745d905/853796e7728edb36d14e852365192328092f1be16ed411f4fc6c1105d745d905-json.log\",\n        \"Name\": \"/elegant_noyce\",\n        \"RestartCount\": 0,\n        \"Driver\": \"overlay2\",\n        \"Platform\": \"linux\",\n        \"MountLabel\": \"\",\n        \"ProcessLabel\": \"\",\n        \"AppArmorProfile\": \"\",\n        \"ExecIDs\": null,\n        \"HostConfig\": {\n            \"Binds\": null,\n            \"ContainerIDFile\": \"\",\n            \"LogConfig\": {\n                \"Type\": \"json-file\",\n                \"Config\": {}\n            },\n            \"NetworkMode\": \"default\",\n            \"PortBindings\": {},\n            \"RestartPolicy\": {\n                \"Name\": \"no\",\n                \"MaximumRetryCount\": 0\n            },\n            \"AutoRemove\": false,\n            \"VolumeDriver\": \"\",\n            \"VolumesFrom\": null,\n            \"CapAdd\": null,\n            \"CapDrop\": null,\n            \"CgroupnsMode\": \"host\",\n            \"Dns\": [],\n            \"DnsOptions\": [],\n            \"DnsSearch\": [],\n            \"ExtraHosts\": null,\n            \"GroupAdd\": null,\n            \"IpcMode\": \"private\",\n            \"Cgroup\": \"\",\n            \"Links\": null,\n            \"OomScoreAdj\": 0,\n            \"PidMode\": \"\",\n            \"Privileged\": false,\n            \"PublishAllPorts\": false,\n            \"ReadonlyRootfs\": false,\n            \"SecurityOpt\": null,\n            \"UTSMode\": \"\",\n            \"UsernsMode\": \"\",\n            \"ShmSize\": 67108864,\n            \"Runtime\": \"runc\",\n            \"ConsoleSize\": [\n                0,\n                0\n            ],\n            \"Isolation\": \"\",\n            \"CpuShares\": 0,\n            \"Memory\": 0,\n            \"NanoCpus\": 0,\n            \"CgroupParent\": \"\",\n            \"BlkioWeight\": 0,\n            \"BlkioWeightDevice\": [],\n            \"BlkioDeviceReadBps\": null,\n            \"BlkioDeviceWriteBps\": null,\n            \"BlkioDeviceReadIOps\": null,\n            \"BlkioDeviceWriteIOps\": null,\n            \"CpuPeriod\": 0,\n            \"CpuQuota\": 0,\n            \"CpuRealtimePeriod\": 0,\n            \"CpuRealtimeRuntime\": 0,\n            \"CpusetCpus\": \"\",\n            \"CpusetMems\": \"\",\n            \"Devices\": [],\n            \"DeviceCgroupRules\": null,\n            \"DeviceRequests\": null,\n            \"KernelMemory\": 0,\n            \"KernelMemoryTCP\": 0,\n            \"MemoryReservation\": 0,\n            \"MemorySwap\": 0,\n            \"MemorySwappiness\": null,\n            \"OomKillDisable\": false,\n            \"PidsLimit\": null,\n            \"Ulimits\": null,\n            \"CpuCount\": 0,\n            \"CpuPercent\": 0,\n            \"IOMaximumIOps\": 0,\n            \"IOMaximumBandwidth\": 0,\n            \"MaskedPaths\": [\n                \"/proc/asound\",\n                \"/proc/acpi\",\n                \"/proc/kcore\",\n                \"/proc/keys\",\n                \"/proc/latency_stats\",\n                \"/proc/timer_list\",\n                \"/proc/timer_stats\",\n                \"/proc/sched_debug\",\n                \"/proc/scsi\",\n                \"/sys/firmware\"\n            ],\n            \"ReadonlyPaths\": [\n                \"/proc/bus\",\n                \"/proc/fs\",\n                \"/proc/irq\",\n                \"/proc/sys\",\n                \"/proc/sysrq-trigger\"\n            ]\n        },\n        \"GraphDriver\": {\n            \"Data\": {\n                \"LowerDir\": \"/var/lib/docker/overlay2/d87402427d9ae960a5fbe249daad05bec1e3ac0843f60ed81aaea60984e36253-init/diff:/var/lib/docker/overlay2/b884d6313036de0e4750cbcea8281ef0fffa98ab829a87a6502d1e9f5ef805f8/diff\",\n                \"MergedDir\": \"/var/lib/docker/overlay2/d87402427d9ae960a5fbe249daad05bec1e3ac0843f60ed81aaea60984e36253/merged\",\n                \"UpperDir\": \"/var/lib/docker/overlay2/d87402427d9ae960a5fbe249daad05bec1e3ac0843f60ed81aaea60984e36253/diff\",\n                \"WorkDir\": \"/var/lib/docker/overlay2/d87402427d9ae960a5fbe249daad05bec1e3ac0843f60ed81aaea60984e36253/work\"\n            },\n            \"Name\": \"overlay2\"\n        },\n        \"Mounts\": [],\n        \"Config\": {\n            \"Hostname\": \"853796e7728e\",\n            \"Domainname\": \"\",\n            \"User\": \"\",\n            \"AttachStdin\": false,\n            \"AttachStdout\": false,\n            \"AttachStderr\": false,\n            \"Tty\": false,\n            \"OpenStdin\": false,\n            \"StdinOnce\": false,\n            \"Env\": [\n                \"PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\"\n            ],\n            \"Cmd\": [\n                \"/bin/bash\"\n            ],\n            \"Image\": \"centos\",\n            \"Volumes\": null,\n            \"WorkingDir\": \"\",\n            \"Entrypoint\": null,\n            \"OnBuild\": null,\n            \"Labels\": {\n                \"org.label-schema.build-date\": \"20210915\",\n                \"org.label-schema.license\": \"GPLv2\",\n                \"org.label-schema.name\": \"CentOS Base Image\",\n                \"org.label-schema.schema-version\": \"1.0\",\n                \"org.label-schema.vendor\": \"CentOS\"\n            }\n        },\n        \"NetworkSettings\": {\n            \"Bridge\": \"\",\n            \"SandboxID\": \"fbdf128c04c0b0083efeb728b1a73f031b8ecb16767b9af5ab952b2bcbcf0bf2\",\n            \"HairpinMode\": false,\n            \"LinkLocalIPv6Address\": \"\",\n            \"LinkLocalIPv6PrefixLen\": 0,\n            \"Ports\": {},\n            \"SandboxKey\": \"/var/run/docker/netns/fbdf128c04c0\",\n            \"SecondaryIPAddresses\": null,\n            \"SecondaryIPv6Addresses\": null,\n            \"EndpointID\": \"\",\n            \"Gateway\": \"\",\n            \"GlobalIPv6Address\": \"\",\n            \"GlobalIPv6PrefixLen\": 0,\n            \"IPAddress\": \"\",\n            \"IPPrefixLen\": 0,\n            \"IPv6Gateway\": \"\",\n            \"MacAddress\": \"\",\n            \"Networks\": {\n                \"bridge\": {\n                    \"IPAMConfig\": null,\n                    \"Links\": null,\n                    \"Aliases\": null,\n                    \"NetworkID\": \"30963c06b94849260983a1dd752bf2feb0329daf0306959f4e6991b1f1460ce9\",\n                    \"EndpointID\": \"\",\n                    \"Gateway\": \"\",\n                    \"IPAddress\": \"\",\n                    \"IPPrefixLen\": 0,\n                    \"IPv6Gateway\": \"\",\n                    \"GlobalIPv6Address\": \"\",\n                    \"GlobalIPv6PrefixLen\": 0,\n                    \"MacAddress\": \"\",\n                    \"DriverOpts\": null\n                }\n            }\n        }\n    }\n]\n```\n\n##### 进入当前正在运行的容器\n\n因为通常我们的容器都是使用后台方式来运行的，有时需要进入容器修改配置\n\n方式一：\n\n```\n[root@iZwz99sm8v95sckz8bd2c4Z ~]# docker exec -it c703b5b1911f /bin/bash\n[root@c703b5b1911f /]# ls\nbin  dev  etc  home  lib  lib64  lost+found  media  mnt  opt  proc  root  run  sbin  srv  sys  tmp  usr  var\n[root@c703b5b1911f /]# ps -ef      \nUID        PID  PPID  C STIME TTY          TIME CMD\nroot         1     0  0 03:31 ?        00:00:00 /bin/sh -c while true;do echo hi;sleep 5;done\nroot       279     0  0 03:54 pts/0    00:00:00 /bin/bash\nroot       315     1  0 03:56 ?        00:00:00 /usr/bin/coreutils --coreutils-prog-shebang=sleep /usr/bin/sleep 5\nroot       316   279  0 03:56 pts/0    00:00:00 ps -ef\n123456789\n```\n\n方式二：\n\n```\n[root@iZwz99sm8v95sckz8bd2c4Z ~]# docker attach c703b5b1911f\n1\n```\n\n**docker exec 进入容器后开启一个新的终端，可以在里面操作**\n\n**docker attach 进入容器正在执行的终端，不会启动新的进程**\n\n##### 拷贝操作\n\n拷贝操作的命令如下：\n\n```\n#拷贝容器的文件到主机中\ndocker cp 容器id:容器内路径  目的主机路径\n\n#拷贝宿主机的文件到容器中\ndocker cp 目的主机路径 容器id:容器内路径\n12345\n[root@iZwz99sm8v95sckz8bd2c4Z ~]# docker exec -it c703b5b1911f /bin/bash\n[root@c703b5b1911f /]# cd home\n[root@c703b5b1911f home]# ls\n#touch 新建文件\n[root@c703b5b1911f home]# touch test.java\n[root@c703b5b1911f home]# ls\ntest.java\n[root@c703b5b1911f home]# exit\nexit\n[root@iZwz99sm8v95sckz8bd2c4Z ~]# docker ps\nCONTAINER ID   IMAGE     COMMAND                  CREATED          STATUS          PORTS     NAMES\nc703b5b1911f   centos    \"/bin/sh -c 'while t…\"   35 minutes ago   Up 35 minutes             pedantic_banach\n[root@iZwz99sm8v95sckz8bd2c4Z ~]# docker cp c703b5b1911f:/home/test.java /home\n[root@iZwz99sm8v95sckz8bd2c4Z ~]# ls /home\nhai  pan  test.java\n```\n\n命令小结图解如下：\n\n![](https://presenter.oss-cn-shanghai.aliyuncs.com/image-20220522213729343.png)\n\n#### 实操\n\n![](https://presenter.oss-cn-shanghai.aliyuncs.com/image-20220522215834755.png)\n\n![](https://presenter.oss-cn-shanghai.aliyuncs.com/image-20220522220224437.png)\n\n![](https://presenter.oss-cn-shanghai.aliyuncs.com/image-20220522215918823.png)\n\n安装tomcat：\n\n```\n#官方的使用\ndocker run -it --rm tomcat:9.0\n# --rm就是删除容器，这个容器在停止时就会被删除，一般用于测试。\n\n#运行容器\ndocker run -d -p 3355:8080 --name tomcat01 tomcat\n\n#进入容器\ndocker exec -it tomcat01 /bin/bash\n\n#发现问题：1.linux命令少了 2.没有webapps。阿里云的原因，默认是最小的镜像，所以不必要的都剔除掉。\n#保证最小可运行的环境\n#在容器内发现有个webapps.dist.可以将里面的内容cp到webapps里面就可以访问了。\nroot@3ae89d3fa3c1:/usr/local/tomcat# ls\nBUILDING.txt     LICENSE  README.md      RUNNING.txt  conf  logs            temp     webapps.dist\nCONTRIBUTING.md  NOTICE   RELEASE-NOTES  bin          lib   native-jni-lib  webapps  work\n\n#复制命令\n\ncp -r webapps.dist/* webapps\n```\n\n部署ES+kibana\n\n```\n# es暴露的端口很多\n# es十分耗内存\n# es的数据一般需要放置在安全目录！挂载\n# --net somenetwork ？ 网络配置\n\n#启动elasticsearch \ndocker run -d --name elasticsearch --net somenetwork -p 9200:9200 -p 9300:9300 -e \"discovery.type=single-node\" elasticsearch:7.6.2\n\n# 配置较低的设备谨慎启动，启动后赶紧关掉，进行内存限制\ndocker run -d --name elasticsearch -p 9200:9200 -p 9300:9300 -e \"discovery.type=single-node\" -e ES_JAVA_OPTS=\"-Xms64m -Xmx512m\" elasticsearch:7.6.2\n```\n\ndocker的网络管理\n\n![](https://presenter.oss-cn-shanghai.aliyuncs.com/image-20220523110158590.png)\n\n### 可视化\n\n- protaniner（先用这个）\n\n```\ndocker run -d -p 8088:9000 --restart=always -v /var/run/docker.sock:/var/run/docker.sock --privileged=true portainer/portainer\n```\n\n- Rancher(CI/CD再用)\n\nPortaniner是Docker的图形化管理工具，提供一个后台面板供我们操作！\n\n下载运行Portaniner镜像并运行，设置本机映射端口为8088\n\n```\n[root@localhost conf]# docker run -d -p 8088:9000 --restart=always -v /var/run/docker.sock:/var/run/docker.sock --privileged=true portainer/portainer\nUnable to find image 'portainer/portainer:latest' locally\nlatest: Pulling from portainer/portainer\n94cfa856b2b1: Pull complete\n49d59ee0881a: Pull complete\na2300fd28637: Pull complete\nDigest: sha256:fb45b43738646048a0a0cc74fcee2865b69efde857e710126084ee5de9be0f3f\nStatus: Downloaded newer image for portainer/portainer:latest\n8c525a0137be22965bd1e3944da622a2c4248f8ad20883f4b3ea4f8a6b11e163\n[root@iZwz99sm8v95sckz8bd2c4Z ~]# docker ps\nCONTAINER ID   IMAGE                 COMMAND        CREATED         STATUS         PORTS                    NAMES\n7789d4505a00   portainer/portainer   \"/portainer\"   6 seconds ago   Up 5 seconds   0.0.0.0:8088->9000/tcp   quirky_sinoussi\n123456789101112\n```\n\n第一次登录设置admin用户的密码\n\n![](https://presenter.oss-cn-shanghai.aliyuncs.com/20210718000547236.png)\n\n这里选择本地的就行\n\n![](https://presenter.oss-cn-shanghai.aliyuncs.com/image-20220523125717097.png)\n\n如果是阿里云服务器记得设置安全组，选择连接本地的Docker,整体界面预览如下图：\n\n![](https://presenter.oss-cn-shanghai.aliyuncs.com/image-20220523125839720.png)\n\n### Docker镜像详解\n\n#### 什么是镜像\n\n镜像是一种轻量级、可执行的独立软件包，用来打包软件运行环境和基于运行环境开发的软件，它包含运行某个软件所需要的所有内容，包括代码，运行时（一个程序在运行或者在被执行的依赖）、库，环境变量和配置文件。\n\n#### Docker镜像加载原理\n\nDocker的镜像实际上由一层一层的文件系统组成，这种层级的文件系统是UnionFS联合文件系统。\n\n> UnionFS（联合文件系统）\n\n我们下载的时候看到的一层层就是这个！  \nUnionFS(联合文件系统)：Union文件系统(UnionFS)是一种分层、轻量级并且高性能的文件系统，它支持对文件系统的修改作为一次提交来一层层的叠加，同时可以将不同目录挂载到同一个虚拟文件系统下(unite several directories into a single virtual filesystem)。Union文件系统是Docker镜像的基础。镜像可以通过分层来进行继承，基于基础镜像（没有父镜像），可以制作各种具体的应用镜像。\n\n特性：一次同时加载多个文件系统，但从外面看起来，只能看到一个文件系统，联合加载会把各层文件系统叠加起来，这样最终的文件系统会包含所有底层的文件和目录\n\n> docker镜像加载原理\n\ndocker的镜像实际上由一层一层的文件系统组成，这种层级的文件系统UnionFS。\n\nbootfs(boot file system)主要包含bootloader和kernel,,bootloader主要是引导加载kernel,Linuxl刚启动时会加载bootfs.文件系统，在Docker镜像的最底层是oootfs。.这一层与我们典型的Linux/Unix系统是一样的，包含boot加载器和内核。当boot加载完成之后整个内核就都在内存中了，此时内存的使用权已由bootfs:转交给内核，此时系统也会卸载bootfs。\n\nrootfs(root file system),在bootfs,之上。包含的就是典型Linux系统中的/dey,/proc,/bin,/etc等标准目录和文件。rootfs就是各种不同的操作系统发行版，比如Jbuntu,Centos等等。\n\n![](https://presenter.oss-cn-shanghai.aliyuncs.com/image-20220523131409142.png)\n\n![](https://presenter.oss-cn-shanghai.aliyuncs.com/image-20220523131456922.png)\n\n#### 分层理解\n\n![](https://presenter.oss-cn-shanghai.aliyuncs.com/20210718123512798.png)\n\n```\n[root@iZwz99sm8v95sckz8bd2c4Z ~]# docker image inspect nginx:latest\n[\n    {\n        \"Id\": \"sha256:ae2feff98a0cc5095d97c6c283dcd33090770c76d63877caa99aefbbe4343bdd\",\n        \"RepoTags\": [\n            \"nginx:latest\"\n        ],\n        \"RepoDigests\": [\n            \"nginx@sha256:4cf620a5c81390ee209398ecc18e5fb9dd0f5155cd82adcbae532fec94006fb9\"\n        ],\n        \"Parent\": \"\",\n        \"Comment\": \"\",\n        \"Created\": \"2020-12-15T20:21:00.007674532Z\",\n        \"Container\": \"4cc5da85f27ca0d200407f0593422676a3bab482227daee044d797d1798c96c9\",\n        \"ContainerConfig\": {\n            \"Hostname\": \"4cc5da85f27c\",\n            \"Domainname\": \"\",\n            \"User\": \"\",\n            \"AttachStdin\": false,\n            \"AttachStdout\": false,\n            \"AttachStderr\": false,\n            \"ExposedPorts\": {\n                \"80/tcp\": {}\n            },\n            \"Tty\": false,\n            \"OpenStdin\": false,\n            \"StdinOnce\": false,\n            \"Env\": [\n                \"PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\",\n                \"NGINX_VERSION=1.19.6\",\n                \"NJS_VERSION=0.5.0\",\n                \"PKG_RELEASE=1~buster\"\n            ],\n            \"Cmd\": [\n                \"/bin/sh\",\n                \"-c\",\n                \"#(nop) \",\n                \"CMD [\\\"nginx\\\" \\\"-g\\\" \\\"daemon off;\\\"]\"\n            ],\n            \"Image\": \"sha256:13bffe371b56f4aeed88218ec17d0c6f653a83b49bd3e211fc8cfa2ca5d7a3d3\",\n            \"Volumes\": null,\n            \"WorkingDir\": \"\",\n            \"Entrypoint\": [\n                \"/docker-entrypoint.sh\"\n            ],\n            \"OnBuild\": null,\n            \"Labels\": {\n                \"maintainer\": \"NGINX Docker Maintainers <docker-maint@nginx.com>\"\n            },\n            \"StopSignal\": \"SIGQUIT\"\n        },\n        \"DockerVersion\": \"19.03.12\",\n        \"Author\": \"\",\n        \"Config\": {\n            \"Hostname\": \"\",\n            \"Domainname\": \"\",\n            \"User\": \"\",\n            \"AttachStdin\": false,\n            \"AttachStdout\": false,\n            \"AttachStderr\": false,\n            \"ExposedPorts\": {\n                \"80/tcp\": {}\n            },\n            \"Tty\": false,\n            \"OpenStdin\": false,\n            \"StdinOnce\": false,\n            \"Env\": [\n                \"PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\",\n                \"NGINX_VERSION=1.19.6\",\n                \"NJS_VERSION=0.5.0\",\n                \"PKG_RELEASE=1~buster\"\n            ],\n            \"Cmd\": [\n                \"nginx\",\n                \"-g\",\n                \"daemon off;\"\n            ],\n            \"Image\": \"sha256:13bffe371b56f4aeed88218ec17d0c6f653a83b49bd3e211fc8cfa2ca5d7a3d3\",\n            \"Volumes\": null,\n            \"WorkingDir\": \"\",\n            \"Entrypoint\": [\n                \"/docker-entrypoint.sh\"\n            ],\n            \"OnBuild\": null,\n            \"Labels\": {\n                \"maintainer\": \"NGINX Docker Maintainers <docker-maint@nginx.com>\"\n            },\n            \"StopSignal\": \"SIGQUIT\"\n        },\n        \"Architecture\": \"amd64\",\n        \"Os\": \"linux\",\n        \"Size\": 132935043,\n        \"VirtualSize\": 132935043,\n        \"GraphDriver\": {\n            \"Data\": {\n                \"LowerDir\": \"/var/lib/docker/overlay2/cb791e78a08db7091bf2ce1d78603f1758f52199e57f1805156fe30e39067aae/diff:/var/lib/docker/overlay2/1e73a72b25af68ee9abf4eb443f778d31226e12e9af428fcc14c7b044c83b258/diff:/var/lib/docker/overlay2/88c9c01762f2af8327db65d0b0d4a64785e87c9c2ab76c62e7d03619db03a985/diff:/var/lib/docker/overlay2/7304ab112ac4a9cb91fc6f74730be28fecbe19f042e92d321aa9181424cc4b2e/diff\",\n                \"MergedDir\": \"/var/lib/docker/overlay2/48b288740bbb2b07b41ed43a4d17a005c46b08d3357d2960b5ef7db4b2de6618/merged\",\n                \"UpperDir\": \"/var/lib/docker/overlay2/48b288740bbb2b07b41ed43a4d17a005c46b08d3357d2960b5ef7db4b2de6618/diff\",\n                \"WorkDir\": \"/var/lib/docker/overlay2/48b288740bbb2b07b41ed43a4d17a005c46b08d3357d2960b5ef7db4b2de6618/work\"\n            },\n            \"Name\": \"overlay2\"\n        },\n        \"RootFS\": {\n            \"Type\": \"layers\",\n            \"Layers\": [\n                \"sha256:87c8a1d8f54f3aa4e05569e8919397b65056aa71cdf48b7f061432c98475eee9\",\n                \"sha256:5c4e5adc71a82a96f02632433de31c998c5a9e2fccdcbaee780ae83158fac4fa\",\n                \"sha256:7d2b207c26790f693ab1942bbe26af8e2b6a14248969e542416155a912fec30d\",\n                \"sha256:2c7498eef94aef8c40d106f3e42f7da62b3eee8fd36012bf7379becc4cd639a2\",\n                \"sha256:4eaf0ea085df254fd5d2beba4e2c11db70a620dfa411a8ad44149e26428caee4\"\n            ]\n        },\n        \"Metadata\": {\n            \"LastTagTime\": \"0001-01-01T00:00:00Z\"\n        }\n    }\n]\n123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117\n```\n\n这里指示了分层信息：\n\n```\n        \"RootFS\": {\n            \"Type\": \"layers\",\n            \"Layers\": [\n                \"sha256:87c8a1d8f54f3aa4e05569e8919397b65056aa71cdf48b7f061432c98475eee9\",\n                \"sha256:5c4e5adc71a82a96f02632433de31c998c5a9e2fccdcbaee780ae83158fac4fa\",\n                \"sha256:7d2b207c26790f693ab1942bbe26af8e2b6a14248969e542416155a912fec30d\",\n                \"sha256:2c7498eef94aef8c40d106f3e42f7da62b3eee8fd36012bf7379becc4cd639a2\",\n                \"sha256:4eaf0ea085df254fd5d2beba4e2c11db70a620dfa411a8ad44149e26428caee4\"\n            ]\n        },\n```\n\n![](https://presenter.oss-cn-shanghai.aliyuncs.com/20210718123636415.png)\n\n![](https://presenter.oss-cn-shanghai.aliyuncs.com/2021071812372978.png)\n\n![](https://presenter.oss-cn-shanghai.aliyuncs.com/2021071812374035.png)\n\n#### 提交镜像\n\n```\n使用docker commit 命令提交容器成为一个新的版本\n\ndocker commit -m=“提交的描述信息”  -a=\"作者\" 容器id 目标镜像名:[TAG] \n```\n\n由于默认的Tomcat镜像的webapps文件夹中没有任何内容，需要从webapps.dist中拷贝文件到webapps文件夹。下面自行制作镜像：就是从webapps.dist中拷贝文件到webapps文件夹下，并提交该镜像作为一个新的镜像。使得该镜像默认的webapps文件夹下就有文件。具体命令如下：\n\n```\n#1.复制文件夹\n[root@iZwz99sm8v95sckz8bd2c4Z ~]# docker run -it tomcat /bin/bash\nroot@2a3bf3eaa2e4:/usr/local/tomcat# cd webapps\nroot@2a3bf3eaa2e4:/usr/local/tomcat/webapps# ls\nroot@2a3bf3eaa2e4:/usr/local/tomcat/webapps# cd ../\nroot@2a3bf3eaa2e4:/usr/local/tomcat# cp -r webapps.dist/* webapps\nroot@2a3bf3eaa2e4:/usr/local/tomcat# cd webapps\nroot@2a3bf3eaa2e4:/usr/local/tomcat/webapps# ls\nROOT  docs  examples  host-manager  manager\n[root@iZwz99sm8v95sckz8bd2c4Z ~]# docker ps\nCONTAINER ID   IMAGE                 COMMAND        CREATED         STATUS         PORTS                    NAMES\n2a3bf3eaa2e4   tomcat                \"/bin/bash\"    4 minutes ago   Up 4 minutes   8080/tcp                 competent_torvalds\n7789d4505a00   portainer/portainer   \"/portainer\"   24 hours ago    Up 24 hours    0.0.0.0:8088->9000/tcp   quirky_sinoussi\n[root@iZwz99sm8v95sckz8bd2c4Z ~]# docker exec -it 2a3bf3eaa2e4 /bin/bash\nroot@2a3bf3eaa2e4:/usr/local/tomcat# cd webapps\nroot@2a3bf3eaa2e4:/usr/local/tomcat/webapps# ls\nROOT  docs  examples  host-manager  manager\nroot@2a3bf3eaa2e4:/usr/local/tomcat/webapps# cd ../\nroot@2a3bf3eaa2e4:/usr/local/tomcat# read escape sequence\n[root@iZwz99sm8v95sckz8bd2c4Z ~]# docker ps\nCONTAINER ID   IMAGE                 COMMAND        CREATED         STATUS         PORTS                    NAMES\n2a3bf3eaa2e4   tomcat                \"/bin/bash\"    8 minutes ago   Up 8 minutes   8080/tcp                 competent_torvalds\n7789d4505a00   portainer/portainer   \"/portainer\"   24 hours ago    Up 24 hours    0.0.0.0:8088->9000/tcp   quirky_sinoussi\n#2.提交镜像作为一个新的镜像\n\n[root@iZwz99sm8v95sckz8bd2c4Z ~]# docker commit -m=\"add webapps\" -a=\"Ethan\" 2a3bf3eaa2e4 mytomcat:1.0\nsha256:f189aac861de51087af5bc88a5f1de02d9574e7ee2d163c647dd7503a2d3982b\n[root@iZwz99sm8v95sckz8bd2c4Z ~]# docker images\nREPOSITORY            TAG       IMAGE ID       CREATED         SIZE\nmytomcat              1.0       f189aac861de   7 seconds ago   653MB\nmysql                 5.7       f07dfa83b528   6 days ago      448MB\ntomcat                latest    feba8d001e3f   10 days ago     649MB\nnginx                 latest    ae2feff98a0c   12 days ago     133MB\ncentos                latest    300e315adb2f   2 weeks ago     209MB\nportainer/portainer   latest    62771b0b9b09   5 months ago    79.1MB\nelasticsearch         7.6.2     f29a1ee41030   9 months ago    791MB\n\n#3.运行容器\n\n[root@iZwz99sm8v95sckz8bd2c4Z ~]# docker run -it mytomcat:1.0 /bin/bash\nroot@1645774d4605:/usr/local/tomcat# cd webapps\nroot@1645774d4605:/usr/local/tomcat/webapps# ls\nROOT  docs  examples  host-manager  manager\nwz99sm8v95sckz8bd2c4Z ~]# docker images\nREPOSITORY            TAG       IMAGE ID       CREATED         SIZE\nmytomcat              1.0       f189aac861de   7 seconds ago   653MB\nmysql                 5.7       f07dfa83b528   6 days ago      448MB\ntomcat                latest    feba8d001e3f   10 days ago     649MB\nnginx                 latest    ae2feff98a0c   12 days ago     133MB\ncentos                latest    300e315adb2f   2 weeks ago     209MB\nportainer/portainer   latest    62771b0b9b09   5 months ago    79.1MB\nelasticsearch         7.6.2     f29a1ee41030   9 months ago    791MB\n```\n\n例如提交一个tomcat\n\n![](https://presenter.oss-cn-shanghai.aliyuncs.com/image-20220523133550877.png)\n\n![](https://presenter.oss-cn-shanghai.aliyuncs.com/image-20220523133609284.png)\n\n```\n#如果你想保存当前容器的状态，就可以通过commit来提交，获得一个镜像，就好比VM里面的快照\n```\n\n学到这里算是入门docker\n","tags":["docker"],"categories":["docker","虚拟机"]},{"title":"docker移动文件或者文件夹的命令","url":"/2022/06/02/docker移动文件或者文件夹的命令/","content":"\n### docker与宿主机互相移动文件或者文件夹\n\n从宿主机到容器：\n\n先利用：\n\n```\ndocker ps -a\n#查看所有容器的信息\n```\n\n![我电脑里的容器](https://presenter.oss-cn-shanghai.aliyuncs.com/image-20220517170746571.png)\n\n然后：\n\n```\n#移动wordpress整个文件夹到wordpress容器的html目录下（这里要用容器ID）\ndocker cp C:\\Users\\Administrator\\Desktop\\wordpress-5.9.3-zh_CN\\wordpress\\. b011b15fd82c:\\var\\www\\html\n#将某个文件移动到容器\ndocker cp C:\\Users\\Administrator\\Desktop\\wordpress-5.9.3-zh_CN\\wordpress\\license.txt b011b15fd82c:\\var\\www\\html\n#将容器的文件复制到宿主机中\ndocker cp b011b15fd82c:\\var\\www\\html\\. C:\\Users\\Administrator\\Desktop\\wordpress-5.9.3-zh_CN\\wordpress\\\n```\n","tags":["docker"]},{"title":"docker进阶","url":"/2022/06/02/docker进阶/","content":"\n## 容器数据卷\n\n### 什么是容器数据卷\n\n**docker的理念回顾**\n\n将应用和环境打包成一个镜像！\n\n数据？如果数据都在容器中，那么我们容器删除，数据就会丢失！需求：数据可以持久化\n\nMySQL，容器删除了，删库跑路！需求：MySQL数据可以存储在本地！\n\n容器之间可以有一个数据共享技术！Docker容器中产生的数据，同步到本地！\n\n这就是卷技术！目录的挂载，将我们容器内的目录，挂载到Linux上面！\n\n![](https://presenter.oss-cn-shanghai.aliyuncs.com/image-20220523194605947.png)\n\n**总结一句话：容器的持久化和同步操作！容器间也是可以数据共享的！**\n\n### 使用数据卷\n\n> 方式一：直接使用命令来挂载 -v\n\n```\ndocker run -it -v 主机目录:容器目录\n#例如下面运行一个容器并且进行挂载\ndocker run -it -v /home/centos01:/home --name=\"centos01\" centos /bin/bash\n#在使用inspect命令查看容器\ndocker inspect centos01\n```\n\n![](https://presenter.oss-cn-shanghai.aliyuncs.com/image-20220523195947438.png)\n\n以后修改数据只需要在本地修改即可，docker会自动帮我们同步到容器内\n\n### 实战：安装MySQL\n\n```\n#获取mysql5.7的镜像\ndocker pull mysql:5.7\n\n#运行容器，需要数据挂载 #安装启动mysql需要配置密码\n#官方测试： \ndocker run --name some-mysql -e MYSQL_ROOT_PASSWORD=my-secret-pw -d mysql:tag\n#我的：\ndocker run -d -p 3310:3306 -v /home/mysql/conf:/etc/mysql/conf.d -v /home/mysql/data:/var/lib/mysql/ -e MYSQL_ROOT_PASSWORD=123456 --name=\"mysql_test\" mysql:5.7\n#启动成功之后，在本地使用Navicat测试连接\n\n\n# 进入数据库容器\ndocker exec -it mysql_first bash\n```\n\n![](https://presenter.oss-cn-shanghai.aliyuncs.com/image-20220523232334775.png)\n\n![](https://presenter.oss-cn-shanghai.aliyuncs.com/image-20220523232645959.png)\n\n```\n#在本地创建一个数据库测试是否同步成功\n```\n\n### 具名和匿名挂载\n\n```\n#匿名挂载\n-v 容器内路径！\ndocker run -d -P --name nginx01 -v /etc/nginx nginx\n#参看所有的卷的情况\ndocker volume ls\n\n#这里发现，这种就是匿名挂载，我们在-v只写了容器内的路径，没有写容器外的路径！\nDRIVER    VOLUME NAME\nlocal     2d5438e11233a296bc9d097a9f7854278fecbd7be7e7d4a701e7191ede1c1c3b\nlocal     56b9ea9722cddab11ef4c91beef28ed6188bff1f98fc2139f15396137531a0be\n\n#具名挂载\ndocker run -d -P --name nginx02 -v juming-nginx:/etc/nginx nginx\n#再次查看卷的情况\nDRIVER    VOLUME NAME\nlocal     2d5438e11233a296bc9d097a9f7854278fecbd7be7e7d4a701e7191ede1c1c3b\nlocal     56b9ea9722cddab11ef4c91beef28ed6188bff1f98fc2139f15396137531a0be\nlocal     juming-nginx\n\n#通过 -v 卷名：容器内路径\n#查看一下这个卷\ndocker volume inspect juming-nginx\n\n[\n    {\n        \"CreatedAt\": \"2022-05-20T13:56:57+08:00\",\n        \"Driver\": \"local\",\n        \"Labels\": null,\n        \"Mountpoint\": \"ar/lib/docker/volumes/juming-nginx/_data\",\n        \"Name\": \"juming-nginx\",\n        \"Options\": null,\n        \"Scope\": \"local\"\n    }\n]\n\n#所有的docker容器内的卷，没有指定目录的情况下都是在/var/lib/docker/volumes/****/_data\n\n#我们通过具名挂载可以方便找到我们的一个卷，大多数情况在使用居民挂载\n\n#如何确定是具名挂载还是指定路径挂载！\n-v 容器内路径    #匿名挂载\n-v 卷名:容器内路径   #具名挂载\n-v /宿主机路径::容器内路径  #指定路径挂载\n```\n\n**拓展**\n\n```\n#通过 -v容器内路径：ro rw改变读写权限\n\n#ro    readonly 只读\n#rw    readwrite 可读可写\n\n#一旦设置了权限 容器对我们挂在出来的内容就有了限定\ndocker run -d -P --name nginx02 -v juming-nginx:/etc/nginx:ro nginx\ndocker run -d -P --name nginx02 -v juming-nginx:/etc/nginx:rw nginx\n\n# ro 只要看到ro就说明这个路径只能通过宿主机来操作，容器内都是无法操作！\n```\n\n### 初识DockerFile\n\nDockerFile就是用来构建docker镜像的构建文件！\n\n通过这个脚本可以生成镜像，镜像是一层一层的，脚本一个个的命令，每个命令都是一层\n\n```\n#创建一个DockerFile文件；名字可以随机 建议 DockerFile\n#文件中的内容 指令（大写） 参数\n\nFROM centos\n\nVOLUME [\"volume01\",\"volume02\"]\n\nCMD echo \"----end-----\"\n\nCMD /bin/bash\n\n#这里的每个命令都是镜像的一层！\n\n#构建DockerFile\ndocker build -f /home/docker-test-volume/dockerfile1 -t ilpvc/centos:1.0 .\n```\n\n![](https://presenter.oss-cn-shanghai.aliyuncs.com/image-20220524095022493.png)\n\n```\n#启动自己写的容器\ndocker run -it 7925f3fefaf6 /bin/bash\n#下面的两个目录就是我们生成镜像自动挂载的，数据卷目录\n#这个卷和外部一定有一个同步的目录！\n#上面使用的是匿名挂载\n```\n\n![](https://presenter.oss-cn-shanghai.aliyuncs.com/image-20220524095710091.png)\n\n```\n#可以通过docker inspect 容器名 查看挂载路径\n#在mounts里面\n```\n\n![](https://presenter.oss-cn-shanghai.aliyuncs.com/image-20220524100155562.png)\n\n> 这种方式我们未来使用的十分多，因为我们通常会构建自己的镜像！\n> \n> 假设构建镜像时没有挂载卷，要手动镜像挂载 -v 卷名：容器内路径！\n\n### 数据卷容器\n\n多个mysql同步数据\n\n![](https://presenter.oss-cn-shanghai.aliyuncs.com/image-20220524101020136.png)\n\n```\n# 启动三个容器，通过我们自己写的镜像启动\n# 启动第一个\ndocker run -it --name docker01 ilpvc/centos:1.0\n# 启动第二个\ndocker run -it --name docker02 --volumes-from docker01 ilpvc/centos:1.0\n```\n\n此时这两个容器的volume就会自动绑定\n\n> docker01->volume01==docker02->volume01\n> \n> docker01->volume02==docker02->volume02\n\n```\n#测试：删除docker01，docker02的数据还在\n```\n\n> 绑定的多个容器之间的数据卷是拷贝的概念。\n\n**多个mysql实现数据共享**\n\n```\n#第一个mysql\n\ndocker run -d -p 3310:3306 -v /etc/mysql/conf.d -v /var/lib/mysql -e MYSQL_ROOT_PASSWORD=123456 --name=\"mysql01\" mysql:5.7\n\n#第二个mysql\ndocker run -d -p 3310:3306 -e MYSQL_ROOT_PASSWORD=123456 --name=\"mysql02\" --volumes-from mysql01 mysql:5.7\n\n#这个时候，可以实现两个容器数据同步！\n```\n\n**结论：**\n\n容器之间配置信息的传递，数据卷容器的生命周期一直持续到没有容器使用为止。\n\n但是一旦你持久化到了本地，那么本地的数据是不会被删除的。\n\n## DockerFile\n\n### DockerFile介绍\n\ndockerfile是用来构建docker镜像的文件！命令参数脚本！\n\n构建步骤：\n\n1、编写一个dockerfile文件\n\n2、docker build构建成为一个镜像\n\n3、docker run 运行镜像\n\n4、docker push 发布镜像（Docker Hub、阿里云镜像仓库！）\n\n查看一下官方怎么做？\n\n![](https://presenter.oss-cn-shanghai.aliyuncs.com/image-20220525161509459.png)\n\n![](https://presenter.oss-cn-shanghai.aliyuncs.com/image-20220525161604817.png)\n\n很多官方镜像都是基础包，很多功能都没有，我们通常会自己搭建自己的镜像！\n\n官方既然可以制作镜像，那我们也可以！\n\n### DockerFile的构建过程\n\n**基础知识：**\n\n1、每个保留关键字（指令）都是必须大写字母\n\n2、执行从上到下顺序执行\n\n3、#表示注释\n\n4、每一个指令都会创建提交一个新的镜像层，并提交！\n\n![](https://presenter.oss-cn-shanghai.aliyuncs.com/image-20220525162541376.png)\n\ndockerfile是面向开发的，我们以后要发布项目，做镜像，就需要编写dockerfile文件，这个文件十分简单！\n\nDocker镜像逐渐成为了企业交付的标准！\n\nDockerFIle：构建文件，定义了一切步骤，源代码\n\nDockerImages：通过DockerFile构件生成的镜像，最终发布和运行的产品！\n\nDocker 容器：容器就是镜像运行起来提供服务器\n\n### DockerFile指令\n\n```\nFROM     #基础镜像，一切都从这里开始构建\n\nMAINTAINER    #镜像是谁写的，姓名+邮箱\n\nADD      #添加镜像，加层\n\nWORKDIR    #镜像的工作目录  \n\nVOLUME    #挂载的目录\n\nEXPOSE     #暴露端口\n\nRUN      #镜像构建的时候需要运行的命令\n\nCMD             #指定容器启动的时候要运行的命令，只有最后一个会生效，可被替代\n\nENTRYPOINT         #指定容器启动的时候要运行的命令，可以直接追加命令\n\nONBUILD      #当构建一个被继承的DockerFile这个时候就会运行ONBUILD的指令，触发指令\n\nCOPY       #类似ADD命令，将我们的文件拷贝到镜像中\n\nENV        #构建的时候设置环境变量\n```\n\n![](https://presenter.oss-cn-shanghai.aliyuncs.com/image-20220525162218682.png)\n\n#### 实战测试\n\nDocker Hub中99%的镜像都是从这个基础镜像过来的 FROM scartch，然后配置需要的软件和配置来进行的构建\n\n![](https://presenter.oss-cn-shanghai.aliyuncs.com/image-20220525161604817.png)\n\n> 创建一个自己的CentOS\n\n```\nFROM centos:7\nMAINTAINER ilpvc<2693285351@qq.com>\n\nENV MYPATH /usr/local\nWORKDIR $MYPATH\n\nRUN yum -y install vim\nRUN yum -y install net-tools\n\nEXPOSE 80\n\nCMD echo $MYPATH\nCMD echo \"-----end-----\"\nCMD /bin/bash\n```\n\n```\n#进行构建\ndocker build -f mydockerfile -t mycentos:1.0 .\n\n#运行成功会出现\nSuccessfully built 1f9ae9bee6dd\nSuccessfully tagged mycentos:1.0\n\n#下面打印的目录就是我们设置的目录\n#vi命令也能使用\n# ifconfig命令也能查看ip了\n```\n\n![](https://presenter.oss-cn-shanghai.aliyuncs.com/image-20220525225439932.png)\n\n我们可以列出本地的历\n\n```\ndocker history 镜像名\n```\n\n![](https://presenter.oss-cn-shanghai.aliyuncs.com/image-20220525225919565.png)\n\n来看看mysql的历史\n\n![](https://presenter.oss-cn-shanghai.aliyuncs.com/image-20220525230011724.png)\n\n##### CMD和ENTRYPOINT的区别\n\n```\nCMD             #指定容器启动的时候要运行的命令，只有最后一个会生效，可被替代\n\nENTRYPOINT         #指定容器启动的时候要运行的命令，可以直接追加命令\n```\n\n创建一个简单的dockerfile用于测试\n\n```\n#centos中运行一个 ls -a命令\n\nFROM centos       \nCMD [\"ls\",\"-a\"]\n\n# 构建这个DockerFile后，运行得到一下结果\n# 发现ls -a生效\n```\n\n![](https://presenter.oss-cn-shanghai.aliyuncs.com/image-20220525230913777.png)\n\n我想在直接在ls -a后面追加 -l发现报错\n\n![](https://presenter.oss-cn-shanghai.aliyuncs.com/image-20220525231216098.png)\n\n但是用ENTRYPOINT就可以\n\n```\nFROM centos\n\nENTRYPOINT [\"ls\",\"-a\"]\n```\n\n![](https://presenter.oss-cn-shanghai.aliyuncs.com/image-20220525231554036.png)\n\n**发现运行结果可以直接追加命令**\n\n##### Tomcat镜像\n\n1、准备镜像文件tomcat压缩包，jdk的压缩包！\n\n2、编写DockerFile文件，官方命名 ==Dockerfile==,build会自动寻找这个文件，就不需要-f指定了。\n\n```\nFROM centos\nMAINTAINER ilpvc<2693285351@qq.com>\n\nCOPY readme.md /usr/local/readme.md\n\nADD jdk-8ull-linux-x64.tar.gz /usr/local/\nADD apache-tomcat-9.0.22.tar.gz /usr/local/\n\nRUN yum -y install vim\n\nENV MYPATH /usr/local\n\nWORKDIR $MYPATH\n\nENV JAVA_HOME /usr/local/jdk.1.8.0_11\nENV CLASSPATH $JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar\n\nENV CATALINA_HOME /usr/local/apach-tomcat-9.0.22\nENV CATALINA_BASH /usr/local/apach-tomcat-9.0.22\nENV PATH $PATH:$JAVA_HOME/bin:$CATALINA_HOME/lib:$CATALINA_HOME/bin\n\nEXPOSE 8080\n\nCMD /usr/local/apach-tomcat-9.0.22/bin/startup.sh && tail -F /usr/local/apach-tomcat-9.0.22/bin/logs/catalina.out\n```\n\n构建镜像\n\n```\n#docker build -t diytomcat .\n```\n\n##### 发布自己的镜像\n\n> docker Hub\n\n1、在dockerhub上注册自己的账号\n\n2、在服务器上面提交自己的镜像\n\n```\n[root@localhost ~]# docker login --help\n\nUsage:  docker login [OPTIONS] [SERVER]\n\nLog in to a Docker registry.\nIf no server is specified, the default is defined by the daemon.\n\nOptions:\n  -p, --password string   Password\n      --password-stdin    Take the password from stdin\n  -u, --username string   Username\n```\n\n3、登录成功后就可以提交了\n\n## Docker网络\n\n### 理解网络\n\n![](https://presenter.oss-cn-shanghai.aliyuncs.com/image-20220526104319133.png)\n\n有三个网络\n\n```\n# 问题： docker是如何处理容器的网络访问的？\n```\n\n测试：\n\n```\n#启动一个容器\n[root@localhost /]# docker run -d -P --name tomcat01 tomcat:7.0\n\n#查看容器内的ip，发现容器启动后会得到 eth0@if94 ip地址 docker分配的\n[root@localhost /]# docker exec -it tomcat01 ip addr\n1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000\n    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00\n    inet 127.0.0.1/8 scope host lo\n       valid_lft forever preferred_lft forever\n93: eth0@if94: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc noqueue state UP group default\n    link/ether 02:42:ac:11:00:03 brd ff:ff:ff:ff:ff:ff link-netnsid 0\n    inet 172.17.0.3/16 brd 172.17.255.255 scope global eth0\n       valid_lft forever preferred_lft forever\n\n# 思考. 宿主机能不能ping通容器内\n[root@localhost /]# ping 172.17.0.3\n# 能够ping通\n```\n\n> 原理\n\n1、我们没安装一个docker容器，docker就会给docker容器分配一个ip，只要我们安装了docker，就会有一个网卡docker0\n\n桥接模式，使用的技术就是evth-pair技术\n\n```\n# 再次测试ip addr\n```\n\n![](https://presenter.oss-cn-shanghai.aliyuncs.com/image-20220526120627462.png)\n\n发现多了几个，这两个就是我刚才启动的两个tomcat\n\n**这里的网卡是直接多了一对**，例如上面的91，92是一对，93，94是一对\n\nevth-pair 就是一对的虚拟设备接口，他们都是成对出现的，一段连着协议，一段彼此相连\n\n正因为这个特性，evth-pair充当一个桥梁，连接各种虚拟网络设备\n\n> 再来测试两个容器是否能ping通\n\n实际是能够ping通的\n\n**桥接模式下，tomcat01是先经过路由表去寻找tomcat02**\n\n网络图\n\n![](https://presenter.oss-cn-shanghai.aliyuncs.com/image-20220526121855548.png)\n\n**结论：tomcat01和tomcat02是公用的一个路由器，docker0。**\n\n**所有的容器不指定网络的情况下，都是docker0路由的，docker会给我们的容器分配一个默认的可用IP**\n\ndocker使用的是Linux的桥接，在宿主机中是一个docker容器的网桥docker0。\n\n**\\--link**\n\n> 思考一个场景，我们编写了一个微服务，database url=ip，项目不重启，数据库ip换掉了，我们希望可以处理这个问题，可以名字来进行访问容器？\n\n```\n# 创建三个容器，其中第三个对第二个进行了连接\n[root@localhost /]# docker run  -d -P --name tomcat01 tomcat:7.0\n13e2b10cb0b6db36bbfecfe8204435660b133f0218b12ab3a2abd5560370414b\n[root@localhost /]# docker run  -d -P --name tomcat02 tomcat:7.0\ne55f02391c0532aaf23b6d8e6d0f2406452182e57d6939b17b73bd8934ac365a\n[root@localhost /]# docker run  -d -P --name tomcat03 --link tomcat02 tomcat:7.0\n288bcac1c4aa5d0cdb26033453205b5e8b7ab5815bcc7740dd5fc5982761bd2e\n\n# 现在来尝试没有连接的容器之间ping，看是否能ping通\n[root@localhost /]# docker exec -it tomcat02 ping tomcat01\nping: tomcat01: Name or service not known\n[root@localhost /]# docker exec -it tomcat01 ping tomcat02\nping: tomcat02: Name or service not known\n\n#现在来看连接的容器之间是否能ping通\n[root@localhost /]# docker exec -it tomcat03 ping tomcat02\nPING tomcat02 (172.17.0.3) 56(84) bytes of data.\n64 bytes from tomcat02 (172.17.0.3): icmp_seq=1 ttl=64 time=0.262 ms\n64 bytes from tomcat02 (172.17.0.3): icmp_seq=2 ttl=64 time=0.095 ms\n^C\n--- tomcat02 ping statistics ---\n2 packets transmitted, 2 received, 0% packet loss, time 999ms\nrtt min/avg/max/mdev = 0.095/0.178/0.262/0.084 ms\n[root@localhost /]# docker exec -it tomcat02 ping tomcat03\nping: tomcat03: Name or service not known\n# 发现能够正向ping通但是不能反向ping通\n\n# 用network inspect查看详细内容\n# 可以看到所有的容器在docker0里的网络配置\n[root@localhost /]# docker network inspect 30963c06b948\n[\n    {\n        \"Name\": \"bridge\",\n        \"Id\": \"30963c06b94849260983a1dd752bf2feb0329daf0306959f4e6991b1f1460ce9\",\n        \"Created\": \"2022-05-20T09:08:35.322002067+08:00\",\n        \"Scope\": \"local\",\n        \"Driver\": \"bridge\",\n        \"EnableIPv6\": false,\n        \"IPAM\": {\n            \"Driver\": \"default\",\n            \"Options\": null,\n            \"Config\": [\n                {\n                    \"Subnet\": \"172.17.0.0/16\",\n                    \"Gateway\": \"172.17.0.1\"\n                }\n            ]\n        },\n        \"Internal\": false,\n        \"Attachable\": false,\n        \"Ingress\": false,\n        \"ConfigFrom\": {\n            \"Network\": \"\"\n        },\n        \"ConfigOnly\": false,\n        \"Containers\": {\n            \"13e2b10cb0b6db36bbfecfe8204435660b133f0218b12ab3a2abd5560370414b\": {\n                \"Name\": \"tomcat01\",\n                \"EndpointID\": \"21344fe98dc1329594b13cdefcd63cdf5cf8626f44de4c31acb4f29c69b8e27d\",\n                \"MacAddress\": \"02:42:ac:11:00:02\",\n                \"IPv4Address\": \"172.17.0.2/16\",\n                \"IPv6Address\": \"\"\n            },\n            \"288bcac1c4aa5d0cdb26033453205b5e8b7ab5815bcc7740dd5fc5982761bd2e\": {\n                \"Name\": \"tomcat03\",\n                \"EndpointID\": \"45be7c38149eadba1a61d660d9ad31c4fc0a24a2ed67029738056244328e1b9b\",\n                \"MacAddress\": \"02:42:ac:11:00:04\",\n                \"IPv4Address\": \"172.17.0.4/16\",\n                \"IPv6Address\": \"\"\n            },\n            \"e55f02391c0532aaf23b6d8e6d0f2406452182e57d6939b17b73bd8934ac365a\": {\n                \"Name\": \"tomcat02\",\n                \"EndpointID\": \"4ba9e3d864da24c4c53276c3948d7576559d6ef9c0afa94cca112a6119ead089\",\n                \"MacAddress\": \"02:42:ac:11:00:03\",\n                \"IPv4Address\": \"172.17.0.3/16\",\n                \"IPv6Address\": \"\"\n            }\n        },\n        \"Options\": {\n            \"com.docker.network.bridge.default_bridge\": \"true\",\n            \"com.docker.network.bridge.enable_icc\": \"true\",\n            \"com.docker.network.bridge.enable_ip_masquerade\": \"true\",\n            \"com.docker.network.bridge.host_binding_ipv4\": \"0.0.0.0\",\n            \"com.docker.network.bridge.name\": \"docker0\",\n            \"com.docker.network.driver.mtu\": \"1500\"\n        },\n        \"Labels\": {}\n    }\n]\n# 查看docker03的hosts的配置，发现，tomcat的host配置文件中添加了tomcat02的ip\n[root@localhost /]# docker exec -it tomcat03 cat /etc/hosts\n127.0.0.1       localhost\n::1     localhost ip6-localhost ip6-loopback\nfe00::0 ip6-localnet\nff00::0 ip6-mcastprefix\nff02::1 ip6-allnodes\nff02::2 ip6-allrouters\n172.17.0.3      tomcat02 e55f02391c05\n172.17.0.4      288bcac1c4aa\n```\n\n**本质探究：--link就是在我们hosts配置中增加了一个172.17.0.3 tomcat02 e55f02391c05**\n\n现在已经不建议使用 --link！\n\n**我们需要自定义网络，docker0的局限性太高例如：不支持容器名连接访问**\n\n### 自定义网络\n\n> 查看所有的docker网络\n\n![](https://presenter.oss-cn-shanghai.aliyuncs.com/image-20220526125915636.png)\n\n**网络模式**\n\nbridge ：桥接 docker（默认，自己创建也是用bridge模式）\n\nnone ：不配置网络\n\nhost ：和宿主机共享网络\n\ncontainer ：容器内网络连通！（用得少！局限很大）\n\n**测试**\n\n```\n# 我们直接启动的命令 --net bridge，而这个就是我们的docker01\n# --net bridge,不写，默认就是这个\ndocker run -d -P --name tomcat01 --net bridge tomcat\n\n# 我们可以自定义一个网络\n# 使用docker network --help\nCommands:\n  connect     Connect a container to a network\n  create      Create a network\n  disconnect  Disconnect a container from a network\n  inspect     Display detailed information on one or more networks\n  ls          List networks\n  prune       Remove all unused networks\n  rm          Remove one or more networks\n\n# 在使用docker network create --help\nOptions:\n      --attachable           Enable manual container attachment\n      --aux-address map      Auxiliary IPv4 or IPv6 addresses used by Network driver (default map[])\n      --config-from string   The network from which to copy the configuration\n      --config-only          Create a configuration only network\n  -d, --driver string        Driver to manage the Network (default \"bridge\")\n      --gateway strings      IPv4 or IPv6 Gateway for the master subnet\n      --ingress              Create swarm routing-mesh network\n      --internal             Restrict external access to the network\n      --ip-range strings     Allocate container ip from a sub-range\n      --ipam-driver string   IP Address Management Driver (default \"default\")\n      --ipam-opt map         Set IPAM driver specific options (default map[])\n      --ipv6                 Enable IPv6 networking\n      --label list           Set metadata on a network\n  -o, --opt map              Set driver specific options (default map[])\n      --scope string         Control the network's scope\n      --subnet strings       Subnet in CIDR format that represents a network segment\n```\n\n**我们现在试着来创建一个自定义网络**\n\n```\n# --driver bridge   桥接模式\n# --subnet 192.168.0.0/16  网段\n# --gateway 192.168.0.1   网关\ndocker network create --driver bridge --subnet 192.168.0.0/16 --gateway 192.168.0.1 mynet\n# 然后就可以看到我们自定义的网络\n[root@localhost /]# docker network ls\nNETWORK ID     NAME      DRIVER    SCOPE\n30963c06b948   bridge    bridge    local\nd34fd26d662e   host      host      local\n9c81d9980296   mynet     bridge    local\n55d10d595808   none      null      local\n```\n\n自定义的网络发现是能够ping通的\n\n```\n[root@localhost /]# docker run -d -P --name tomcat02 --net mynet tomcat:7.0\n34d2b8b547c9bb41e65a2da07f611311d9061f75a38e4fcec8cfc819c27ca2e3\n[root@localhost /]# docker exec -it tomcat01 ping tomcat02\nPING tomcat02 (192.168.0.3) 56(84) bytes of data.\n64 bytes from tomcat02.mynet (192.168.0.3): icmp_seq=1 ttl=64 time=0.155 ms\n64 bytes from tomcat02.mynet (192.168.0.3): icmp_seq=2 ttl=64 time=0.095 ms\n^C\n--- tomcat02 ping statistics ---\n2 packets transmitted, 2 received, 0% packet loss, time 5ms\nrtt min/avg/max/mdev = 0.095/0.125/0.155/0.030 ms\n```\n\n我们自定义的网络docker都已经帮我们维护好了对应关系，推荐我们平时都这样使用网络！\n\n好处：\n\nredis-不同的集群使用不同的网络，保证集群是安全和健康的\n\nmysql-不同的集群使用不同的网络，保证集群是安全和健康的\n\n### 网络连通\n\n假如我们有两个不同的网络配置的容器\n\ntomcat03使用的是docker0\n\ntomcat01使用的是自定义\n\n这两个tomcat处在不同的网段中，还能联通嘛？\n\n```\n[root@localhost /]# docker run -d -P --name tomcat03 tomcat:7.0\nfcf802fc4dd78d6d4c088c17c3574030c6c62d9514fe2156f1899afea958676f\n[root@localhost /]# docker run -d -P --name tomcat04 tomcat:7.0\ndc77cfd0e70aed481d42dd9164c3ecd681d9fb4966d7a24f129621f7d6bdaf9a\n```\n\n现在我们需要打通两个网络\n\n```\n# 这里使用docker network connect \n\n# 测试打通tomcat03到mynet\n\ndocker network connect mynet tomcat03\n```\n\n![](https://presenter.oss-cn-shanghai.aliyuncs.com/image-20220526132557525.png)\n\n**这里发现能够ping的通了**\n\n```\n# 再来看看docker network inspect mynet\n# 可以看到多了一条\n```\n\n![](https://presenter.oss-cn-shanghai.aliyuncs.com/image-20220526132746507.png)\n\n```\n# 再看看tomcat03的ip\n[root@localhost /]# docker exec -it tomcat03 ip addr\n1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000\n    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00\n    inet 127.0.0.1/8 scope host lo\n       valid_lft forever preferred_lft forever\n112: eth0@if113: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc noqueue state UP group default\n    link/ether 02:42:ac:11:00:02 brd ff:ff:ff:ff:ff:ff link-netnsid 0\n    inet 172.17.0.2/16 brd 172.17.255.255 scope global eth0\n       valid_lft forever preferred_lft forever\n116: eth1@if117: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc noqueue state UP group default\n    link/ether 02:42:c0:a8:00:04 brd ff:ff:ff:ff:ff:ff link-netnsid 0\n    inet 192.168.0.4/16 brd 192.168.255.255 scope global eth1\n       valid_lft forever preferred_lft forever\n# 发现多了一个evth -pair，多了一个网卡\n```\n\n### 实战：部署Redis集群\n","tags":["docker"],"categories":["docker","虚拟机"]},{"title":"Git基础","url":"/2022/06/02/git基础/","content":"\n# git基础\n\n\\==在windows安装好git之后，会在右键菜单出现一个git bash here，点击这个就能进入命令行窗口。==\n\n## 1.用户信息配置\n\n![image-20210418091827503](https://presenter.oss-cn-shanghai.aliyuncs.com/image/20210418091827.png)\n\n### 常用命令\n\n```\ngit branch -a      //查看当前项目的分支\ngit checkout [branch]   //修改分支\n```\n\n### 文本编辑器\n\n设置Git默认使用的文本编辑器, 一般可能会是 Vi 或者 Vim。如果你有其他偏好，比如 Emacs 的话，可以重新设置：:\n\n```\n$ git config --global core.editor emacs\n```\n\n### 查看配置信息\n\n要检查已有的配置信息，可以使用 git config --list 命令：\n\n```\n$ git config --list\nhttp.postbuffer=2M\nuser.name=runoob\nuser.email=test@runoob.com\n```\n\n## 2.创建仓库\n\n### 使用方法\n\n```\ngit init\n// 使用当前目录作为Git仓库，我们只需使它初始化。\ngit init newpro\n//在当前目录创建一个newpro文件作为仓库\n```\n\n## git clone\n\n我们使用 **git clone** 从现有 Git 仓库中拷贝项目（类似 **svn checkout**）。\n\n克隆仓库的命令格式为：\n\n```\ngit clone <repo>\n```\n\n如果我们需要克隆到指定的目录，可以使用以下命令格式：\n\n```\ngit clone <repo> <directory>\n```\n\n### 配置\n\ngit 的设置使用 **git config** 命令。\n\n显示当前的 git 配置信息：\n\n```\n$ git config --list\ncredential.helper=osxkeychain\ncore.repositoryformatversion=0\ncore.filemode=true\ncore.bare=false\ncore.logallrefupdates=true\ncore.ignorecase=true\ncore.precomposeunicode=true\n```\n\n编辑 git 配置文件:\n\n```\n$ git config -e    # 针对当前仓库 \n```\n\n或者：\n\n```\n$ git config -e --global   # 针对系统上所有仓库\n```\n\n设置提交代码时的用户信息：\n\n```\n$ git config --global user.name \"runoob\"\n$ git config --global user.email test@runoob.com\n```\n\n如果去掉 **\\--global** 参数只对当前仓库有效。\n\n## 3.Git 远程仓库(Github)\n\n### 添加远程库\n\n要添加一个新的远程仓库，可以指定一个简单的名字，以便将来引用,命令格式如下：\n\n```\ngit remote add [shortname] [url]\n```\n\n本例以 Github 为例作为远程仓库，如果你没有 Github 可以在官网 https://github.com/注册。\n\n由于你的本地 Git 仓库和 GitHub 仓库之间的传输是通过SSH加密的，所以我们需要配置验证信息：\n\n使用以下命令生成 SSH Key：\n\n```\n$ ssh-keygen -t rsa -C \"github上注册的邮箱\"\n```\n\n例如：\n\n```\n$ ssh-keygen -t rsa -C \"429240967@qq.com\"\nGenerating public/private rsa key pair.\nEnter file in which to save the key (/Users/tianqixin/.ssh/id_rsa): \nEnter passphrase (empty for no passphrase):    # 直接回车\nEnter same passphrase again:                   # 直接回车\nYour identification has been saved in /Users/tianqixin/.ssh/id_rsa.\nYour public key has been saved in /Users/tianqixin/.ssh/id_rsa.pub.\nThe key fingerprint is:\nSHA256:MDKVidPTDXIQoJwoqUmI4LBAsg5XByBlrOEzkxrwARI 429240967@qq.com\nThe key's randomart image is:\n+---[RSA 3072]----+\n|E*+.+=**oo       |\n|%Oo+oo=o. .      |\n|%**.o.o.         |\n|OO.  o o         |\n|+o+     S        |\n|.                |\n|                 |\n|                 |\n|                 |\n+----[SHA256]-----+\n```\n\n然后在上面第7排的所显示的目录下找到id\\_rsa.pub,用记事本打开，复制里面所有的信息。\n\n回到 github 上，进入 Account => Settings（账户配置）。\n\n![img](https://presenter.oss-cn-shanghai.aliyuncs.com/image/20210418100925.jpeg)\n\n左边选择 **SSH and GPG keys**，然后点击 **New SSH key** 按钮,title 设置标题，可以随便填，粘贴在你电脑上生成的 key。\n\n![img](https://www.runoob.com/wp-content/uploads/2015/03/B0589847-A498-4415-8700-252BDE1B20C0.jpg)\n\n![img](https://www.runoob.com/wp-content/uploads/2015/03/106AD534-A38A-47F3-88A3-B7BE3F2FEEF1.jpg)\n\n将复制的key粘贴进去\n\n![img](https://presenter.oss-cn-shanghai.aliyuncs.com/image/20210418101218.jpeg)\n\n为了验证是否成功，输入以下命令：\n\n```\n$ ssh -T git@github.com\nThe authenticity of host 'github.com (52.74.223.119)' can't be established.\nRSA key fingerprint is SHA256:nThbg6kXUpJWGl7E1IGOCspRomTxdCARLviKw6E5SY8.\nAre you sure you want to continue connecting (yes/no/[fingerprint])? yes                   # 输入 yes\nWarning: Permanently added 'github.com,52.74.223.119' (RSA) to the list of known hosts.\nHi tianqixin! You've successfully authenticated, but GitHub does not provide shell access. # 成功信息\n```\n\n之后登录后点击\" New repository \" ,就是新建一个项目如下图所示：\n\n![img](https://presenter.oss-cn-shanghai.aliyuncs.com/image/20210418101349.jpeg)\n\n之后在在Repository name 填入 runoob-git-test(远程仓库名) ，其他保持默认设置，点击\"Create repository\"按钮，就成功地创建了一个新的Git仓库：![img](https://presenter.oss-cn-shanghai.aliyuncs.com/image/20210418101442.jpeg)\n\n创建成功后，显示如下信息：\n\n![img](https://presenter.oss-cn-shanghai.aliyuncs.com/image/20210418101453.jpeg)\n\n右键打开git bash here，然后输入以下命令\n\n```\n$ mkdir runoob-git-test                     # 创建测试目录\n$ cd runoob-git-test/                       # 进入测试目录\n$ echo \"# 菜鸟教程 Git 测试\" >> README.md     # 创建 README.md 文件并写入内容\n$ ls                                        # 查看目录下的文件\nREADME\n$ git init                                  # 初始化\n$ git add README.md                         # 添加文件\n$ git commit -m \"添加 README.md 文件\"        # 提交并备注信息\n[master (root-commit) 0205aab] 添加 README.md 文件\n 1 file changed, 1 insertion(+)\n create mode 100644 README.md\n\n# 提交到 Github\n$ git remote add origin git@github.com:tianqixin/runoob-git-test.git\n$ git push -u origin master\n```\n\n这就可以在github上面看到我们刚才上传的的内容\n\n![img](https://presenter.oss-cn-shanghai.aliyuncs.com/image/20210418101658.jpeg)\n\n## 查看当前的远程库\n\n要查看当前配置有哪些远程仓库，可以用命令：\n\n```\ngit remote\n```\n\n### 实例\n\n```\n$ git remote\norigin\n$ git remote -v\norigin    git@github.com:tianqixin/runoob-git-test.git (fetch)\norigin    git@github.com:tianqixin/runoob-git-test.git (push)\n```\n\n执行时加上 -v 参数，你还可以看到每个别名的实际链接地址。\n\n* * *\n\n## 提取远程仓库\n\nGit 有两个命令用来提取远程仓库的更新。\n\n1、从远程仓库下载新分支与数据：\n\n```\ngit fetch\n```\n\n该命令执行完后需要执行 git merge 远程分支到你所在的分支。\n\n2、从远端仓库提取数据并尝试合并到当前分支：\n\n```\ngit merge\n```\n\n该命令就是在执行 git fetch 之后紧接着执行 git merge 远程分支到你所在的任意分支。\n\n假设你配置好了一个远程仓库，并且你想要提取更新的数据，你可以首先执行 **git fetch \\[alias\\]** 告诉 Git 去获取它有你没有的数据，然后你可以执行 **git merge \\[alias\\]/\\[branch\\]** 以将服务器上的任何更新（假设有人这时候推送到服务器了）合并到你的当前分支。\n\n接下来我们在 Github 上点击\" README.md\" 并在线修改它:\n\n![img](https://www.runoob.com/wp-content/uploads/2015/03/C5A6670F-202D-4F2C-8A63-07CEA37BB67A.jpg)\n\n然后我们在本地更新修改。\n\n```\n$ git fetch origin\nremote: Counting objects: 3, done.\nremote: Compressing objects: 100% (2/2), done.\nremote: Total 3 (delta 0), reused 0 (delta 0), pack-reused 0\nUnpacking objects: 100% (3/3), done.\nFrom github.com:tianqixin/runoob-git-test\n   0205aab..febd8ed  master     -> origin/master\n```\n\n以上信息\"0205aab..febd8ed master -> origin/master\" 说明 master 分支已被更新，我们可以使用以下命令将更新同步到本地：\n\n```\n$ git merge origin/master\nUpdating 0205aab..febd8ed\nFast-forward\n README.md | 1 +\n 1 file changed, 1 insertion(+)\n```\n\n查看 README.md 文件内容：\n\n```\n$ cat README.md \n# 菜鸟教程 Git 测试\n## 第一次修改内容\n```\n\n* * *\n\n## 推送到远程仓库\n\n推送你的新分支与数据到某个远端仓库命令:\n\n```\ngit push [alias] [branch]\n```\n\n以上命令将你的 \\[branch\\] 分支推送成为 \\[alias\\] 远程仓库上的 \\[branch\\] 分支，实例如下。\n\n```\n$ touch runoob-test.txt      # 添加文件\n$ git add runoob-test.txt \n$ git commit -m \"添加到远程\"\nmaster 69e702d] 添加到远程\n 1 file changed, 0 insertions(+), 0 deletions(-)\n create mode 100644 runoob-test.txt\n\n$ git push origin master    # 推送到 Github\n```\n\n重新回到我们的 Github 仓库，可以看到文件已经提交上来了：\n\n![img](https://presenter.oss-cn-shanghai.aliyuncs.com/image/20210418101854.jpeg)\n\n* * *\n\n## 删除远程仓库\n\n删除远程仓库你可以使用命令：\n\n```\ngit remote rm [别名]\n```\n\n### 实例\n\n```\n$ git remote -v\norigin    git@github.com:tianqixin/runoob-git-test.git (fetch)\norigin    git@github.com:tianqixin/runoob-git-test.git (push)\n\n# 添加仓库 origin2\n$ git remote add origin2 git@github.com:tianqixin/runoob-git-test.git\n\n$ git remote -v\norigin    git@github.com:tianqixin/runoob-git-test.git (fetch)\norigin    git@github.com:tianqixin/runoob-git-test.git (push)\norigin2    git@github.com:tianqixin/runoob-git-test.git (fetch)\norigin2    git@github.com:tianqixin/runoob-git-test.git (push)\n\n# 删除仓库 origin2\n$ git remote rm origin2\n$ git remote -v\norigin    git@github.com:tianqixin/runoob-git-test.git (fetch)\norigin    git@github.com:tianqixin/runoob-git-test.git (push)\n```\n","tags":["git"],"categories":["git","工具类"]},{"title":"IDEA常用设置及插件","url":"/2022/06/02/idea常用设置及插件/","content":"\n## 基本设置\n\n### 设置界面风格及修改外部UI尺寸大小\n\n![](https://presenter.oss-cn-shanghai.aliyuncs.com/idea_screen_1.png)\n\n### 打开IDEA时设置不重新打开最近的项目\n\n> IDEA默认会打开最近的项目，有时候我们需要自己选择要打开的项目，不勾选该选项可以实现。\n\n![](https://presenter.oss-cn-shanghai.aliyuncs.com/idea_screen_2.png)\n\n### 设置IDEA的快捷键\n\n![](https://presenter.oss-cn-shanghai.aliyuncs.com/idea_screen_3.png)\n\n### 设置代码字体大小\n\n![](https://presenter.oss-cn-shanghai.aliyuncs.com/idea_screen_4.png)\n\n### 设置项目文件编码格式\n\n![](https://presenter.oss-cn-shanghai.aliyuncs.com/idea_screen_5.png)\n\n### 设置代码提示的匹配模式\n\n![](https://presenter.oss-cn-shanghai.aliyuncs.com/idea_screen_6.png)\n\n### 设置新建类文件的类注释模版\n\n![](https://presenter.oss-cn-shanghai.aliyuncs.com/idea_screen_7.png)\n\n## IDEA和Eclipse常用快捷键对比\n\n> 友情提示：IDEA可以设置为Eclipse风格的快捷键，在File->Settings->Keymap处，如需更改部分快捷键可按如下表格中的英文描述进行搜索，并改为相应快捷键。\n\n| Eclipse | IDEA | 英文描述 | 中文描述 |\n| --- | --- | --- | --- |\n| ctrl+shift+r | ctrl+shift+n | Navigate->File | 找工作空间的文件 |\n| ctrl+shift+t | ctrl+n | Navigate->Class | 找类定义 |\n| ctrl+shift+g | alt+f7 | Edit->Find->Find Usages | 查找方法在哪里调用.变量在哪里被使用 |\n| ctrl+t | ctrl+t | Other->Hierarchy Class | 看类继承结构 |\n| ctrl+o | ctrl+f12 | Navigate->File Structure | 搜索一个类里面的方法 |\n| shift+alt+z | ctrl+alt+t | Code->Surround With | 生成常见的代码块 |\n| shift+alt+l | ctrl+alt+v | Refactor->Extract->Variable | 抽取变量 |\n| shift+alt+m | ctrl+alt+m | Refactor->Extract->Method | 抽取方法 |\n| alt+左箭头 | ctrl+alt+左箭头 | Navigate->Back | 回退上一个操作位置 |\n| alt+右箭头 | ctrl+alt+右键头 | Navigate->Forward | 前进上一个操作位置 |\n| ctrl+home | ctrl+home | Move Caret to Text Start | 回到类最前面 |\n| ctrl+end | ctrl+end | Move Caret to Text End | 回到类最后面 |\n| ctrl+e | ctrl+e | View->Recent Files | 最近打开的文件 |\n| alt+/ | ctrl+space | Code->Completion->Basic | 提示变量生成 |\n| ctrl+1 | alt+enter | Other->Show Intention Actions | 提示可能的操作 |\n| ctrl+h | ctrl+shift+f | Find in Path | 全局搜索 |\n| alt+上/下箭头 | alt+shift+上/下箭头 | Code->Move Line Up/Down | 移动一行代码 |\n| ctrl+/ | ctrl+/ | Other->Fix doc comment | 方法注释 |\n| ctrl+alt+s | alt+insert | Generate | 生成getter,setter,tostring等 |\n\n## 推荐插件\n\n> 由于IDEA本身就自带很多插件，可以完成大部分需求，这里就推荐两个本人常用的插件。\n\n### Free MyBatis plugin\n\n> 非常好用的MyBatis插件，对MyBatis的xml具有强大的提示功能，同时可以关联mapper接口和mapper.xml中的sql实现。\n\n#### 可以从mapper接口和mapper.xml文件中相互跳转\n\n![](https://presenter.oss-cn-shanghai.aliyuncs.com/idea_screen_8.png)\n\n#### mapper.xml中的各种提示\n\n![](https://presenter.oss-cn-shanghai.aliyuncs.com/idea_screen_9.png)\n\n![](https://presenter.oss-cn-shanghai.aliyuncs.com/idea_screen_10.png)\n\n### Lombok plugin\n\n> Lombok为Java语言添加了非常有趣的附加功能，你可以不用再为实体类手写getter,setter等方法，通过一个注解即可拥有。\n\n一个没有getter,setter方法的类通过添加@Getter和@Setter注解拥有了getter,setter方法。\n\n![](https://presenter.oss-cn-shanghai.aliyuncs.com/idea_screen_11.png)\n","tags":["idea"],"categories":["工具类"]},{"title":"Git命令","url":"/2022/06/02/git命令/","content":"\n## 一、Git常用命令\n\n**1、常用**\n\n```\ngit remote add origin git@github.com:yeszao/dofiler.git     # 配置远程git版本库\ngit pull origin master                     # 下载代码及快速合并\ngit push origin master                     # 上传代码及快速合并\ngit fetch origin                        # 从远程库获取代码\ngit branch                           # 显示所有分支\ngit checkout master                       # 切换到master分支\ngit checkout -b dev                       # 创建并切换到dev分支\ngit commit -m \"first version\"                  # 提交\ngit status                           # 查看状态\ngit log                             # 查看提交历史\ngit config --global core.editor vim               # 设置默认编辑器为vim（git默认用nano）\ngit config core.ignorecase false                # 设置大小写敏感\ngit config --global user.name \"YOUR NAME\"            # 设置用户名\ngit config --global user.email \"YOUR EMAIL ADDRESS\"       # 设置邮箱\n```\n\n**2、别名alias**\n\n```\ngit config --global alias.br=\"branch\"         # 创建/查看本地分支\ngit config --global alias.co=\"checkout\"        # 切换分支\ngit config --global alias.cb=\"checkout -b\"      # 创建并切换到新分支\ngit config --global alias.cm=\"commit -m\"       # 提交\ngit config --global alias.st=\"status\"         # 查看状态\ngit config --global alias.pullm=\"pull origin master\" # 拉取分支\ngit config --global alias.pushm=\"push origin master\" # 提交分支\ngit config --global alias.log=\"git log --oneline --graph --decorate --color=always\" # 单行、分颜色显示记录\ngit config --global alias.logg=\"git log --graph --all --format=format:'%C(bold blue)%h%C(reset) - %C(bold green)(%ar)%C(reset) %C(white)%s%C(reset) %C(bold white)— %an%C(reset)%C(bold yellow)%d%C(reset)' --abbrev-commit --date=relative\" # 复杂显示\n```\n\n3.创建版本库\n\n```\ngit clone         # 克隆远程版本库\ngit init            # 初始化本地版本库\n```\n\n4.修改和提交\n\n```\ngit status           # 查看状态\ngit diff            # 查看变更内容\ngit add .            # 跟踪所有改动过的文件\ngit add          # 跟踪指定的文件\ngit mv        # 文件改名\ngit rm          # 删除文件\ngit rm --cached      # 停止跟踪文件但不删除\ngit commit -m “commit message” # 提交所有更新过的文件\ngit commit --amend       # 修改最后一次提交\n```\n\n5.查看历史\n\n```\ngit log             # 查看提交历史\ngit log -p        # 查看指定文件的提交历史\ngit blame         # 以列表方式查看指定文件的提交历史\n```\n\n6.撤销\n\n```\ngit reset --hard HEAD      # 撤消工作目录中所有未提交文件的修改内容\ngit reset --hard    # 撤销到某个特定版本\ngit checkout HEAD     # 撤消指定的未提交文件的修改内容\ngit checkout -- # 同上一个命令\ngit revert       # 撤消指定的提交分支与标签\n```\n\n7.分支与标签\n\n```\ngit branch           # 显示所有本地分支\ngit checkout    # 切换到指定分支或标签\ngit branch     # 创建新分支\ngit branch -d      # 删除本地分支\ngit tag             # 列出所有本地标签\ngit tag        # 基于最新提交创建标签\ngit tag -a \"v1.0\" -m \"一些说明\" # -a指定标签名称，-m指定标签说明\ngit tag -d       # 删除标签\ngit checkout dev        # 合并特定的commit到dev分支上\ngit cherry-pick 62ecb3\n```\n\n8.合并与衍合\n\n```\ngit merge        # 合并指定分支到当前分支\ngit merge --abort        # 取消当前合并，重建合并前状态\ngit merge dev -Xtheirs     # 以合并dev分支到当前分支，有冲突则以dev分支为准\ngit rebase       # 衍合指定分支到当前分支\n```\n\n9.远程操作\n\n```\ngit remote -v          # 查看远程版本库信息\ngit remote show     # 查看指定远程版本库信息\ngit remote add  # 添加远程版本库\ngit remote remove    # 删除指定的远程版本库\ngit fetch        # 从远程库获取代码\ngit pull    # 下载代码及快速合并\ngit push    # 上传代码及快速合并\ngit push : # 删除远程分支或标签\ngit push --tags         # 上传所有标签\n```\n\n10.打包\n\n```\ngit archive --format=zip --output ../file.zip master  # 将master分支打包成file.zip文件，保存在上一级目录\ngit archive --format=zip --output ../v1.2.zip v1.2   # 打包v1.2标签的文件，保存在上一级目录v1.2.zip文件中\ngit archive --format=zip v1.2 > ../v1.2.zip       # 作用同上一条命令\n```\n\n11.全和局部配置\n\n```\n全局配置保存在：$Home/.gitconfig\n本地仓库配置保存在：.git/config\n```\n\n12.远程与本地合并\n\n```\ngit init               # 初始化本地代码仓\ngit add .               # 添加本地代码\ngit commit -m \"add local source\"   # 提交本地代码\ngit pull origin master        # 下载远程代码\ngit merge master           # 合并master分支\ngit push -u origin master       # 上传代码\n```\n","tags":["git"],"categories":["git","工具类"]},{"title":"java泛型 T与T的用法","url":"/2022/06/02/java泛型-t与t的用法/","content":"\n# [Java之泛型 T与T的用法](https://www.cnblogs.com/jpfss/p/9929108.html)\n\n`<T> T`表示返回值是一个泛型，传递啥，就返回啥类型的数据，而单独的`T`就是表示限制你传递的参数类型，这个案例中，通过一个泛型的返回方式，获取每一个集合中的第一个数据， 通过返回值`<T> T` 和`T`的两种方法实现\n\n## `<T> T` 用法\n\n这个`<T> T` 表示的是返回值T是泛型，T是一个占位符，用来告诉编译器，这个东西先给我留着，等我编译的时候，告诉你。\n\n```\npublic class Demo {\n\n    public static void main(String[] args) {\n\n        Demo demo = new Demo();\n\n        //获取string类型\n        List<String> array = new ArrayList<String>();\n        array.add(\"test\");\n        array.add(\"doub\");\n        String str = demo.getListFisrt(array);\n        System.out.println(str);\n\n        //获取nums类型\n        List<Integer> nums = new ArrayList<Integer>();\n        nums.add(12);\n        nums.add(13);\n\n        Integer num = demo.getListFisrt(nums);\n        System.out.println(num);\n    }\n\n    /**\n     * 这个<T> T 可以传入任何类型的List\n     * 参数T\n     *     第一个 表示是泛型\n     *     第二个 表示返回的是T类型的数据\n     *     第三个 限制参数类型为T\n     * @param data\n     * @return\n     */\n    private <T> T getListFisrt(List<T> data) {\n        if (data == null || data.size() == 0) {\n            return null;\n        }\n        return data.get(0);\n    }\n\n}\n```\n\n## T 用法\n\n返回值，直接写`T`表示限制参数的类型，这种方法一般多用于共同操作一个类对象，然后获取里面的集合信息啥的。\n\n```\npublic class Demo2<T> {\n\n    public static void main(String[] args) {\n\n        //限制T 为String 类型\n        Demo2<String> demo = new Demo2<String>();\n\n        //获取string类型\n        List<String> array = new ArrayList<String>();\n        array.add(\"test\");\n        array.add(\"doub\");\n        String str = demo.getListFisrt(array);\n        System.out.println(str);\n\n        //获取Integer类型 T 为Integer类型\n        Demo2<Integer> demo2 = new Demo2<Integer>();\n        List<Integer> nums = new ArrayList<Integer>();\n        nums.add(12);\n        nums.add(13);\n        Integer num = demo2.getListFisrt(nums);\n        System.out.println(num);\n    }\n\n    /**\n     * 这个只能传递T类型的数据\n     * 返回值 就是Demo<T> 实例化传递的对象类型\n     * @param data\n     * @return\n     */\n    private T getListFisrt(List<T> data) {\n        if (data == null || data.size() == 0) {\n            return null;\n        }\n        return data.get(0);\n    }\n}\n```\n","tags":["java"],"categories":["java全栈","java进阶"]},{"title":"JQuery","url":"/2022/06/02/jquery/","content":"\n# 基础\n\n## JQuery介绍\n\n**是什么：**JQuery是辅助JavaScript开发的一个js的类库。“J”就是javascript，‘Query’就是查询的意思\n\n**目前JQuery是最流行的javascript库**\n\n**从官网下载的JQuery实际是是一个.js的文本**\n\n## JQuery的使用\n\n实例：\n\n```\n<!-- 这里的src就是引用JQuery库，直接从官网将整个js代码复制下来保存就行-->\n<script type=\"text/javascript\" src=\"../代码/JQuery.js\"></script>\n<script type=\"text/javascript\"> \n<!-- $符号就是JQuery中的一个函数，JQuery的基本使用如下-->\n<!-- 获取的某个标签的属性.click(function(){})这样的形式-->\n$(function(){\n    var $but=$('#item');\n    $but.click(function(){\n        alert(\"danji\")\n    })\n})\n</script>\n```\n\n## JQuery的核心函数\n\n**‘$’符号**：是JQuery的核心函数能够完成JQuery的核心功能，\\\\$()就是调用$这个函数\n\n**1、当传入的参数是函数时'$(function)'**:\n\n表示页面加载完成后，相当于window.onload=function(){}\n\n```\n<script type=\"text/javascript\" src=\"../AJAX/代码/JQuery.js\"></script>\n<script type=\"text/javascript\" >\n    $(function(){\n        alert('页面加载完毕！！！')\n    })\n</script>\n```\n\n**2、当传入的的参数为【html字符串】时：**\n\n会直接为我们创建这个html标签对象\n\n```\n<script type=\"text/javascript\" src=\"../AJAX/代码/JQuery.js\"></script>\n<script type=\"text/javascript\" >\n    $(function(){\n        alert('页面加载完毕！！！')\n        $('<div>'+\n        '<span>wenjian1</span>'+\n        '<span>wenjian2</span>'+\n        '</div>').appendTo(\"body\")\n    })    \n</script>\n```\n\n**3、当传入参数为选择器参数时：**\n\n**$(\"#id\")：**按照id查询标签对象\n\n**$(\"标签名\")：**按照标签名查询标签对象\n\n**$(\".class属性值\")：**按照class属性查询标签\n\n```\n$(\"#sp1\"))\n$(\".class sp\"))\n$(\"span\").length\n```\n\n**4、当传入的参数为DOM'对象时，会自动转为JQuery对象：**\n\n第三点里面的查出来的值全部都转换为了JQuery对象\n\n## JQuery对象的本质\n\n**JQuery对象本质是DOM对象数组+JQuery提供的一系列功能函数**\n\n## JQuery对象和DOM对象的区别\n\n**JQuery对象不能使用DOM对象的属性和方法，DOM对象也不能使用JQuery对象的属性和方法**\n\n\\==但是JQuery和DOM可以互相转换，也就可以实现两种对象的方法都能使用==\n\nDOM转换为JQuery直接用$()就行，而JQuery转DOM则根据JQuery是数组，取下标就能进行转换。\n\n# JQuery选择器\n\n## 基本选择器\n\n[选择器API文档下载](https://presenter.oss-cn-shanghai.aliyuncs.com/jQueryAPI_1.7.1_CN.chm)\n\n$(\"#id\")\n\n$(\"\")\n\n# JQuery属性操作\n\n## jquery属性操作\n\n**html()** 可以设置和获取起始标签和结束标签的内容，和DOM中的innerHTML()一样\n\n\\*\\*text() \\*\\* 可以设置和获取起始标签和结束标签的内容，和DOM中的innerTEXT()一样\n\n**val()** 可以设置和获取表单项的value属性值\n\n**在这里面不传参是获取，传参是设置。**\n\n实例：\n\n```\n<script type=\"text/javascript\" src=\"../AJAX/代码/JQuery.js\"></script>\n<script type=\"text/javascript\">\n    $(function(){\n        alert($('div').html())\n        $('div').eq(1).html('这不是第二个div标签')\n        $('div').first().html('这不是第一个div标签')\n        $(\"button\").click(function(){\n        $(\"#usename\").val(\"niupida\")\n})\n    })\n</script>\n\n<body>\n    <div>第一个div标签</div>\n    <div>第二个div标签</div>\n    <div>第三个div标签</div>\n    <input type=\"text\" id=\"usename\">\n    <button>提交</button>\n</body>\n```\n\n**注：在html()中传进去的参数会将包含的标签进行转换，而在text()中，一切都当文本处理。**\n\n**例如：text(“\\\\**\n\n# **这是一个标题\\\\**\n\n”)，那么会将这个文本直接读取出来，不会识别标签。\\\\\n\n# 这是一个标题\\\\\n\n还有一些重要的属性值操作方法\n\n**attr()** 获取某个特定的属性值，在进行改变，一个参数是获取，两个参数是改变，不推荐操控checked，readonly，selected，disabled等等。\n\n**prop()** 同上，但是只推荐操作checked，readonly，selected，disabled等等\n\n```\n<script type=\"text/javascript\" src=\"../AJAX/代码/JQuery.js\"></script>\n<script type=\"text/javascript\">\n    $(function(){\n        alert($(\"[name='dv']:first\").attr('name','ddiic'))\n    })\n</script>\n```\n\n## JQuery插入\n\n### 内部插入\n\n**appendTo()** a.appendTo(b) 将a插入到b中，且成为最后一个元素\n\n**prependTo()** a.prependTo(b) 把a插到b所有子元素前面，并成为第一个子元素\n\n### 外部插入\n\n**insertAfter()** a.insertAfter(b) 得到ba\n\n**bainsertBefore()** a.insertBefore(b) 得到ab\n\n### 替换\n\n**replaceWith()** a.replaceWith(b) 用 b 替换掉 a\n\n**areplaceAll()** a.replaceAll(b) 用 a 替换掉所有 b\n\n### 删除\n\n**remove()** a.remove() 删除 a 标签\n\n**empty()** a.empty() 清空 a 标签里的\n\n## CSS 样式操作\n\n**addClass()** 添加样式\n\n**removeClass()** 删除样式\n\n**toggleClass()** 有就删除，没有就添加样式。\n\n**offset()** 获取和设置元素的坐标。\n\n例子：\n\n```\n<style>\n    div.bagaq{\n        background-color: aqua;\n    }\n    div.bagbr{\n        background-color: brown;\n    }\n    div.sty{\n        background-color: chartreuse;\n        font-size: large;\n    }\n</style>\n<script type=\"text/javascript\" src=\"../AJAX/代码/JQuery.js\"></script>\n<script type=\"text/javascript\">\n    $(function(){\n        $('div:first').addClass('bagaq')\n        $('div:eq(1)').removeClass()\n        $('div:last').toggleClass('sty')\n        $('div:eq(1)').offset({\n            top:100,\n            left:100\n        }\n        )\n    })\n</script>\n<body>\n    <table>\n        <tr>\n            <td><div>厉害啊</div></td>\n            <td><div class=\"bagbr\">不厉害</div></td>\n            <td><div>就这嘛</div></td>\n        </tr>\n    </table>\n\n</body>\n```\n\n## jQuery 动画\n\n### 基本动画\n\n**show()** 将隐藏的元素显示\n\n**hide()** 将可见的元素隐藏。\n\n**toggle()** 可见就隐藏，不可见就显示。\n\n**以上动画方法都可以添加参数。**\n\n​ **1、第一个参数是动画 执行的时长，以毫秒为单位**\n\n​ **2、第二个参数是动画的回调函数 (动画完成后自动调用的函数)**\n\n### 淡入淡出动画\n\n**fadeIn()** 淡入（慢慢可见）\n\n**fadeOut()** 淡出（慢慢消失）\n\n**fadeTo()** 在指定时长内慢慢的将透明度修改到指定的值。0 透明，1 完成可见，0.5 半透明\n\n**fadeToggle()** 淡入/淡出\n\n### 代码\n\n```\n<script type=\"text/javascript\">\n    /*  \n        基本\n        show([speed,[easing],[fn]]) \n        hide([speed,[easing],[fn]]) \n        toggle([speed],[easing],[fn]) \n        滑动\n        slideDown([spe],[eas],[fn]) \n        slideUp([speed,[easing],[fn]]) \n        slideToggle([speed],[easing],[fn]) \n        淡入淡出\n        fadeIn([speed],[eas],[fn]) \n        fadeOut([speed],[eas],[fn]) \n        fadeTo([[spe],opa,[eas],[fn]]) \n        fadeToggle([speed,[eas],[fn]])\n        */\n        $(function(){\n            //显示   show()\n            $(\"#btn1\").click(function(){\n                $(\"#div1\").show(2000,function () {\n                    alert(\"show动画完成 \")\n                });\n            });     \n            //隐藏  hide()\n            $(\"#btn2\").click(function(){\n                $(\"#div1\").hide(1000,function () {\n                    alert(\"hide动画 执行完成 \")\n                });\n            }); \n            //切换   toggle()\n            $(\"#btn3\").click(function(){\n                $(\"#div1\").toggle(1000,function () {\n                    alert(\"toggle动画 完成 \")\n                });\n            });\n\n            // var abc = function(){\n            //  $(\"#div1\").toggle(1000,abc);\n            // }\n            // abc();\n\n            //淡入   fadeIn()\n            $(\"#btn4\").click(function(){\n                $(\"#div1\").fadeIn(2000,function () {\n                    alert(\"fadeIn完成 \")\n                });\n            }); \n            //淡出  fadeOut()\n            $(\"#btn5\").click(function(){\n                $(\"#div1\").fadeOut(2000,function () {\n                    alert(\"fadeOut完成 \")\n                });\n            }); \n\n            //淡化到  fadeTo()\n            $(\"#btn6\").click(function(){\n                $(\"#div1\").fadeTo(2000,0.5,function () {\n                    alert('fadeTo完成 ')\n                });\n            }); \n            //淡化切换  fadeToggle()\n            $(\"#btn7\").click(function(){\n                $(\"#div1\").fadeToggle(1000,function () {\n                    alert(\"fadeToggle完成 \")\n                });\n            }); \n        })\n</script>\n\n    </head>\n    <body>\n        <table style=\"float: left;\">\n            <tr>\n                <td><button id=\"btn1\">显示show()</button></td>\n            </tr>\n            <tr>\n                <td><button id=\"btn2\">隐藏hide()</button></td>\n            </tr>\n            <tr>\n                <td><button id=\"btn3\">显示/隐藏切换 toggle()</button></td>\n            </tr>\n            <tr>\n                <td><button id=\"btn4\">淡入fadeIn()</button></td>\n            </tr>\n            <tr>\n                <td><button id=\"btn5\">淡出fadeOut()</button></td>\n            </tr>\n            <tr>\n                <td><button id=\"btn6\">淡化到fadeTo()</button></td>\n            </tr>\n            <tr>\n                <td><button id=\"btn7\">淡化切换fadeToggle()</button></td>\n            </tr>\n        </table>\n\n        <div id=\"div1\" style=\"float:left;border: 1px solid;background-color: blue;width: 300px;height: 200px;\">\n            jquery动画定义了很多种动画效果，可以很方便的使用这些动画效果\n        </div>\n    </body>\n```\n\n## JQuery 事件\n\n### 基本\n\n\\*\\*$( function(){} ) 和 window.onload = function(){} 的区别？ \\*\\*\n\n**他们分别是在什么时候触发？**\n\n1、jQuery 的页面加载完成之后是浏览器的内核解析完页面的标签创建好 DOM 对象之后就会马上执行。\n\n2、原生 js 的页面加载完成之后，除了要等浏览器内核解析完标签创建好 DOM 对象，还要等标签显示时需要的内容加载完成。\n\n**他们触发的顺序？**\n\n1、jQuery 页面加载完成之后先执行\n\n2、原生 js 的页面加载完成之后\n\n**他们执行的次数？**\n\n1、原生 js 的页面加载完成之后，只会执行最后一次的赋值函数。\n\n2、jQuery 的页面加载完成之后是全部把注册的 function 函数，依次顺序全部执行。\n\n**jQuery 中其他的事件处理方法：**\n\n> **click()** 它可以绑定单击事件，以及触发单击事件\n> \n> **mouseover()** 鼠标移入事件\n> \n> \\*\\*mouseout() \\*\\* 鼠标移出事件\n> \n> **bind()** 可以给元素一次性绑定一个或多个事件。\n> \n> \\*\\*one() \\*\\* 使用上跟 bind 一样。但是 one 方法绑定的事件只会响应一次\n> \n> **unbind()** 跟 bind 方法相反的操作，解除事件的绑定\n> \n> **live()** 也是用来绑定事件。它可以用来绑定选择器匹配的所有元素的事件。哪怕这个元素是后面动态创建出来的也\n\n### 事件的冒泡\n\n**什么是事件的冒泡？**\n\n​ 事件的冒泡是指，父子元素同时监听同一个事件。当触发子元素的事件的时候，同一个事件也被传递到了父元素的事件里去响应。\n\n**那么如何阻止事件冒泡呢？**\n\n​ ==在子元素事件函数体内，return false; 可以阻止事件的冒泡传==\n","tags":["jquery"],"categories":["前端"]},{"title":"kali安装.deb的安装包","url":"/2022/06/02/kali安装-deb的安装包/","content":"\n### 在kali中安装一些下载好的deb安装包时\n\n#### 一，找到安装包位置\n\n![image-20220318155623220](https://presenter.oss-cn-shanghai.aliyuncs.com/image-20220318155623220.png)\n\n\\==这里原本有个utools==\n\n#### 二，打开终端\n\n![image-20220318155937843](https://presenter.oss-cn-shanghai.aliyuncs.com/image-20220318155937843.png)\n\n命令：\n\n```\nsudo su\n#超级用户\ncd /tmp/mozilla_kali0\n#打开需要安装文件所在目录\nls\n#显示当前目录所有文件和文件夹\ndpkg -i [需要安装文件的全名称]\n#安装\n```\n\n等待安装即可\n","tags":["kali"],"categories":["kali","系统类"]},{"title":"leetcode-942","url":"/2022/06/02/leetcode-942/","content":"\n### 题目描述\n\n由范围 \\[0,n\\] 内所有整数组成的 n + 1 个整数的排列序列可以表示为长度为 n 的字符串 s ，其中:\n\n如果 perm\\[i\\] < perm\\[i + 1\\] ，那么 s\\[i\\] == 'I' 如果 perm\\[i\\] > perm\\[i + 1\\] ，那么 s\\[i\\] == 'D'  \n给定一个字符串 s ，重构排列 perm 并返回它。如果有多个有效排列perm，则返回其中 任何一个 。\n\n**示例 1：**\n\n```\n输入：s = \"IDID\"\n输出：[0,4,1,3,2]\n```\n\n**示例 2：**\n\n```\n输入：s = \"III\"\n输出：[0,1,2,3]\n```\n\n**示例 3：**\n\n```\n输入：s = \"DDI\"\n输出：[3,2,0,1]\n```\n\n### 方法一：贪心\n\n考虑 perm\\[0\\] 的值，根据题意：\n\n如果 s\\[0\\]=‘I’，那么令 perm\\[0\\]=0，则无论perm\\[1\\] 为何值都满足perm\\[0\\]perm\\[1\\]；  \n确定好perm\\[0\\] 后，剩余的 n−1 个字符和 n 个待确定的数就变成了一个和原问题相同，但规模为 n−1 的问题。因此我们可以继续按照上述方法确定perm\\[1\\]：如果 s\\[1\\]=‘I’，那么令 perm\\[1\\] 为剩余数字中的最小数；如果 s\\[1\\]=‘D’，那么令perm\\[1\\] 为剩余数字中的最大数。如此循环直至剩下一个数，填入perm\\[n\\] 中。\n\n代码实现时，由于每次都选择的是最小数和最大数，我们可以用两个变量lo 和 hi 表示当前剩余数字中的最小数和最大数。\n\n代码：\n\n```\nclass Solution {\n    public int[] diStringMatch(String s) {\n        int n = s.length(), lo = 0, hi = n;\n        int[] perm = new int[n + 1];\n        for (int i = 0; i < n; ++i) {\n            perm[i] = s.charAt(i) == 'I' ? lo++ : hi--;\n        }\n        perm[n] = lo; // 最后剩下一个数，此时 lo == hi\n        return perm;\n    }\n}\n```\n\n**复杂度分析**\n\n- 时间复杂度：O(n)_O_(_n_)，其中 n_n_ 是字符串 s_s_ 的长度。\n- 空间复杂度：O(1)_O_(1)，返回值不计入空间复杂度。\n","tags":["leetcode"],"categories":["刷题"]},{"title":"leetcode-442","url":"/2022/06/02/leetcode-442/","content":"\n### 题目描述\n\n给你一个**长度为 n** 的整数数组 nums ，其中 nums 的所有整数都在**范围 \\[1, n\\]** 内，且每个整数**出现 一次 或 两次** 。请你找出所有出现 两次 的整数，并以数组形式返回。\n\n你必须设计并实现一个时间复杂度为 O(n) 且仅使用常量额外空间的算法解决此问题。\n\n### 方法一：取反\n\n从起始位置进行遍历，每次将下标为 nums\\[i\\] - 1nums\\[i\\]−1的数字取反；  \n当遍历到 nums\\[i\\]nums\\[i\\]为负数，需要忽略其负号。  \n若发现下标为 nums\\[i\\] - 1nums\\[i\\]−1的数字已经是负数，说明之前出现过同样的数字 nums\\[i\\]nums\\[i\\]，即找到了重复数字；\n\n动画图解如下：\n\n![442. 数组中重复的数据.gif](https://pic.leetcode-cn.com/1651978075-VevYmq-442.%20%E6%95%B0%E7%BB%84%E4%B8%AD%E9%87%8D%E5%A4%8D%E7%9A%84%E6%95%B0%E6%8D%AE.gif)\n\njava代码实现：\n\n```\nclass Solution {\n    public List<Integer> findDuplicates(int[] nums) {\n        List<Integer> res = new ArrayList<>();\n        for (int num : nums) {\n            if (nums[Math.abs(num) - 1] < 0) {\n                res.add(Math.abs(num));\n            } else {\n                nums[Math.abs(num) - 1] *= -1;\n            }\n        }\n        return res;\n    }\n}\n```\n\n[原文出处](https://leetcode-cn.com/problems/find-all-duplicates-in-an-array/solution/by-fuxuemingzhu-dko5/)\n","tags":["leetcode"],"categories":["刷题"]},{"title":"lex词法分析器语法+实验","url":"/2022/06/02/lex词法分析器语法实验/","content":"\n### lex词法分析器\n\nLex是LEXical compiler的缩写，是Unix环境下非常著名的工具,主要功能是生成一个词法分析器(scanner)的C源码,描述规则采用正则表达式(regular expression)。描述词法分析器的文件\\*.l，经过lex编译后，生成一个lex.yy.c 的文件，然后由C编译器编译生成一个词法分析器。词法分析器，简单来说，其任务就是将输入的各种符号，转化成相应的标识符(token)，转化后的标识符 很容易被后续阶段处理。 —— \\[ [百度百科 \\]](https://link.segmentfault.com/?enc=DKF%2BjPXr%2FIrO38QOqzaDew%3D%3D.YXj5UoakqwCBY404TA0%2Fuw3J2B6Khy7T9K5AzuhOw9ouSgDDUZFRI38JcPO%2FDd9m)\n\n### Lex语法格式\n\nflex的语法被分为三个部分：\n\n```\n{definitions} //声明部分\n%%\n{rules} //转换规则\n%%\n{user subroutines}//辅助函数\n```\n\n声明部分\n\n声明部分通常包括变量，明示常量和正则表达式的定义，明示常量是一个值为数字的标识符，用来表示词法单元的类型。\n\n转换规则\n\n转换规则具有如下的形式: 模式 { 动作 }。每个模式是一个正则表达式，可以使用声明部分给出的正则定义。动作部分是代码片段，通常用 C 语言编写。\n\n辅助函数\n\n这个部分中定义了各个动作所需要的函数，也可以包含 main 函数，这部分的代码将会放到输出的 C 代码中。\n\n**实例：**\n\n1. 为文本文件添加行号\n\n代码：\n\n```\n %{\n#include <stdio.h>\nint lineno=1;\n%}\n\n%%\n[^\\n]     {yymore();}\n\\n     {printf(\"%1d %s\",lineno++,yytext);}\n%%\n\nint yywrap(void)\n{\n  return 1;\n}\nmain()\n{\n  yylex();\n}\n```\n\n待测试文件：\n\n![img](https://presenter.oss-cn-shanghai.aliyuncs.com/wps2.jpg)\n\n结果：\n\n![img](https://presenter.oss-cn-shanghai.aliyuncs.com/wps3.jpg)\n\n2. 编写LEX源程序，其功能是将文本中的十进制数替换成十六进制，并打印被替换的次数\n\n```\n%{\n    #include<stdio.h>\n    #include <stdlib.h>\n    int count=0;\n    int n=0;\n    int i=0;\n    int j =0;\n    char hex[16];\n    char arr[] = \"0123456789ABCDEF\";\n%}\n%%\n\n[0][x][0-9A-F]* {printf(\"\\nCONFIRM IS hexadecimal!!!\");} \n\n[1-9][0-9]* {\n  n = atoi(yytext);\n  while (n)\n    {\n        hex[i++] = arr[n%16];  \n        n = n / 16;\n    }\n    for (j = i - 1; j >= 0; --j)\n        printf(\"%c\", hex[j]);\n    printf(\"\\nNumber of conversion: %d\",++count);\n    for (j = i - 1; j >= 0; --j){\n        hex[j]=\" \";\n        i=0;\n    }\n}\n[0-9]+ {printf(\"\\nerror number!!\");}\n%%\nint yywrap(void)\n{\n  return 1;\n}\nmain()\n{\n  int n=yylex();\n  return n;\n}\n```\n\n待测试文件：\n\n![img](https://presenter.oss-cn-shanghai.aliyuncs.com/wps4.jpg)\n\n测试结果：\n\n![img](https://presenter.oss-cn-shanghai.aliyuncs.com/wps5.jpg)\n","tags":["lex"],"categories":["c语言"]},{"title":"Linux命令","url":"/2022/06/02/linux命令/","content":"\n### 1\\. ls — List\n\nls会列举出当前工作目录的内容（文件或文件夹）。\n\nls命令演示\n\n![image-20211110165533037](https://presenter.oss-cn-shanghai.aliyuncs.com/image-20211110165533037.png)\n\n### 2.mkdir — Make Directory\n\nmkdir 用于新建一个新目录\n\n执行mkdir命令创建相应的文件夹\n\n### 3.pwd — Print Working Directory\n\n显示当前工作目录\n\n![image-20211110165732581](https://presenter.oss-cn-shanghai.aliyuncs.com/image-20211110165732581.png)\n\n显示当前工作目录\n\n### 4.cd — Change Directory\n\n切换文件路径，cd 将给定的文件夹（或目录）设置成当前工作目录。\n\n![image-20211110165802063](https://presenter.oss-cn-shanghai.aliyuncs.com/image-20211110165802063.png)\n\n切换路径到桌面\n\n### 5.rmdir— Remove Directory\n\n删除给定的目录。\n\n![image-20211110165820229](https://presenter.oss-cn-shanghai.aliyuncs.com/image-20211110165820443.png)\n\n创建的文件夹会被删除\n\n### 6\\. rm— Remove\n\nrm 会删除给定的文件\n\n![image-20211110165846775](https://presenter.oss-cn-shanghai.aliyuncs.com/image-20211110165846775.png)\n\n删除某个文件\n\n### 7\\. cp— Copy\n\ncp 命令对文件进行复制\n\n![image-20211110165910526](https://presenter.oss-cn-shanghai.aliyuncs.com/image-20211110165910526.png)\n\n文件的复制\n\n### 8\\. mv— Move\n\nmv 命令对文件或文件夹进行移动，如果文件或文件夹存在于当前工作目录，还可以对文件或文件夹进行重命名。\n\n![image-20211110165943030](https://presenter.oss-cn-shanghai.aliyuncs.com/image-20211110165943030.png)\n\n移动文件\n\n### 9\\. cat— concatenate and print files\n\ncat 用于在标准输出（监控器或屏幕）上查看文件内容\n\n![image-20211110170004319](https://presenter.oss-cn-shanghai.aliyuncs.com/image-20211110170004319.png)\n\n查看某个文件内容\n\n### 10\\. tail — print TAIL(from last)\n\nail 默认在标准输出上显示给定文件的最后10行内容，可以使用tail -n N 指定在标准输出上显示文件的最后N行内容。\n\n![image-20211110170027384](https://presenter.oss-cn-shanghai.aliyuncs.com/image-20211110170027384.png)\n\n显示文件内容\n\n### 11.less — print LESS\n\nless 按页或按窗口打印文件内容。在查看包含大量文本数据的大文件时是非常有用和高效的。你可以使用Ctrl+F向前翻页，Ctrl+B向后翻页。\n\n![image-20211110170053313](https://presenter.oss-cn-shanghai.aliyuncs.com/image-20211110170053313.png)\n\n打印文件内容\n\n### 12.grep\n\ngrep 在给定的文件中搜寻指定的字符串。grep -i “” 在搜寻时会忽略字符串的大小写，而grep -r “” 则会在当前工作目录的文件中递归搜寻指定的字符串。\n\n![image-20211110170114877](https://presenter.oss-cn-shanghai.aliyuncs.com/image-20211110170114877.png)\n\n查找相关内容\n\n### 13.find\n\n这个命令会在给定位置搜寻与条件匹配的文件。你可以使用find -name 的-name选项来进行区分大小写的搜寻，find -iname 来进行不区分大小写的搜寻。\n\n![image-20211110170134533](https://presenter.oss-cn-shanghai.aliyuncs.com/image-20211110170134533.png)\n\n三种使用示例\n\n### 14.tar\n\ntar命令能创建、查看和提取tar压缩文件。tar -cvf 是创建对应压缩文件，tar -tvf 来查看对应压缩文件，tar -xvf 来提取对应压缩文件。\n\n![image-20211110170149686](https://presenter.oss-cn-shanghai.aliyuncs.com/image-20211110170149686.png)\n\n创建压缩文件\n\n![image-20211110170208173](https://presenter.oss-cn-shanghai.aliyuncs.com/image-20211110170208173.png)\n\n查看压缩文件\n\n### 15\\. gzip\n\ngzip 命令创建和提取gzip压缩文件，还可以用gzip -d 来提取压缩文件。\n\n![image-20211110170224085](https://presenter.oss-cn-shanghai.aliyuncs.com/image-20211110170224085.png)\n\n生成gzip文件\n\n### 16\\. unzip\n\nunzip 对gzip文档进行解压。在解压之前，可以使用unzip -l 命令查看文件内容。\n\n![image-20211110170235645](https://presenter.oss-cn-shanghai.aliyuncs.com/image-20211110170235645.png)\n\n解压缩文件\n\n### 17.help\n\nhelp会在终端列出所有可用的命令,可以使用任何命令的-h或-help选项来查看该命令的具体用法。图就省略啦，会有详细列表显示出来的。\n\n### 18.whatis — What is this command\n\nwhatis 会用单行来描述给定的命令，就是解释当前命令。\n\n![image-20211110170251248](https://presenter.oss-cn-shanghai.aliyuncs.com/image-20211110170251248.png)\n\ncd的描述\n\n### 19.exit\n\nexit用于结束当前的终端会话。\n\n![image-20211110170318511](https://presenter.oss-cn-shanghai.aliyuncs.com/image-20211110170318511.png)\n\n结束当前终端会话\n\n### 20.ping\n\nping 通过发送数据包ping远程主机(服务器)，常用与检测网络连接和服务器状态。\n\n![image-20211110170332359](https://presenter.oss-cn-shanghai.aliyuncs.com/image-20211110170332359.png)\n\nping百度演示\n\n### 21.who — Who Is logged in\n\nwho能列出当前登录的用户名。\n\n![image-20211110170347878](https://presenter.oss-cn-shanghai.aliyuncs.com/image-20211110170347878.png)\n\n当前用户列表\n\n### 22.su — Switch User\n\nsu 用于切换不同的用户。即使没有使用密码，超级用户也能切换到其它用户。\n\n![image-20211110170416878](https://presenter.oss-cn-shanghai.aliyuncs.com/image-20211110170416878.png)\n\n切换当前用户\n\n### 23.uname\n\nuname会显示出关于系统的重要信息，如内核名称、主机名、内核版本、处理机类型等等，使用uname -a可以查看所有信息。\n\n![image-20211110170431901](https://presenter.oss-cn-shanghai.aliyuncs.com/image-20211110170431901.png)\n\n系统信息\n\n### 24.df — Disk space Free\n\ndf查看文件系统中磁盘的使用情况–硬盘已用和可用的存储空间以及其它存储设备。你可以使用df -h将结果以人类可读的方式显示。\n\n![image-20211110170454512](https://presenter.oss-cn-shanghai.aliyuncs.com/image-20211110170454512.png)\n\n磁盘使用情况\n\n### 25.ps — ProcesseS\n\nps显示系统的运行进程。\n\n![image-20211110170507036](https://presenter.oss-cn-shanghai.aliyuncs.com/image-20211110170507036.png)\n\n系统进程\n\n### 26.top — Top processes\n\ntop命令会默认按照CPU的占用情况，显示占用量较大的进程,可以使用top -u 查看某个用户的CPU使用排名情况。\n\n![image-20211110170550416](https://presenter.oss-cn-shanghai.aliyuncs.com/image-20211110170550416.png)\n\ncpu占用情况\n\n### 27\\. shutdown\n\nshutdown用于关闭计算机，而shutdown -r用于重启计算机。这个我就不试了……\n\n出自：https://www.jianshu.com/p/0056d671ea6d\n","tags":["linux"],"categories":["linux","系统类"]},{"title":"Linux基础","url":"/2022/06/02/linux基础/","content":"\n## Linux系统目录结构\n\n登录系统后，在当前命令窗口下输入命令：\n\n```\n ls / \n```\n\n![img](https://presenter.oss-cn-shanghai.aliyuncs.com/image/20210422192703.png)\n\n![img](https://presenter.oss-cn-shanghai.aliyuncs.com/image/20210422192721.jpeg)\n\n以下是对这些目录的解释：\n\n- **/bin**：  \n    bin 是 Binaries (二进制文件) 的缩写, 这个目录存放着最经常使用的命令。\n- **/boot：**  \n    这里存放的是启动 Linux 时使用的一些核心文件，包括一些连接文件以及镜像文件。\n- **/dev ：**  \n    dev 是 Device(设备) 的缩写, 该目录下存放的是 Linux 的外部设备，在 Linux 中访问设备的方式和访问文件的方式是相同的。\n- **/etc：**  \n    etc 是 Etcetera(等等) 的缩写,这个目录用来存放所有的系统管理所需要的配置文件和子目录。\n- **/home**：  \n    用户的主目录，在 Linux 中，每个用户都有一个自己的目录，一般该目录名是以用户的账号命名的，如上图中的 alice、bob 和 eve。\n- **/lib**：  \n    lib 是 Library(库) 的缩写这个目录里存放着系统最基本的动态连接共享库，其作用类似于 Windows 里的 DLL 文件。几乎所有的应用程序都需要用到这些共享库。\n- **/lost+found**：  \n    这个目录一般情况下是空的，当系统非法关机后，这里就存放了一些文件。\n- **/media**：  \n    linux 系统会自动识别一些设备，例如U盘、光驱等等，当识别后，Linux 会把识别的设备挂载到这个目录下。\n- **/mnt**：  \n    系统提供该目录是为了让用户临时挂载别的文件系统的，我们可以将光驱挂载在 /mnt/ 上，然后进入该目录就可以查看光驱里的内容了。\n- **/opt**：  \n    opt 是 optional(可选) 的缩写，这是给主机额外安装软件所摆放的目录。比如你安装一个ORACLE数据库则就可以放到这个目录下。默认是空的。\n- **/proc**：  \n    proc 是 Processes(进程) 的缩写，/proc 是一种伪文件系统（也即虚拟文件系统），存储的是当前内核运行状态的一系列特殊文件，这个目录是一个虚拟的目录，它是系统内存的映射，我们可以通过直接访问这个目录来获取系统信息。  \n    这个目录的内容不在硬盘上而是在内存里，我们也可以直接修改里面的某些文件，比如可以通过下面的命令来屏蔽主机的ping命令，使别人无法ping你的机器：\n\n```\n  echo 1 > /proc/sys/net/ipv4/icmp_echo_ignore_all\n```\n\n- **/root**：  \n    该目录为系统管理员，也称作超级权限者的用户主目录。\n- **/sbin**：  \n    s 就是 Super User 的意思，是 Superuser Binaries (超级用户的二进制文件) 的缩写，这里存放的是系统管理员使用的系统管理程序。\n- **/selinux**：  \n    这个目录是 Redhat/CentOS 所特有的目录，Selinux 是一个安全机制，类似于 windows 的防火墙，但是这套机制比较复杂，这个目录就是存放selinux相关的文件的。\n- **/srv**：  \n    该目录存放一些服务启动之后需要提取的数据。\n- **/sys**： 这是 Linux2.6 内核的一个很大的变化。该目录下安装了 2.6 内核中新出现的一个文件系统 sysfs 。 sysfs 文件系统集成了下面3种文件系统的信息：针对进程信息的 proc 文件系统、针对设备的 devfs 文件系统以及针对伪终端的 devpts 文件系统。 该文件系统是内核设备树的一个直观反映。 当一个内核对象被创建的时候，对应的文件和目录也在内核对象子系统中被创建。\n- **/tmp**：  \n    tmp 是 temporary(临时) 的缩写这个目录是用来存放一些临时文件的。\n- **/usr**：  \n    usr 是 unix shared resources(共享资源) 的缩写，这是一个非常重要的目录，用户的很多应用程序和文件都放在这个目录下，类似于 windows 下的 program files 目录。\n- **/usr/bin：**  \n    系统用户使用的应用程序。\n- **/usr/sbin：**  \n    超级用户使用的比较高级的管理程序和系统守护程序。\n- **/usr/src：**  \n    内核源代码默认的放置目录。\n- **/var**：  \n    var 是 variable(变量) 的缩写，这个目录中存放着在不断扩充着的东西，我们习惯将那些经常被修改的目录放在这个目录下。包括各种日志文件。\n- **/run**：  \n    是一个临时文件系统，存储系统启动以来的信息。当系统重启时，这个目录下的文件应该被删掉或清除。如果你的系统上有 /var/run 目录，应该让它指向 run。\n\n在 Linux 系统中，有几个目录是比较重要的，平时需要注意不要误删除或者随意更改内部文件。\n\n**/etc**： 上边也提到了，这个是系统中的配置文件，如果你更改了该目录下的某个文件可能会导致系统不能启动。\n\n**/bin, /sbin, /usr/bin, /usr/sbin**: 这是系统预设的执行文件的放置目录，比如 ls 就是在 /bin/ls 目录下的。\n\n值得提出的是，/bin, /usr/bin 是给系统用户使用的指令（除root外的通用户），而/sbin, /usr/sbin 则是给 root 使用的指令。\n\n**/var**： 这是一个非常重要的目录，系统上跑了很多程序，那么每个程序都会有相应的日志产生，而这些日志就被记录到这个目录下，具体在 /var/log 目录下，另外 mail 的预设放置也是在这里。\n\n## Linux 文件与目录管理\n\n我们知道Linux的目录结构为树状结构，最顶级的目录为根目录 /。\n\n其他目录通过挂载可以将它们添加到树中，通过解除挂载可以移除它们。\n\n在开始本教程前我们需要先知道什么是绝对路径与相对路径。\n\n- **绝对路径：**  \n    路径的写法，由根目录 **/** 写起，例如： /usr/share/doc 这个目录。\n- **相对路径：**  \n    路径的写法，不是由 **/** 写起，例如由 /usr/share/doc 要到 /usr/share/man 底下时，可以写成： **cd ../man** 这就是相对路径的写法。\n\n* * *\n\n## 处理目录的常用命令\n\n接下来我们就来看几个常见的处理目录的命令吧：\n\n- ls（英文全拼：list files）: 列出目录及文件名\n- cd（英文全拼：change directory）：切换目录\n- pwd（英文全拼：print work directory）：显示目前的目录\n- mkdir（英文全拼：make directory）：创建一个新的目录\n- rmdir（英文全拼：remove directory）：删除一个空的目录\n- cp（英文全拼：copy file）: 复制文件或目录\n- rm（英文全拼：remove）: 删除文件或目录\n- mv（英文全拼：move file）: 移动文件与目录，或修改文件与目录的名称\n\n你可以使用 _man \\[命令\\]_ 来查看各个命令的使用文档，如 ：man cp。\n\n注：详细用法在[这里](https://www.runoob.com/linux/linux-file-content-manage.html)\n","tags":["linux"],"categories":["linux","系统类"]},{"title":"mysql基础语句","url":"/2022/06/02/mysql基础语句/","content":"\n### mySql基础语句\n\n##### 1、登录 `mysql -uroot -p` 回车后输入 密码\n\n##### 2、查询所有数据库 `show databases;`\n\n##### 3、新建数据库 `create database <数据库名>;`\n\n##### 4、使用某个数据库 `use <数据库名>;`\n\n##### 5、删除数据库`drop database <数据库名>;`\n\n##### 6、查询某个数据库里所有表`show tables;`\n\n##### 7、新建一张表`CREATE TABLE table_name (column_name column_type);`\n\n##### 8、删除一张表`DROP TABLE table_name ;`\n\n##### 9、插入数据 `INSERT INTO 表的名字(列名a,列名b,列名c) VALUES(值1,值2,值3);`\n\n##### 10、`and`、`or`、`between`\n\n##### 11、`IN`、`NOT IN`，用于筛选“在”或“不在”某个范围内的结果，比如说我们要查询在 dpt3 或 dpt4 的人:\n\n##### 12、`LIKE` 用于实现模糊查询，常见于搜索功能中。\n\n和 LIKE 联用的通常还有通配符，代表未知字符。SQL中的通配符是 \\_ 和 % 。其中 \\_ 代表一个未指定字符，% 代表不定个未指定字符  \n比如，要只记得电话号码前四位数为1101，而后两位忘记了，则可以用两个 \\_ 通配符代替：  \n另一种情况，比如只记名字的首字母，又不知道名字长度，则用 % 通配符代替不定个字符：\n\n##### 13、`ORDER BY` 排序使用 ，还会配合 `ASC`和`DESC`即升序和降序。查询结果默认升序排序\n\n##### 14、内置函数和计算\n\n##### 15、子查询\n\n```\nSELECT of_dpt,COUNT(proj_name) AS count_project FROM project GROUP BY of_dpt\nHAVING of_dpt IN\n(SELECT in_dpt FROM employee WHERE name='Tom');\n```\n\n##### 16、修改表名字\n\n```\nRENAME TABLE 原名 TO 新名字;\n\nALTER TABLE 原名 RENAME 新名;\n\nALTER TABLE 原名 RENAME TO 新名;\n```\n\n##### 17、对列的修改\n\n###### 17.1、增加一列\n\n```\nALTER TABLE 表名字 ADD COLUMN 列名字 数据类型 约束;\n或：\nALTER TABLE 表名字 ADD 列名字 数据类型 约束;\n\nALTER TABLE employee ADD height INT(4) DEFAULT 170;\n```\n\n新增列默认放在最右边，如果要把增加的列插入在指定位置，则需要在语句的最后使用`AFTER`关键词(“AFTER 列1” 表示新增的列被放置在 “列1” 的后面)。\n\n```\nALTER TABLE employee ADD weight INT(4) DEFAULT 120 AFTER age;\n```\n\n如果想放在第一列的位置，则使用`FIRST`关键词，如语句：\n\n```\nALTER TABLE employee ADD test INT(10) DEFAULT 11 FIRST;\n```\n\n##### 17.2 删除一列\n\n```\nALTER TABLE 表名字 DROP COLUMN 列名字;\n\n或： ALTER TABLE 表名字 DROP 列名字;\n```\n\n##### 17.3 重命名一列\n\n```\nALTER TABLE 表名字 CHANGE 原列名 新列名 数据类型 约束;\nALTER TABLE employee CHANGE height shengao INT(4) DEFAULT 170;\n```\n\n#### 18、 对表的内容进行修改\n\n##### 18.1、修改表中某个值或某列某个字段值\n\n```\nUPDATE 表名字 SET 列1=值1,列2=值2 WHERE 条件;\n```\n\n比如，我们要把 Tom 的 age 改为 21，salary 改为 3000：\n\n```\nUPDATE employee SET age=21,salary=3000 WHERE name='Tom';\n```\n\n##### 18.2、删除一行记录\n\n```\nDELETE FROM 表名字 WHERE 条件;\n```\n","tags":["mysql"],"categories":["数据库"]},{"title":"office激活","url":"/2022/06/02/office激活/","content":"\n1.新建一个文本文档\n\n2.复制下面的文本，粘贴。\n\n```\n@echooff\n(cd /d \"%~dp0\")&&(NET FILE||(powershell start-process -FilePath '%0' -verb runas)&&(exit /B)) >NUL 2>&1\ntitle Office 2019 Activator r/Piracy\necho Converting... & mode 40,25\n(if exist \"%ProgramFiles%\\Microsoft Office\\Office16\\ospp.vbs\" cd /d \"%ProgramFiles%\\Microsoft Office\\Office16\")&(if exist \"%ProgramFiles(x86)%\\Microsoft Office\\Office16\\ospp.vbs\" cd /d \"%ProgramFiles(x86)%\\Microsoft Office\\Office16\")&(for /f %%x in ('dir /b ..\\root\\Licenses16\\ProPlus2019VL*.xrm-ms') do cscript ospp.vbs /inslic:\"..\\root\\Licenses16\\%%x\" >nul)&(for /f %%x in ('dir /b ..\\root\\Licenses16\\ProPlus2019VL*.xrm-ms') do cscript ospp.vbs /inslic:\"..\\root\\Licenses16\\%%x\" >nul)\ncscript //nologo ospp.vbs /unpkey:6MWKP >nul&cscript //nologo ospp.vbs /inpkey:NMMKJ-6RK4F-KMJVX-8D9MJ-6MWKP >nul&set i=1\n:server\nif %i%==1 set KMS_Sev=kms7.MSGuides.com\nif %i%==2 set KMS_Sev=kms8.MSGuides.com\nif %i%==3 set KMS_Sev=kms9.MSGuides.com\ncscript //nologo ospp.vbs /sethst:%KMS_Sev% >nul\necho %KMS_Sev% & echo Activating...\ncscript //nologo ospp.vbs /act | find /i \"successful\" && (echo Complete) || (echo Trying another KMS Server & set /a i+=1 & goto server)\npause >nul\nexit\n```\n\n3.将文件后缀改为.bat\n\n4.管理员身份运行，等待数分钟如果提示success，表示成功\n","tags":["office"],"categories":["技术类"]},{"title":"二叉树遍历","url":"/2022/06/02/二叉树遍历/","content":"\n**二叉树是一种非常重要的数据结构，很多其它数据结构都是基于二叉树的基础演变而来的。对于二叉树，有深度遍历和广度遍历，深度遍历有前序、中序以及后序三种遍历方法，广度遍历即我们平常所说的层次遍历。因为树的定义本身就是递归定义，因此采用递归的方法去实现树的三种遍历不仅容易理解而且代码很简洁，而对于广度遍历来说，需要其他数据结构的支撑，比如堆了。所以，对于一段代码来说，可读性有时候要比代码本身的效率要重要的多。**\n\n四种主要的遍历思想为：\n\n前序遍历：根结点 ---> 左子树 ---> 右子树\n\n中序遍历：左子树---> 根结点 ---> 右子树\n\n后序遍历：左子树 ---> 右子树 ---> 根结点\n\n层次遍历：只需按层次遍历即可\n\n例如，求下面二叉树的各种遍历\n\n![20150204101904649](https://presenter.oss-cn-shanghai.aliyuncs.com/20150204101904649.png)\n\n- 前序遍历：1 2 4 5 7 8 3 6\n- 中序遍历：4 2 7 5 8 1 3 6\n- 后序遍历：4 7 8 5 2 6 3 1\n- 层次遍历：1 2 3 4 5 6 7 8\n\n```\n//前序遍历\npublic void preOrderTraverse1(TreeNode root) {\n        if (root != null) {\n            System.out.print(root.val+\"  \");\n            preOrderTraverse1(root.left);\n            preOrderTraverse1(root.right);\n        }\n    }\n```\n\n```\n//中序遍历\npublic void inOrderTraverse1(TreeNode root) {\n        if (root != null) {\n            inOrderTraverse1(root.left);\n            System.out.print(root.val+\"  \");\n            inOrderTraverse1(root.right);\n        }\n    }\n```\n\n```\n//后序遍历\npublic void postOrderTraverse1(TreeNode root) {\n        if (root != null) {\n            postOrderTraverse1(root.left);\n            postOrderTraverse1(root.right);\n            System.out.print(root.val+\"  \");\n        }\n    }\n```\n","tags":["数据结构"],"categories":["数据结构"]},{"title":"创建 Docker 容器后修改挂载目录的方法","url":"/2022/06/02/创建-docker-容器后修改挂载目录的方法/","content":"\n**1、主要方法**\n\n主要有两种方法：\n\n（1）重启容器，重新挂载；\n\n（2）原始容器，修改配置。\n\n**2、方法一：重启容器，重新挂载**\n\n这个方法没啥好说的，就是 docker commit new\\_image，然后 docker run new\\_container 就好了。\n\n**3、方法二：原始容器，修改配置**\n\n这个方法仔细介绍一下，因为我觉得比较方便。\n\n首先看一看你容器现在的挂载路径\n\n```\ndocker inspect -f \"{{.Mounts}}\" container_name\n```\n\n然后用 docker ps -a 看看你的容器 ID\n\n```\ndocker ps -a\n```\n\n可以看到我的容器的 ID 为 2f18dce34e92。\n\n然后我们开始操作一波。\n\n把 docker 服务停止了：\n\n```\nsystemctl stop docker.service\n```\n\n在 /var/lib/docker/containers/container-ID/config.v2.json 中找到 MountPoints，并修改挂载路径\n\n```\nvim /var/lib/docker/containers/container-ID/config.v2.json\n\"MountPoints\":{\"/home\":{\"Source\":\"/path/to/your/host\",\"Destination\":\"/home\",\"RW\":true,\"Name\":\"\",\"Driver\":\"\",\"Type\":\"bind\",\"Propagation\":\"rprivate\",\"Spec\":{\"Type\":\"bind\",\"Source\":\"/path/to/your/host\",\"Target\":\"/home\"}}}\n```\n\n重启 docker 服务\n\n```\nsystemctl start docker.service\n```\n\n重启 docker 容器\n\n```\ndocker start <container-name/ID>\ndocker attach <container-name/ID>\n```\n","tags":["docker"],"categories":["docker"]},{"title":"基本类型和对象类型","url":"/2022/06/02/基本类型和对象类型/","content":"\n### **Java中数据类型分两种**\n\n> 1.基本类型：long,int,byte,float,double  \n> 2.对象类型：Long,Integer,Byte,Float,Double其它一切java提供的，或者你自己创建的类。\n> \n> 其中Long叫 long的包装类。Integer、Byte和Float也类似，一般包装类的名字首写是数值名的大写开头。\n\n**什么是包装类？**\n\n在java中有时候的运算必须是两个类对象之间进行的，不充许对象与数字之间进行运算。所以需要有一个对象，这个对象把数字进行了一下包装，这样这个对象就可以和另一个对象进行运算了。\n\n比如我们可以定义一个类：\n\n```\npublic class Long {  \n    int i=0;  \n    public Long (int i){  \n        this.i=i;  \n    }  \n}  \n```\n\n这个Long 就是一个包装类，它包装了一个整数值，然后可以在里面写一些运算符重载的方法使它支持某些运算。这个时候可以赋值：  \nLong l = new Long(10);  \n现在变量 l 就是一个对象，不是一个数字。\n\nlong是原始数据类型,没有属性方法,只能进行数学运算，Long是long相对应的引用数据类型，它有方法和属性，一个没方法属性，一个有方法属性,这就是它们的区别。\n\n看下面的小程序：\n\n```\nlong l = 1;  \nLong l1 = new Long(1);   \nLong l2 = new Long(1);   \n\nif (l == l1){   \n    System.out.println(\"=====l与l1相等=====\");  \n }   \n\nif(l == l2){   \n    System.out.println(\"=====l与l2相等=====\");  \n}  \n\nif(l1 == l2){  \n    System.out.println(\"=====l1与l2相等=====\");  \n }     \n```\n\n输出：\n\n```\n=====l与l1相等=====  \n=====l与l2相等===== \n```\n\n如果将第三个if语句的条件换成\"l1.equals(l2)\"，那么输出结果就会变成：\n\n```\n=====l与l1相等=====  \n=====l与l2相等=====  \n=====l1与l2相等=====  \n```\n\n由此也能看出，Long定义的变量为一个Long类型的对象；而long定义的变量为一个长整形数值的数值变量。\n\n**ID用long还是Long？**\n\nhibernate、el表达式等都是包装类型，用Long类型可以减少装箱/拆箱；\n\n在hibernate中的自增的hid在实体中的类型要用Long 来定义而不是long。否则在DWR的匹配过程中会出现Marshallingerror:null的错误提示。\n\n到底是选择Long 还是long这个还得看具体环境，如果你认为这个属性不能为null,那么就用long，因为它默认初值为0，如果这个字段可以为null，那么就应该选择Long。\n\n**注意事项**\n\n![](https://presenter.oss-cn-shanghai.aliyuncs.com/20180521104209734.png)\n","tags":["java"],"categories":["java基础"]},{"title":"宝塔面板+wordpress搭建博客","url":"/2022/06/02/宝塔面板+wordpress搭建博客/","content":"\n在这之前默认已经装好了宝塔面板。\n\n# **5.2 安装 WordPress**\n\n在主面板，软件中选择 “一键部署源码”。如果没有，就在软件商店进行下载\n\n[![](https://presenter.oss-cn-shanghai.aliyuncs.com/image-20220506151731695.png)](https://presenter.oss-cn-shanghai.aliyuncs.com/image-20220506151731695.png)\n\n如果主面板没有，勾上面板显示\n\n一键部署 WordPress。\n\n[![](https://presenter.oss-cn-shanghai.aliyuncs.com/v2-126ddbc167827fa2c4c149cef9a6b8de_720w.jpg)](https://presenter.oss-cn-shanghai.aliyuncs.com/v2-126ddbc167827fa2c4c149cef9a6b8de_720w.jpg)\n\n在域名输入框中填写自己的域名，其他默认，点击 “提交”。（域名我填的本地局域网ip）\n\n[![](https://presenter.oss-cn-shanghai.aliyuncs.com/image-20220506151934690.png)](https://presenter.oss-cn-shanghai.aliyuncs.com/image-20220506151934690.png)\n\n提交之后可以直接访问这个ip地址就可以\n\n可能会出现以下错误\n\n**centos 6 7 检测配置文件 /usr/local/nginx/sbin/nginx -t  \n出现以下错误：**  \n**/usr/local/nginx/sbin/nginx: error while loading shared libraries: libluajit-5.1.so.2: cannot open shared object file: No such file or directory**  \n解决方案：\n\n<table><tbody><tr><td>1</td><td>yum -y install lua*</td></tr></tbody></table>\n\n 复制 复制\n\n接下来访问-》点击现在开始\n\n[![](https://presenter.oss-cn-shanghai.aliyuncs.com/image-20220506152135208.png)](https://presenter.oss-cn-shanghai.aliyuncs.com/image-20220506152135208.png)\n\n填写上面记录下的数据库信息，提交。（这里是之前得到的账号密码）\n\n[![](https://presenter.oss-cn-shanghai.aliyuncs.com/v2-a61f146678390151326ef1bae08d0a64_720w.jpg)](https://presenter.oss-cn-shanghai.aliyuncs.com/v2-a61f146678390151326ef1bae08d0a64_720w.jpg)\n\n填写网站信息，安装WordPress。\n\n[![](https://presenter.oss-cn-shanghai.aliyuncs.com/v2-6604cd5e86c0b03e9e6e48b91205a5f2_r.jpg)](https://presenter.oss-cn-shanghai.aliyuncs.com/v2-6604cd5e86c0b03e9e6e48b91205a5f2_r.jpg)\n\n安装完成后，登陆网站后台，开始创作之旅！访问域名，即可进入自己的网站。\n\n现在就完成了。（后面可以发布文章，修改主题，下载插件）\n","tags":["wordpress"],"categories":["技术类"]},{"title":"开发者必备Mysql命令","url":"/2022/06/02/开发者必备mysql命令/","content":"\n### 开发者必备Mtsql命令\n\n> 开发者必备Mysql常用命令，涵盖了数据定义语句、数据操纵语句及数据控制语句，基于Mysql5.7。\n\n## 数据定义语句(DDL)\n\n### 数据库操作\n\n- 登录数据库：\n\n```\nmysql -uroot -proot\n```\n\n- 创建数据库：\n\n```\ncreate database test\n```\n\n- 查看所有数据库：\n\n```\nshow databases\n```\n\n![](https://presenter.oss-cn-shanghai.aliyuncs.com/refer_screen_41.png)\n\n- 选择数据库并使用：\n\n```\nuse test\n```\n\n- 查看所有数据表：\n\n```\nshow tables\n```\n\n- 删除数据库：\n\n```\ndrop database test\n```\n\n### 表操作\n\n- 创建表：\n\n```\ncreate table emp(ename varchar(10),hiredate date,sal decimal(10,2),deptno int(2))  \n```\n\n```\ncreate table dept(deptno int(2),deptname varchar(10))\n```\n\n![](https://presenter.oss-cn-shanghai.aliyuncs.com/refer_screen_42.png)\n\n- 查看表的定义：\n\n```\ndesc emp\n```\n\n![](https://presenter.oss-cn-shanghai.aliyuncs.com/refer_screen_43.png)\n\n- 查看表定义（详细）：\n\n```\nshow create table emp \\G\n```\n\n![](https://presenter.oss-cn-shanghai.aliyuncs.com/refer_screen_44.png)\n\n- 删除表：\n\n```\ndrop table emp\n```\n\n- 修改表字段：\n\n```\nalter table emp modify ename varchar(20)\n```\n\n- 添加表字段：\n\n```\nalter table emp add column age int(3)\n```\n\n- 删除表字段：\n\n```\nalter table emp drop column age\n```\n\n- 字段改名；\n\n```\nalter table emp change age age1 int(4)\n```\n\n- 修改表名：\n\n```\nalter table emp rename emp1\n```\n\n## 数据操纵语句(DML)\n\n### 插入记录\n\n- 指定名称插入：\n\n```\ninsert into emp (ename,hiredate,sal,deptno) values ('zhangsan','2018-01-01','2000',1)\n```\n\n- 不指定名称插入：\n\n```\ninsert into emp values ('lisi','2018-01-01','2000',1)\n```\n\n- 批量插入数据：\n\n```\ninsert into dept values(1,'dept1'),(2,'dept2')\n```\n\n### 修改记录\n\n```\nupdate emp set sal='4000',deptno=2 where ename='zhangsan'\n```\n\n### 删除记录\n\n```\ndelete from emp where ename='zhangsan'\n```\n\n### 查询记录\n\n- 查询所有记录：\n\n```\nselect * from emp\n```\n\n- 查询不重复的记录：\n\n```\nselect distinct deptno from emp\n```\n\n- 条件查询：\n\n```\nselect * from emp where deptno=1 and sal<3000\n```\n\n- 排序和限制：\n\n```\nselect * from emp order by deptno desc limit 2\n```\n\n- 分页查询(查询从第0条记录开始10条)：\n\n```\nselect * from emp order by deptno desc limit 0,10\n```\n\n- 聚合(查询部门人数大于1的部门编号)：\n\n```\nselect deptno,count(1) from emp group by deptno having count(1) > 1\n```\n\n- 连接查询：\n\n```\nselect * from emp e left join dept d on e.deptno=d.deptno\n```\n\n- 子查询：\n\n```\nselect * from emp where deptno in (select deptno from dept)\n```\n\n- 记录联合：\n\n```\nselect deptno from emp union select deptno from dept\n```\n\n## 数据控制语句(DCL)\n\n### 权限相关\n\n- 授予操作权限(将test数据库中所有表的select和insert权限授予test用户)：\n\n```\ngrant select,insert on test.* to 'test'@'localhost' identified by '123'\n```\n\n- 查看账号权限：\n\n```\nshow grants for 'test'@'localhost'\n```\n\n![](https://presenter.oss-cn-shanghai.aliyuncs.com/refer_screen_45.png)\n\n- 收回操作权限：\n\n```\nrevoke insert on test.* from 'test'@'localhost'\n```\n\n![](https://presenter.oss-cn-shanghai.aliyuncs.com/refer_screen_46.png)\n\n- 授予所有数据库的所有权限：\n\n```\ngrant all privileges on *.* to 'test'@'localhost'\n```\n\n- 授予所有数据库的所有权限(包括grant)：\n\n```\ngrant all privileges on *.* to 'test'@'localhost' with grant option\n```\n\n- 授予SUPER PROCESS FILE权限（系统权限不能指定数据库）：\n\n```\ngrant super,process,file on *.* to 'test'@'localhost'\n```\n\n- 只授予登录权限：\n\n```\ngrant usage on *.* to 'test'@'localhost'\n```\n\n### 帐号相关\n\n- 删除账号：\n\n```\ndrop user 'test'@'localhost'\n```\n\n- 修改自己的密码：\n\n```\nset password = password('123')\n```\n\n- 管理员修改他人密码：\n\n```\nset password for 'test'@'localhost' = password('123')\n```\n\n## 其他\n\n### 字符集相关\n\n- 查看字符集：\n\n```\nshow variables like 'character%'\n```\n\n![](https://presenter.oss-cn-shanghai.aliyuncs.com/refer_screen_47.png)\n\n- 创建数据库时指定字符集：\n\n```\ncreate database test2 character set utf8\n```\n\n![](https://presenter.oss-cn-shanghai.aliyuncs.com/refer_screen_48.png)\n\n### 时区相关\n\n- 查看当前时区（UTC为世界统一时间，中国为UTC+8）：\n\n```\nshow variables like \"%time_zone%\"\n```\n\n![](https://presenter.oss-cn-shanghai.aliyuncs.com/refer_screen_49.png)\n\n- 修改mysql全局时区为北京时间，即我们所在的东8区：\n\n```\nset global time_zone = '+8:00';\n```\n\n- 修改当前会话时区：\n\n```\nset time_zone = '+8:00'\n```\n\n![](https://presenter.oss-cn-shanghai.aliyuncs.com/refer_screen_50.png)\n\n- 立即生效：\n\n```\nflush privileges\n```\n","tags":["mysql"],"categories":["mysql","数据库"]},{"title":"拓扑排序","url":"/2022/06/02/拓扑排序/","content":"\n### 一、什么是[拓扑排序](https://so.csdn.net/so/search?q=拓扑排序&spm=1001.2101.3001.7020)\n\n在图论中，拓扑排序（Topological Sorting）是一个有向无环图（DAG, Directed Acyclic Graph）的所有顶点的线性序列。且该序列必须满足下面两个条件：\n\n每个顶点出现且只出现一次。  \n若存在一条从顶点 A 到顶点 B 的路径，那么在序列中顶点 A 出现在顶点 B 的前面。  \n有向无环图（DAG）才有拓扑排序，非DAG图没有拓扑排序一说。\n\n例如，下面这个图：\n\n![](https://presenter.oss-cn-shanghai.aliyuncs.com/image-20220510081352708.png)\n\n它是一个 DAG 图，那么如何写出它的拓扑排序呢？这里说一种比较常用的方法：\n\n从 DAG 图中选择一个 **没有前驱（即入度为0）**的顶点并输出。  \n从图中删除该顶点和所有以它为起点的有向边。  \n重复 1 和 2 直到当前的 DAG 图为空或当前图中不存在无前驱的顶点为止。后一种情况说明有向图中必然存在环。\n\n![](https://presenter.oss-cn-shanghai.aliyuncs.com/image-20220510081428471.png)\n\n于是，得到拓扑排序后的结果是 { 1, 2, 4, 3, 5 }。\n\n通常，一个有向无环图可以有**一个或多个**拓扑排序序列。\n\n二、拓扑排序的应用  \n拓扑排序通常用来“排序”具有依赖关系的任务。\n\n比如，如果用一个DAG图来表示一个工程，其中每个顶点表示工程中的一个任务，用有向边表示在做任务 B 之前必须先完成任务 A。故在这个工程中，任意两个任务要么具有确定的先后关系，要么是没有关系，绝对不存在互相矛盾的关系（即环路）。\n\n## 三、拓扑排序的实现\n\n根据上面讲的方法，我们关键是要**维护一个入度为0的顶点的集合**。\n\n图的存储方式有两种：[邻接矩阵](https://baike.baidu.com/item/邻接矩阵/9796080#:~:text=SnippetTab)和[邻接表](https://baike.baidu.com/item/邻接表/9796152)。这里我们采用**邻接表**来存储图，C++代码如下：\n\n```\n#include<iostream>\n#include <list>\n#include <queue>\nusing namespace std;\n\n/************************类声明************************/\nclass Graph\n{\n    int V;             // 顶点个数\n    list<int> *adj;    // 邻接表\n    queue<int> q;      // 维护一个入度为0的顶点的集合\n    int* indegree;     // 记录每个顶点的入度\npublic:\n    Graph(int V);                   // 构造函数\n    ~Graph();                       // 析构函数\n    void addEdge(int v, int w);     // 添加边\n    bool topological_sort();        // 拓扑排序\n};\n\n/************************类定义************************/\nGraph::Graph(int V)\n{\n    this->V = V;\n    adj = new list<int>[V];\n\n    indegree = new int[V];  // 入度全部初始化为0\n    for(int i=0; i<V; ++i)\n        indegree[i] = 0;\n}\n\nGraph::~Graph()\n{\n    delete [] adj;\n    delete [] indegree;\n}\n\nvoid Graph::addEdge(int v, int w)\n{\n    adj[v].push_back(w); \n    ++indegree[w];\n}\n\nbool Graph::topological_sort()\n{\n    for(int i=0; i<V; ++i)\n        if(indegree[i] == 0)\n            q.push(i);         // 将所有入度为0的顶点入队\n\n    int count = 0;             // 计数，记录当前已经输出的顶点数 \n    while(!q.empty())\n    {\n        int v = q.front();      // 从队列中取出一个顶点\n        q.pop();\n\n        cout << v << \" \";      // 输出该顶点\n        ++count;\n        // 将所有v指向的顶点的入度减1，并将入度减为0的顶点入栈\n        list<int>::iterator beg = adj[v].begin();\n        for( ; beg!=adj[v].end(); ++beg)\n            if(!(--indegree[*beg]))\n                q.push(*beg);   // 若入度为0，则入栈\n    }\n\n    if(count < V)\n        return false;           // 没有输出全部顶点，有向图中有回路\n    else\n        return true;            // 拓扑排序成功\n}\n```\n\n测试如下DAG图：\n\n![](https://presenter.oss-cn-shanghai.aliyuncs.com/image-20220510081730199.png)\n\n```\nint main()\n{\n    Graph g(6);   // 创建图\n    g.addEdge(5, 2);\n    g.addEdge(5, 0);\n    g.addEdge(4, 0);\n    g.addEdge(4, 1);\n    g.addEdge(2, 3);\n    g.addEdge(3, 1);\n\n    g.topological_sort();\n    return 0;\n}\n```\n\n输出结果是 4, 5, 2, 0, 3, 1。这是该图的拓扑排序序列之一。\n\n每次在入度为0的集合中取顶点，并没有特殊的取出规则，随机取出也行，这里使用的queue。取顶点的顺序不同会得到不同的拓扑排序序列，当然前提是该图存在多个拓扑排序序列。\n\n由于输出每个顶点的同时还要删除以它为起点的边，故上述拓扑排序的时间复杂度为O(V+E)O(V+E)。\n","tags":["数据结构"],"categories":["数据结构"]},{"title":"线性规划问题","url":"/2022/06/02/线性规划问题/","content":"\n### 1.线性规划的概念\n\n线性规划(Linear Programming 简记 LP)是了运筹学中数学规划的一个重要分支。自从 1947 年 G. B. Dantzig 提出 求解线性规划的单纯形法以来，线性规划在理论上趋向成熟，在实用中由于计算机能处理成千上万个约束条件和决策变量的线性规划问题之后，线性规划现代管理中经常采用的基本方法之一。 在解决实际问题时，需要把问题归结成一个线性规划数学模型，关键及难点在于选适当的决策变量建立恰当的模型，这直接影响到问题的求解。\n\n线性规划问题的目标函数及约束条件均为线性函数；约束条件记为 s.t.(即 subject to)。目标函数可以是求最大值，也可以是求最小值，约束条件的不等号可以 是小于号也可以是大于号。\n\n一般线性规划问题的（数学）标准型为\n\n![](https://presenter.oss-cn-shanghai.aliyuncs.com/20190329151240157.png)\n\n​ **实例：**\n\n![](https://presenter.oss-cn-shanghai.aliyuncs.com/20190424195022627.png)\n\n### 2.线性规划问题的解的概念 ：可行解、可行域、图解法\n\n可行解 满足约束条件（4）的解 称为线性规划问题的可行解， 而使目标函数（3）达到最大值的可行解叫最优解。\n\n可行域 所有可行解构成的集合称为问题的可行域，记为R 。\n\n图解法 简单直观，适用于二维决策变量，它有助于了解线性规划问题求解的基本原理。。对于每一固定的值z，使目标函数值等于z的点构成的直线称为目标函数等位线，当z变动时，我们得到一族平行直线。\n\n![](https://presenter.oss-cn-shanghai.aliyuncs.com/20190424195312914.png)\n\n### 2.1. 推广到多维空间的线性规划：超平面、多胞形、多面体\n\n以下结论可以推广到一般的线性规划问题，区别只在于空间的维数：\n\n（1）可行域R 可能会出现多种情况。R 可能是空集也可能是非空集合，当R 非空 时，它必定是若干个半平面的交集（除非遇到空间维数的退化） 。R 既可能是有界区域， 也可能是无界区域。\n\n（2）在R 非空时，线性规划既可以存在有限最优解，也可以不存在有限最优解（其 目标函数值无界）。\n\n（3）若线性规划存在有限最优解，则必可找到具有最优目标函数值的可行域R 的 “顶点” 。\n\n在一般的n维 空间中，满足线性等式 ![](https://presenter.oss-cn-shanghai.aliyuncs.com/gif.gif)的点集被称为一个**超平面；**\n\n![](https://presenter.oss-cn-shanghai.aliyuncs.com/gif.gif)或![](https://presenter.oss-cn-shanghai.aliyuncs.com/gif.gif)的点集被称为一个半空间，其中![](https://presenter.oss-cn-shanghai.aliyuncs.com/gif%20(1).gif)为一个n维行向量，b为一个实数。\n\n若干个半空间的交集被称为多胞形，有界的多胞形又被称为多面体。易见，线性规划的可行域必为多胞形（为统一起见，空集Φ也被视为多胞形）。 在一般n维空间中，要直接得出多胞形“顶点”概念还有一些困难。二维空间中的顶点可以看成为边界直线的交点，但这一几何概念的推广在一般n维空间中的几何意义并不十分直观。为此，我们将采用另一途径来定义它。\n\n![](https://presenter.oss-cn-shanghai.aliyuncs.com/20190329152724917.png)\n\n单纯形法是求解线性规划问题的最常用、最有效的算法之一 ，此处不作介绍。这里我们就不介绍 单纯形法，有兴趣的读者可以参看其它线性规划书籍。下面我们介绍线性规划的 Matlab 解法。\n\n### 3.求解线性规划的 Matlab 解法\n\nMatlab 中规定线性规划的标准形式为\n\n![](https://presenter.oss-cn-shanghai.aliyuncs.com/2019032915072569.png)\n\n其中c和 x为n 维列向量， A、 Aeq 为适当维数的矩阵，b 、beq为适当维数的列向量。 （**Aeq** 对应约束条件中**等式约束**的系数矩阵，A为约**不等式约束**的系数矩阵）。\n\n![](https://presenter.oss-cn-shanghai.aliyuncs.com/20190329153446939.png)\n\n基本函数形式为 linprog(c,A,b)，它的返回值是向量 x的值。还有其它的一些函数调用形 式（在 Matlab 指令窗运行 help linprog 可以看到所有的函数调用形式），如：\n\n```\n[x,fval]=linprog(c,A,b,Aeq,beq,LB,UB,X0,OPTIONS) \n```\n\n这里 **fval 返回目标函数的值，LB 和 UB 分别是变量 x的下界和上界， 0 x 是x的初始值， OPTIONS 是控制参数**。\n\n### 例题\n\n例如求解下列线性规划问题\n\n![](https://presenter.oss-cn-shanghai.aliyuncs.com/20190329153141919.png)\n\n解 （i）编写 M 文件\n\n```\nc=[2;3;-5]; \na=[-2,5,-1;1,3,1]; \nb=[-10;12]; \naeq=[1,1,1]; \nbeq=7; \nx=linprog(-c,a,b,aeq,beq,zeros(3,1)) \nvalue=c'*x\n```\n\n（ii）将M文件存盘，并命名为example1.m。\n\n（iii）在Matlab指令窗运行example1即可得所求结果。\n\n例3 求解线性规划问题\n\n![](https://presenter.oss-cn-shanghai.aliyuncs.com/20190424195629342.png)\n\n解 编写Matlab程序如下：\n\n```\nc=[2;3;1]; \na=[1,4,2;3,2,0]; \nb=[8;6]; \n[x,y]=linprog(c,-a,-b,[],[],zeros(3,1)) \n```\n","tags":["最优化"],"categories":["最优化"]},{"title":"远程控制+Sakurafrp实现非局域网远程控制","url":"/2022/06/02/远程控制sakurafrp实现非局域网远程控制/","content":"\n## 一、下载RD Client\n\n- 安卓端网页下载或者[RDClient](https://presenter.oss-cn-shanghai.aliyuncs.com/base.apk)\n- ios端在App Store搜索RDClient\n\n## 二、设置PC允许远程连接\n\n- **win11**：这里打开电脑设置-> 系统->远程桌面\n\n![QQ图片20211109094906](https://presenter.oss-cn-shanghai.aliyuncs.com/QQ%E5%9B%BE%E7%89%8720211109094906.png)\n\n\\==这里的打开后你能连接你的用户就是你电脑开机时的用户，例如administrator，win10也是一样的==\n\n- **win10**： 进入控制面板->系统和安全->系统->远程设置  \n    按照下图方式勾选  \n    ![这里写图片描述](https://img-blog.csdn.net/20170215163223342?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvcXFfMzA0NjU2NTc=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)\n\n## 三、注册sakura frp（需要实名认证，支付宝授权就行）\n\n![image-20211109101421526](https://presenter.oss-cn-shanghai.aliyuncs.com/image-20211109101421526.png)\n\n![image-20211109101508848](https://presenter.oss-cn-shanghai.aliyuncs.com/image-20211109101508848.png)\n\n在导航栏上\n\n用户->实名认证\n\n根据提示完成认证\n\n![image-20211109101620430](https://presenter.oss-cn-shanghai.aliyuncs.com/image-20211109101620430.png)\n\n点击穿透->隧道列表\n\n![image-20211109101742287](https://presenter.oss-cn-shanghai.aliyuncs.com/image-20211109101742287.png)\n\n![image-20211109102002178](https://presenter.oss-cn-shanghai.aliyuncs.com/image-20211109102002178.png)\n\n![image-20211109102044910](https://presenter.oss-cn-shanghai.aliyuncs.com/image-20211109102044910.png)\n\n点击软件下载\n\n![image-20211109102209378](https://presenter.oss-cn-shanghai.aliyuncs.com/image-20211109102209378.png)\n\n然后解压安装\n\n再打开frpc.ini配置文件（可以用记事本打开）\n\n![image-20211109103125704](https://presenter.oss-cn-shanghai.aliyuncs.com/image-20211109103125704.png)\n\n再去sakura frp网站点击**隧道列表**，找到你刚才新建的隧道\n\n![image-20211109103347791](https://presenter.oss-cn-shanghai.aliyuncs.com/image-20211109103347791.png)\n\n![image-20211109103506496](https://presenter.oss-cn-shanghai.aliyuncs.com/image-20211109103506496.png)\n\n![image-20211109103555304](https://presenter.oss-cn-shanghai.aliyuncs.com/image-20211109103555304.png)\n\n然后直接去刚才打开的frpc.ini粘贴即可。\n\n最后直接打开exe\n\n![image-20211109103722486](https://presenter.oss-cn-shanghai.aliyuncs.com/image-20211109103722486.png)\n\n运行结果：然后缩小，去平板或者手机或者pc连接电脑\n\n![image-20211109103802090](https://presenter.oss-cn-shanghai.aliyuncs.com/image-20211109103802090.png)\n\n## 四、连接电脑\n\n点击Desktop\n\n![image-20211109104240443](https://presenter.oss-cn-shanghai.aliyuncs.com/image-20211109104240443.png)\n\n然后add MANUALLY\n\n![image-20211109104948381](https://presenter.oss-cn-shanghai.aliyuncs.com/image-20211109104948381.png)\n\n然后点击save就行\n\n最后直接连接\n","tags":["远程连接"],"categories":["技术类"]},{"title":"openwrt安装主题","url":"/2022/06/01/openwrt安装主题/","content":"\n### OpenWrt安装主题\n\n**Argon——超漂亮的OpenWrt主题**\n\n![](https://presenter.oss-cn-shanghai.aliyuncs.com/3877976271.png)\n\n## 安装条件\n\n> Openwrt及其衍生系统，包括Lede，PandoraBox,DD-Wrt  \n> 系统版本高于18.0，且能联网下载（这不废话）  \n> 有Opkg环境，空闲空间>1M，或者有内存卡/U盘\n\n## 安装方法\n\n### 下载安装\n\n```\nopkg update\nopkg install wget\nopkg install ca-certificates\n#注意这里版本可能不是最新的，打开https://github.com/jerrykuku/luci-theme-argon/releases/可以看到最新链接\nwget --no-check-certificate https://github.com/jerrykuku/luci-theme-argon/releases/download/v1.7.3/luci-theme-argon-18.06_1.7.3-20220421_all.ipk\nopkg install luci-theme-argon_2.01-20200203_all.ipk\n```\n\n### 手动安装\n\n[**下载文件luci-theme-argon\\_1.5.1.zip**](https://code.52pika.cn/usr/uploads/2020/04/2634254018.zip)  \n解压了将ipk通过WinSCP上传到路由器/tmp文件夹，然后：\n\n```\nopkg install luci-theme-argon_1.5.1.ipk\n```\n\n### 手动构建\n\n```\ncd openwrt/package\ngit clone https://github.com/jerrykuku/luci-theme-argon.git  \nmake menuconfig #choose LUCI->Theme->Luci-theme-argon  \nmake -j1 V=s \n```\n\n现在就已经可以了\n\n如果想换回以前地主题。\n\n如果出现错误可以尝试这个\n\n```\nwget --no-check-certificate https://github.com/jerrykuku/luci-theme-argon/releases/download/v2.1/luci-theme-argon_2.1-20200206_all.ipk\nopkg install luci-theme-argon_2.1-20200206_all.ipk\n```\n\n\\### 修改主题\n\n```\n主题配置是在：/etc/config/luci\n```\n\n第一个红框里面的就是当前主题，改掉就能修改主题。\n\n![](https://presenter.oss-cn-shanghai.aliyuncs.com/1614698-20200618162007275-421635754.png)\n","tags":["openwrt"],"categories":["openwrt","系统类"]},{"title":"openwrt开启passwall","url":"/2022/06/01/openwrt开启passwall/","content":"\n### 科学上网\n\n![](https://presenter.oss-cn-shanghai.aliyuncs.com/image-20220515100457474.png)\n\n![](https://presenter.oss-cn-shanghai.aliyuncs.com/image-20220515100516090.png)\n\n![](https://presenter.oss-cn-shanghai.aliyuncs.com/image-20220515100552968.png)\n\n这里也可以直接导入剪切板\n\n![](https://presenter.oss-cn-shanghai.aliyuncs.com/image-20220515100617845.png)\n\n最后保存就行。\n","tags":["openwrt"],"categories":["openwrt","系统类"]},{"title":"Openwrt下ipk包的安装、卸载与更新","url":"/2022/06/01/openwrt下ipk包的安装、卸载与更新/","content":"\n### Openwrt下ipk包的安装、卸载与更新\n\n#### 一、环境说明\n\nOpenwrt\\_version:17.01.4  \nLinux\\_version:4.4.92\n\n#### 二、安装ipk\n\n将编译好的.ipk传到开发板上，使用命令：\n\n```\nopkg install xxxxx.ipk安装成功的界面如下：\n```\n\n再进入/lib/modules/4.4.92（在/lib/modules文件夹下，不同的机子可能有不同的文件夹），找到xxxx.ko文件，执行命令：insmod xxxx.ko，命令lsmod就能看到插入内核的.ko文件\n\n#### 三、卸载ipk\n\n这里有一个需要注意的地方，就是直接执行  \nopkg remove xxxx.ipk是没有用的，因为安装好以后的文件名是和原来的.ipk文件名不一样的  \n步骤：  \n1、执行 opkg list\\_installed,找到想卸载的文件名称  \n2、执行opkg remove 文件名（就是上一步找到的名称）  \n卸载成功的界面：\n\n![](https://presenter.oss-cn-shanghai.aliyuncs.com/image-20220508232159227.png)\n\n#### 四、更新\n\n经过卸载这一步，在重新执行安装步骤即可\n","tags":["openwrt"],"categories":["openwrt","系统类"]},{"title":"ps快捷键","url":"/2022/06/01/ps快捷键/","content":"\n| 新建文件 | 【Ctrl】+【N】 | 打开文件 | 【Ctrl】+【O】 |\n| --- | --- | --- | --- |\n| 关闭文件 | 【Ctrl】+【W】 | 图像大小 | 【Ctrl】+【Alt】+【I】 |\n| 画布大小 | 【Ctrl】+【Alt】+【C】 | 保存文件 | 【Ctrl】+【S】 |\n| 合并可见图层 | 【Ctrl】+【Shift】+【E】 | 复制图层 | 【Ctrl】+【J】 |\n| 创建剪切蒙版 | 【Ctrl】+【Alt】+【G】 | 盖印图层 | 【Ctrl】+【Alt】+【Shift】+【E】 |\n| 上下移动图层 | 【Ctrl】+【\\[】或【\\]】 | 图层置顶或移到底部 | 【Ctrl】+【Shift】+【\\[】或【\\]】 |\n| 调整边缘 | 【Ctrl】+【Alt】+【R】 | 改变画笔大小 | 【\\[】或【\\]】 |\n| 全选 | 【Ctrl】+【A】 | 载入高光选区 | 【Ctrl】+【Alt】+【2】 |\n| 改变图层不透明度 | 直接按键盘上的数字，如15%，按【1】和【5】 | 重复上次滤镜 | 【Ctrl】+【F】 |\n| 羽化 | 【Shift】+【F6】 | 取消选区 | 【Ctrl】+【D】 |\n\n| **二、工具箱工具** |  |  |\n| --- | --- | --- |\n| 移动工具 | 【V】 | ![img](https://presenter.oss-cn-shanghai.aliyuncs.com/kj_2a.jpg) |\n| 矩形、椭圆选框工具 | 【M】 |  |\n| 套索、多边形套索、磁性套索 | 【L】 |  |\n| 快速选择工具、魔棒工具 | 【W】 |  |\n| 裁剪、透视裁剪、切片、切片选择工具 | 【C】 |  |\n| 吸管、颜色取样器、标尺、注释、123计数工具 | 【I】 |  |\n| 污点修复画笔、修复画笔、修补、内容感知移动、红眼工具 | 【J】 |  |\n| 画笔、铅笔、颜色替换、混合器画笔工具 | 【B】 |  |\n| 仿制图章、图案图章工具 | 【S】 |  |\n| 历史记录画笔工具、历史记录艺术画笔工具 | 【Y】 |  |\n| 像皮擦、背景橡皮擦、魔术橡皮擦工具 | 【E】 |  |\n| 渐变、油漆桶工具 | 【G】 |  |\n| 减淡、加深、海棉工具 | 【O】 |  |\n| 钢笔、自由钢笔、添加锚点、删除锚点、转换点工具 | 【P】 |  |\n| 横排文字、直排文字、横排文字蒙板、直排文字蒙板 | 【T】 |  |\n| 路径选择、直接选择工具 | 【A】 |  |\n| 矩形、圆角矩形、椭圆、多边形、直线、自定义形状工具 | 【U】 |  |\n| 抓手工具 | 【H】 |  |\n| 旋转视图工具 | 【R】 |  |\n| 缩放工具 | 【Z】 |  |\n| 添加锚点工具 | 【+】 |  |\n| 删除锚点工具 | 【-】 |  |\n| 默认前景色和背景色 | 【D】 |  |\n| 切换前景色和背景色 | 【X】 |  |\n| 切换标准模式和快速蒙板模式 | 【Q】 |  |\n| 标准屏幕模式、带有菜单栏的全屏模式、全屏模式 | 【F】 |  |\n| 临时使用移动工具 | 【Ctrl】 |  |\n| 临时使用吸色工具 | 【Alt】 |  |\n| 临时使用抓手工具 | 【空格】 |  |\n| 打开工具选项面板 | 【Enter】 |  |\n| 快速输入工具选项(当前工具选项面板中至少有一个可调节数字) | 【0】至【9】 |  |\n| 循环选择画笔 | 【,】或【.】 |  |\n| 选择第一个画笔 | 【Shift】+【,】 |  |\n| 选择最后一个画笔 | 【Shift】+【.】 |  |\n| 改变画笔大小 | 【\\[】或【\\]】 |  |\n\n| **三、画笔工具快捷键大全** |  |\n| --- | --- |\n| 画笔工具【B】 | 普通模式和精确光标模式切换【Caps Lock】 |\n| 使用画笔工具时按住【Ctrl】就会变成移动工具 | 使用画笔工具时按住【Alt】就会变成吸管工具 |\n| 改变画笔大小【\\[】或【\\]】 | 改变画笔软硬度**【Shift】+**【\\[】或【\\]】 |\n| 画笔不透明度【数字】，如5%，按【0】和【5】 | 画笔流量调节【Shift】+【数字】 |\n| 循环选择画笔预设中的画笔【,】或【.】 | 显示/隐藏“画笔预设”面板【F5】 |\n| 选择第一款画笔**【Shift】+**【,】 | 选择最后一款画笔**【Shift】+**【.】 |\n| **使用画笔工具时按住【Alt】+【Shift】+【鼠标右键不放】就可以显示色轮** |  |\n| 按**【Alt】**+**【鼠标右键不放】**，左右拖动是调节笔刷大小，上下拖动是调节画笔不透明度 |  |\n\n| **四、文件操作** |  |\n| --- | --- |\n| 新建图形文件 | 【Ctrl】+【N】 |\n| 用默认设置创建新文件 | 【Ctrl】+【Alt】+【N】 |\n| 打开已有的图像 | 【Ctrl】+【O】 |\n| 打开为… | 【Ctrl】+【Alt】+【O】 |\n| 关闭当前图像 | 【Ctrl】+【W】 |\n| 保存当前图像 | 【Ctrl】+【S】 |\n| 另存为… | 【Ctrl】+【Shift】+【S】 |\n| 存储为Web所用格式 | 【Ctrl】+【Alt】+ 【Shift】+【S】 |\n| 页面设置 | 【Ctrl】+【Shift】+【P】 |\n| 打印 | 【Ctrl】+【P】 |\n| 打开“预置”对话框 | 【Ctrl】+【K】 |\n\n| **五、编辑操作** |  |\n| --- | --- |\n| 还原/重做前一步操作 | 【Ctrl】+【Z】 |\n| 一步一步向前还原 | 【Ctrl】+【Alt】+【Z】 |\n| 一步一步向后重做 | 【Ctrl】+【Shift】+【Z】 |\n| 淡入/淡出 | 【Ctrl】+【Shift】+【F】 |\n| 剪切选取的图像或路径 | 【Ctrl】+【X】或【F2】 |\n| 拷贝选取的图像或路径 | 【Ctrl】+【C】 |\n| 合并拷贝 | 【Ctrl】+【Shift】+【C】 |\n| 将剪贴板的内容粘到当前图形中 | 【Ctrl】+【V】或【F4】 |\n| 将剪贴板的内容粘到选框中 | 【Ctrl】+【Shift】+【V】 |\n| 自由变换 | 【Ctrl】+【T】 |\n| 应用自由变换(在自由变换模式下) | 【Enter】 |\n| 从中心或对称点开始变换 (在自由变换模式下) | 【Alt】 |\n| 限制(在自由变换模式下) | 【Shift】 |\n| 扭曲(在自由变换模式下) | 【Ctrl】 |\n| 取消变形(在自由变换模式下) | 【Esc】 |\n| 自由变换复制的象素数据 | 【Ctrl】+【Shift】+【T】 |\n| 再次变换复制的象素数据并建立一个副本 | 【Ctrl】+【Shift】+【Alt】+【T】 |\n| 删除选框中的图案或选取的路径 | 【DEL】 |\n| 用背景色填充所选区域或整个图层 | 【Ctrl】+【BackSpace】或【Ctrl】+【Del】 |\n| 用前景色填充所选区域或整个图层 | 【Alt】+【BackSpace】或【Alt】+【Del】 |\n| 弹出“填充”对话框 | 【Shift】+【BackSpace】 |\n| 从历史记录中填充 | 【Alt】+【Ctrl】+【Backspace】 |\n| 打开“颜色设置”对话框 | 【Ctrl】+【Shift】+【K】 |\n| 打开“预先调整管理器”对话框 | 【Alt】+【E】放开后按【M】 |\n| 预设画笔（在“预先调整管理器”对话框中） | 【Ctrl】+【1】 |\n| 预设颜色样式（在“预先调整管理器”对话框中） | 【Ctrl】+【2】 |\n| 预设渐变填充（在“预先调整管理器”对话框中） | 【Ctrl】+【3】 |\n| 预设图层效果（在“预先调整管理器”对话框中） | 【Ctrl】+【4】 |\n| 预设图案填充（在“预先调整管理器”对话框中） | 【Ctrl】+【5】 |\n| 预设轮廓线（在“预先调整管理器”对话框中） | 【Ctrl】+【6】 |\n| 预设定制矢量图形（在“预先调整管理器”对话框中） | 【Ctrl】+【7】 |\n| 打开“预置”对话框 | 【Ctrl】+【K】 |\n| 显示最后一次显示的“预置”对话框 | 【Alt】+【Ctrl】+【K】 |\n| 设置“常规”选项(在预置对话框中) | 【Ctrl】+【1】 |\n| 设置“存储文件”(在预置对话框中) | 【Ctrl】+【2】 |\n| 设置“显示和光标”(在预置对话框中) | 【Ctrl】+【3】 |\n| 设置“透明区域与色域”(在预置对话框中) | 【Ctrl】+【4】 |\n| 设置“单位与标尺”(在预置对话框中) | 【Ctrl】+【5】 |\n| 设置“参考线与网格”(在预置对话框中) | 【Ctrl】+【6】 |\n| 设置“增效工具与暂存盘”(在预置对话框中) | 【Ctrl】+【7】 |\n| 设置“内存与图像高速缓存”(在预置对话框中) | 【Ctrl】+【8】 |\n\n| **六、图层操作** |  |\n| --- | --- |\n| 从对话框新建一个图层 | 【Ctrl】+【Shift】+【N】 |\n| 以默认选项建立一个新的图层 | 【Ctrl】+【Alt】+【Shift】+【N】 |\n| 通过拷贝建立一个图层（无对话框） | 【Ctrl】+【J】 |\n| 从对话框建立一个通过拷贝的图层 | 【Ctrl】+【Alt】+【J】 |\n| 通过剪切建立一个图层（无对话框） | 【Ctrl】+【Shift】+【J】 |\n| 从对话框建立一个通过剪切的图层 | 【Ctrl】+【Shift】+【Alt】+【J】 |\n| 与前一图层编组 | 【Ctrl】+【G】 |\n| 取消编组 | 【Ctrl】+【Shift】+【G】 |\n| 将当前层下移一层 | 【Ctrl】+【\\[】 |\n| 将当前层上移一层 | 【Ctrl】+【\\]】 |\n| 将当前层移到最下面 | 【Ctrl】+【Shift】+【\\[】 |\n| 将当前层移到最上面 | 【Ctrl】+【Shift】+【\\]】 |\n| 激活下一个图层 | 【Alt】+【\\[】 |\n| 激活上一个图层 | 【Alt】+【\\]】 |\n| 激活底部图层 | 【Shift】+【Alt】+【\\[】 |\n| 激活顶部图层 | 【Shift】+【Alt】+【\\]】 |\n| 向下合并或合并联接图层 | 【Ctrl】+【E】 |\n| 合并可见图层 | 【Ctrl】+【Shift】+【E】 |\n| 盖印或盖印联接图层 | 【Ctrl】+【Alt】+【E】 |\n| 盖印可见图层 | 【Ctrl】+【Alt】+【Shift】+【E】 |\n| 调整当前图层的透明度(当前工具为无数字参数的,如移动工具) | 【0】至【9】 |\n| 保留当前图层的透明区域(开关) | 【/】 |\n| 使用预定义效果(在“效果”对话框中) | 【Ctrl】+【1】 |\n| 混合选项(在“效果”对话框中) | 【Ctrl】+【2】 |\n| 投影(在“效果”对话框中) | 【Ctrl】+【3】 |\n| 内阴影(在“效果”对话框中) | 【Ctrl】+【4】 |\n| 外发光(在“效果”对话框中) | 【Ctrl】+【5】 |\n| 内发光(在“效果”对话框中) | 【Ctrl】+【6】 |\n| 斜面和浮雕(在“效果”对话框中) | 【Ctrl】+【7】 |\n| 描边(在“效果”对话框中) | 【Ctrl】+【8】 |\n| 图案叠加(在“效果”对话框中) | 【Ctrl】+【9】 |\n\n| **七、图像调整** |  |\n| --- | --- |\n| 调整色阶 | 【Ctrl】+【L】 |\n| 自动调整色阶 | 【Ctrl】+【Shift】+【L】 |\n| 自动调整对比度 | 【Ctrl】+【Alt】+【Shift】+【L】 |\n| 打开曲线调整对话框 | 【Ctrl】+【M】 |\n| 在所选通道的曲线上添加新的点(‘曲线’对话框中) | 在图象中【Ctrl】加点按 |\n| 在复合曲线以外的所有曲线上添加新的点(‘曲线’对话框中) | 【Ctrl】+【Shift】加点按 |\n| 移动所选点(‘曲线’对话框中) | 【↑】/【↓】/【←】/【→】 |\n| 以10点为增幅移动所选点以10点为增幅(‘曲线’对话框中) | 【Shift】+【箭头】 |\n| 选择多个控制点(‘曲线’对话框中) | 【Shift】加点按 |\n| 前移控制点(‘曲线’对话框中) | 【Ctrl】+【Tab】 |\n| 后移控制点(‘曲线’对话框中) | 【Ctrl】+【Shift】+【Tab】 |\n| 添加新的点(‘曲线’对话框中) | 点按网格 |\n| 删除点(‘曲线’对话框中) | 【Ctrl】加点按点 |\n| 取消选择所选通道上的所有点(‘曲线’对话框中) | 【Ctrl】+【D】 |\n| 使曲线网格更精细或更粗糙(‘曲线’对话框中) | 【Alt】加点按网格 |\n| 选择彩色通道(‘曲线’对话框中) | 【Ctrl】+【~】 |\n| 选择单色通道(‘曲线’对话框中) | 【Ctrl】+【数字】 |\n| 打开“色彩平衡”对话框 | 【Ctrl】+【B】 |\n| 打开“色相/饱和度”对话框 | 【Ctrl】+【U】 |\n| 全图调整(在色相/饱和度”对话框中) | 【Ctrl】+【~】 |\n| 只调整红色(在色相/饱和度”对话框中) | 【Ctrl】+【1】 |\n| 只调整黄色(在色相/饱和度”对话框中) | 【Ctrl】+【2】 |\n| 只调整绿色(在色相/饱和度”对话框中) | 【Ctrl】+【3】 |\n| 只调整青色(在色相/饱和度”对话框中) | 【Ctrl】+【4】 |\n| 只调整蓝色(在色相/饱和度”对话框中) | 【Ctrl】+【5】 |\n| 只调整洋红(在色相/饱和度”对话框中) | 【Ctrl】+【6】 |\n| 去色 | 【Ctrl】+【Shift】+【U】 |\n| 反相 | 【Ctrl】+【I】 |\n| 打开“抽出滤镜”对话框 | 【Ctrl】+【Alt】+【X】 |\n| 边缘增亮工具(在“抽出”对话框中) | 【B】 |\n| 填充工具(在“抽出”对话框中) | 【G】 |\n| 擦除工具(在“抽出”对话框中) | 【E】 |\n| 清除工具(在“抽出”对话框中) | 【C】 |\n| 边缘修饰工具(在“抽出”对话框中) | 【T】 |\n| 缩放工具(在“抽出”对话框中) | 【Z】 |\n| 抓手工具(在“抽出”对话框中) | 【H】 |\n| 改变显示模式(在“抽出”对话框中) | 【F】 |\n| 加大画笔大小(在“抽出”对话框中) | 【\\]】 |\n| 减小画笔大小(在“抽出”对话框中) | 【\\[】 |\n| 完全删除增亮线(在“抽出”对话框中) | 【Alt】+【BackSpace】 |\n| 增亮整个抽取对像(在“抽出”对话框中) | 【Ctrl】+【BackSpace】 |\n| 打开“液化滤镜”对话框 | 【Ctrl】+【Shift】+【X】 |\n| 扭曲工具(在“液化”对话框中) | 【W】 |\n| 顺时针转动工具(在“液化”对话框中) | 【R】 |\n| 逆时针转动工具(在“液化”对话框中) | 【L】 |\n| 缩拢工具(在“液化”对话框中) | 【P】 |\n| 扩张工具(在“液化”对话框中) | 【B】 |\n| 反射工具(在“液化”对话框中) | 【M】 |\n| 重构工具(在“液化”对话框中) | 【E】 |\n| 冻结工具(在“液化”对话框中) | 【F】 |\n| 解冻工具(在“液化”对话框中) | 【T】 |\n| 应用“液化”效果并退回Photoshop主界面(在“液化”对话框中) | 【Enter】 |\n| 放弃“液化”效果并退回Photoshop主界面(在“液化”对话框中) | 【ESC】 |\n\n| **八、选择功能** |  |\n| --- | --- |\n| 全部选取 | 【Ctrl】+【A】 |\n| 取消选区 | 【Ctrl】+【D】 |\n| 重新选区 | 【Ctrl】+【Shift】+【D】 |\n| 羽化选区 | 【Ctrl】+【Alt】+【D】 |\n| 选区反向 | 【Ctrl】+【Shift】+【I】 |\n| 载入选区 | 【Ctrl】+点按图层、路径、通道面板中的缩约图 |\n| 按上次的参数再做一次上次的滤镜 | 【Ctrl】+【F】 |\n| 渐隐上次所做滤镜的效果 | 【Ctrl】+【Shift】+【F】 |\n| 重复上次所做的滤镜(可调参数) | 【Ctrl】+【Alt】+【F】 |\n| 选择工具(在“3D变化”滤镜中) | 【V】 |\n| 直接选择工具(在“3D变化”滤镜中) | 【A】 |\n| 立方体工具(在“3D变化”滤镜中) | 【M】 |\n| 球体工具(在“3D变化”滤镜中) | 【N】 |\n| 柱体工具(在“3D变化”滤镜中) | 【C】 |\n| 添加锚点工具(在“3D变化”滤镜中) | 【+】 |\n| 减少锚点工具(在“3D变化”滤镜中) | 【-】 |\n| 轨迹球(在“3D变化”滤镜中) | 【R】 |\n| 全景相机工具(在“3D变化”滤镜中) | 【E】 |\n| 移动视图(在“3D变化”滤镜中) | 【H】 |\n| 缩放视图(在“3D变化”滤镜中) | 【Z】 |\n| 应用三维变形并退回到Photoshop主界面(在“3D变化”滤镜中) | 【Enter】 |\n| 放弃三维变形并退回到Photoshop主界面(在“3D变化”滤镜中) | 【Esc】 |\n\n| **九、视图操作** |  |\n| --- | --- |\n| 选择彩色通道 | 【Ctrl】+【2】 |\n| 选择单色通道 | 【Ctrl】+【数字】 |\n| 选择快速蒙板 | 【Ctrl】+【\\\\】 |\n| 始终在视窗显示复合通道 | 【~】 |\n| 以CMYK方式预览(开关) | 【Ctrl】+【Y】 |\n| 打开/关闭色域警告 | 【Ctrl】+【Shift】+【Y】 |\n| 放大视图 | 【Ctrl】+【+】 |\n| 缩小视图 | 【Ctrl】+【-】 |\n| 满画布显示 | 【Ctrl】+【0】 |\n| 实际象素显示 | 【Ctrl】+【Alt】+【0】 |\n| 向上卷动一屏 | 【PageUp】 |\n| 向下卷动一屏 | 【PageDown】 |\n| 向左卷动一屏 | 【Ctrl】+【PageUp】 |\n| 向右卷动一屏 | 【Ctrl】+【PageDown】 |\n| 向上卷动10 个单位 | 【Shift】+【PageUp】 |\n| 向下卷动10 个单位 | 【Shift】+【PageDown】 |\n| 向左卷动10 个单位 | 【Shift】+【Ctrl】+【PageUp】 |\n| 向右卷动10 个单位 | 【Shift】+【Ctrl】+【PageDown】 |\n| 将视图移到左上角 | 【Home】 |\n| 将视图移到右下角 | 【End】 |\n| 显示/隐藏选择区域 | 【Ctrl】+【H】 |\n| 显示/隐藏路径 | 【Ctrl】+【Shift】+【H】 |\n| 显示/隐藏标尺 | 【Ctrl】+【R】 |\n| 捕捉 | 【Ctrl】+【;】 |\n| 锁定参考线 | 【Ctrl】+【Alt】+【;】 |\n| 显示/隐藏“颜色”面板 | 【F6】 |\n| 显示/隐藏“图层”面板 | 【F7】 |\n| 显示/隐藏“信息”面板 | 【F8】 |\n| 显示/隐藏“动作”面板 | 【F9】 |\n| 显示/隐藏所有命令面板 | 【TAB】 |\n| 显示或隐藏工具箱以外的所有调板 | 【Shift】+【TAB】 |\n| 文字处理(在字体编辑模式中) |  |\n| 显示/隐藏“字符”面板 | 【Ctrl】+【T】 |\n| 显示/隐藏“段落”面板 | 【Ctrl】+【M】 |\n| 左对齐或顶对齐 | 【Ctrl】+【Shift】+【L】 |\n| 中对齐 | 【Ctrl】+【Shift】+【C】 |\n| 右对齐或底对齐 | 【Ctrl】+【Shift】+【R】 |\n| 左／右选择 1 个字符 | 【Shift】+【←】/【→】 |\n| 下／上选择 1 行 | 【Shift】+【↑】/【↓】 |\n| 选择所有字符 | 【Ctrl】+【A】 |\n| 显示/隐藏字体选取底纹 | 【Ctrl】+【H】 |\n| 选择从插入点到鼠标点按点的字符 | 【Shift】加点按 |\n| 左／右移动 1 个字符 | 【←】/【→】 |\n| 下／上移动 1 行 | 【↑】/【↓】 |\n| 左／右移动1个字 | 【Ctrl】+【←】/【→】 |\n| 将所选文本的文字大小减小2 点象素 | 【Ctrl】+【Shift】+【<】 |\n| 将所选文本的文字大小增大2 点象素 | 【Ctrl】+【Shift】+【>】 |\n| 将所选文本的文字大小减小10 点象素 | 【Ctrl】+【Alt】+【Shift】+【<】 |\n| 将所选文本的文字大小增大10 点象素 | 【Ctrl】+【Alt】+【Shift】+【>】 |\n| 将行距减小2点象素 | 【Alt】+【↓】 |\n| 将行距增大2点象素 | 【Alt】+【↑】 |\n| 将基线位移减小2点象素 | 【Shift】+【Alt】+【↓】 |\n| 将基线位移增加2点象素 | 【Shift】+【Alt】+【↑】 |\n| 将字距微调或字距调整减小20/1000ems | 【Alt】+【←】 |\n| 将字距微调或字距调整增加20/1000ems | 【Alt】+【→】 |\n| 将字距微调或字距调整减小100/1000ems | 【Ctrl】+【Alt】+【←】 |\n| 将字距微调或字距调整增加100/1000ems | 【Ctrl】+【Alt】+【→】 |\n\naa\n\n| **十、图层混合模式** |  |\n| --- | --- |\n| 循环选择混合模式 | 【Shift】+【-】或【+】 |\n| 正常 | 【Shift】+【Alt】+【N】 |\n| 溶解 | 【Shift】+【Alt】+【I】 |\n| 变暗 | 【Shift】+【Alt】+【K】 |\n| 正片叠底 | 【Shift】+【Alt】+【M】 |\n| 颜色加深 | 【Shift】+【Alt】+【B】 |\n| 线性加深 | 【Shift】+【Alt】+【A】 |\n| 变亮 | 【Shift】+【Alt】+【G】 |\n| 滤色 | 【Shift】+【Alt】+【S】 |\n| 颜色减淡 | 【Shift】+【Alt】+【D】 |\n| 线性减淡 | 【Shift】+【Alt】+【W】 |\n| 叠加 | 【Shift】+【Alt】+【O】 |\n| 柔光 | 【Shift】+【Alt】+【F】 |\n| 强光 | 【Shift】+【Alt】+【H】 |\n| 亮光 | 【Shift】+【Alt】+【V】 |\n| 线性光 | 【Shift】+【Alt】+【J】 |\n| 点光 | 【Shift】+【Alt】+【Z】 |\n| 实色混合 | 【Shift】+【Alt】+【L】 |\n| 差值 | 【Shift】+【Alt】+【E】 |\n| 排除 | 【Shift】+【Alt】+【X】 |\n| 色相 | 【Shift】+【Alt】+【U】 |\n| 饱和度 | 【Shift】+【Alt】+【T】 |\n| 颜色 | 【Shift】+【Alt】+【C】 |\n| 明度 | 【Shift】+【Alt】+【Y】 |\n\n参考网站：[PS新手自学视频教程，PS自学视频教程](http://www.240ps.com/jc/xinshouzixue.asp)\n","tags":["ps"],"categories":["adobe全家桶","photoshop"]},{"title":"postman:API接口调试器","url":"/2022/06/01/postmanapi接口调试器/","content":"\n## 安装\n\n- 下载地址：https://www.getpostman.com/downloads/\n- 下载完安装包后直接双击安装即可。\n\n## 设置\n\n### 主题设置\n\n这里不得不说，Postman的界面还是做的很好的，比起Swagger来说好多了，Postman默认提供了两种主题，一种亮色和一种暗色，可以通过左上角的File->Settings按钮打开。\n\n![](https://presenter.oss-cn-shanghai.aliyuncs.com/postman_screen_01.png)\n\n![](https://presenter.oss-cn-shanghai.aliyuncs.com/postman_screen_02.png)\n\n### 调整字体大小\n\n可能界面默认的字体大小并不适合你，尤其是大屏幕的电脑，可以在View下的Zoom In和Zoom Out按钮进行放大和缩小。\n\n![](https://presenter.oss-cn-shanghai.aliyuncs.com/postman_screen_03.png)\n\n## 进行接口调试\n\n> 测试接口均来自mall-admin后台，启动后可以直接测试。\n\n### 调用GET请求\n\n![](https://presenter.oss-cn-shanghai.aliyuncs.com/postman_screen_04.png)\n\n### 调用POST请求提交JSON格式数据\n\n![](https://presenter.oss-cn-shanghai.aliyuncs.com/postman_screen_05.png)\n\n### 调用POST请求提交表单\n\n![](https://presenter.oss-cn-shanghai.aliyuncs.com/postman_screen_06.png)\n\n### 调用文件上传接口\n\n![](https://presenter.oss-cn-shanghai.aliyuncs.com/postman_screen_07.png)\n\n![](https://presenter.oss-cn-shanghai.aliyuncs.com/postman_screen_08.png)\n\n### 调用需要登录的接口\n\n### 调用登录接口获取令牌\n\n![](https://presenter.oss-cn-shanghai.aliyuncs.com/postman_screen_09.png)\n\n### 设置令牌头并调用需要登录的接口\n\n![](https://presenter.oss-cn-shanghai.aliyuncs.com/postman_screen_10.png)\n\n## 调试文件的导入与导出\n\n### 将调试接口信息进行保存\n\n![](https://presenter.oss-cn-shanghai.aliyuncs.com/postman_screen_12.png)\n\n### 导出Collection中的调试信息\n\n![](https://presenter.oss-cn-shanghai.aliyuncs.com/postman_screen_17.png)\n\n### 导入Collection中的调试信息\n\n![](https://presenter.oss-cn-shanghai.aliyuncs.com/postman_screen_18.png)\n\n![](https://presenter.oss-cn-shanghai.aliyuncs.com/postman_screen_19.png)\n\n## 使用过程中的一些技巧\n\n### 设置不同的环境\n\n我们开发时，都会分本地环境和测试环境，本地环境用于本机调试接口，测试环境用于前后端联调接口。上面我们把[http://localhost:8080](http://localhost:8080)这个ip端口直接写在请求路径之中，当我们要调试测试环境接口时，就会产生麻烦。定义多个环境变量，在接口地址中进行引用，可以解决这个问题。\n\n#### 添加本地环境\n\n![](https://presenter.oss-cn-shanghai.aliyuncs.com/postman_screen_13.png)\n\n#### 添加测试环境\n\n![](https://presenter.oss-cn-shanghai.aliyuncs.com/postman_screen_14.png)\n\n#### 引用环境变量\n\n![](https://presenter.oss-cn-shanghai.aliyuncs.com/postman_screen_15.png)\n\n#### 环境变量的切换\n\n![](https://presenter.oss-cn-shanghai.aliyuncs.com/postman_screen_16.png)\n\n### 设置通用的登录令牌\n\n当我们有很多接口需要登录令牌头时，如果以前使用的令牌失效了，那所有接口的令牌头都会需要修改，这里可以把登录令牌定义好，再引用，这样令牌失效了，只需要修改一处即可。\n\n![](https://presenter.oss-cn-shanghai.aliyuncs.com/postman_screen_20.png)\n\n![](https://presenter.oss-cn-shanghai.aliyuncs.com/postman_screen_21.png)\n","tags":["api"],"categories":["api","工具类"]},{"title":"Serializable对象序列化","url":"/2022/06/01/serializable对象序列化/","content":"\n### [序列化](https://so.csdn.net/so/search?q=序列化&spm=1001.2101.3001.7020)\n\n查看 [官方文档](http://docs.oracle.com/javase/8/docs/api/java/io/Serializable.html) 就会发现 [Serializable](https://so.csdn.net/so/search?q=Serializable&spm=1001.2101.3001.7020)接口中一个成员函数或者成员变量也没有。那么这个接口的作用是什么呢。网上找了一些博客看过之后，知道这个接口的作用是实现序列化。\n\n序列化：对象的寿命通常随着生成该对象的程序的终止而终止，有时候需要把在内存中的各种对象的状态（也就是实例变量，不是方法）保存下来，并且可以在需要时再将对象恢复。虽然你可以用你自己的各种各样的方法来保存对象的状态，但是Java给你提供一种应该比你自己的好的保存对象状态的机制，那就是序列化。\n\n总结：Java 序列化技术可以使你将一个对象的状态写入一个Byte 流里（系列化），并且可以从其它地方把该Byte 流里的数据读出来（反序列化）。\n\n## 系列化的用途\n\n- 想把的内存中的对象状态保存到一个文件中或者数据库中时候\n- 想把对象通过网络进行传播的时候\n\n## 如何序列化\n\n只要一个类实现Serializable接口，那么这个类就可以序列化了。\n\n例如有一个 Person类，实现了Serializable接口，那么这个类就可以被序列化了。\n\n```\nclass Person implements Serializable{   \n    private static final long serialVersionUID = 1L; //一会就说这个是做什么的\n    String name;\n    int age;\n    public Person(String name,int age){\n        this.name = name;\n        this.age = age;\n    }   \n    public String toString(){\n        return \"name:\"+name+\"\\tage:\"+age;\n    }\n}\n```\n\n通过ObjectOutputStream 的writeObject()方法把这个类的对象写到一个地方（文件），再通过ObjectInputStream 的readObject()方法把这个对象读出来。\n\n```\n    File file = new File(\"file\"+File.separator+\"out.txt\");\n\n    FileOutputStream fos = null;\n\n    try {\n        fos = new FileOutputStream(file);\n        ObjectOutputStream oos = null;\n        try {\n            oos = new ObjectOutputStream(fos);\n            Person person = new Person(\"tom\", 22);\n            System.out.println(person);\n            oos.writeObject(person);            //写入对象\n            oos.flush();\n        } catch (IOException e) {\n            e.printStackTrace();\n        }finally{\n            try {\n                oos.close();\n            } catch (IOException e) {\n                System.out.println(\"oos关闭失败：\"+e.getMessage());\n            }\n        }\n    } catch (FileNotFoundException e) {\n        System.out.println(\"找不到文件：\"+e.getMessage());\n    } finally{\n        try {\n            fos.close();\n        } catch (IOException e) {\n            System.out.println(\"fos关闭失败：\"+e.getMessage());\n        }\n    }\n\n    FileInputStream fis = null;\n    try {\n        fis = new FileInputStream(file);\n        ObjectInputStream ois = null;\n        try {\n            ois = new ObjectInputStream(fis);\n            try {\n                Person person = (Person)ois.readObject();   //读出对象\n                System.out.println(person);\n            } catch (ClassNotFoundException e) {\n                e.printStackTrace();\n            } \n        } catch (IOException e) {\n            e.printStackTrace();\n        }finally{\n            try {\n                ois.close();\n            } catch (IOException e) {\n                System.out.println(\"ois关闭失败：\"+e.getMessage());\n            }\n        }\n    } catch (FileNotFoundException e) {\n        System.out.println(\"找不到文件：\"+e.getMessage());\n    } finally{\n        try {\n            fis.close();\n        } catch (IOException e) {\n            System.out.println(\"fis关闭失败：\"+e.getMessage());\n        }\n    }\n```\n\n输出结果为：\n\n```\nname:tom    age:22\nname:tom    age:22\n```\n\n结果完全一样。如果我把Person类中的implements Serializable 去掉，Person类就不能序列化了。此时再运行上述程序，就会报java.io.NotSerializableException异常。\n\n### serialVersionUID\n\n注意到上面程序中有一个 serialVersionUID ，实现了Serializable接口之后，Eclipse就会提示你增加一个 serialVersionUID，虽然不加的话上述程序依然能够正常运行。\n\n序列化 ID 在 Eclipse 下提供了两种生成策略\n\n- 一个是固定的 1L\n- 一个是随机生成一个不重复的 long 类型数据（实际上是使用 JDK 工具，根据类名、接口名、成员方法及属性等来生成）\n\n上面程序中，输出对象和读入对象使用的是同一个Person类。\n\n如果是通过网络传输的话，如果Person类的serialVersionUID不一致，那么反序列化就不能正常进行。例如在客户端A中Person类的serialVersionUID=1L，而在客户端B中Person类的serialVersionUID=2L 那么就不能重构这个Person对象。\n\n客户端A中的Person类：\n\n```\nclass Person implements Serializable{   \n\n    private static final long serialVersionUID = 1L;\n\n    String name;\n    int age;\n\n    public Person(String name,int age){\n        this.name = name;\n        this.age = age;\n    }   \n    public String toString(){\n        return \"name:\"+name+\"\\tage:\"+age;\n    }\n}\n```\n\n客户端B中的Person类：\n\n```\nclass Person implements Serializable{   \n\n    private static final long serialVersionUID = 2L;\n\n    String name;\n    int age;\n\n    public Person(String name,int age){\n        this.name = name;\n        this.age = age;\n    }   \n    public String toString(){\n        return \"name:\"+name+\"\\tage:\"+age;\n    }\n}\n```\n\n试图重构就会报java.io.InvalidClassException异常，因为这两个类的版本不一致，local class incompatible，重构就会出现错误。\n\n如果没有特殊需求的话，使用用默认的 1L 就可以，这样可以确保代码一致时反序列化成功。那么随机生成的序列化 ID 有什么作用呢，有些时候，通过改变序列化 ID 可以用来限制某些用户的使用。\n\n### 静态变量序列化\n\n串行化只能保存对象的非静态成员交量，不能保存任何的成员方法和静态的成员变量，而且串行化保存的只是变量的值，对于变量的任何修饰符都不能保存。\n\n如果把Person类中的name定义为static类型的话，试图重构，就不能得到原来的值，只能得到null。说明对静态成员变量值是不保存的。这其实比较容易理解，**序列化保存的是对象的状态，静态变量属于类的状态**，因此 序列化并不保存静态变量。\n\n### transient关键字\n\n经常在实现了 Serializable接口的类中能看见transient关键字。这个关键字并不常见。 transient关键字的作用是：阻止实例中那些用此关键字声明的变量持久化；当对象被反序列化时（从源文件读取字节序列进行重构），这样的实例变量值不会被持久化和恢复。\n\n当某些变量不想被序列化，同是又不适合使用static关键字声明，那么此时就需要用transient关键字来声明该变量。\n\n例如用 transient关键字 修饰name变量\n\n```\nclass Person implements Serializable{   \n\n    private static final long serialVersionUID = 1L;\n\n    transient String name;\n    int age;\n\n    public Person(String name,int age){\n        this.name = name;\n        this.age = age;\n    }   \n    public String toString(){\n        return \"name:\"+name+\"\\tage:\"+age;\n    }\n}\n```\n\n在反序列化视图重构对象的时候，作用与static变量一样： 输出结果为：\n\n```\nname:null   age:22\n```\n\n**在被反序列化后，transient 变量的值被设为初始值，如 int 型的是 0，对象型的是 null。**\n\n注：对于某些类型的属性，其状态是瞬时的，这样的属性是无法保存其状态的。例如一个线程属性或需要访问IO、本地资源、网络资源等的属性，对于这些字段，我们必须用transient关键字标明，否则编译器将报措。\n\n### 序列化中的继承问题\n\n- **当一个父类实现序列化，子类自动实现序列化，不需要显式实现Serializable接口。**\n- 一个子类实现了 Serializable 接口，它的父类都没有实现 Serializable 接口，要想将父类对象也序列化，就需要让父类也实现Serializable 接口。\n\n第二种情况中：如果父类不实现 Serializable接口的话，就需要有默认的无参的构造函数。这是因为一个 Java 对象的构造必须先有父对象，才有子对象，反序列化也不例外。在反序列化时，为了构造父对象，只能调用父类的无参构造函数作为默认的父对象。因此当我们取父对象的变量值时，它的值是调用父类无参构造函数后的值。在这种情况下，在序列化时根据需要在父类无参构造函数中对变量进行初始化，否则的话，父类变量值都是默认声明的值，如 int 型的默认是 0，string 型的默认是 null。\n\n例如：\n\n```\nclass People{\n    int num;\n    public People(){}           //默认的无参构造函数，没有进行初始化\n    public People(int num){     //有参构造函数\n        this.num = num;\n    }\n    public String toString(){\n        return \"num:\"+num;\n    }\n}\nclass Person extends People implements Serializable{    \n\n    private static final long serialVersionUID = 1L;\n\n    String name;\n    int age;\n\n    public Person(int num,String name,int age){\n        super(num);             //调用父类中的构造函数\n        this.name = name;\n        this.age = age;\n    }\n    public String toString(){\n        return super.toString()+\"\\tname:\"+name+\"\\tage:\"+age;\n    }\n}\n```\n\n在一端写出对象的时候\n\n```\n    Person person = new Person(10,\"tom\", 22); //调用带参数的构造函数num=10,name = \"tim\",age =22\n    System.out.println(person);\n    oos.writeObject(person);                  //写出对象\n```\n\n在另一端读出对象的时候\n\n```\n    Person person = (Person)ois.readObject(); //反序列化，调用父类中的无参构函数。\n    System.out.println(person);\n```\n\n输出为\n\n```\n    num:0   name:tom    age:22\n```\n\n发现由于父类中无参构造函数并没有对num初始化，所以num使用默认值为0。\n\n## 总结\n\n序列化给我们提供了一种技术，用于保存对象的变量。以便于传输。虽然也可以使用别的一些方法实现同样的功能，但是java给我们提供的方法使用起来是非常方便的。\n","tags":["java"],"categories":["java进阶"]},{"title":"SpringBoot学习","url":"/2022/06/01/springboot学习/","content":"\n### SpringBoot是什么？[#](http://c.biancheng.net/spring_boot/)\n\n上面引用了其他的教程\n\n**这是我的SpringBoot的学习思考**\n\n刚开始学习SpringBoot先开启一个Maven项目帮助理解\n\n这是Helloworld的目录结构\n\n![](https://presenter.oss-cn-shanghai.aliyuncs.com/image-20220509152524282.png)\n\n现在先开始一个Helloworld\n\n```\n@SpringBootApplication\npublic class MainApplication {\n    public static void main(String[] args) {\n        SpringApplication.run(MainApplication.class,args);\n    }\n}\n```\n\nController\n\n```\n@RestController\npublic class HelloController {\n    @RequestMapping(\"/hello\")\n    public String handle01(){\n        return \"Hello, Spring Boot 2!\";\n    }\n\n}\n```\n\n```\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<project xmlns=\"http://maven.apache.org/POM/4.0.0\"\n         xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n         xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\">\n    <modelVersion>4.0.0</modelVersion>\n\n    <groupId>org.example</groupId>\n    <artifactId>springboot</artifactId>\n    <version>1.0-SNAPSHOT</version>\n\n    <properties>\n        <maven.compiler.source>8</maven.compiler.source>\n        <maven.compiler.target>8</maven.compiler.target>\n        <!--例如-->\n        <mysql.version>5.1</mysql.version>\n    </properties>\n\n    <!--父项目做依赖管理，后面的依赖都不需要写版本号，因为已经自动配置-->\n    <!--想要自定义版本号，只需要在porperties里重新添加，上面有例子-->\n    <parent>\n        <artifactId>spring-boot-starter-parent</artifactId>\n        <groupId>org.springframework.boot</groupId>\n        <version>2.5.8</version>\n    </parent>\n\n    <dependencies>\n        <dependency>\n            <groupId>org.springframework.boot</groupId>\n            <artifactId>spring-boot-starter-web</artifactId>\n        </dependency>\n    </dependencies>\n\n\n    <build>\n        <plugins>\n            <plugin>\n                <groupId>org.springframework.boot</groupId>\n                <artifactId>spring-boot-maven-plugin</artifactId>\n            </plugin>\n        </plugins>\n    </build>\n\n</project>\n```\n\n现在是可以运行的了，端口号8080.\n\n现在演示如何进行打包package命令  \n![](https://presenter.oss-cn-shanghai.aliyuncs.com/image-20220509152906773.png)\n\n直接执行，得到一个jar包\n\n![](https://presenter.oss-cn-shanghai.aliyuncs.com/image-20220509153010400.png)\n\n直接在cmd中就可以直接运行这个jar包\n\n```\njava -jar springboot-1.0-SNAPSHOT.jar\n```\n\n这就是简化部署，直接在目标服务器执行就行。\n","tags":["springboot"],"categories":["java全栈","springboot"]},{"title":"SpringBoot项目实战","url":"/2022/06/01/springboot项目实战/","content":"\n### mall整合SpringBoot+MyBatis搭建基本骨架\n\n本文主要讲解mall整合SpringBoot+MyBatis搭建基本骨架，以商品品牌为例实现基本的CRUD操作及通过PageHelper实现分页查询。\n\n## [#](https://www.macrozheng.com/mall/architect/mall_arch_01.html#mysql数据库环境搭建)mysql数据库环境搭建\n\n- 下载并安装mysql5.7版本，下载地址：https://dev.mysql.com/downloads/installer/\n- 设置数据库帐号密码：root root\n- 下载并安装客户端连接工具Navicat,下载地址：http://www.formysql.com/xiazai.html\n- 创建数据库mall\n- 导入mall的数据库脚本，脚本地址：https://github.com/macrozheng/mall-learning/blob/master/document/sql/mall.sql\n\n## [#](https://www.macrozheng.com/mall/architect/mall_arch_01.html#项目使用框架介绍)项目使用框架介绍\n\n### [#](https://www.macrozheng.com/mall/architect/mall_arch_01.html#springboot)SpringBoot\n\n> SpringBoot可以让你快速构建基于Spring的Web应用程序，内置多种Web容器(如Tomcat)，通过启动入口程序的main函数即可运行。\n\n### [#](https://www.macrozheng.com/mall/architect/mall_arch_01.html#pagerhelper)PagerHelper\n\n> MyBatis分页插件，简单的几行代码就能实现分页，在与SpringBoot整合时，只要整合了PagerHelper就自动整合了MyBatis。\n\n```\nPageHelper.startPage(pageNum, pageSize);\n//之后进行查询操作将自动进行分页\nList<PmsBrand> brandList = brandMapper.selectByExample(new PmsBrandExample());\n//通过构造PageInfo对象获取分页信息，如当前页码，总页数，总条数\nPageInfo<PmsBrand> pageInfo = new PageInfo<PmsBrand>(list);\n```\n\n### Druid\n\n> alibaba开源的数据库连接池，号称Java语言中最好的数据库连接池。\n\n### Mybatis generator\n\n> MyBatis的代码生成器，可以根据数据库生成model、mapper.xml、mapper接口和Example，通常情况下的单表查询不用再手写mapper。\n\n## [#](https://www.macrozheng.com/mall/architect/mall_arch_01.html#项目搭建)项目搭建\n\n### [#](https://www.macrozheng.com/mall/architect/mall_arch_01.html#使用idea初始化一个springboot项目)使用IDEA初始化一个SpringBoot项目\n\n![img](https://presenter.oss-cn-shanghai.aliyuncs.com/arch_screen_01.ab5f2485.png)\n\n### [#](https://www.macrozheng.com/mall/architect/mall_arch_01.html#添加项目依赖)添加项目依赖\n\n> 在pom.xml中添加相关依赖。\n\n```\n<parent>\n        <groupId>org.springframework.boot</groupId>\n        <artifactId>spring-boot-starter-parent</artifactId>\n        <version>2.1.3.RELEASE</version>\n        <relativePath/> <!-- lookup parent from repository -->\n    </parent>\n    <dependencies>\n        <!--SpringBoot通用依赖模块-->\n        <dependency>\n            <groupId>org.springframework.boot</groupId>\n            <artifactId>spring-boot-starter-web</artifactId>\n        </dependency>\n        <dependency>\n            <groupId>org.springframework.boot</groupId>\n            <artifactId>spring-boot-starter-actuator</artifactId>\n        </dependency>\n        <dependency>\n            <groupId>org.springframework.boot</groupId>\n            <artifactId>spring-boot-starter-aop</artifactId>\n        </dependency>\n        <dependency>\n            <groupId>org.springframework.boot</groupId>\n            <artifactId>spring-boot-starter-test</artifactId>\n            <scope>test</scope>\n        </dependency>\n        <!--MyBatis分页插件-->\n        <dependency>\n            <groupId>com.github.pagehelper</groupId>\n            <artifactId>pagehelper-spring-boot-starter</artifactId>\n            <version>1.2.10</version>\n        </dependency>\n        <!--集成druid连接池-->\n        <dependency>\n            <groupId>com.alibaba</groupId>\n            <artifactId>druid-spring-boot-starter</artifactId>\n            <version>1.1.10</version>\n        </dependency>\n        <!-- MyBatis 生成器 -->\n        <dependency>\n            <groupId>org.mybatis.generator</groupId>\n            <artifactId>mybatis-generator-core</artifactId>\n            <version>1.3.3</version>\n        </dependency>\n        <!--Mysql数据库驱动-->\n        <dependency>\n            <groupId>mysql</groupId>\n            <artifactId>mysql-connector-java</artifactId>\n            <version>8.0.15</version>\n        </dependency>\n    </dependencies>\n```\n\n### [#](https://www.macrozheng.com/mall/architect/mall_arch_01.html#修改springboot配置文件)修改SpringBoot配置文件\n\n> 在application.yml中添加数据源配置和MyBatis的mapper.xml的路径配置。\n\n```\nserver:\n  port: 8080\n\nspring:\n  datasource:\n    url: jdbc:mysql://localhost:3306/mall?useUnicode=true&characterEncoding=utf-8&serverTimezone=Asia/Shanghai\n    username: root\n    password: root\n\n#mybatis的路径配置\nmybatis:\n  mapper-locations:\n    - classpath:mapper/*.xml\n    - classpath*:com/**/mapper/*.xml\n```\n\n### 项目结构说明\n\n![](https://presenter.oss-cn-shanghai.aliyuncs.com/arch_screen_02.151cd8d3.png)\n\n### Mybatis generator 配置文件\n\n> 配置数据库连接，Mybatis generator生成model、mapper接口及mapper.xml的路径\n","tags":["springboot"],"categories":["java全栈","springboot"]},{"title":"图床搭建","url":"/2022/06/01/图床搭建/","content":"\n# picgo+阿里云oss+typora图床搭建\n\n## 1.购买阿里云的oss对象储存\n\n## 2.建立 bucket\n\n![image-20210416171724270](https://presenter.oss-cn-shanghai.aliyuncs.com/image/20210416171724.png)\n\n![image-20210416172033033](https://presenter.oss-cn-shanghai.aliyuncs.com/image/20210416172033.png)\n\n![image-20210416172125379](https://presenter.oss-cn-shanghai.aliyuncs.com/image/20210416172125.png)\n\n![image-20210416172219107](https://presenter.oss-cn-shanghai.aliyuncs.com/image/20210416172219.png)\n\n![image-20210416172312448](https://presenter.oss-cn-shanghai.aliyuncs.com/image/20210416172312.png)\n\n### 然后记下来显示的AccessKey和AccessKey Serect。分别是用户号和密码\n\n![image-20210416172507376](https://presenter.oss-cn-shanghai.aliyuncs.com/image/20210416172507.png)\n\n![image-20210416172540595](https://presenter.oss-cn-shanghai.aliyuncs.com/image/20210416172540.png)\n\n再到picgo\n\n![image-20210416172627340](https://presenter.oss-cn-shanghai.aliyuncs.com/image/20210416172627.png)\n\n![image-20210416172754089](https://presenter.oss-cn-shanghai.aliyuncs.com/image/20210416172754.png)\n\n然后就可以了。\n","tags":["图床"],"categories":["技术类"]},{"title":"npm常用命令","url":"/2022/05/31/npm常用命令/","content":"\n## 简介\n\nnpm 是跟随 node 一起安装的包（模块）管理器。常见的使用场景有以下几种：\n\n- 允许用户从 npm 服务器下载别人编写的第三方包到本地使用。\n- 允许用户从 npm 服务器下载并安装别人编写的命令行程序到本地使用。\n- 允许用户将自己编写的包或命令行程序上传到 npm 服务器供别人使用。\n\n## 常用命令\n\n#### 检测是否安装及版本\n\n```shell\nnpm -v # 显示版本号说明已经安装相应的版本\n```\n\n#### 生成 package.json 文件\n\n```shell\nnpm init\n```\n\n> package.json 用来描述项目中用到的模块和其他信息\n\n#### 安装模块\n\n```shell\nnpm install # 安装package.json定义好的模块，简写 npm i\n \n# 安装包指定模块\nnpm i <ModuleName>\n \n# 全局安装\nnpm i <ModuleName> -g \n \n# 安装包的同时，将信息写入到package.json中的 dependencies 配置中\nnpm i <ModuleName> --save\n \n# 安装包的同时，将信息写入到package.json中的 devDependencies 配置中\nnpm i <ModuleName> --save-dev\n \n# 安装多模块\nnpm i <ModuleName1> <ModuleName2>\n \n# 安装方式参数：\n-save # 简写-S，加入到生产依赖中\n-save-dev # 简写-D，加入到开发依赖中\n-g # 全局安装 将安装包放在 /usr/local 下或者你 node 的安装目录\n```\n\n#### 查看\n\n```shell\n# 查看所有全局安装的包\nnpm ls -g\n \n# 查看本地项目中安装的包\nnpm ls\n \n# 查看包的 package.json文件\nnpm view <ModuleName>\n \n# 查看包的依赖关系\nnpm view <ModuleName> dependencies\n \n# 查看包的源文件地址\nnpm view <ModuleName> repository.url\n \n# 查看包所依赖的node版本\nnpm view <ModuleName> engines\n \n# 查看帮助\nnpm help\n```\n\n#### 更新模块\n\n```shell\n# 更新本地模块\nnpm update <ModuleName>\n \n# 更新全局模块\nnpm update -g <ModuleName> # 更新全局软件包。\nnpm update -g # 更新所有的全局软件包。\nnpm outdated -g --depth=0 # 找出需要更新的包。\n```\n\n#### 卸载模块\n\n```shell\n# 卸载本地模块\nnpm uninstall <ModuleName>\n \n# 卸载全局模块\nnpm uninstall -g <ModuleName> # 卸载全局软件包。\n```\n\n#### 清空缓存\n\n```shell\n# 清空npm缓存\nnpm cache clear\n```\n\n#### 使用淘宝镜像\n\n```shell\n# 使用淘宝镜像\nnpm install -g cnpm --registry=https://registry.npm.taobao.org\n```\n\n#### 其他\n\n```shell\n# 更改包内容后进行重建\nnpm rebuild <ModuleName>\n \n# 检查包是否已经过时，此命令会列出所有已经过时的包，可以及时进行包的更新\nnpm outdated\n \n# 访问npm的json文件，此命令将会打开一个网页\nnpm help json\n \n# 发布一个包的时候，需要检验某个包名是否存在\nnpm search <ModuleName>\n \n# 撤销自己发布过的某个版本代码\nnpm unpublish <package> <version>\n```\n\n## 使用技巧\n\n#### 多次安装不成功尝试先清除缓存\n\n```shell\nnpm cache clean -f\n```\n\n#### 查看已安装的依赖包版本号\n\n```shell\nnpm ls <ModuleName>\n```\n\n> 注意：用此方法才能准确的知道项目使用的版本号，查看 package.json 时，有 “^” 符号表示大于此版本\n\n## nrm 的作用与使用\n\n#### nrm 是什么？\n\nnrm (npm registry manager) 是 npm 的镜像源管理工具，有时候国外资源太慢，使用这个就可以快速地在 npm 源间切换\n\n#### nrm 的安装\n\n```shell\nnpm install -g nrm\n```\n\n#### nrm 命令\n\n```shell\nnrm ls　#查看可用的源（有*号的表示当前所使用的源,以下<registry>表示源的名称）\nnrm use <registry> # 将npm下载源切换成指定的源\nnrm add <registry> <url> # 添加源，url为源的路径\nnrm del <registry> # 删除源\nnrm test <registry> # 测试源的响应时间，可以作为使用哪个源的参考\n \nnrm help　# 查看nrm帮助\nnrm home <registry>　# 跳转到指定源的官网\n```\n\n#### nrm 使用\n\n如果在你的网络不太理想或者受到其他网络限制导致不能使用 npm 原本的源进行下载时，nrm 就非常有用了，你只需要：\n\n```shell\nnrm ls # 查看可用的源\nnrm use <registry>　# 切换到指定源\n```\n","tags":["工具类"]},{"title":"staruml破解","url":"/2022/05/31/staruml破解/","content":"\n# starUML破解步骤\n\n## 1下载starUML\n\n在官网下载：http://staruml.io/download\n\n## 2安装\n\n## 3破解\n\n### 3.1安装nodejs，配置环境\n\n### 3.2、反编译Star UML\n\n使用管理员打开cmd,依次执行下面的命令\n\n```\nnpm install -g asar\ncd C:\\Program Files\\StarUML\\resources  //进入到StarUML的默认安装目录下面\nasar extract app.asar app  //反编译软件\n```\n\n反编译完成后会发现这里有一个app文件夹\n\n![image-20211117141008058](https://presenter.oss-cn-shanghai.aliyuncs.com/image-20211117141008058.png)\n\n打开app\\\\src\\\\engine\\\\license-manager.js文件，把原来的注释掉，然后加上一句setStatus(this,true)\n\n**修改前**\n\n![image-20211117141247967](https://presenter.oss-cn-shanghai.aliyuncs.com/image-20211117141247967.png)\n\n**修改后**\n\n![image-20211117142645167](https://presenter.oss-cn-shanghai.aliyuncs.com/image-20211117142645167.png)\n\n**3.3 再把代码编译成软件就可以了**\n\n```\ncd C:\\Program Files\\StarUML\\resources  //进入到StarUML的默认安装目录下面\nasar pack app app.asar\n```\n","tags":["破解"],"categories":["技术类"]},{"title":"VMware安装openwrt","url":"/2022/05/31/vmware安装openwrt/","content":"\n### 现在默认已经安装VMware\n\n准备好openwrt的镜像文件\n\n[点击下载](https://downloads.openwrt.org/)\n\n下载路径类似下方\n\n![](https://presenter.oss-cn-shanghai.aliyuncs.com/image-20220508224407205.png)\n\n**我在阿里云盘和学习通又备份**\n\n由于vmware不支持img，需要转换\n\n使用StarWindV2VConverter将 img 转换为 vmdk\n\n打开\n\n![](https://presenter.oss-cn-shanghai.aliyuncs.com/image-20220508224522831.png)\n\n选择local file将刚才下载的openwrt选择\n\n![](https://presenter.oss-cn-shanghai.aliyuncs.com/image-20220508224553958.png)\n\n然后还是选择local file，在选择如下\n\n![](https://presenter.oss-cn-shanghai.aliyuncs.com/image-20220508224657061.png)\n\n![](https://presenter.oss-cn-shanghai.aliyuncs.com/image-20220508224712728.png)\n\n然后就可以转换了。\n\n### 在VMware中配置虚拟机\n\n![](https://presenter.oss-cn-shanghai.aliyuncs.com/image-20220508224822164.png)\n\n![](https://presenter.oss-cn-shanghai.aliyuncs.com/image-20220508224835772.png)\n\n![](https://presenter.oss-cn-shanghai.aliyuncs.com/image-20220508224848661.png)\n\n然后后面都直接下一步。但是这里要选择\n\n![](https://presenter.oss-cn-shanghai.aliyuncs.com/image-20220508224944494.png)\n\n然后将转换好的文件选择\n\n后面基本都直接下一步\n\n然后开机之后卡住不动记得按回车\n\n### 接下来就是修改ip\n\n```\n vi /etc/config/network\n```\n\n![](https://presenter.oss-cn-shanghai.aliyuncs.com/image-20220508225253432.png)\n\n接下来可以直接浏览器输入ip就能进入界面了。\n\n中文包的名称\n\nluci-i18n-base-zh-cn\n\n[VMware安装OpenWrt - 姚坤 - 博客园 (cnblogs.com)](https://www.cnblogs.com/bwcxyk/p/13672461.html)\n","tags":["系统","虚拟机"],"categories":["系统类","虚拟机"]},{"title":"VMware虚拟机中配置静态IP的方法","url":"/2022/05/31/vmware虚拟机中配置静态ip的方法/","content":"\n* * *\n\n![img](https://presenter.oss-cn-shanghai.aliyuncs.com/1868057-20200315154409190-813762847.png)VMnet0：用于虚拟桥接网络下的虚拟交换机\n\n桥接网络是指本地物理网卡和虚拟网卡通过VMnet0虚拟交换机进行桥接，物理网卡和虚拟网卡在拓扑图上处于同等地位。\n\nVMnet1：用于虚拟Host-Only网络下的虚拟交换机（仅主机）\n\n在Host-Only模式下，虚拟网络是一个全封闭的网络，它唯一能够访问的就是主机。\n\nVMnet8：用于虚拟NAT网络下的虚拟交换机\n\n在NAT网络中，会用到VMware Network Adepter VMnet8虚拟网卡，主机上的VMware Network Adepter VMnet8虚拟网卡被直接连接到VMnet8虚拟交换机上与虚拟网卡进行通信。\n\nVMware Network Adepter VMnet1：Host用于与Host-Only虚拟网络进行通信的虚拟网卡\n\nVMware Network Adepter VMnet8：Host用于与NAT虚拟网络进行通信的虚拟网卡\n\n**综上所诉：在这三种网络模式中NAT模式是最简单的，基本不需要手动配置IP地址相关参数。桥接模需要配置额外的IP地址。**\n\n#### 1、查看网关，以及网段\n\n【编辑】——〉【虚拟网络编辑器】\n\n![img](https://presenter.oss-cn-shanghai.aliyuncs.com/1868057-20200315154409190-813762847.png)\n\n**我们使用NAT模式，所以选择VMnet8.取消【使用本地DHCP】这个选项不打勾，这是分配动态IP的。**\n\n![img](https://presenter.oss-cn-shanghai.aliyuncs.com/1868057-20200315160047395-767075949.png)\n\n网关IP需要记住，通过这个我们得知\n\n我们的网关192.168.228.2，子网掩码是255.255.255.0。子网IP的192.168.228.0的意思是如果你要往这个网段内添加机器，你的机器ip只能是192.168.228.0~192.168.228.255这个范围内的。其实你会发现192.168.228.2是网关IP了。\n\n一般而言192.168.228.255是广播IP所以不用，192.168.228.0一般是网段IP也不用。也就是说除了0 2 255这三个，其他的数字你可以随便设置。\n\n#### 2、设置虚拟机IP\n\n这里演示的是centos系统\n\n```\nvi /etc/sysconfig/network-scripts/ifcfg-ens33\n```\n\n![img](https://presenter.oss-cn-shanghai.aliyuncs.com/1868057-20200315160108866-52349871.png)\n\n```\ncd /etc/sysconfig/network-scripts/**\nls\n```\n\n![img](https://presenter.oss-cn-shanghai.aliyuncs.com/1868057-20200315160117499-1422848875.png)\n\n**ifcfg-ens33****第一个就是网卡名称**\n\n编辑\n\n输入i后编辑更改成ONBOOT：yes\n\nBOOTPROTO：static\n\n把IP地址、网关、子网掩码、DNS添加上\n\nIPADDR：192.168.228.119\n\nNETMASK：255.255.255.0\n\nGETEWAY：192.168.228.254\n\nDNS1：114.114.114.114\n\n![img](https://presenter.oss-cn-shanghai.aliyuncs.com/1868057-20200315160204742-936507531.png)\n\n同样需要在windows下修改vmware8的ip\n\n![img](https://presenter.oss-cn-shanghai.aliyuncs.com/1868057-20200315160305010-661807387.png)\n\n点击internet协议版本4（TCP/IPv4）\n\n点击输入使用下面的IP地址（S）\n\n输入IP地址：192.168.228.98\n\n子网掩码：255.255.255.0\n\n默认网关：192.168.228.254\n\n首选DNS服务器（P）：114.114.114.114\n\n确定再确定保存\n\n现在就配置完成了，可以尝试ping一下试试能不能ping通\n\n**windows网络和虚拟机的网络ip不要一样，否则会连不上(造成IP冲突)**\n","tags":["虚拟机","网络"],"categories":["虚拟机"]},{"title":"win11的资源管理器卡顿","url":"/2022/05/31/win11的资源管理器卡顿/","content":"\n解决办法：\n\n> 1.打开注册表 win+r ，输入regedit。复制这个路径进去搜索`计算机\\HKEY_LOCAL_MACHINE\\SOFTWARE\\Microsoft\\Windows\\CurrentVersion\\Shell Extensions`\n> \n> 2.在 `Shell Extensions` 上右键新建==项==，命名为 `Blocked`\n> \n> 3.右键 `Blocked` ，新建字符串值，命名为 `{e2bf9676-5f8f-435c-97eb-11607a5bedf7}`\n> \n> 4.最后重启资源管理器\n> \n> \\==注：若想回到win11，删除Blocked即可==\n","tags":["win11"],"categories":["系统类"]},{"title":"YACC概述","url":"/2022/05/31/yacc概述/","content":"\n* * *\n\nyacc(Yet Another Compiler Compiler)，是一个经典的生成语法分析器的工具。yacc生成的编译器主要是用C语言写成的语法解析器（Parser），需要与词法解析器Lex一起使用，再把两部份产生出来的C程序一并编译。\n\n### YACC语法规则\n\nyacc语法包括三部分：定义段、规则段和用户子例程段\n\n```\n...定义段...\n\n%%\n\n...规则段...\n\n%%\n\n...用户子例程段...\n```\n\n**实例：**\n\n一个简单的四则运算：\n\ntest.l\n\n```\n%{\n#include \"test.tab.h\"\nextern int yylval;\n%}\n\n%%\n[0-9]+  { yylval = atoi(yytext); return NUMBER; }\n[ \\t]   ;       /* ignore white space */\n\\n  return 0;   /* logical EOF */\n.   return yytext[0];\n%%\n```\n\ntest.y\n\n```\n%{\n#include <stdio.h>\n%}\n%token NAME NUMBER\n%%\nstatement:  NAME '=' expression\n    |   expression      { printf(\"= %d\\n\", $1); }\n    ;\n\nexpression: expression '+' NUMBER   { $$ = $1 + $3; }\n    |   expression '-' NUMBER   { $$ = $1 - $3; }\n    |   expression '*' NUMBER   { $$ = $1 * $3; }\n    |   expression '/' NUMBER   { $$ = $1 / $3; }\n    |   expression '%' NUMBER   { $$ = $1 % $3; }\n    |   NUMBER          { $$ = $1; }\n    ;\n%%\nint main()\n{\n    yyparse();\n    return 0;\n}\n\nint yyerror(char *s)\n{\n    printf(\"%s/n\",s);\n    return 0;\n}\n```\n\n```\nflex test.l\nbison -d test.y\ngcc -o test test.tab.c test.yy.c -lfl\n```\n\n结果：\n\n![](https://presenter.oss-cn-shanghai.aliyuncs.com/wps1.jpg)\n\n![](https://presenter.oss-cn-shanghai.aliyuncs.com/wps2.jpg)\n\n[全文参考](https://www.cnblogs.com/thl8664/p/6971244.html)\n","tags":["c语言"],"categories":["c语言"]}]